{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Opencast 11 Administration Guide Welcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the system delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture, Opencast provides capture agent software and third party appliances are available. An awesome community provides new features and support. The Software Opencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to several formats and our engage components. The core can be deployed on one (all-in-one deployment) or many (distributed deployment) Linux servers so your Opencast installation can grow with the needs of your university. Release Documentation The Opencast Release Documentation is the official Opencast documentation for each release. It contains: Release Notes Upgrade Changelog Installation Guides Configuration Guides Basic Configuration Database Configuration HTTPS Configuration Workflow Configuration Encoding Configuration more... Module Documentation Atom and RSS Feed AWS S3 Distribution Media Module Metrics (OpenMetrics, Prometheus) Stream Security Stand-alone Video Editor Studio Text Extraction Video Segmentation YouTube Publication more... Version Support","title":"Home"},{"location":"#opencast-11-administration-guide","text":"Welcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the system delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture, Opencast provides capture agent software and third party appliances are available. An awesome community provides new features and support.","title":"Opencast 11 Administration Guide"},{"location":"#the-software","text":"Opencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to several formats and our engage components. The core can be deployed on one (all-in-one deployment) or many (distributed deployment) Linux servers so your Opencast installation can grow with the needs of your university.","title":"The Software"},{"location":"#release-documentation","text":"The Opencast Release Documentation is the official Opencast documentation for each release. It contains: Release Notes Upgrade Changelog Installation Guides Configuration Guides Basic Configuration Database Configuration HTTPS Configuration Workflow Configuration Encoding Configuration more... Module Documentation Atom and RSS Feed AWS S3 Distribution Media Module Metrics (OpenMetrics, Prometheus) Stream Security Stand-alone Video Editor Studio Text Extraction Video Segmentation YouTube Publication more... Version Support","title":"Release Documentation"},{"location":"changelog/","text":"Changelog Opencast 10 Opencast 10.1 Released on July 14th, 2021 [ #2830 ] - Remove Unnecessary Error Logging [ #2829 ] - Handle Ingest with Unavailable Media Package Element [ #2827 ] - Transformer Factory Identification [ #2816 ] - Remove all Java 8 packages in the Java upgrade guide [ #2815 ] - Fix publication of language tagged metadata [ #2813 ] - Don't Ask Developers to Register [ #2812 ] - Fix Possible NullPointerException During Ingest [ #2807 ] - Fix Prepare-AV Target Tag Handling [ #2805 ] - Remove Harvester Configuration [ #2791 ] - Fix Assembly Builds [ #2787 ] - Prevent workflow from failing if we have no logs [ #2776 ] - Fix Workflow Operation Documentation [ #2768 ] - Fix Upgrade Documentation [ #2766 ] - Document Opencast 10 RPM Install [ #2765 ] - Fix Wowza Streaming Misconfiguration [ #2764 ] - Remove Unused Dependency on Series Service [ #2763 ] - Hello World Configuration Example [ #2762 ] - Small additions and improvements in search service (for the upcoming Tobira module) [ #2761 ] - Prevent Users From Modifying ICLA Workflow [ #2748 ] - Simplify Publication Check [ #2747 ] - Fix jakarta.mail Dependency Problem [ #2740 ] - Fix Log Statements [ #2724 ] - Remove Usertracking from Worker [ #2721 ] - Update Admin Interface Dependencies [ #2720 ] - Fixed admin interface tests in certain timezones [ #2706 ] - Add Integration Tests [ #2698 ] - Improved Error Handling Opencast 10.0 Released on June 15th, 2021 [ #2741 ] - Add JVM Metrics to Release Notes [ #2730 ] - Use version variable in poms [ #2713 ] - Update Opencast Studio to 2021-06-11 [ #2708 ] - Add info about renamed enum name of search API to release notes [ #2694 ] - Add JVM metrics to metrics exporter [ #2691 ] - Document Start Task Endpoint [ #2677 ] - Move just the latest snapshot to S3 [ #2673 ] - Don't list docs twice [ #2667 ] - Removed Paella Player Play Button when pausing playback [ #2648 ] - Spelling Fixes [ #2647 ] - Fix broken distributions [ #2645 ] - Update to Elasticsearch 7.10.2 [ #2644 ] - Use millisecond precision in Solr date range queries (instead of secs) [ #2643 ] - Set modified date to deletion date when an event is deleted [ #2625 ] - Add Description to republish-metadata [ #2624 ] - Update ActiveMQ Client [ #2623 ] - Update CXF [ #2619 ] - Autoconfigure Job Dispatching [ #2554 ] - Retract publications before deleting events [ #2387 ] - Update Managed ACLs in Elasticsearch Indices directly [ #2354 ] - Update Themes in Elasticsearch Indices directly [ #2311 ] - Update Comments in ElasticSearch Indices directly [ #2612 ] - Add board members to governance page [ #2611 ] - Bump @types/node from 15.0.2 to 15.3.0 in /modules/lti [ #2610 ] - Bump i18next from 20.2.2 to 20.2.4 in /modules/lti [ #2609 ] - Bump react-bootstrap from 1.5.2 to 1.6.0 in /modules/lti [ #2608 ] - Bump react-select from 4.3.0 to 4.3.1 in /modules/lti [ #2607 ] - Bump @types/react-dom from 17.0.3 to 17.0.5 in /modules/lti [ #2606 ] - Bump bootstrap from 5.0.0 to 5.0.1 in /modules/lti [ #2605 ] - Fix Graphs in Documentation [ #2601 ] - Bump karma from 5.2.3 to 6.3.2 in /modules/admin-ui-frontend [ #2600 ] - Bump grunt-karma from 4.0.0 to 4.0.2 in /modules/admin-ui-frontend [ #2590 ] - New woh: conditional-config [ #2589 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/engage-ui [ #2588 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/engage-theodul-core [ #2587 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/runtime-info-ui [ #2586 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/runtime-info-ui-ng [ #2583 ] - Bump i18next-browser-languagedetector from 6.1.0 to 6.1.1 in /modules/lti [ #2582 ] - Bump bootstrap from 4.6.0 to 5.0.0 in /modules/lti [ #2581 ] - Bump @types/react from 17.0.4 to 17.0.5 in /modules/lti [ #2580 ] - Bump @types/node from 15.0.1 to 15.0.2 in /modules/lti [ #2579 ] - Bump node-sass from 5.0.0 to 6.0.0 in /modules/admin-ui-frontend [ #2578 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/admin-ui-frontend [ #2577 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/engage-paella-player [ #2572 ] - Dont index groups (fixes distributed develop) [ #2558 ] - Add organization ID to the S3 distribution object path [ #2555 ] - Add Java Version to Upgrade Docs [ #2551 ] - Bump @types/react from 17.0.3 to 17.0.4 in /modules/lti [ #2550 ] - Bump react-i18next from 11.8.13 to 11.8.15 in /modules/lti [ #2549 ] - Bump @types/node from 14.14.41 to 15.0.1 in /modules/lti [ #2548 ] - Bump @types/jest from 26.0.22 to 26.0.23 in /modules/lti [ #2547 ] - Bump i18next from 20.2.1 to 20.2.2 in /modules/lti [ #2542 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/engage-theodul-core [ #2541 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/runtime-info-ui [ #2540 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/runtime-info-ui-ng [ #2539 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/engage-ui [ #2538 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/admin-ui-frontend [ #2537 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/engage-paella-player [ #2533 ] - Bump grunt from 1.3.0 to 1.4.0 in /modules/admin-ui-frontend [ #2531 ] - Hand over Elasticsearch Index to Services for Index Rebuild [ #2529 ] - Expose some of the S3 client configuration for assets [ #2524 ] - Merge r/9.x into develop [ #2523 ] - Bump @types/node from 14.14.37 to 14.14.41 in /modules/lti [ #2522 ] - Bump @types/react-select from 4.0.14 to 4.0.15 in /modules/lti [ #2521 ] - Bump react-i18next from 11.8.12 to 11.8.13 in /modules/lti [ #2520 ] - Do not build against Java 8 [ #2518 ] - Update Note About commons-lang/2.x [ #2517 ] - Java Library Update [ #2515 ] - Update Prometheus Libraries [ #2514 ] - Update Database Driver [ #2508 ] - Remove standard check-availability for publication [ #2507 ] - Change Paella Usertracking Default [ #2505 ] - Bump underscore from 1.13.0 to 1.13.1 in /modules/engage-ui [ #2503 ] - Bump chromedriver from 89.0.0 to 90.0.0 in /modules/admin-ui-frontend [ #2495 ] - Bump js-yaml from 4.0.0 to 4.1.0 in /modules/engage-ui [ #2488 ] - Bump underscore from 1.12.1 to 1.13.0 in /modules/engage-ui [ #2487 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/engage-ui [ #2486 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/engage-theodul-core [ #2485 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/runtime-info-ui [ #2484 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/runtime-info-ui-ng [ #2483 ] - Bump i18next from 20.1.0 to 20.2.1 in /modules/lti [ #2482 ] - Bump @types/react-helmet from 6.1.0 to 6.1.1 in /modules/lti [ #2481 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/admin-ui-frontend [ #2480 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/engage-paella-player [ #2471 ] - Remove broken admin-frontend test [ #2469 ] - Bump @types/react-select from 3.0.21 to 4.0.14 in /modules/lti [ #2468 ] - Bump grunt-cli from 1.4.1 to 1.4.2 in /modules/admin-ui-frontend [ #2466 ] - Bump y18n from 4.0.0 to 4.0.1 in /modules/admin-ui-frontend [ #2465 ] - Exclude Dependabot from ICLA Check [ #2463 ] - Bump grunt-contrib-uglify from 5.0.0 to 5.0.1 in /modules/admin-ui-frontend [ #2461 ] - Bump y18n from 3.2.1 to 3.2.2 in /modules/engage-paella-player [ #2459 ] - Remove a duplicate dependency declaration [ #2458 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/engage-ui [ #2457 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/engage-theodul-core [ #2456 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/runtime-info-ui-ng [ #2455 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/runtime-info-ui [ #2454 ] - Bump @types/node from 14.14.35 to 14.14.37 in /modules/lti [ #2453 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/admin-ui-frontend [ #2452 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/engage-paella-player [ #2450 ] - Bump i18next from 19.9.2 to 20.1.0 in /modules/lti [ #2449 ] - Bump react-i18next from 11.8.10 to 11.8.12 in /modules/lti [ #2448 ] - Bump react and react-dom in /modules/lti [ #2447 ] - Bump i18next-browser-languagedetector from 6.0.1 to 6.1.0 in /modules/lti [ #2445 ] - Bump @types/jest from 26.0.21 to 26.0.22 in /modules/lti [ #2444 ] - Bump @types/react-dom from 17.0.2 to 17.0.3 in /modules/lti [ #2441 ] - fixed publish-configure argument in fast-HLS [ #2439 ] - Bump grunt-cli from 1.3.2 to 1.4.1 in /modules/admin-ui-frontend [ #2434 ] - Bump @fortawesome/free-solid-svg-icons from 5.15.2 to 5.15.3 in /modules/lti [ #2433 ] - Bump @fortawesome/fontawesome-svg-core from 1.2.34 to 1.2.35 in /modules/lti [ #2432 ] - Bump query-string from 6.14.1 to 7.0.0 in /modules/lti [ #2431 ] - Bump react-select from 4.2.1 to 4.3.0 in /modules/lti [ #2430 ] - Bump @types/node from 14.14.34 to 14.14.35 in /modules/lti [ #2429 ] - Bump @types/jest from 26.0.20 to 26.0.21 in /modules/lti [ #2426 ] - Bump @types/react-select from 3.0.21 to 4.0.13 in /modules/lti [ #2425 ] - Bump jasmine-core from 3.7.0 to 3.7.1 in /modules/admin-ui-frontend [ #2422 ] - Bump jasmine-core from 3.6.0 to 3.7.0 in /modules/admin-ui-frontend [ #2421 ] - Create Dependabot config file [ #2412 ] - Bump underscore from 1.12.0 to 1.12.1 in /modules/engage-ui [ #2408 ] - Bump react-scripts from 3.4.1 to 4.0.3 in /modules/lti [ #2406 ] - Bump @types/node from 14.14.32 to 14.14.34 in /modules/lti [ #2405 ] - Bump react-i18next from 11.8.9 to 11.8.10 in /modules/lti [ #2404 ] - Bump @types/react-dom from 17.0.1 to 17.0.2 in /modules/lti [ #2403 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/admin-ui-frontend [ #2402 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/runtime-info-ui [ #2401 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/engage-theodul-core [ #2400 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/engage-ui [ #2399 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/runtime-info-ui-ng [ #2398 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/engage-paella-player [ #2396 ] - Fix 9.x to develop merge conflicts [ #2392 ] - [Security] Bump yargs-parser from 5.0.0 to 5.0.1 in /modules/engage-paella-player [ #2389 ] - Bump i18next from 19.8.9 to 19.9.2 in /modules/lti [ #2388 ] - [Security] Bump elliptic from 6.5.3 to 6.5.4 in /modules/lti [ #2385 ] - Bump @types/react from 17.0.2 to 17.0.3 in /modules/lti [ #2384 ] - Bump react and react-dom in /modules/lti [ #2383 ] - Bump @types/node from 14.14.31 to 14.14.32 in /modules/lti [ #2382 ] - Bump react-i18next from 11.0.0 to 11.8.9 in /modules/lti [ #2381 ] - Bump react-select from 4.1.0 to 4.2.1 in /modules/lti [ #2380 ] - Bump chromedriver from 88.0.0 to 89.0.0 in /modules/admin-ui-frontend [ #2379 ] - Bump jquery from 3.5.1 to 3.6.0 in /modules/engage-ui [ #2378 ] - Bump jquery from 3.5.1 to 3.6.0 in /modules/runtime-info-ui-ng [ #2377 ] - Bump markdownlint-cli from 0.27.0 to 0.27.1 in /docs/guides [ #2376 ] - Bump jquery from 3.5.1 to 3.6.0 in /modules/runtime-info-ui [ #2375 ] - Bump markdownlint-cli from 0.26.0 to 0.27.0 in /docs/guides [ #2372 ] - Bump query-string from 6.14.0 to 6.14.1 in /modules/lti [ #2369 ] - Bump react-dom from 16.13.1 to 16.14.0 in /modules/lti [ #2367 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/admin-ui-frontend [ #2366 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/engage-theodul-core [ #2365 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/runtime-info-ui [ #2364 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/engage-paella-player [ #2363 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/engage-ui [ #2362 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/runtime-info-ui-ng [ #2350 ] - Bump react from 16.13.1 to 16.14.0 in /modules/lti [ #2349 ] - Bump @types/jest from 26.0.14 to 26.0.20 in /modules/lti [ #2348 ] - Bump typescript from 3.6.3 to 3.9.9 in /modules/lti [ #2347 ] - Bump @fortawesome/react-fontawesome from 0.1.11 to 0.1.14 in /modules/lti [ #2345 ] - Bump @types/react-dom from 16.9.8 to 17.0.1 in /modules/lti [ #2342 ] - Bump @types/node from 14.14.21 to 14.14.31 in /modules/lti [ #2341 ] - Bump i18next from 17.3.1 to 19.8.9 in /modules/lti [ #2337 ] - Bump url-parse from 1.4.7 to 1.5.1 in /modules/admin-ui-frontend [ #2333 ] - Added doc string to UserEndoint for the admin API [ #2326 ] - Bump @types/react from 16.9.50 to 17.0.2 in /modules/lti [ #2325 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/admin-ui-frontend [ #2324 ] - Bump grunt-contrib-cssmin from 3.0.0 to 4.0.0 in /modules/admin-ui-frontend [ #2323 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/runtime-info-ui-ng [ #2322 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/engage-ui [ #2321 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/runtime-info-ui [ #2320 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/engage-theodul-core [ #2319 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/engage-paella-player [ #2315 ] - Bump query-string from 6.13.1 to 6.14.0 in /modules/lti [ #2307 ] - Don't Store Documentation Redirect in History [ #2303 ] - Bump react-select from 3.1.0 to 4.1.0 in /modules/lti [ #2293 ] - Added the access_policy field to elasticsearch and made it searchable [ #2289 ] - Start Index Rebuild directly [ #2288 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/admin-ui-frontend [ #2287 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/engage-paella-player [ #2286 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/engage-theodul-core [ #2285 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/runtime-info-ui-ng [ #2284 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/runtime-info-ui [ #2283 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/engage-ui [ #2269 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/admin-ui-frontend [ #2268 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/runtime-info-ui [ #2267 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/engage-paella-player [ #2266 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/runtime-info-ui-ng [ #2265 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/engage-ui [ #2264 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/engage-theodul-core [ #2262 ] - Remove dom4j [ #2255 ] - Clean up PR review documentation [ #2252 ] - Bump bootstrap from 4.5.3 to 4.6.0 in /modules/lti [ #2250 ] - Bump chromedriver from 87.0.7 to 88.0.0 in /modules/admin-ui-frontend [ #2240 ] - [Security] Bump socket.io from 2.3.0 to 2.4.1 in /modules/admin-ui-frontend [ #2232 ] - Bump bower from 1.8.10 to 1.8.12 in /modules/admin-ui-frontend [ #2231 ] - Bump chromedriver from 87.0.5 to 87.0.7 in /modules/admin-ui-frontend [ #2230 ] - Don't ask Dependabot to sign ICLA [ #2229 ] - Bump @fortawesome/fontawesome-svg-core from 1.2.30 to 1.2.34 in /modules/lti [ #2227 ] - Bump @types/node from 14.11.2 to 14.14.21 in /modules/lti [ #2226 ] - [Security] Bump semver from 2.3.2 to 5.3.0 in /modules/admin-ui-frontend [ #2225 ] - [Security] Bump handlebars from 4.5.3 to 4.7.6 in /modules/admin-ui-frontend [ #2224 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/admin-ui-frontend [ #2223 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/runtime-info-ui [ #2222 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/engage-theodul-core [ #2221 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/engage-ui [ #2220 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/engage-paella-player [ #2219 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/runtime-info-ui-ng [ #2217 ] - Bump bower from 1.8.8 to 1.8.10 in /modules/admin-ui-frontend [ #2212 ] - Securing Static Files by Default [ #2211 ] - Refactor Index Rebuild [ #2210 ] - Document use of self-signed certificates [ #2209 ] - Check ICLA only on pull request [ #2208 ] - Fix user tracking duplicate session key error [ #2206 ] - Update Development Process [ #2200 ] - Bump chromedriver from 87.0.4 to 87.0.5 in /modules/admin-ui-frontend [ #2195 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/admin-ui-frontend [ #2194 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/runtime-info-ui-ng [ #2193 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/engage-theodul-core [ #2192 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/runtime-info-ui [ #2191 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/engage-ui [ #2190 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/engage-paella-player [ #2189 ] - Bump js-yaml from 3.14.1 to 4.0.0 in /modules/engage-ui [ #2175 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/admin-ui-frontend [ #2174 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/engage-theodul-core [ #2173 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/engage-ui [ #2172 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/runtime-info-ui [ #2171 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/engage-paella-player [ #2170 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/runtime-info-ui-ng [ #2163 ] - Added upload progressbar to the LTI upload tool [ #2159 ] - Bump markdownlint-cli from 0.25.0 to 0.26.0 in /docs/guides [ #2156 ] - Fix Google transcription service indefinite errors generation #1664 #2146 [ #2154 ] - Move governance document from website to docs [ #2151 ] - Fix paths to docker-compose development files [ #2144 ] - [Security] Bump ini from 1.3.5 to 1.3.8 in /modules/lti [ #2141 ] - [Security] Bump ini from 1.3.5 to 1.3.8 in /modules/admin-ui-frontend [ #2140 ] - [Security] Bump ini from 1.3.5 to 1.3.8 in /modules/engage-paella-player [ #2138 ] - Adding Step-by-Step to Config docs and Minor Documentation Changes [ #2126 ] - Bump js-yaml from 3.14.0 to 3.14.1 in /modules/engage-ui [ #2125 ] - Standardization of Tag and Flavor handling [ #2102 ] - Added link to recordings to docs landing page [ #2065 ] - Fixes Maven dependencies in remaining modules [ #2053 ] - Fixes Maven dependencies in modules: common-jpa-impl, common, and cover-image-impl [ #2052 ] - Check for Apereo CLA [ #2027 ] - Bump node-sass from 4.14.1 to 5.0.0 in /modules/admin-ui-frontend [ #2019 ] - Users in the admin ui filter can be reduced via regex now. [ #1959 ] - Bump bootstrap from 4.5.0 to 4.5.3 in /modules/lti [ #1955 ] - Remove Ingest service reference from duplicate event WOH [ #1938 ] - One place for streaming configuration [ #1909 ] - Enable ESLint for Theodul Player [ #1902 ] - Drop broken theodul-plugin-timeline-statistics [ #1877 ] - Extended CoverImageWOH to be able to use extended and series metadata [ #1784 ] - Bump i18next-browser-languagedetector from 3.1.1 to 6.0.1 in /modules/lti [ #1634 ] - LDAP Group Mapping Opencast 9 Opencast 9.7 Released on July 15th, 2021 [ #2793 ] - More HTML validation for AdminUI [ #2790 ] - Fix file permissions of start-opencast [ #2788 ] - Introduce Allinone Profile [ #2778 ] - Cut Marks Attachments [ #2771 ] - Documentation Deployment Conflicts [ #2770 ] - Link Video in Installation Guide [ #2736 ] - Fix processing of fast events [ #2723 ] - Limit Ingest Filename Length [ #2722 ] - Default for Access Control Entry Allow [ #2719 ] - Closing tags for non-void elements in Admin UI [ #2717 ] - Make Series Endpoint Accept Metadata Fields [ #2714 ] - Fix pagination in engage-ui [ #2710 ] - Recognize more input types in WF configuration [ #2678 ] - OAI-PMH Sets [ #2543 ] - Exclude user provider configuration for contributors list provider [ #2535 ] - Prevent Ingests with Illegal Data Opencast 9.6 Released on June 15th, 2021 [ #2734 ] - Prepare AV fix for fast workflow: add textual warning to docs [ #2719 ] - Closing tags for non-void elements in Admin UI [ #2718 ] - Closing tags for consecutive select elements [ #2715 ] - Update pull request template's URL [ #2714 ] - Fix pagination in engage-ui [ #2702 ] - Update Elasticsearch adopter documentation [ #2697 ] - Admin UI theme wizard fixed (fixes #2460) [ #2696 ] - Fix Media Package Series ACL Update [ #2695 ] - Fixes removing a series from an event [ #2692 ] - Admin UI editor segment list item delete button position fixed [ #2676 ] - Event status will not change after removing the workflow [ #2675 ] - Add workflow state for standalone editor [ #2665 ] - Removing references to registering on pkg.opencast.org since this is no longer required [ #2656 ] - Require EDIT role for editing metadata in Admin UI [ #2654 ] - Update examples in publish-configure WOH's docs [ #2653 ] - Meta publication handling by publish-configure WOH [ #2652 ] - change translation for the video file upload from the lti tool [ #2651 ] - fix language for the captions upload, als dfxp is supported now [ #2646 ] - Wording error in release notes regarding Amberscript transcriptions? [ #2630 ] - Update Adopter Registration [ #2629 ] - Add missing new line in Elasticsearch admin docs [ #2626 ] - Update new editor to release 2021-05-20 [ #2620 ] - Replacing remaining Freenode references with Matrix [ #2617 ] - Estimate number of frames if not declared in file [ #2615 ] - Ignore not found exception when automatically archiving to another storage [ #2614 ] - Fix variable always resolving to the default value even when set [ #2604 ] - Fix kernel test with running Opencast [ #2594 ] - Series list provider should use admin UI index [ #2574 ] - Silence detection should create media duration properties [ #2571 ] - Fixed display error for the start date filter in the Admin UI [ #2568 ] - Temporarily Ignore Failing Test [ #2566 ] - Add support for basic authentication with Elasticsearch [ #2563 ] - AmberScript WOH documentation updated [ #2562 ] - Add \"iFrame Resizer\" library to LTI tools [ #2490 ] - Multiple Creators in Series LTI Tool [ #2489 ] - Attachment is not a function LTI error fixed Opencast 9.5 Released on May 17th, 2021 [ #2602 ] - Fix Graphs in Documentation [ #2575 ] - Fixing unchecked directory list() call [ #2565 ] - Organization Fallback for UI Configuration [ #2544 ] - Remove unused org.opencastproject.export.distribution.ExportUi.cfg [ #2536 ] - Tesseract Option Documentation [ #2530 ] - macOS installation update [ #2526 ] - LTI Service Docs [ #2525 ] - Fix checkstyle violations in 11 modules [ #2516 ] - Fix Default Password [ #2512 ] - Add Build Date in User Interface [ #2502 ] - Handle multiple creators in Paella player [ #2501 ] - Handle multiple creators in Media Module [ #2493 ] - Fixed \"No response from service\" for videogrid [ #2489 ] - Attachment is not a function LTI error fixed [ #2435 ] - Added Download Dropdown to Series LTI-Tools [ #2344 ] - Auto-generate OAI-PMH database [ #2103 ] - Only persist users with specific LTI role Opencast 9.4 Released on April 19th, 2021 [ #2526 ] - LTI Service Docs [ #2509 ] - Fix checkstyle violations in 24 modules [ #2506 ] - Fix checkstyle violation in 4 search* modules [ #2500 ] - Make media package handle multi-byte Unicode characters [ #2497 ] - Fixes getting the version information behind a proxy [ #2494 ] - Fix Processing of Unicode Titles [ #2492 ] - Prevent NPE if mediapackage duration is null [ #2479 ] - Fix Memory Leak [ #2478 ] - Fixed test for daylight saving time [ #2475 ] - Enable Elasticsearch in docs [ #2473 ] - Document Hardware Requirements [ #2472 ] - Internal server error in workflow endpoint [ #2470 ] - fixed admin UI - displaying roles correctly when adding a new event to a series [ #2467 ] - Changed the content-type of the adopter POST request. [ #2464 ] - Use a different ServiceType for the Standalone Video Editor on the presentation Node [ #2443 ] - Bump guava from 24.1.1-jre to 30.1.1-jre [ #2437 ] - Updated new editor with new frontend-release 2021-03-24 [ #2427 ] - Revert \"No Matrix Build on Opencast 8\" [ #2424 ] - Fix checkstyle violations in 22 modules [ #2423 ] - Fix checkstyle violations for 3 series-service* modules [ #2420 ] - Fix checkstyle violations in lti and lti-service-impl [ #2419 ] - Fix checkstyle violations in 5 asset manager modules [ #2417 ] - Correct Series ACLs when Recreating the Search Service Index [ #2414 ] - Corrected configuration files in editor documentation [ #2413 ] - Link new features [ #2411 ] - Editor Documentation [ #2391 ] - Perform check-availibility WF check with system user [ #2332 ] - Fix resolution scaling by removing force_original_aspect_ratio [ #2318 ] - Serverless HLS leaves files open [ #2298 ] - Add infos about Wowza streaming configuration changes to upgrade guide [ #2112 ] - Fix admin interface not displaying the correct role [ #2103 ] - Only persist users with specific LTI role [ #1792 ] - Standalone downloads Paella plugin Opencast 9.3 Released on March 15th, 2021 [ #2395 ] - Fix Hardcoded Dependency Version [ #2394 ] - Editor Workflow Description [ #2373 ] - Fix code formatting for aws s3 distribution [ #2368 ] - Improve Email Workflow Operation [ #2361 ] - Handle image extraction from very short videos [ #2355 ] - Document and Test i18next in LTI Tools [ #2353 ] - OAI-PMH Primary Key Length [ #2343 ] - Fix LTI Tool Value Checks [ #2340 ] - Fix checkstyle violations in 5 distribution-* modules [ #2338 ] - Fix checkstyle violations in 5 publications-service-* modules [ #2335 ] - Distinguish Between Documentation and Configuration Checks [ #2331 ] - Simplify Conflict Check [ #2330 ] - Fix Search Capability in Documentation [ #2329 ] - Fixes Solr search failing when titles containing lots of upper case characters [ #2328 ] - Document publish-configure changes from #1663 in upgrade guide [ #2316 ] - Changed PartialImportWOH to ignore smil entries for tracks that don't exist [ #2301 ] - Run Tests Only If Necessary [ #2296 ] - Admin UI now shows a warning if it cannot reach Github [ #2277 ] - Add Event Metrics [ #2263 ] - Fix memory leak / performance in the LTI upload and job overview [ #2260 ] - Stand-Alone Video Editor [ #2248 ] - Selenium Tests for LTI Tools [ #2026 ] - Fix Job Dispatching Test Opencast 9.2 Released on February 15th, 2021 [ GHSA-vpc2-3wcv-qj4w#1 ] - Fix Engage Series Publication and Access [ #2309 ] - HTTPS / Port [ #2300 ] - Add Mermaid to Documentation [ #2299 ] - Fix Total Search Results [ #2295 ] - Limit Incident Text ID Text [ #2292 ] - Fix Adopter Registration Configuration [ #2291 ] - Shorten Adopter Registration Primary Key [ #2290 ] - Fix Exception if GitHub is Unreachable [ #2281 ] - Admin UI says current OC version unsupported when it can't reach GitHub [ #2275 ] - Fixed possible typo in database grants statement [ #2274 ] - Fix checkstyle violations for 7 modules [ #2273 ] - Fix checkstyle violations for 9 modules [ #2270 ] - Fix checkstyle violations for authorization-manager [ #2259 ] - Enforce indentation checkstyle [ #2258 ] - Fix Series Details [ #2257 ] - Add syncronization to the access of the not thread safe xml marshaller. [ #2249 ] - Test documentation only if necessary [ #2247 ] - LTI Tools Mock Data and UI Server [ #2245 ] - Default to server localhost also for multi tenancy [ #2244 ] - Fix NullPointerException when accessing series details [ #2243 ] - Fix Feeds REST Docs [ #2237 ] - Add checkstyle-enforced rule about bracing style (K&R style, braces are mandatory) [ #2216 ] - Add checkstyle-enforced line length limit (with most modules being excluded for now) [ #2203 ] - Improved Development Runtime Dependency Containers [ #2198 ] - List Upload Tool on LTI Landing Page [ #2188 ] - Inspect Media Size [ #2186 ] - No Decoration on Section Links [ #2185 ] - Copy to Clipboard Tooltip [ #2181 ] - Fix LTI Tool Documentation [ #2169 ] - Better Port Randomization [ #2168 ] - Fixes the lti captions upload together with the default ingest workflow #2167 [ #2166 ] - Add Firewall Documentation [ #2134 ] - Addressing (most of) the missing ES config documentation [ #2106 ] - Attempt to detect invalid DB credentials [ #2078 ] - Setting appropriate defaults for AWS S3 dist config, matching the docs [ #2055 ] - Metrics Exporter [ #2042 ] - More efficient retrieval of active jobs [ #1686 ] - Workflow Operation \"CutMarksToSmil\" [ #1017 ] - Securing Static Files Opencast 9.1 Released on December 16th, 2020 [ #2150 ] - Add note about Studio config changes to the 8->9 update guide [ #2133 ] - Update Debian install documentation [ #2160 ] - Fix Ingest by Non-privileged User Opencast 9.0 Released on December 15th, 2020 [ #2133 ] - Update Debian install documentation [ #2110 ] - Error Notification Style [ #2109 ] - Fix apache-httpd doc [ #2108 ] - Fix pagination for LTI series page [ #2107 ] - Use series ACL as default ACL for events in LTI upload tool if available [ #2086 ] - Move from Travis CI to GitHub Actions [ #2084 ] - Add null checker when publishing to streaming service [ #2083 ] - Reverting part of #1291 because this code is actually needed [ #2082 ] - Fix Video Editor (Start Workflow) [ #2077 ] - Fixing NPE exposed in PublishEngageWOH when publishing to AWS S3. [ #2074 ] - #1907 Fix Start Task [ #2056 ] - Add 'if-height-lt-' variable to resolution based encoding [ #2054 ] - Add I18n translation sample file to Paella episodesFromSeries plugin [ #2048 ] - Update lti landing page about series subtool [ #2044 ] - Add S3 presigned URL support [ #2043 ] - Add I18n support for text 'General' in 2 modals [ #2041 ] - Update Node [ #2039 ] - Show language of LTI tool depend on LTI param [ #2038 ] - Load all supported languages in LTI tool [ #2023 ] - Fix Broken Video Editor [ #2022 ] - Long Labels in Segment List [ #2009 ] - Fixing OpenJDK 11 builds by adding missing dependency. [ #2007 ] - Fix Broken Admin Interface Sub-Tabs [ #2006 ] - Update pull request to-do list [ #2005 ] - Synchronize merge conflict check [ #2000 ] - Better documentation for AAI DynamicLoginHandler [ #1982 ] - Update Media Package POST Operation [ #1981 ] - Remove Deprecated Process Executor [ #1970 ] - Update cURL Commands [ #1963 ] - Non-unique-files fix for Videogrid WOH [ #1950 ] - Update documentation for the Docker images [ #1939 ] - Update jakarta.xml.bind-api to 2.3.3 [ #1937 ] - Update adopter-registration-rest.xml to solve #1934 issue [ #1931 ] - Make copy-event-to-series workflow id configurable [ #1836 ] - Ensure User Roles [ #1910 ] - Test admin frontend only once on CI [ #1904 ] - Enforce Maven Dependency Checks on some more modules [ #1901 ] - OSGi Annotations and Configuration [ #1900 ] - Docs: admin-ui moved to admin-ui-frontend [ #1898 ] - Add preencode option to partialImport WOH [ #1897 ] - Bump markdownlint-cli from 0.23.2 to 0.24.0 in /docs/guides [ #1896 ] - Bump @types/react from 16.9.2 to 16.9.50 in /modules/lti [ #1895 ] - Development Runtime Dependency Containers [ #1890 ] - Fix error while searching episode by browser [ #1889 ] - Bump @types/react-select from 3.0.14 to 3.0.21 in /modules/lti [ #1888 ] - Bump bootbox from 5.4.0 to 5.4.1 in /modules/engage-ui [ #1886 ] - Remove Spring's Patched JDOM [ #1884 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/admin-ui-frontend [ #1883 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/engage-theodul-core [ #1882 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/runtime-info-ui [ #1881 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/engage-ui [ #1880 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/engage-paella-player [ #1879 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/runtime-info-ui-ng [ #1876 ] - OSGi Dependency Update [ #1875 ] - Update NodeJS [ #1874 ] - PostgreSQL and auto-generated databases [ #1873 ] - Bump karma from 5.2.2 to 5.2.3 in /modules/admin-ui-frontend [ #1872 ] - Fix Version Check [ #1871 ] - Workflow conditioner to handle floats correctly [ #1869 ] - Extend the documentation concerning multiple audio tracks [ #1868 ] - Bump @types/node from 12.7.5 to 14.11.2 in /modules/lti [ #1867 ] - Update Mock Data [ #1866 ] - Update to AngularJS 1.8 [ #1858 ] - User and role provider for Canvas LMS [ #1857 ] - Refactor Metadata classes (Updated version) [ #1854 ] - Bump @types/jest from 24.0.18 to 26.0.14 in /modules/lti [ #1844 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/admin-ui-frontend [ #1843 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/engage-ui [ #1841 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/runtime-info-ui [ #1840 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/engage-paella-player [ #1839 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/runtime-info-ui-ng [ #1838 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/engage-theodul-core [ #1833 ] - Add Merge Conflict Check [ #1831 ] - Clarify the documentation on when new source tracks can be added [ #1830 ] - Bump karma from 5.2.1 to 5.2.2 in /modules/admin-ui-frontend [ #1829 ] - Bump chromedriver from 85.0.0 to 85.0.1 in /modules/admin-ui-frontend [ #1825 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/admin-ui-frontend [ #1824 ] - Bump karma from 5.1.1 to 5.2.1 in /modules/admin-ui-frontend [ #1823 ] - Update Studio from 2020-06-25 to 2020-09-14 [ #1822 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/runtime-info-ui-ng [ #1819 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-theodul-core [ #1817 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-paella-player [ #1816 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-ui [ #1814 ] - Add a 'defaultValue' to getComponentContextProperty [ #1808 ] - Bump underscore from 1.10.2 to 1.11.0 in /modules/engage-ui [ #1801 ] - Remove Unused Servicewarnings Backend [ #1800 ] - Adopter Registration [ #1796 ] - Minimal message broker impl improvement [ #1795 ] - Login Autocomplete Instructions [ #1794 ] - Icon Cleanup [ #1791 ] - Add with acl option to series api [ #1790 ] - Request Lowercase Usernames in Moodle [ #1789 ] - Remove JDOM From Ingest Service [ #1788 ] - Properly parse boolean values [ #1773 ] - Ingest Service Cleanup [ #1772 ] - Role Prefix in Moodle User Provider [ #1771 ] - OSGi Annotations for Engage UI [ #1764 ] - LTI Context Role Prefix [ #1750 ] - HTTPS with Apache httpd [ #1746 ] - VideoGrid WOH [ #1743 ] - Bump @types/react-helmet from 5.0.16 to 6.1.0 in /modules/lti [ #1728 ] - Bump @types/react-dom from 16.9.0 to 16.9.8 in /modules/lti [ #1727 ] - Bump react-helmet from 5.2.1 to 6.1.0 in /modules/lti [ #1724 ] - Bump react-i18next from 10.13.2 to 11.0.0 in /modules/lti [ #1719 ] - Download button in theodul player [ #1684 ] - Partial Retract WOH [ #1636 ] - Support Serverless HLS [ #1615 ] - Aditive Filter for Api/events endpoint [ #1607 ] - Shibboleth dynamic login handler [ #1580 ] - TagWorkflowOperationHandler now allows wildcards in target flavor [ #1825 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/admin-ui-frontend [ #1824 ] - Bump karma from 5.1.1 to 5.2.1 in /modules/admin-ui-frontend [ #1822 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/runtime-info-ui-ng [ #1819 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-theodul-core [ #1817 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-paella-player [ #1816 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-ui [ #1813 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/runtime-info-ui [ #1811 ] - Bump chromedriver from 84.0.1 to 85.0.0 in /modules/admin-ui-frontend [ #1810 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/admin-ui-frontend [ #1809 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/runtime-info-ui [ #1808 ] - Bump underscore from 1.10.2 to 1.11.0 in /modules/engage-ui [ #1807 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/engage-ui [ #1806 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/engage-theodul-core [ #1803 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/engage-paella-player [ #1802 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/runtime-info-ui-ng [ #1785 ] - Bump grunt from 1.2.1 to 1.3.0 in /modules/admin-ui-frontend [ #1781 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/engage-paella-player [ #1780 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/admin-ui-frontend [ #1777 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/engage-theodul-core [ #1776 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/engage-ui [ #1775 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/runtime-info-ui-ng [ #1774 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/runtime-info-ui [ #1768 ] - Remove Empty Test Classes [ #1766 ] - Fix minor typos [ #1765 ] - Bump karma-jasmine from 4.0.0 to 4.0.1 in /modules/admin-ui-frontend [ #1763 ] - Fix for issue 1280: Notification of Newer Opencast Version in Admin UI [ #1762 ] - Fixed a typo in es.upv.paella.opencast.loader.md [ #1761 ] - Bump karma-jasmine from 3.3.1 to 4.0.0 in /modules/admin-ui-frontend [ #1760 ] - User interface to sort by number of publications [ #1759 ] - Create admin user cleanup [ #1758 ] - Fix events sorted by publication [ #1742 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/engage-paella-player [ #1741 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/admin-ui-frontend [ #1739 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/runtime-info-ui [ #1738 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/engage-theodul-core [ #1737 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/engage-ui [ #1736 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/runtime-info-ui-ng [ #1734 ] - Bump autoprefixer from 9.8.5 to 9.8.6 in /modules/admin-ui-frontend [ #1722 ] - Bump karma from 5.1.0 to 5.1.1 in /modules/admin-ui-frontend [ #1717 ] - Bump karma-coverage from 2.0.2 to 2.0.3 in /modules/admin-ui-frontend [ #1715 ] - Bump jasmine-core from 3.5.0 to 3.6.0 in /modules/admin-ui-frontend [ #1714 ] - Bump chromedriver from 84.0.0 to 84.0.1 in /modules/admin-ui-frontend [ #1713 ] - Fixed double encoding of search-field in engage-ui [ #1710 ] - Added Elasticsearch dependency to developer installation guide [ #1709 ] - Use FontAwesome Icon [ #1708 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/engage-paella-player [ #1707 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/admin-ui-frontend [ #1706 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/engage-ui [ #1705 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/runtime-info-ui-ng [ #1704 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/runtime-info-ui [ #1703 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/lti [ #1702 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/engage-theodul-core [ #1701 ] - Window Selection Style [ #1700 ] - Document bundle:watch [ #1699 ] - Bump chromedriver from 83.0.1 to 84.0.0 in /modules/admin-ui-frontend [ #1698 ] - Bump grunt-contrib-connect from 2.1.0 to 3.0.0 in /modules/admin-ui-frontend [ #1697 ] - Bump grunt-contrib-uglify from 4.0.1 to 5.0.0 in /modules/admin-ui-frontend [ #1696 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/runtime-info-ui [ #1695 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/runtime-info-ui-ng [ #1694 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/lti [ #1693 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/engage-theodul-core [ #1692 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/engage-ui [ #1691 ] - Bump lodash from 4.17.15 to 4.17.19 in /modules/engage-paella-player [ #1689 ] - Bump autoprefixer from 9.8.4 to 9.8.5 in /modules/admin-ui-frontend [ #1687 ] - Bump grunt from 1.2.0 to 1.2.1 in /modules/admin-ui-frontend [ #1683 ] - Bump chromedriver from 83.0.0 to 83.0.1 in /modules/admin-ui-frontend [ #1681 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/engage-paella-player [ #1680 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/admin-ui-frontend [ #1679 ] - Bump grunt from 1.1.0 to 1.2.0 in /modules/admin-ui-frontend [ #1678 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/lti [ #1677 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/engage-ui [ #1676 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/runtime-info-ui [ #1675 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/engage-theodul-core [ #1674 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/runtime-info-ui-ng [ #1671 ] - Python < 3.0 requirement deleted [ #1670 ] - Python < 3.0 requirement deleted [ #1668 ] - Improved ffmpeg profile for extracting the last image of a video in P\u2026 [ #1666 ] - Bump markdownlint-cli from 0.23.1 to 0.23.2 in /docs/guides [ #1665 ] - Bump http-errors from 1.7.3 to 1.8.0 in /modules/engage-paella-player [ #1663 ] - Enable publish-configure to publish to streaming [ #1660 ] - Bump autoprefixer from 9.8.2 to 9.8.4 in /modules/admin-ui-frontend [ #1658 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/engage-paella-player [ #1656 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/admin-ui-frontend [ #1655 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/lti [ #1654 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/engage-theodul-core [ #1653 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/runtime-info-ui [ #1652 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/runtime-info-ui-ng [ #1651 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/engage-ui [ #1650 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/engage-paella-player [ #1649 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/admin-ui-frontend [ #1648 ] - Bump autoprefixer from 9.8.0 to 9.8.2 in /modules/admin-ui-frontend [ #1647 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/engage-ui [ #1646 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/runtime-info-ui [ #1645 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/lti [ #1644 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/engage-theodul-core [ #1643 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/runtime-info-ui-ng [ #1640 ] - Fix Capture Agent API REST Docs [ #1638 ] - Bump karma from 5.0.9 to 5.1.0 in /modules/admin-ui-frontend [ #1637 ] - Fix: Multiple identical workflow IDs prevent Opencast form starting properly [ #1635 ] - Admin UI embedding code [ #1632 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/engage-paella-player [ #1631 ] - Bump eslint from 7.1.0 to 7.2.0 in /modules/runtime-info-ui [ #1630 ] - Fix Series in Media Module [ #1629 ] - LTI User Data [ #1628 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/admin-ui-frontend [ #1627 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/engage-theodul-core [ #1626 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/lti [ #1625 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/engage-ui [ #1624 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/runtime-info-ui-ng [ #1623 ] - Update Node.js [ #1621 ] - [Security] Bump websocket-extensions from 0.1.3 to 0.1.4 in /modules/admin-ui-frontend [ #1619 ] - Bump angular from 1.7.9 to 1.8.0 in /modules/runtime-info-ui [ #1618 ] - Bump angular-route from 1.7.9 to 1.8.0 in /modules/runtime-info-ui [ #1614 ] - Bump karma-jasmine from 3.2.0 to 3.3.1 in /modules/admin-ui-frontend [ #1606 ] - Bump karma-jasmine from 3.1.1 to 3.2.0 in /modules/admin-ui-frontend [ #1605 ] - Update Several JavaScript Libraries [ #1601 ] - Bump js-yaml from 3.13.1 to 3.14.0 in /modules/engage-ui [ #1599 ] - Bump eslint from 6.8.0 to 7.1.0 in /modules/runtime-info-ui [ #1591 ] - Bump karma from 5.0.8 to 5.0.9 in /modules/admin-ui-frontend [ #1590 ] - Bump chromedriver from 81.0.0 to 83.0.0 in /modules/admin-ui-frontend [ #1587 ] - Bump karma from 5.0.5 to 5.0.8 in /modules/admin-ui-frontend [ #1585 ] - Bump http-proxy from 1.18.0 to 1.18.1 in /modules/engage-paella-player [ #1584 ] - Bump autoprefixer from 9.7.6 to 9.8.0 in /modules/admin-ui-frontend [ #1582 ] - Bump markdownlint-cli from 0.23.0 to 0.23.1 in /docs/guides [ #1569 ] - Bump karma from 5.0.4 to 5.0.5 in /modules/admin-ui-frontend [ #1567 ] - Update Python on Travis CI [ #1566 ] - Switching to Paella player by default [ #1563 ] - Bump node-sass from 4.14.0 to 4.14.1 in /modules/admin-ui-frontend [ #1562 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/runtime-info-ui-ng [ #1561 ] - Bump markdownlint-cli from 0.22.0 to 0.23.0 in /docs/guides [ #1560 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/runtime-info-ui [ #1559 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/engage-ui [ #1558 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/lti [ #1555 ] - Bump karma from 5.0.3 to 5.0.4 in /modules/admin-ui-frontend [ #1553 ] - Fix custom roles in admin ui [ #1552 ] - Bump karma from 5.0.2 to 5.0.3 in /modules/admin-ui-frontend [ #1549 ] - Resolution based encoding extension: if-width-or-height-geq- [ #1548 ] - #1541 adding write access parameter to events and series endpoint [ #1547 ] - Download paella source code from github instead of using npm + paella update to 6.4.3 [ #1544 ] - Bump node-sass from 4.13.1 to 4.14.0 in /modules/admin-ui-frontend [ #1536 ] - Typo correction [ #1531 ] - Bump karma from 4.4.1 to 5.0.2 in /modules/admin-ui-frontend [ #1530 ] - REST Docs: Ingest: WF parameters, WFIID deprecated [ #1524 ] - Bump grunt-karma from 3.0.2 to 4.0.0 in /modules/admin-ui-frontend [ #1523 ] - Documentation: OsgiAclServiceRestEndpoint [ #1522 ] - Bump karma-coverage from 2.0.1 to 2.0.2 in /modules/admin-ui-frontend [ #1521 ] - Bump chromedriver from 80.0.1 to 81.0.0 in /modules/admin-ui-frontend [ #1520 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/runtime-info-ui [ #1519 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/runtime-info-ui-ng [ #1518 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/lti [ #1517 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/engage-ui [ #1511 ] - Bump autoprefixer from 9.7.5 to 9.7.6 in /modules/admin-ui-frontend [ #1510 ] - Bump grunt-ng-annotate from 3.0.0 to 4.0.0 in /modules/admin-ui-frontend [ #1499 ] - Add NUT container format [ #1498 ] - Bump underscore from 1.9.2 to 1.10.2 in /modules/engage-ui [ #1497 ] - Documentation: Update asset-delete-woh.md [ #1490 ] - Make encoding profiles support odd widths and heights develop [ #1484 ] - Bump autoprefixer from 9.7.4 to 9.7.5 in /modules/admin-ui-frontend [ #1469 ] - Bump grunt from 1.0.4 to 1.1.0 in /modules/admin-ui-frontend [ #1466 ] - Bump mustache from 4.0.0 to 4.0.1 in /modules/lti [ #1465 ] - [Security] Bump minimist from 1.2.0 to 1.2.5 in /docs/guides [ #1464 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/engage-paella-player [ #1463 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/engage-theodul-core [ #1462 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/engage-ui [ #1461 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/lti [ #1460 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/runtime-info-ui-ng [ #1459 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/runtime-info-ui [ #1456 ] - Adding support for 360 video playback to paella player [ #1455 ] - Add bower_components/ to .gitignore file [ #1444 ] - Make Admin Interface Use npm ci [ #1443 ] - Allow Root In Bower (Again) [ #1440 ] - Update android-mms [ #1439 ] - Editor zooming improved [ #1431 ] - Override all POSIX language variables in Gruntfile.js [ #1430 ] - #1429 rewrite ServiceRegistryJpaImplTest to reduce TravisCI failures [ #1423 ] - Fix REST Documentation [ #1421 ] - Remove compose in favor of encode [ #1420 ] - Override all LANG and LC_ environment variables for stable tests [ #1419 ] - Set fixed LANG for stable tests. Fixes #1418 [ #1417 ] - Bump karma-jasmine from 3.1.0 to 3.1.1 in /modules/admin-ui-frontend [ #1416 ] - Bump chromedriver from 80.0.0 to 80.0.1 in /modules/admin-ui-frontend [ #1415 ] - Bump request from 2.88.0 to 2.88.2 in /modules/admin-ui-frontend [ #1413 ] - Remove Unused Admin Interface Ressources [ #1407 ] - Fix typo in LDAP documentation [ #1406 ] - Add CAS authentication to default XML config [ #1403 ] - Remove Outdated Shibboleth Configuration [ #1402 ] - Quick-links in documentation [ #1401 ] - Fix More Dependencies [ #1398 ] - Bump markdownlint-cli from 0.21.0 to 0.22.0 in /docs/guides [ #1397 ] - Silence Detector Cleanup [ #1396 ] - Image Extraction Without Stream Duration [ #1395 ] - Fix Image Extraction At Position Zero [ #1391 ] - Documentation: Text Extraction Configuration [ #1389 ] - Bump chromedriver from 79.0.2 to 80.0.0 in /modules/admin-ui [ #1388 ] - Return bibliographic start date of event via API [ #1387 ] - Speedup silence detection in case there is a video stream [ #1383 ] - Bump checkstyle from 8.21 to 8.29 [ #1382 ] - Show search results after changing chosen list [ #1381 ] - Remove get acl scheduler endpoint as it's not used [ #1378 ] - Bump chromedriver from 79.0.0 to 79.0.2 in /modules/admin-ui [ #1377 ] - Update to MariaDB Client [ #1376 ] - Create JpaUserReference for LTI user (update to 9.x) [ #1375 ] - Log the proper index name when updating the asset manager index [ #1371 ] - Split AdminUI in Java and JavaScript parts [ #1368 ] - More OSGi Service Annotations [ #1365 ] - Remove Drupal Based Pingback Service [ #1363 ] - Added the adopter registration form for statistics. [ #1361 ] - Bump node-sass from 4.13.0 to 4.13.1 in /modules/admin-ui [ #1360 ] - Bump mustache from 3.2.1 to 4.0.0 in /modules/lti [ #1355 ] - Bump autoprefixer from 9.7.3 to 9.7.4 in /modules/admin-ui [ #1354 ] - Addition of trim segment configuration and new documentation [ #1350 ] - Dependency Tests [ #1349 ] - Drop X-Opencast-Matterhorn-Authorization [ #1348 ] - Add AmberScript Transcription Service [ #1347 ] - LDAP Configuration [ #1346 ] - Adjust documentation regarding Elasticsearch setup [ #1344 ] - Bump karma-jasmine from 3.0.3 to 3.1.0 in /modules/admin-ui [ #1342 ] - Bump karma-jasmine from 3.0.1 to 3.0.3 in /modules/admin-ui [ #1334 ] - Bump karma-firefox-launcher from 1.2.0 to 1.3.0 in /modules/admin-ui [ #1332 ] - Bump karma-jasmine from 2.0.1 to 3.0.1 in /modules/admin-ui [ #1331 ] - Bump underscore from 1.9.1 to 1.9.2 in /modules/engage-ui [ #1330 ] - ESLint For Theodul Connection Plugin [ #1322 ] - Bump markdownlint-cli from 0.20.0 to 0.21.0 in /docs/guides [ #1317 ] - Bump mustache from 3.1.0 to 3.2.1 in /modules/lti [ #1316 ] - [Security] Bump handlebars from 4.2.0 to 4.5.3 in /modules/admin-ui [ #1314 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/engage-ui [ #1313 ] - Bump bootbox from 5.3.4 to 5.4.0 in /modules/engage-ui [ #1312 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/engage-paella-player [ #1311 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/engage-theodul-core [ #1310 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/runtime-info-ui [ #1309 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/admin-ui [ #1308 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/lti [ #1307 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/runtime-info-ui-ng [ #1298 ] - Bump markdownlint-cli from 0.19.0 to 0.20.0 in /docs/guides [ #1295 ] - Change npm install to npm ci [ #1293 ] - Actually update event workflow via API [ #1291 ] - Clean up unused code and ignored tests [ #1289 ] - Improve LTI: add create event and edit event, improve series tool [ #1288 ] - Java 11 Compatibility [ #1287 ] - Add option to remove running workflows, fix restdocs for delete requests [ #1283 ] - Fix hourly statistics export [ #1282 ] - Bump chromedriver from 78.0.1 to 79.0.0 in /modules/admin-ui [ #1277 ] - Fixed streaming distribution remote [ #1275 ] - Fix small typo in External API docs [ #1272 ] - Log progress of solr search reindex [ #1268 ] - Additional logging for ACL parse errors [ #1267 ] - Log the Ids of items being indexed [ #1264 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/engage-theodul-core [ #1263 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/lti [ #1262 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/runtime-info-ui-ng [ #1261 ] - Bump autoprefixer from 9.7.2 to 9.7.3 in /modules/admin-ui [ #1260 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/engage-ui [ #1259 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/admin-ui [ #1258 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/runtime-info-ui [ #1257 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/engage-paella-player [ #1255 ] - Update paella player to 6.3.2 [ #1254 ] - Map internal service host URLs to tenant-specific URLs [ #1252 ] - Make JPA Generated Database Match Script Generated Database [ #1250 ] - Drop Unused Tables [ #1249 ] - Documentation: Metadata fixes [ #1242 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/engage-paella-player [ #1241 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/engage-theodul-core [ #1240 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/admin-ui [ #1239 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/engage-ui [ #1238 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/runtime-info-ui [ #1237 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/runtime-info-ui-ng [ #1236 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/lti [ #1235 ] - Update selected components to use OSGI annotations [ #1234 ] - Add audio and video stream selectors for tracks to ExecuteMany WOH [ #1230 ] - Single image video fix [ #1226 ] - Implement StreamingDistributionService remotely [ #1225 ] - Bump autoprefixer from 9.7.1 to 9.7.2 in /modules/admin-ui [ #1222 ] - Bump paginationjs from 2.1.4 to 2.1.5 in /modules/lti [ #1211 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/admin-ui [ #1210 ] - Bump autoprefixer from 9.7.0 to 9.7.1 in /modules/admin-ui [ #1209 ] - Bump bootbox from 5.3.3 to 5.3.4 in /modules/engage-ui [ #1208 ] - Bump bootbox from 5.3.2 to 5.3.3 in /modules/engage-ui [ #1205 ] - Dropping SysV-Init [ #1198 ] - Introduce ESlint for Theodul Controls Plugin [ #1196 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/runtime-info-ui-ng [ #1195 ] - Bump http-proxy from 1.17.0 to 1.18.0 in /modules/engage-paella-player [ #1194 ] - Bump karma from 4.3.0 to 4.4.1 in /modules/admin-ui [ #1193 ] - Bump node-sass from 4.12.0 to 4.13.0 in /modules/admin-ui [ #1192 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/engage-ui [ #1191 ] - Bump autoprefixer from 9.6.1 to 9.7.0 in /modules/admin-ui [ #1190 ] - Bump chromedriver from 76.0.1 to 78.0.1 in /modules/admin-ui [ #1189 ] - Bump jasmine-core from 3.4.0 to 3.5.0 in /modules/admin-ui [ #1188 ] - Bump seedrandom from 3.0.3 to 3.0.5 in /modules/engage-ui [ #1187 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/engage-paella-player [ #1186 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/lti [ #1184 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/runtime-info-ui [ #1183 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/engage-theodul-core [ #1182 ] - Bump markdownlint-cli from 0.18.0 to 0.19.0 in /docs/guides [ #1179 ] - Make wowza configuration tenant-specific [ #1171 ] - Removed wrong comma in .json example [ #1163 ] - Improve embed code generation of Theodul player to create a fully responsive embed code fragment [ #1161 ] - fix #1158, add config properties to prevent XSS attacks on session co\u2026 [ #1159 ] - Removing old references to org.opencastproject.db.ddl.generate [ #1154 ] - Show users with same mail address and name [ #1150 ] - Workflow: update-previews: Add description [ #1149 ] - Workflow title: Update editor previews [ #1135 ] - Allow to overwrite setenv variables [ #1133 ] - Better JPA Annotation for Scheduler [ #1130 ] - Updated com.fasterxml.jackson from version 2.9.9 to 2.10.0. [ #1128 ] - Load series ACL-list step by step [ #1127 ] - Update accesspolicies.md: fixed grammar issues [ #1121 ] - Remove unnecessary ExceptionUtils.getStackTrace #1119 [ #1120 ] - Updates Service Registry dispatch interval property name and time unit [ #1118 ] - Removes String.format calls in logs [ #1109 ] - Extended statistics export [ #1107 ] - ESLint for Theodul Core [ #1106 ] - Update to ESLint 6.5.0 [ #1105 ] - Use JPA to auto-generate SQL schema [ #1104 ] - Login Response for JavaScript [ #1081 ] - Add modal to edit metadata of multiple events [ #1064 ] - Update to paella player 6.2.2 [ #1054 ] - Fix a bug in paella loader plugin when a track has no tags [ #1046 ] - Load all roles in Admin UI [ #1043 ] - Multiple audio tracks support on paella [ #1032 ] - Sort roles alphabetically in UI [ #1002 ] - S3 S3 compatibility - Endpoint configuration for Amazon S3 alternatives added [ #884 ] - Display global notifications as overlay Opencast 8 Opencast 8.11 Released on April 6th, 2021 [ #2418 ] - Update Test Server Builds [ #2416 ] - Restore \"8.x specific fixes for the markdown generation code\" [ #2415 ] - Revert \"8.x specific fixes for the markdown generation code\" [ #2409 ] - 8.x specific fixes for the markdown generation code [ #2310 ] - Gracefully handle missing Shibboleth User References [ #2261 ] - Handle broken encoding profiles without killing the ComposerService [ #2253 ] - Configure POST api/groups access correctly [ #2239 ] - Fix Typo in Branding Properties [ #2214 ] - Validate Ingested DublinCore Catalogs [ #2177 ] - Fix Sorting Series by Creators [ #2071 ] - Properly configure AWS S3 distribution on startup by default Opencast 8.10 Released on December 23rd, 2020 [ #2160 ] - Fix Ingest by Non-privileged User [ #2049 ] - Endtime of segments fixed in the editor Opencast 8.9 Released on December 8th, 2020 [ #2099 ] - Support faster playback rates in paella video player [ #2087 ] - Move from Travis CI to GitHub Actions (8.x) [ #2075 ] - Reduce IO Load When Starting a Workflow [ #2068 ] - JDK Support proposal (2020-11-11) documentation for 8.x [ #1988 ] - #1987 Admin UI event start filter datepicker timezone patch Opencast 8.8 Released on November 19th, 2020 [ #2075 ] - Reduce IO Load When Starting a Workflow [ #2072 ] - Update player.matomo.tracking.md [ #2067 ] - Solves #2034 (Execute-once subprocess issue) [ #2051 ] - Limit OpenMP Threads to Prevent Tesseract Blocking the System [ #2040 ] - Drop user login log level [ #2020 ] - Set the RFC 822 \"Date\" header field when sending an email (r/8.x) [ #2008 ] - Speed up preview encoding [ #1988 ] - #1987 Admin UI event start filter datepicker timezone patch [ #1954 ] - Fix Paella Player assuming track is audio-only when it's actually video and audio [ #1894 ] - Remove references to removed modules [ #1891 ] - Creating a new series doesn't send user collections anymore [ #1887 ] - Remove Dead OpenID Module Opencast 8.7 Released on September 27th, 2020 [ #1851 ] - Fix conflict checking for scheduled events in multitenant systems [ #1848 ] - Fix capture agent dropdown menus [ #1837 ] - Adding bugfix from #1668 to 8.x [ #1828 ] - Recommend https [ #1827 ] - Clean up basic configuration [ #1812 ] - Missing ACL after asset upload [ #1786 ] - Removed servicewarnings endpoint [ #1770 ] - Paella player should only list http(s) URLs in the download plugin [ #1756 ] - Change markdown CI checks to bash [ #1753 ] - Admin interface event API logs on user error [ #1735 ] - Added reloading of filters in users page Opencast 8.6 Released on August 5th, 2020 [ #1744 ] - Fix for issue 1616: User keep write permission on ACL template selection [ #1720 ] - Corrected title of user delete button [ #1711 ] - Fixes issue #1642: Drop-down menu does not disappear [ #1662 ] - Update Studio from 2020-05-20 to 2020-06-25 [ #1639 ] - Don't raise a NPE when the workflow creator was deleted Opencast 8.5 Released on June 15th, 2020 [ #1633 ] - Using ConcurrentHashMap for synchronizing LTI user login [ #1622 ] - Fix LTI Without Persistence [ #1620 ] - Fix Formatting [ #1612 ] - Use normal file appender instead of RandomAccessFile for logging [ #1611 ] - Fix LDAP Debug Logging [ #1593 ] - Update paella to 6.2.7 Opencast 8.4 Released on May 22nd, 2020 [ #1593 ] - Update player Paella to 6.2.7 [ #1592 ] - Update Studio version to 2020-05-20 [ #1581 ] - Update Studio to 2020-05-14 [ #1578 ] - Add cutting to the default Studio workflow [ #1570 ] - Partial import muxing fix [ #1568 ] - Fix URL to Wowza documentation [ #1565 ] - Avoids normal user to delete series with events when option series.hasEvents.delete.allow is set to false [ #1550 ] - Be more lenient towards service failures [ #1543 ] - 403 Logout Option [ #1542 ] - Allow Admin UI Users to Access / [ #1540 ] - Studio workflow should archive prepared versioned of videos [ #1535 ] - Opencast server node name should be optional [ #1534 ] - Admin UI systems filters should be accessible by the corresponding roles [ #1532 ] - Fix race condition when creating or updating user references from LTI [ #1516 ] - Studio encoding profile performance improved [ #1515 ] - Studio-upload workflow should generate search preview images [ #1509 ] - Allow anonymous access to static Studio files [ #1508 ] - Fixed a typo in the Theodul Config [ #1500 ] - Adding documentation on how to use the multiserver docker-compose [ #1496 ] - Fix Adaptive Encoding [ #1492 ] - Update Studio (for bug fixes) and add docs for Studio [ #1488 ] - Make encoding profiles support odd widths/heights [ #1479 ] - Fix Theodul quality selection Opencast 8.3 Released on March 26th, 2020 [ #1492 ] - Update Studio (for bugfixes) and add docs for Studio [ #1489 ] - Workaround early lti session timeout [ #1488 ] - Make encoding profiles support odd widths/heights [ #1487 ] - Fix Studio login redirect [ #1485 ] - Custom Roles for LTI users [ #1483 ] - Read published files direct from filesystem if possible (completed) [ #1482 ] - Create JpaUserReference for LTI user (backport) [ #1480 ] - Preserve ACL On Workflow Errors [ #1479 ] - Fix Theodul quality selection [ #1478 ] - Studio upload optimized workflows [ #1476 ] - Fix Studio Redirect discarding GET Parameters [ #1475 ] - Fix Theodul Matomo plugin after configuration data structure change [ #1473 ] - Move OC Studio configuration to etc/ui-config and update Studio [ #1468 ] - Studio in admin-presentation Opencast 8.2 Released on March 14th, 2020 [ #1458 ] - Fix Image Extraction At Position Zero [ #1457 ] - Image Extraction Without Stream Duration [ #1454 ] - Fix HLS on iOS [ #1448 ] - Adding link to community workflow repository to the markdown docs [ #1446 ] - Disable 2 more instances of jmxremote param, #1445 [ #1441 ] - Remove databasemigration for Opencast 7 [ #1436 ] - integrate opencast studio [ #1433 ] - Series ACLs not propagating to individual events [ #1414 ] - Gracefully crash if there is no password stored [ #1409 ] - Asset Upload Title [ #1408 ] - Simplify Asset Upload Workflow [ #1399 ] - Gracefully Fail Hash Verification [ #1364 ] - Temination state service test [ #1359 ] - Fix workflow dropdown in start task [ #1327 ] - Video Segemntation On Short Videos [ #1301 ] - Fix event delete with existing publications [ #1248 ] - Fix conflict detection for non-admin users and for multiple events Opencast 8.1 Released on January 29, 2020 [ #1341 ] - Spring Framework Dependency Specification [ #1340 ] - LDAP User Directory Dependencies [ #1339 ] - Add Missing Karaf Features [ #1338 ] - Sakai User Directory Dependencies [ #1328 ] - AngularJS Components 1.7.9 [ #1326 ] - Fix Image Extraction From Short Videos [ #1321 ] - Fix URL Parameters in Theodul Player [ #1300 ] - Allow Root In Bower [ #1299 ] - Fix AWS WOH OSGI dependencies [ #1266 ] - Allow capture agent users to read properties of series Fixed Security Issues CVE-2020-5231 \u2013 Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 \u2013 Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 \u2013 Hard-Coded Key Used For Remember-me Token CVE-2020-5230 \u2013 Unsafe Identifiers CVE-2020-5229 \u2013 Replace MD5 with bcrypt for password hashing CVE-2020-5228 \u2013 Public Access Via OAI-PMH Opencast 8.0 Released on December 17, 2019 [ #1292 ] - Release notes for Opencast 8.0 [ #1290 ] - Fix for MP3 with embedded image [ #1286 ] - Fix Role For Assets Quick Access [ #1278 ] - Editor Thumbnail Default [ #1274 ] - Update Security Configuration [ #1269 ] - Fix processing of odd video width [ #1256 ] - Remove publishedhours default statistics provider [ #1245 ] - AngularJS 1.7.9 Security Update [ #1216 ] - Simplify Editor URL Signing [ #1212 ] - Update paella player to 6.2.4 [ #1207 ] - Enable Browser Tests [ #1206 ] - Temporarily Ignore Failing Test [ #1203 ] - Warn about using H2 [ #1202 ] - Overhaul RPM Installation Guide [ #1199 ] - Fix Crowdin Upload [ #1197 ] - Fix Theodul Embed Configuration [ #1167 ] - Migrate IBM Watson transcription to shared persistence [ #1153 ] - Keep generated SMIL for partial tracks [ #1151 ] - (#1008): Better crop detect test #1085 [ #1146 ] - Remove unnecessary global package-lock.json [ #1141 ] - Consider file extension of uploaded asset [ #1134 ] - Do not use stack-overflow logo [ #1131 ] - Issue1123 TEMP FIX for Paella Player Build error [ #1110 ] - Build failed on captions-impl tests for non english OS [ #1108 ] - Fix external API versioning for EventsEndpoint [ #1103 ] - Fix PostreSQL Support [ #1102 ] - Clean-up Fast Testing Workflow [ #1101 ] - Filter jobs by transcription service provider ID [ #1073 ] - close esc function for new event and new series modals [ #1067 ] - Publication Button show fix [ #1100 ] - Player Scroll/Zoom Overlay [ #1098 ] - Fix displaying tracks with no tags in player [ #1095 ] - Add a new optional date_expected column to the transcription job table [ #1094 ] - Smarter etc/ hints in documentation [ #1093 ] - Provide access to file contents in the WFR [ #1091 ] - Remove inaccurate url-pattern ${element_uri} [ #1090 ] - Elasticsearch access_policy field increased in size [ #1086 ] - Fix CI Builds (Crop Tests) [ #1084 ] - Fix Player ID Parameter Parsing [ #1082 ] - Docs readme extended. [ #1079 ] - Remove Workflow Operations from Worker [ #1078 ] - Fix database docs [ #1075 ] - Remove State Mapping \u201cImporting\u201d [ #1074 ] - Navbar icons toggle [ #1071 ] - Fix Pull Request Template [ #1070 ] - Temporarily Ignore Service Registry Test [ #1066 ] - Major developer docs update [ #1065 ] - Remove the RoleProvider.getRoles() method [ #1063 ] - Only events with write access [ #1062 ] - start on used port [ #1059 ] - Hide Column Stop By Default [ #1058 ] - Custom LTI Series Tool Styles [ #1057 ] - Update ESLint [ #1055 ] - Move to GitHub Issues [ #1053 ] - Update mustache [ #1052 ] - Update bootbox [ #1050 ] - && MH-13425 - Feeds-Tab / adds a new tab in series properties. [ #1048 ] - Add an optional build step to clean easily clean the frontend caches [ #1047 ] - ServiceRegistry not updating database correctly when dispatching jobs [ #1044 ] - clean node, node_modules and bower_components folders [ #1042 ] - Update Admin Interface JS Test Libraries [ #1041 ] - Update ESLint [ #1039 ] - paella can filter which tracks to load depending on the user's device [ #1037 ] - Update paella player to 6.2.0 [ #1034 ] - Update Translation Key for Published Hours [ #1033 ] - Direct link to assets tab [ #1030 ] - Configure max open files [ #1029 ] - Update admin interface JS libraries [ #1028 ] - Update Engage JS Libraries [ #1027 ] - Update Markdownlint [ #1023 ] - fix invisible icon for specific zoom level [ #1022 ] - Automatic publication of streaming URLs [ #1021 ] - Moving mediapackages needs to handle missing version information [ #1020 ] - Logging [ #1016 ] - Update Deprecated EqualsUtil.hash(\u2026) [ #1015 ] - IDEA Settings [ #1014 ] - Don't start opencast on a used port [ #1009 ] - Shell information for developer distribution [ #1008 ] - Crop service [ #1007 ] - Update several JS libraries [ #1006 ] - Improve metadata handling in backend [ #1005 ] - Fix dropdown menus [ #1004 ] - eslint 6.1.0 [ #1003 ] - Update karma [ #1001 ] - Access org properties from publish-configure WOH [ #998 ] - Concat Operation Graphics [ #997 ] - Update Development Process Documentation [ #996 ] - Update commons-text [ #995 ] - Composer Should Not Overwrite Files [ #994 ] - Added name of the configuration file where properties of login details are modified [ #992 ] - switch to compatible file type filter definitions [ #990 ] - Upgrade chromedriver [ #985 ] - Update grunt-concurrent [ #983 ] - Update ESLint [ #978 ] - Mh 13617 Duplicate encoding profiles for PrepareAV/SelectStreams [ #973 ] - Don't consider raw fields updated [ #972 ] - Improve setting values from dublin core catalog [ #971 ] - NOJIRA: Add ALTER to necessary MySQL permissions [ #970 ] - Fix hello-world modules [ #968 ] - Resolution Based, Conditional Encoding [ #967 ] - Introduce general CatalogUIAdapter [ #966 ] - Update frontend-maven-plugin [ #965 ] - Update Logger [ #964 ] - Update Checkstyle [ #963 ] - Update Paella Build Dependencies [ #962 ] - Update Chromedriver [ #961 ] - Update autoprefixer to 9.6.0 [ #960 ] - Update Markdownlint [ #959 ] - Update Admin Interface Test Framework [ #957 ] - Clean-up Static Resource Servlet [ #956 ] - Re-introduce Prepare AV [ #954 ] - Fix bundle versions [ #952 ] - Cleanup workflows [ #951 ] - More Dependency Checks\u2026 [ #950 ] - Tag elements retrieved from asset manager [ #949 ] - Termination State Service to integrate with AWS AutoScaling Lifecycle [ #948 ] - add health-check endpoint [ #945 ] - -publication [ #943 ] - color \"blue\" for links in the admin ui [ #942 ] - Theodul player ui config [ #941 ] - More dependency fixes [ #937 ] - Workflow Condition Parser Location [ #936 ] - Drop distribution-service-streaming [ #935 ] - Drop Distribution \u201cadminworker\u201d [ #934 ] - Drop Migration Distribution [ #931 ] - Assembly Configuration [ #929 ] - Check dependencies at build time [ #928 ] - Admin Interface Browser Tests [ #927 ] - Metadata Transfer Operation [ #926 ] - Remove unused code [ #925 ] - Media Module Dependency Management [ #924 ] - Jettison Dependency Management [ #923 ] - Introduce ESLint to Media Module [ #922 ] - Support for exclusion pattern for URL signing [ #921 ] - Officially support URL signing keys that handle multiple URL prefixes [ #920 ] - Streaming Module Cleanup [ #919 ] - Fix dependencies for statistics- and workflow-condition-parser [ #918 ] - Remove module 'dataloader' [ #917 ] - Remove obviously unused classes [ #908 ] - Admin interface dependency update [ #906 ] - Media Module Configuration [ #899 ] - Fix Login Page [ #898 ] - Fix Spelling of Flavor [ #895 ] - Update Tesseract Code [ #894 ] - NOJIRA Speed up statistics api tests [ #893 ] - Dependency Fixes [ #892 ] - Drop Custom Logger Configuration [ #891 ] - Unnecessary LineReader [ #890 ] - NOJIRA: Remove statistics provider configs [ #889 ] - Limit accepted file types when uploading assets [ #887 ] - Collect and visualize published hours of video [ #885 ] - Rework workflow conditions, add string data type [ #883 ] - Remove inclusion of non-existent scripts in Admin UI [ #882 ] - Navigation of statistics broken [ #881 ] - JavaScript Dependency Management [ #880 ] - Improve icons and wording in video editor [ #879 ] - statistics csv export [ #876 ] - Add Hourly Data Resolution For Statistics [ #874 ] - Role support for workflows [ #872 ] - Remove pseudo-mechanism for workflow definition registration [ #869 ] - Remove unused method WorkflowDefinition.isPublished [ #865 ] - Empty node name causes exception [ #864 ] - Multitenancy support for workflows [ #863 ] - Improve URL signing performance [ #862 ] - add single step event deletion [ #861 ] - Add option to configure state mappings for workflows [ #860 ] - Remove unused fields from search index [ #858 ] - Improve navigation in video editor when zoom is active [ #857 ] - resume on past table page when leaving video editor [ #854 ] - move ingest-download Operation to worker [ #851 ] - Highlight main table rows on hover [ #850 ] - Add node name to host registration as a UI searchable alternative to hostname [ #849 ] - Upgrade Admin Interface Libraries (Including AngularJS) [ #848 ] - Remove method canLogin from interface User [ #847 ] - Fix License and Documentation Links [ #846 ] - Automatically Launch Logs for dist-develop [ #842 ] - Harmonizing the column names [ #841 ] - Expand log messages to add error detail [ #834 ] - Introduce basic statistics visualization capabilities [ #831 ] - userprovider for the d2l brightspace LMS [ #826 ] - url query string incorrect [ #825 ] - Remove leftover service [ #824 ] - Use Username In Workflows [ #823 ] - Automatic caption using Google speech to text api [ #816 ] - Change the default composer job load from 0.8 to 1.5 [ #784 ] - Admin UI new event media upload progress bar [ #757 ] - Timelinepreviews process first one only Opencast 7 Opencast 7.9 Released on December 8, 2020 [ GHSA-44cw-p2hm-gpf6 ] Security: Disabled Hostname Verification [ #1964 ] - Docs: When the sidebar is hidden, the navigation links are disabled now [ #1922 ] - Remove Spring snapshot repository from main pom Opencast 7.8 Released on August 17, 2020 [ #1667 ] - Fix managed ACL filter in API [ #1659 ] - Updating Guava version [ #1657 ] - Fixed the video outline in the Theodul Player [ #1641 ] - Capture Agent Authentication Method [ #1595 ] - Gracefully Handle Missing Timeline Preview [ #1594 ] - Fix Calculation of Aspect Ratio [ #1589 ] - Engage: Theodul: Audio: Refer to correct items Opencast 7.7 Released on April 27, 2020 [ #1539 ] - Fix Karma Safari test in mac OS [ #1474 ] - Add comment to document remember me keys [ #1442 ] - Fix Remember-Me Authentication [ #1427 ] - 1281: Ignoring test which randomly fails in CI testing [ #1426 ] - Autodetect browsers for Admin UI tests, fix phantomJS OpenSSL issue [ #1425 ] - Don't duplicate publications [ #1380 ] - In fast, don't cleanup ACLs (see other workflows) [ #1379 ] - Use active, not episode ACL in scheduler service Opencast 7.6 Released on January 29, 2020 CVE-2020-5231 - Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 - Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 - Hard-Coded Key Used For Remember-me Token CVE-2020-5230 - Unsafe Identifiers CVE-2020-5228 - Public Access Via OAI-PMH [ #1358 ] - Switch To HTTPS Maven Repository [ #1353 ] - Handle empty fields from REST docs in EventHttpServletRequest [ #1352 ] - Remove unsafe option in ffmpeg command for SMIL processing [ #1343 ] - Fixes Admin-UI Presenter's column [ #1333 ] - Switch to mvn.opencast.org [ #1329 ] - Remove Spring Request Logger Configuration [ #1325 ] - Secure FPS For SMIL Processing [ #1318 ] - Remove Custom Plugin Repositories [ #1315 ] - Bump spring-security-oauth from 2.3.6.RELEASE to 2.3.7.RELEASE [ #1276 ] - Don't add the internal publication of the original event twice [ #1271 ] - Wrong encoding in video editor zoom box [ #1270 ] - S3 Distribution Fails [ #1265 ] - Some error operations referencing the wrong error-handler. [ #1246 ] - Remove default storage_id setting from asset Manager Opencast 7.5 Released on December 10, 2019 [ #1233 ] - Change bibliographicdate if technicaldate is changed. [ #1220 ] - Make Thumbnail Optional [ #1218 ] - [Documentation] Added path hint to upgrade.md [ #1170 ] - MH-9753: Prepare AV WOH can throw a NPE [ #1164 ] - CentOS basic installation guide rewording [ #1148 ] - VideoEditorServiceImpl: Fixed the file extension duplication with removeExtention from FilenameUtils. [ #1122 ] - fixes #1069 workflow tab shows scheduling info instead of workflows Opencast 7.4 Released on October 02, 2019 [ MH-13517 ][ #1092 ] - Set an absolute limit on Solr query size [ MH-13476 ][ #1088 ] - Filter capture agent roles for ACLs [ #1087 ] - Issue 1068, Stop job dispatcher before unregistering hosts, junit MH-13675 [ MH-13706 ][ #1072 ] - fix the date cell of the events overview table in the admin UI [ #1056 ] - NOISSUE: CAS security example is very out of date Opencast 7.3 Released on September 19, 2019 [ MH-13716 ][ #1061 ] - Update xmlsec [ MH-13715 ][ #1060 ] - Check Markdown for newline character [ #1056 ] - CAS security example is very out of date [ MH-13707 ][ #1051 ] - Watermark missing [ MH-13706 ][ #1049 ] - Show bibliographic event dates on the events overview page [ MH-13701 ][ #1040 ] - Interpret source-audio-name correctly for composite operation [ MH-13699 ][ #1038 ] - Fix Workflow Index Rebuild ACL Handling [ MH-13697 ][ #1036 ] - Workflow Index Rebuild Memory [ MH-13684 ][ #1024 ] - Do not include auth token in republished URLs [ MH-12533 ][ #714 ] - Re-introduce ability to avoid data loss during ingest Opencast 7.2 Released on August 02, 2019 [ MH-13662 ][ #1000 ] - Update LTI Information Opencast 7.1 Released on July 09, 2019 [ MH-13656 ][ #993 ] - Fix Scheduler Index Rebuild [ MH-13655 ][ #991 ] - Scheduler Message Logging [ MH-13653 ][ #989 ] - Fully Migrate Scheduled Events [ MH-13652 ][ #988 ] - Don't save unchanged values in dropdown menus [ MH-13651 ][ #987 ] - Don't call submit of SingleSelect twice [ MH-13650 ][ #986 ] - Scheduler Migration Performance [ MH-13646 ][ #982 ] - Delete scheduled events [ MH-13645 ][ #981 ] - Only send delete comments message if we delete something [ MH-13642 ][ #977 ] - Fix Index Update Logging [ MH-13639 ][ #976 ] - Admin interface does not handle missing metadata well [ MH-13638 ][ #975 ] - Update NPM [ MH-13619 ][ #958 ] - Fix Logging in Video Segmenter [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13610 ][ #947 ] - LDAP User Directory Fixes Opencast 7.0 Released on June 13, 2019 [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13602 ][ #940 ] - Update jackson-databind to fix CVE-2019-12086 [ MH-13599 ][ #938 ] - Select well supported mime type by default [ MH-13593 ][ #933 ] - Incorrect default waveform colors [ MH-13569 ][ #913 ] - Change of PlayerRedirection variable from to #{id} [ MH-13568 ][ #911 ] - Catch exception from overlapping RRule and return bad request [ MH-13566 ][ #910 ] - Accept duration as either string or number in scheduling JSON [ MH-13385 ][ #909 ] - Add release note about URL signing configuration changes [ MH-13375 ][ #907 ] - Handle empty-range errors correctly [ MH-13563 ][ #905 ] - Duplicated Variables in Media Module [ MH-13562 ][ #904 ] - ReferenceError in Media Module [ MH-13561 ][ #903 ] - Access to UI Configuration [ MH-13558 ][ #900 ] - Paella Track Filter [ MH-13554 ][ #897 ] - Theodul Zoom [ MH-13553 ][ #896 ] - Fix Paella Track Selection [ MH-13538 ][ #878 ] - Update jQuery [ MH-13531 ][ #873 ] - upgrade spring-security and jasig cas library to fix issue\u2026 [ MH-13529 ][ #871 ] - Don't warn about expected behavior [ MH-13528 ][ #870 ] - Non-Interactive FFmpeg [ MH-13525 ][ #867 ] - Update Admin Interface Libraries [ MH-13519 ][ #855 ] - Migrate mappings to Elastic Search 5.x [ MH-13505 ][ #844 ] - Update Admin Interface JavaScript Libraries [ MH-13504 ][ #843 ] - JavaScript Library Update [ MH-12047 ][ #832 ] - MH-13380 MH-13490 MH-13489 Add missing indexes [ MH-13477 ][ #819 ] - Faster Asset Manager Property Access [ MH-13465 ][ #807 ] - Prevent NullPointerException [ MH-13389 ][ #815 ] - More informative job load logging [ MH-13472 ][ #813 ] - Permissions for /play/ missing [ MH-13471 ][ #812 ] - Shibboleth SSO plugin to add roles for users on OC according to their EDUPERSONAFFILIATION. eg: \"ROLE_AAI_USER_AFFILIATION_student\" for \"student\" [ MH-13469 ][ #811 ] - Drop LastHeardFrom On Scheduler Messages [ MH-13468 ][ #810 ] - Capture Agent Registration Exception [ MH-13466 ][ #809 ] - Prevent Capture Agents From Modifying Metadata [ MH-13467 ][ #808 ] - opencast-security-cas feature can not be started [ #806 ] - extend the ingest-download-woh [ MH-12643 ][ #804 ] - Allow workspace to read from asset manager [ MH-13462 ][ #802 ] - Prevent Being Started By Root [ MH-13461 ][ #801 ] - Dependency Fixes & Dependency Checks [ MH-13460 ][ #800 ] - Update JavaScript Dependencies [ MH-13459 ][ #799 ] - Make Paella Use UI Configuration Service [ MH-13458 ][ #798 ] - Live Scheduler Dependencies [ MH-13457 ][ #797 ] - Dependency Update [ MH-13456 ][ #796 ] - Move Log Workflow Operation To Admin [ MH-13455 ][ #795 ] - Opencast Plug-in Features [ MH-13454 ][ #794 ] - Drop Unused Configuration Option Maps [ MH-13453 ][ #793 ] - Add more log output to WOH select-streams [ MH-13452 ][ #792 ] - Show creators correctly in delete modals [ MH-13450 ][ #790 ] - Remove unused class org.opencastproject.adminui.api.SortType [ MH-13448 ][ #789 ] - Make translation of creators consistent [ MH-13446 ][ #788 ] - Removed unfinished feature \"ACL transitions\" [ MH-13445 ][ #787 ] - Update Checkstyle [ MH-13443 ][ #783 ] - Don't use deprecated $http.success and $http.error methods [ MH-13439 ][ #782 ] - Dynamic Player Redirect [ MH-13438 ][ #781 ] - Simplify Streaming Format Check [ #780 ] - ACL documentation pointed to wrong config file [ MH-13436 ][ #778 ] - Improve error message for out of bounds image extraction [ MH-13421 ][ #776 ] - Remove unused workflowservice exceptions [ MH-13434 ][ #775 ] - Opencast Common Clean-up [ MH-13381 ][ #771 ] - Use Organization Identifier In Roles [ MH-13432 ][ #770 ] - Remove unused modals \"Job Details\" and \"Server Details\" [ MH-13431 ][ #769 ] - Remove unfinished feature \"Bulk Messaging\" [ MH-13430 ][ #768 ] - Fix Opencast Offline Builds [ MH-13428 ][ #766 ] - Remove unused library angular-scenario from admin ui tests [ MH-13426 ][ #765 ] - Remove unused Protractor end-to-end tests [ MH-13427 ][ #764 ] - Remove unused test resources [ MH-13381 ][ #763 ] - Use Organization Identifier in Workflows [ MH-13424 ][ #762 ] - Elasticsearch 5.6.15 [ MH-13423 ][ #761 ] - Possible NPE if debugging is enabled [ MH-13422 ][ #760 ] - Switch to markdownlint-cli [ MH-13420 ][ #759 ] - ngRepeat does not allow duplicates [ MH-13417 ][ #758 ] - UI Configuration Service Tests [ MH-13414 ][ #756 ] - extended metadata multivalue fields are not handled properly [ MH-13413 ][ #755 ] - UI Configuration Service Improvements [ MH-13412 ][ #754 ] - Deprecate PathSupport.concat(\u2026) [ MH-13411 ][ #753 ] - Fix UI Config Service Dependencies [ MH-13410 ][ #752 ] - Fix Broken Build Number [ MH-13397 ][ #751 ] - Remove unfinished feature \"Participation Management\" [ MH-13396 ][ #750 ] - Remove unfinished feature \"Location Blacklisting\" [ MH-13400 ][ #745 ] - Admin Index Test Cleanup [ MH-13399 ][ #744 ] - Update Elasticsearch Configuration [ MH-13395 ][ #742 ] - Remove unfinished feature \"Dashboard\" [ MH-13394 ][ #741 ] - Remove unfinished feature \"User Blacklisting\" [ MH-13393 ][ #738 ] - Remove leftover index resources [ MH-13392 ][ #737 ] - Added allowConflict parameter to methods and implemented [ #736 ] - Revert #523: Special handling of asset manager event removal [ MH-13390 ][ #735 ] - Quick-Filter by Presenter [ MH-13221 ][ #732 ] - Improve behaviour of single-select metadata fields [ MH-13385 ][ #731 ] - Simplify the configuration of the URL signing components [ MH-13384 ][ #730 ] - Remove duplicate joda-time dependency declaration [ MH-13277 ][ #729 ] - fix concurrent Map updates in scheduler [ MH-13382 ][ #727 ] - Minor Waveform Service Fixes [ MH-13379 ][ #726 ] - Simplify Mime Type Handling [ MH-13368 ][ #724 ] - Added color property to waveform operation handler [ MH-13376 ][ #722 ] - Fix OSGI Bindings [ MH-13374 ][ #720 ] - Update Node.js [ MH-13373 ][ #719 ] - Upgrade Admin Interface Libraries [ MH-13372 ][ #718 ] - Clean up orphaned asset manager properties [ MH-13371 ][ #717 ] - Drop unused angular-md5 [ MH-13370 ][ #716 ] - Don't configure unnecessary default credentials [ MH-13294 ][ #713 ] - Workflow for track replacement and cleanup Snapshots [ MH-13367 ][ #711 ] - External API series acl returns null pointer with missing acl [ #710 ] - adds an WOH, which can add catalogs to the MediaPackage of an workflow instance [ MH-13365 ][ #709 ] - inbox ingest into series and inbox retry [ MH-13364 ][ #707 ] - Fix hidden OSGI wiring errors [ #704 ] - Fixed a typo in the analyze-tracks description [ MH-13362 ][ #703 ] - Harmonize Admin Interface Menu Tooltips [ MH-13361 ][ #702 ] - Fix Scheduler Item Serialization [ MH-13360 ][ #701 ] - MH-13316: Watson transcripts improvements [ MH-13358 ][ #698 ] - Update JavaScript Dependencies [ #691 ] - Documentation: Developer Console: How to shutdown [ MH-13275 ][ #689 ] - Allows the workflow to select the audio track for composite videos [ MH-13350 ][ #688 ] - Theodul core HTML validation [ #687 ] - Documentation: Publish Engage Workflow OH [ MH-13344 ][ #685 ] - Enable AssetManager to reply NOT_MODIFIED [ #682 ] - add docs.opencast.org anchors for somewhat deep linking [ MH-13345 ][ #681 ] - Switch to Gson for Languages Endpoint [ MH-13342 ][ #678 ] - Don't try to create events with empty metadata [ #677 ] - Documentation: Dictionary service [ MH-13341 ][ #676 ] - Deleting Capture Agents Should Not Modify Users [ MH-13340 ][ #675 ] - Handle Empty Passwords [ MH-13339 ][ #674 ] - Handle Bad User Update Requests [ MH-13336 ][ #671 ] - Upgrade c3p0 [ #670 ] - Documentation: Analyze Audio WOH: Unbreak table [ MH-13331 ][ #667 ] - Fix ActiveMQ Defaults [ MH-13328 ][ #666 ] - Remove save button at top of videoeditor [ MH-13147 ][ #664 ] - OptimisticLockException in ServiceRegistry dispatchJob [ MH-13324 ][ #662 ] - Simplify Data Loader [ MH-13323 ][ #661 ] - Add documentation for list providers [ MH-13322 ][ #660 ] - Avoid . in Elasticsearch Field Names [ MH-13321 ][ #659 ] - Fix Series Item Serialization [ MH-13320 ][ #658 ] - Asset Manager Performance [ MH-13319 ][ #657 ] - Update Paella Binding Dependencies [ MH-13318 ][ #656 ] - Update to Apache Karaf 4.2.2 [ MH-13313 ][ #653 ] - Properly Use ACL Merge-Mode Configuration [ MH-13307 ][ #648 ] - Update Release Manager Documentation [ MH-13306 ][ #647 ] - Clean up MetadataUtils [ MH-13244 ][ #642 ] - Add override support to external api [ MH-13221 ][ #641 ] - Add placeholder to multi-select fields [ MH-13290 ][ #632 ] - Asset Manager Query Performance [ MH-13289 ][ #631 ] - Introduce Metadatafield Copy Constructor [ MH-13288 ][ #630 ] - Don't create incomplete metadata fields [ MH-13287 ][ #629 ] - Fix incorrect text metadatafield types [ MH-13286 ][ #628 ] - Remove unused functionality from MetadataField [ MH-13285 ][ #627 ] - Display workflow description [ #626 ] - Provide location of org.ops4j.pax.web.cfg [ MH-13284 ][ #625 ] - Update Elasticsearch to 2.x [ MH-12091 ][ #622 ] - Per-Tenant Capture Agent Users [ MH-13281 ][ #621 ] - Added property keep-last-snapshot for asset-delete WOH [ MH-13278 ][ #617 ] - Drop Unused Exception [ MH-13238 ][ #615 ] - don't throw related services straight into ERROR state just because job succeeded on current service [ MH-13277 ][ #614 ] - improve scheduler performance [ MH-13276 ][ #613 ] - Drop org.opencastproject.fun [ MH-13271 ][ #610 ] - Remove Useless ACL Check [ MH-13270 ][ #609 ] - Fix Message Item Serialization [ MH-13267 ][ #607 ] - Update Deprecated Code In UIRolesRoleProvider [ #605 ] - NOJIRA: Fix misspelled digest [ MH-13157 ][ #600 ] - Add multi-tenant support for all list providers [ MH-13262 ][ #596 ] - Changed for partial-error comment description to better description. [ MH-13261 ][ #595 ] - User Directory OSGI Service Definitions [ MH-13260 ][ #594 ] - Simplify Runtime Info UI [ MH-13259 ][ #593 ] - User/Role Directory Cleanup [ MH-13255 ][ #590 ] - Updated Deprecated Methods in Workspace Tests [ MH-13254 ][ #589 ] - Automate Dependency Checking [ MH-13253 ][ #588 ] - External Elasticsearch [ MH-13251 ][ #586 ] - Remove duplicate dependency [ MH-13247 ][ #582 ] - Deprecated Methods In Elasticsearch [ MH-12816 ][ #579 ] - Make waveform size configurable in WOH [ MH-13242 ][ #578 ] - Set disable_search_threshold for chosen globally [ MH-13241 ][ #577 ] - Filter Fileinstall Artifacts [ MH-13129 ][ #575 ] - More configuration options for thumbnails [ MH-13239 ][ #574 ] - Docs: Fix 'Edit on GitHub' link [ #573 ] - Documentation: Inbox [ MH-13234 ][ #565 ] - Workspace Deprecation Fixes [ MH-13231 ][ #564 ] - Allow entering multiple metadata values at once [ MH-13233 ][ #563 ] - add note about the jdk version use for build [ MH-13229 ][ #561 ] - External Library Updates [ MH-13227 ][ #559 ] - Update to Apache Karaf 4.2 [ MH-13226 ][ #558 ] - Update Docuemnation Landing Page [ MH-13224 ][ #556 ] - Drop commons-beanutils [ MH-13217 ][ #551 ] - pom.xml housekeeping [ MH-13213 ][ #548 ] - Separate External API Index [ MH-13212 ][ #546 ] - Fix external-api dependencies [ MH-13210 ][ #545 ] - Fix Deprecated IOUtils Usage [ #542 ] - Developer Installation Guide [ MH-13208 ][ #540 ] - Create a short contributor guide [ MH-13200 ][ #535 ] - Remove unused file acl-modal.html [ MH-13127 ][ #534 ] - Make table headers non-interactive by default [ MH-13198 ][ #529 ] - Properly Display Multiple Presenters [ MH-13197 ][ #528 ] - Separate Admin Interface Index [ MH-13195 ][ #526 ] - Fix Admin Interface Dependencies [ MH-13193 ][ #524 ] - Improve performance of event deletion (2) [ MH-13193 ][ #523 ] - Improve performance of event deletion (1) [ MH-13084 ][ #519 ] - Create a generic user interface configuration service [ MH-13054 ][ #518 ] - Update angular-ui-sortable, adapting build pipeline [ #515 ] - NOJIRA: Documentation: wait_timeout should be bigger than max.idle.time [ MH-13187 ][ #514 ] - Improve Track Stream Handling [ MH-13186 ][ #513 ] - Episode and Series ACL Handling [ MH-13185 ][ #511 ] - Don't include test web server [ MH-13183 ][ #505 ] - Add link to series details, out of the eventstable-view [ MH-13178 ][ #502 ] - Clean-up Series Dialog Code [ MH-13177 ][ #501 ] - Further Simplify MediaPackageElementFlavor [ MH-13175 ][ #499 ] - Remove Apache Tika for Generating Mimetypes [ MH-13174 ][ #498 ] - Simplify class MediaPackageElementFlavor [ MH-13155 ][ #497 ] - Make weekday preselection optional [ MH-13168 ][ #491 ] - Testcases to test a captureagent with Opencast integration. [ MH-13160 ][ #488 ] - Send actually required data in workflow messages [ MH-13161 ][ #483 ] - Simplify log statements [ MH-13158 ][ #480 ] - Use default functional interface for SecurityUtil#runAs [ MH-13153 ][ #477 ] - Workflow Service Code Cleanup [ MH-13151 ][ #475 ] - Update to Apache Karaf 4.1.6 [ MH-13148 ][ #472 ] - Internationalization support for series LTI tools [ MH-13140 ][ #466 ] - Clean-up REST Documentation Code [ MH-13061 ][ #450 ] - Display responsible person for workflows [ MH-13121 ][ #447 ] - Fix usertracking plugin in paella player [ MH-13124 ][ #446 ] - Unify linting for JavaScript and HTML [ MH-13082 ][ #440 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13098 ][ #430 ] - Add start-workflow WOH [ MH-13062 ][ #401 ] - Added credentials for the Ingest Service. [ MH-13000 ][ #398 ] - Group \u201cEdit scheduled\u201d events by weekday [ MH-12782 ][ #209 ] - As an unprivileged user, I only want to see series and events that I have write access to. Opencast 6 Opencast 6.7 Released on December 8, 2019 [ #1200 ] - Fix Crowdin Deployment [ #1143 ] - Upgrade jackson to 2.9.10 (6.x) [ #1142 ] - Update apache commons-compress to 1.19 [ #1132 ] - Fixed the \"hide\" button in the Documentation. [ #1080 ] - Documentation reworked [ #1035 ] - Pushing to Maven Central [ #1026 ] - Adding Ansible script documentation [ #1019 ] - SMIL tests fail when doctype url can't be resolved Opencast 6.6 Released on August 2, 2019 [ MH-13674 ][ #1013 ] - Fix Cutting [ MH-13673 ][ #1012 ] - Workflow options not visually aligned [ MH-13672 ][ #1011 ] - Editor Maximum Height [ MH-13671 ][ #1010 ] - OAI-PMH autorepublish fails due to invalid urls [ MH-13648 ][ #984 ] - Asset Manager Concurrecy Issue [ MH-13644 ][ #980 ] - Sometimes paella does not play audio [ MH-13643 ][ #979 ] - Update to Paella 6.1.4 [ MH-13637 ][ #974 ] - Asset manager endpoint fix [ MH-13633 ][ #969 ] - Update spring-security-oauth [ MH-13611 ][ #955 ] - Duplicate events fix Opencast 6.5 Released on June 14, 2019 [ MH-13607 ][ #946 ] - Show composite duration in video editor [ MH-13606 ][ #944 ] - Don't archive smil on publication [ MH-13601 ][ #939 ] - OAI-PMH database access syncronization [ MH-13575 ][ #916 ] - Update paella player to 6.1.3 [ MH-13573 ][ #914 ] - Add .factorypath to .gitignore [ MH-13560 ][ #902 ] - Admin Role in Moodle User Provider [ MH-13546 ][ #888 ] - textextraction performance improvement [ MH-13544 ][ #886 ] - Video editor shows incorrect notification [ MH-13536 ][ #877 ] - OAI-PMH Remote Broken [ MH-13533 ][ #875 ] - Document parameter \"sign\" of GET /api/events/{id}/publications/* [ MH-13526 ][ #868 ] - Show unequal tracks correctly in editor [ MH-13521 ][ #859 ] - Switch to openJDK 8 on Travis [ MH-13503 ][ #856 ] - Job Dispatch Fairness [ MH-13330 ][ #853 ] - The video editor does not always close after the user presses \"Publish\" [ MH-13511 ][ #852 ] - Adding events in parallel does not work correctly [ MH-13501 ][ #840 ] - Match against user pattern for loadUser() lookups [ MH-13495 ][ #839 ] - Ignore old requests instead of cancelling [ #837 ] - Fix adaptive streaming configuration guide [ MH-13492 ][ #833 ] - Add language support for Italian [ MH-13486 ][ #829 ] - Cleanup NOTICES 6.x [ MH-13485 ][ #828 ] - Update paella player to 6.1.2 [ #827 ] - Change url query syntax to ? [ MH-13476 ][ #818 ] - Filter capture agent roles for ACLs Opencast 6.4 Released on April 01, 2019 [ MH-13449 ][ cc11441 ] - MH-13449, upgrade spring-security-oauth libs [ MH-13464 ][ #805 ] - Update paella player to 6.1.0 [ MH-13463 ][ #803 ] - WOH select-streams does not hide audio track as expected [ MH-13444 ][ #786 ] - Insecure Series Creation [ MH-13387 ][ #777 ] - Get ACLs of finished workflows from AssetManager Document encoding-profiles parameter in ComposeWorkflowHandler [ MH-13429 ][ #767 ] - Make sure series LTI tool respects provided series custom param Opencast 6.3 Released on March 05, 2019 [ MH-13402 ][ #749 ] - WOH select-tracks does not work with audio-only input [ MH-13404 ][ #748 ] - Improve Workspace Logging [ MH-13401 ][ #747 ] - Fix icon in Paella Player [ MH-13388 ][ #734 ] - Updating job load values for composer service on worker nodes \u2026 [ MH-13378 ][ #725 ] - Add mimetype audio/m4a [ MH-13377 ][ #723 ] - Fix scheduler rrule TimeZone issue [ MH-12631 ][ #721 ] - Drop the ORGANIZER field from the ical feed [ MH-13369 ][ #715 ] - Delete Capture Agents [ MH-12177 ][ #712 ] - TimeZone threadsafe and bulk schedule across DST (NEW) [ MH-13355 ][ #700 ] - Increase the default timeout for TrustedHttpClientImpl [ MH-13359 ][ #699 ] - Adding UTF-8 encoding for all remote services [ MH-13357 ][ #697 ] - Enable being able to disable 2 confusing Admin UI metadata: \"duration\" & \"created\" [ MH-13356 ][ #696 ] - Unnecessary Snapshots [ MH-13347 ][ #695 ] - Don't always look for orphaned properties [ MH-13354 ][ #694 ] - Asset Manager Property Performance [ MH-13352 ][ #693 ] - Unnecessary Format [ MH-13310 ][ #692 ] - Simplify AQueryBuilderImpl#always [ #686 ] - Document workaround steps for authentication with IBM Watson STT [ MH-13147 ][ #683 ] - 6.x): OptimisticLockException in ServiceRegistry dispatchJob [ MH-13343 ][ #679 ] - Load track into workspace with unique ID [ MH-13338 ][ #673 ] - Elasticsearch Upgrade Documentation [ MH-13337 ][ #672 ] - Admin UI workflow status translation keys added [ MH-13329 ][ #668 ] - Removing a capture agent resets the password of all Opencast users [ MH-13326 ][ #663 ] - No file/directory found when taking snapshot [ MH-13315 ][ #655 ] - Don't destroy Notifications service on destruction of the Notifications directive [ MH-13312 ][ #654 ] - Do not show outdated conflict information Opencast 6.2 Released on January 24, 2019 [ MH-13309 ][ #649 ] - return empty list when finding findUsersByUserName when the name param is empty. Opencast 6.1 Released on January 12, 2019 [ MH-13305 ][ #646 ] - MacOS installation update [ MH-13304 ][ #645 ] - Multi-value consistent with multi-select [ MH-13302 ][ #644 ] - Don't save unnecessarily in Multi-Select [ MH-13301 ][ #643 ] - Don't require event.publisher since it is a readonly field [ MH-13300 ][ #640 ] - Display multi-value fields correctly on summary pages [ MH-13299 ][ #639 ] - Make multi-select fields consistent again [ MH-13295 ][ #635 ] - Handle null for presentable value extraction [ MH-13283 ][ #624 ] - Fix Custom CXF Error Handler [ MH-13248 ][ #623 ] - Allow hidden workflow parameters Opencast 6.0 Released on December 10, 2018 [ #620 ] - Remove dropped translations [ MH-13230 ][ #616 ] - remove the need for passing an Accept header with external api requests [ MH-13272 ][ #611 ] - fix missing roles [ MH-13266 ][ #606 ] - Start date cross link does not work correctly [ MH-13215 ][ #602 ] - WorkflowOperationTagUtil throws a null pointer [ MH-13245 ][ #601 ] - Paella player does not show a single presentation video [ MH-13252 ][ #587 ] - Ineffective Synchronization of Elasticsearch Startup [ MH-13221 ][ #585 ] - Improve multi-select metadata fields [ MH-13250 ][ #584 ] - Thumbnail feature does not work for unprivileged users [ MH-13249 ][ #583 ] - Invalid Group Endpoint Registration [ MH-13237 ][ #576 ] - Track previews do not work with stream security [ MH-13214 ][ #570 ] - Fix HTTP Digest Authentication [ MH-13232 ][ #562 ] - Fix potentially negative fade-out start [ MH-13228 ][ #560 ] - Homogeneous Width of Shortcut Icons [ MH-13225 ][ #557 ] - Fix for exception in live scheduler service when rebuilding the admin ui index [ MH-13222 ][ #554 ] - Some fixes to tiered storage asset manager [ MH-13209 ][ #544 ] - Put CAS Feature In Distributions [ MH-13150 ][ #541 ] - Add note about CAAM to release notes [ MH-13201 ][ #538 ] - Convert uploaded images to appropriate size and format [ MH-13206 ][ #537 ] - Use correct mouse cursor in filters [ MH-13205 ][ #536 ] - Document, fix and improve thumbnail support [ MH-13196 ][ #527 ] - Unregister Resource Servlets of Bundles to be Removed [ MH-13192 ][ #522 ] - Improve performance of list requests [ MH-13191 ][ #521 ] - Improve performance of retrieving groups [ MH-13188 ][ #516 ] - Update paella player 6.0.3 [ MH-13154 ][ #512 ] - Unify vertical spacing in wizards [ MH-13184 ][ #508 ] - Update request-digest [ #507 ] - Remove documentation about unused workflow pause role [ MH-13162 ][ #506 ] - Show all series in edit-scheduled-events [ MH-13179 ][ #503 ] - Fix Video Editor Preview Mode Default [ MH-13176 ][ #500 ] - Bug fix update of Jackson [ MH-13170 ][ #496 ] - Fix workflow not selected in event details [ MH-13171 ][ #495 ] - Fix workflow configuration settings being displayed incorrectly [ MH-13173 ][ #494 ] - Do not hardcode value of ACL override [ MH-13169 ][ #492 ] - Update bibliographic metadata when technical metadata changes [ MH-13166 ][ #489 ] - OAI-PMH Message Handler Performance [ MH-13164 ][ #487 ] - Load catalog for snapshot message effeciently [ MH-13130 ][ #486 ] - java.lang.ClassCastException in AdminUserAndGroupLoader when starting up [ MH-13163 ][ #484 ] - Fix empty REST documentation notes [ MH-13159 ][ #481 ] - Fix mattermost notification operation issues [ MH-13111 ][ #479 ] - Fix display of metadata in series creation summary [ MH-13110 ][ #478 ] - Fix display of metadata in event creation summary [ MH-13150 ][ #474 ] - Opencast 6.0 release notes [ MH-13149 ][ #473 ] - Timed tiered storage test fails on fast systems [ MH-13051 ][ #471 ] - Fix dropdown placeholders [ #470 ] - Fix rest docs of GroupsEndpoint [ MH-13141 ][ #469 ] - Correctly initialize stats service [ MH-13142 ][ #468 ] - Error parsing non-existent schedule [ MH-13135 ][ #467 ] - Pending requests are not cancelled as expected [ MH-13139 ][ #465 ] - Documentation for the event publisher metadata [ MH-12819 ][ #464 ] - change extract-text encoding profile for better OCR results\u2026 [ MH-13137 ][ #462 ] - Less extensive statistics configuration [ MH-13136 ][ #461 ] - Add Danish Translation [ MH-13133 ][ #459 ] - TypeError: Cannot read property 'results' of null [ MH-13092 ][ #458 ] - Fix failing scheduling for non-english browsers [ MH-13132 ][ #457 ] - Fix REST Docs Overview Rendering [ MH-13131 ][ #456 ] - Fix Feed Service REST Docs [ #455 ] - Remove misleading - sign in tag woh docs [ MH-13125 ][ #451 ] - Remove unused configuration keys [ MH-13123 ][ #448 ] - Update paella player 6.0.2 [ MH-13117 ][ #445 ] - Mark NPM managed modules as private packages [ MH-13116 ][ #444 ] - Fix typo in paella error message [ MH-13115 ][ #443 ] - Update Node, NPM and Libs [ MH-13114 ][ #442 ] - Fix broken REST docs [ MH-13113 ][ #441 ] - Drop unused HTML page [ MH-13025 ][ #439 ] - Fix workflow-definitions URL [ MH-13109 ][ #438 ] - Update Paella Player to 6.0.x [ MH-13107 ][ #436 ] - Update admin interface build dependencies [ MH-13106 ][ #435 ] - Add Moodle groups to Moodle role provider [ MH-13105 ][ #434 ] - Fix minor mattermost notification operation issues [ MH-13104 ][ #433 ] - Add linter for LTI tools [ MH-13103 ][ #432 ] - Runtime UI NG JavaScript Dependencies [ MH-13102 ][ #431 ] - Add linter (checkstyle) for JavaScript to engage-paella-player module [ MH-13097 ][ #429 ] - Added a configuration parameter to be able to send HTML emails [ MH-13101 ][ #428 ] - Update paella dependencies [ MH-13100 ][ #427 ] - fix series view in Paella [ MH-13099 ][ #426 ] - Warn when default credentials are being used [ MH-13096 ][ #425 ] - Set workflow variables with duplicated media package IDs [ MH-13095 ][ #424 ] - Add linter (checkstyle) for JavaScript [ MH-13083 ][ #423 ] - Unify modal navigation [ MH-13094 ][ #422 ] - Use global NPM repository [ MH-13090 ][ #420 ] - Added support for blacklisting languages from the admin UI [ MH-12699 ][ #419 ] - Remove opencast-paella binding dependency on Admin server [ MH-13088 ][ #417 ] - Update Several Dependencies [ MH-13087 ][ #416 ] - Update Runtime UI Libraries [ MH-13086 ][ #415 ] - Update LTI Series Tool [ MH-13079 ][ #413 ] - Introduce REST Interface for AssetManager Properties [ MH-13060 ][ #412 ] - Add i18n support for workflow, operations, job and services status [ MH-13073 ][ #411 ] - Don't split series metadata fields by , [ MH-13074 ][ #410 ] - Clean up asset manager REST endpoints [ MH-13072 ][ #409 ] - Remove broken ltitool player [ MH-13071 ][ #408 ] - Update markdown linter [ MH-13070 ][ #407 ] - Update JS build and test libraries [ MH-13064 ][ #399 ] - Encoding profile mimetypes are mostly ignored [ MH-13058 ][ #395 ] - Remove unused font libraries [ MH-12688 ][ #392 ] - Add translations for comment filter values [ MH-13045 ][ #391 ] - Add missing i18n translations [ MH-13040 ][ #388 ] - Make options fit \u201cActions\u201d drop-down [ MH-12810 ][ #387 ] - External API 1.1.0 - Add filters for new fields [ MH-13037 ][ #386 ] - Remove unused External API roles [ MH-12690 ][ #384 ] - Add i18n support for capture agent statuses [ MH-12761 ][ #382 ] - Fixed event to listen to \"plugin.events.captionsFound\". [ MH-13028 ][ #381 ] - Clean up mockup [ MH-13022 ][ #378 ] - fixed LTI highly trusted keys being discarded [ #376 ] - Update and improve documentation for reviews [ MH-13027 ][ #374 ] - Update angular-translate to 2.18.1 [ MH-13026 ][ #373 ] - Update Mac OS X 'Install from source' documentation [ MH-13025 ][ #372 ] - Add workflow API to external API [ MH-13024 ][ #371 ] - Video editor does not display information when being opened while an event is being processed [ #369 ] - Documentation: message-broker: binding localhost [ #368 ] - Documentation: Update security.https.md [ MH-13016 ][ #362 ] - Workflow display order not working in editor screen [ MH-13013 ][ #359 ] - Unused code in scheduler [ MH-13008 ][ #358 ] - Prefill other input of startdate filter [ MH-13012 ][ #357 ] - The iterable metadata values should not be splitted by , [ MH-13010 ][ #356 ] - Series-Service-Remote incorrect character encoding [ MH-13009 ][ #355 ] - Update translations [ MH-13007 ][ #354 ] - Clarify Scheduler Calendar cutoff units in REST docs [ MH-12829 ][ #348 ] - Make admin-ui statistics configurable [ MH-12998 ][ #346 ] - Clear conflicts when closing \u201cEdit Scheduled Events\u201d modal [ MH-12996 ][ #345 ] - Add header row to conflict table in \u201cEdit scheduled\u201d [ MH-12995 ][ #344 ] - Fix conflict check not detecting some conflicts [ MH-12990 ][ #343 ] - User switching: Privilege escalation too restrictive [ MH-12993 ][ #342 ] - REST docs for Admin UI Event endpoint broken [ MH-12994 ][ #341 ] - Make \u201cTitle\u201d in \u201cEdit scheduled\u201d non-mandatory [ MH-12992 ][ #340 ] - Trigger conflict check in \u201cEdit scheduled\u201d on \u201cNext\u201d [ MH-12989 ][ #338 ] - Add missing roles for actions->edit scheduled [ #336 ] - Update version info [ MH-12987 ][ #335 ] - Prohibit changing a scheduled event to be in the past [ MH-12985 ][ #332 ] - Fix incorrect warnings in event modals [ MH-12803 ][ #329 ] - Fix for mp 'start' when event is created (affects live scheduler service) [ MH-12980 ][ #328 ] - Update documentation landign page [ MH-12930 ][ #327 ] - Fill creator metadata field with actual user when new event [ MH-12977 ][ #322 ] - Fix data placeholders in edit scheduled events [ MH-11918 ][ #321 ] - AWS S3 Asset Storage [ MH-12975 ][ #320 ] - Inconsistent access control handling [ MH-12738 ][ #319 ] - Tiered Storage for the Asset Manager [ MH-12969 ][ #317 ] - Eclipse IDE import Opencast XML style preferences [ MH-12972 ][ #316 ] - Drop unused getAclAttachments [ MH-12969 ][ #314 ] - Ensure formatting of OSGI configuration [ #313 ] - NOJIRA-live-schedule-fix-issue-in-documatation [ MH-12965 ][ #311 ] - Add more logging data to metadata parse WARN [ MH-12961 ][ #308 ] - Remove unused JavaScript library bootstrap from Admin UI [ MH-12960 ][ #307 ] - Remove unused JavaScript library backbone.js from Admin UI [ MH-12959 ][ #306 ] - Remove unused JavaScript library visualsearch.js [ MH-12956 ][ #305 ] - Incorrect permission check when requesting indexed workflows [ MH-12958 ][ #301 ] - image-convert WOH [ MH-12607 ][ #299 ] - Multiencode [ MH-12955 ][ #298 ] - ffmpeg expect floating timestamp values separated by '.' [ MH-12949 ][ #294 ] - Fix spacing between action items [ MH-12946 ][ #292 ] - add event summary input translation [ MH-12948 ][ #291 ] - Directly read XACML files [ MH-12905 ][ #289 ] - Opencast does not startup anymore [ MH-12911 ][ #266 ] - Hotkey cheat sheet [ MH-12813 ][ #265 ] - Add audio and video track selection to video editor [ MH-12607 ][ #264 ] - Process-Smil - edit and encode to multiple delivery formats [ MH-12918 ][ #261 ] - Use Karaf generated jre.properties [ MH-12904 ][ #252 ] - Paella player 5.3 update [ MH-12829 ][ #237 ] - Fix broken sub tabs of Event Details->Assets [ MH-12889 ][ #236 ] - Intuitive Merging of Video Segments [ MH-12828 ][ #233 ] - re-enable Scheduler service conflicts json REST endpoint [ MH-12885 ][ #232 ] - Capture Agent Access Management [ MH-12877 ][ #231 ] - Add new modal to edit multiple scheduled events at once [ MH-12871 ][ #220 ] - Ability to use user names in to/cc/bcc fields in send-email woh [ MH-12869 ][ #219 ] - Remove superfluous playback tool [ MH-12829 ][ #218 ] - Switch and rename event details tabs [ MH-12814 ][ #208 ] - Manually Select And Upload Thumbnails [ MH-12815 ][ #197 ] - delete series with events option [ MH-12826 ][ #193 ] - Make workflow processing settings persistent [ MH-12823 ][ #182 ] - Log Configuration and GELF Log4J with graylog [ #181 ] - adapt tracking default options to respect the EU GDPR [ MH-12822 ][ #179 ] - Remove old OCv2x security context fix artifacts [ MH-12607 ][ #172 ] - Harvard DCE), Demux Operation [ MH-12607 ][ #171 ] - Harvard DCE), Lossless Concat Operation [ MH-12804 ][ #170 ] - Introduce displayOrder for workflow definitions [ MH-12797 ][ #168 ] - Explain UI actions (added missing tooltips) [ MH-12820 ][ #167 ] - Mattermost-notification-workflowoperationhandler [ #165 ] - Be less quiet about errors on Travis [ MH-12797 ][ #164 ] - Explain UI Actions [ MH-12794 ][ #162 ] - turn off matomo notification [ MH-12793 ][ #161 ] - Collapse multiple, redundant composer process methods [ MH-12647 ][ #155 ] - MH-12756 extend external api [ MH-12786 ][ #154 ] - Undistinguishable Entries in Groups Editor User List [ MH-12784 ][ #153 ] - External API: Accept header not specified correctly [ MH-12091 ][ #150 ] - Implement per-tenant digest user for capture agents [ MH-12703 ][ #89 ] - Add userdirectory for Moodle [ MH-11621 ][ #56 ] - Option to marshal empty values in DublinCore XML catalog. Opencast 5 Opencast 5.5 Released on April 1, 2019 [ MH-12603 ][ #746 ] - Take 'ng' out of the youtube composite operation [ MH-13386 ][ #733 ] - Event status calculation wrong assumption fixed [ MH-13383 ][ #728 ] - don't smooth the waveform in the editor [ MH-13366 ][ #708 ] - Add REFERENCES permission to standard Opencast GRANT statement [ MH-13363 ][ #706 ] - Publish to OAI-PMH an allready published mediapackage \u2026 [ MH-13333 ][ #669 ] - Do not import properties in publish WF Opencast 5.4 Released on January 24, 2019 [ MH-13311 ][ #652 ] - WOH cover-image is broken SUREFIRE-1588: Resolving compilation issue on Debian and related distros [ MH-13244 ][ #581 ] - Improve concurrency of OAIPMH republication Opencast 5.3 Released on January 11, 2019 [ MH-13297 ][ #638 ] - FasterXML Jackson Bugfix Update [ MH-13296 ][ #637 ] - Disable buttons of start task wizard while the tasks are being submitted [ MH-12290 ][ #636 ] - prevent SAXParserFactory and SAXParser class load lag in series listprovider [ MH-13269 ][ #608 ] - Handle Authorization Errors [ MH-13263 ][ #598 ] - Invalid Ingest Encoding [ MH-13257 ][ #597 ] - Fix outdated command line argument for tesseract >= 4.0.0 [ MH-13258 ][ #592 ] - Broken User Provider Removal [ MH-13256 ][ #591 ] - Waveform operation fails [ MH-13243 ][ #580 ] - Asset Manager ACL Cache Updates [ #572 ] - Documentation: Opencast 5.2 was released in Nov [ #571 ] - Documentation: Linkfixes in OC5.x upgrade guide [ MH-12332 ][ #567 ] - disable workflows whose tags don't explicitly match the source type, UPLOAD|SCHEDULE 5.x Opencast 5.2 Released on November 13, 2018 [ MH-13144 ][ #553 ] - only set Job startDate if no set before [ MH-13216 ][ #550 ] - Fix Documentation Pages [ MH-13211 ][ #547 ] - engage-ui: Fix live schedule bug: event available before schedule [ MH-13190 ][ #520 ] - Factor out JpaGroupRoleProvider JaxRs REST to mitigate load cycle race [ MH-13189 ][ #517 ] - Fix paella xss security isues in opencast 5.x [ MH-13167 ][ #490 ] - Republishing metadata does not update all metadata [ MH-13152 ][ #476 ] - Reduce Workflow Messages [ MH-13138 ][ #463 ] - Fix media module language configuration [ MH-13108 ][ #437 ] - Prevent permission problem in Travis cache [ MH-13091 ][ #421 ] - Concat operation problem with FFMPEG 4.x [ MH-13069 ][ #406 ] - Update problematic admin interface libraries [ MH-12976 ][ #389 ] - custom role patterns not working [ MH-12387 ][ #350 ] - Fix CAS Opencast 5.1 Released on September 3, 2018 [ MH-13067 ][ #404 ] - Configuration panel does not work for default workflow [ MH-13049 ][ #400 ] - Fix video editor zoom dropdown showing wrong value [ MH-13055 ][ #396 ] - Stop making events with no ACL public on ingest [ MH-13048 ][ #394 ] - Improve stability of the series index rebuild [ MH-13047 ][ #393 ] - Document using Nginx for HTTPS [ MH-13044 ][ #390 ] - Organization server configuration documentation [ MH-12016 ][ #379 ] - Scrolling role fetch [ MH-13031 ][ #377 ] - Active transaction notification on top [ MH-13029 ][ #375 ] - Don't show old notifications [ MH-13023 ][ #370 ] - Let default value fulfill requirement [ MH-13018 ][ #367 ] - re-add recordings json to 5x (includes MH-12828 re-add conflicts.json) [ MH-13020 ][ #366 ] - Read listproviders as UTF-8 [ MH-13017 ][ #363 ] - JS syntax error in publish workflow [ MH-13015 ][ #361 ] - 5.x database upgrade scripts [ MH-13014 ][ #360 ] - Don't show stale search results [ MH-13006 ][ #353 ] - Waveform operation cleanup creates problem with asynchronous NFS [ MH-13003 ][ #352 ] - Implement detection of already recorded (as opposed to yet to be recorded, scheduled) events by the index service [ MH-13005 ][ #351 ] - Skip waveform operation when no tracks [ MH-13001 ][ #347 ] - Fixed live scheduler service pom [ MH-12988 ][ #337 ] - delete-scheduled-live Fix for scheduled live event not deleted [ MH-12986 ][ #333 ] - Admin UI deployed debugging: include source in SourceMap files [ MH-12981 ][ #331 ] - fix for local admin-ui develop finding main.css [ MH-12979 ][ #325 ] - Automatically test ddl scripts [ MH-12978 ][ #324 ] - Fix data-placeholder in add event wizard [ MH-12974 ][ #318 ] - Access denial to event for unprivileged user [ MH-12970 ][ #315 ] - Senseless XACML parsing [ MH-12966 ][ #312 ] - Do not pre-select-from option in metadata property sheets [ MH-12963 ][ #310 ] - Localize dates/times in add-event summary [ MH-12950 ][ #309 ] - Fix for workflow with no acl in solr index NOJIRA: Skip install of Crowdin if it is already installed [ MH-12957 ][ #300 ] - Defaults on tab Source in Add Event wizards are broken [ MH-12954 ][ #297 ] - wrong date format in coverimage file Opencast 5.0 Released on June 12, 2018 [ MH-12952 ][ #295 ] - animate WOH dependency version fixed [ MH-12946 ][ #290 ] - Fix summary of add-event-dialog [ MH-12944 ][ #288 ] - Remove bashism from start script [ MH-12905 ][ #287 ] - TEMPORARY Karaf config assembly workaround (KARAF-5693) [ MH-12943 ][ #286 ] - Minor Paella config REST endpoint improvements [ MH-12942 ][ #285 ] - Paella player config REST endpoint should be accessible by anonymous user [ MH-12941 ][ #284 ] - Gracefully handle empty flavors [ MH-12940 ][ #283 ] - Ensure admin configuration is applied [ MH-12864 ][ #282 ] - Don't attempt to parse 'undefined' [ MH-12938 ][ #281 ] - Fix NullPointerException if no flavor is set [ MH-12937 ][ #280 ] - Correctly place admin UI test helper [ MH-12936 ][ #279 ] - Handle invalid flavors [ MH-12935 ][ #278 ] - Update Docker image repository documentation [ MH-12934 ][ #277 ] - Update translations [ MH-12933 ][ #276 ] - Link documentation from Systemd unit [ MH-12932 ][ #275 ] - Kernel Build Failure [ MH-12922 ][ #272 ] - Job load fixes [ MH-12929 ][ #271 ] - Change paella URL to /paella/ui [ MH-12928 ][ #270 ] - Mitigation for KARAF-5526 [ MH-12926 ][ #269 ] - Prevent cluttering of logs by invalid access [ MH-12924 ][ #268 ] - fix missing dropdown arrow [ MH-12919 ][ #262 ] - REST Docs Dependencies [ MH-12917 ][ #260 ] - Remove debug logging [ MH-12916 ][ #259 ] - Admin Interface Configuration Defaults [ MH-12914 ][ #258 ] - Remove deprecated IOUtils.closeQuietly [ MH-12913 ][ #257 ] - Fix Admin Interface Deprecation Warnings [ MH-12868 ][ #255 ] - Make frame-by-frame skipping function in the editor use the \"actual\" framerate [ MH-12908 ][ #251 ] - Fix escaping of spaces [ MH-12907 ][ #250 ] - Fix segmentation default job load [ MH-12906 ][ #249 ] - Composoer should ignore system specific output pathes like /dev/null [ MH-12902 ][ #248 ] - closing videoeditor should continue in events list [ MH-12901 ][ #247 ] - Fix YouTube publication job loads [ MH-12900 ][ #246 ] - Fix search service job loads [ MH-12899 ][ #245 ] - Fix streaming distribution job load defaults [ MH-12898 ][ #244 ] - Fix download distribution job load defaults [ MH-12897 ][ #243 ] - Improve visibility of selected segments in the videoeditor [ MH-12896 ][ #242 ] - Clarify default player configuration [ MH-12894 ][ #240 ] - Update markdownlint [ MH-12893 ][ #239 ] - Added ability to configure the job load for the aws s3 distribution service. [ MH-12892 ][ #238 ] - Added ability to configure the job load for the transcription service. [ MH-12888 ][ #235 ] - Missing FFmpeg on Travis CI [ MH-12887 ][ #234 ] - Only set job date completed and runtime once. [ MH-12883 ][ #230 ] - Maven build of admin-ui module without frontend profile [ MH-12882 ][ #229 ] - Fix org.w3c.dom.smil version [ MH-12881 ][ #228 ] - Remove deprecated method [ MH-12880 ][ #227 ] - Remove redundant OSGI declarations [ MH-12879 ][ #226 ] - Default location of paella configuration [ MH-12878 ][ #224 ] - Don't verify NPM cache to speed up build process [ MH-12874 ][ #223 ] - NotFoundException handling for OAI-PMH retract operation with non published event [ MH-12872 ][ #222 ] - event can not be deleted [ MH-12873 ][ #221 ] - Speed up test builds [ MH-12864 ][ #215 ] - Readonly mode of fields not working correctly in property sheets [ MH-12807 ][ #213 ] - Do not overwrite owner [ MH-12863 ][ #212 ] - Fix default owner in SMIL endpoint [ MH-12862 ][ #211 ] - Line break after required marker in REST docs [ MH-12834 ][ #207 ] - Central documentation for filtering, sorting and pagination [ MH-12833 ][ #204 ] - Consistently use External API as name [ MH-12852 ][ #203 ] - Required fields not indicated in the event details and series details modals [ MH-12843 ][ #200 ] - Fix \u201cAdd Event\u201d Tab Index Update main readme Fix tabs and trailing spaces in docs [ MH-12839 ][ #196 ] - fix all pom.xml [ MH-12837 ][ #194 ] - external series API ACL is required [ MH-12832 ][ #192 ] - Update to commons-collection4 [ MH-12836 ][ #191 ] - Fix event-comment dependencies not correctly specified [ MH-12831 ][ #190 ] - Fixing dependencies NOJIRA fix engage paella url security rules NOJIRA Localization developer guide updated [ MH-12780 ][ #184 ] - Fix sorting jobs by identifier in Systems->Jobs [ MH-12824 ][ #183 ] - Speed up mvn site T/clarify wording of user tracking in documentation [ MH-12818 ][ #177 ] - Improve Sox service tests NOJIRA Crowdin project configuration updated NOJIRA Crowdin documentation updated [ MH-12771 ][ #173 ] - Document fields of External API 1.0.0 [ MH-12795 ][ #163 ] - REST docs don't respect @Produces annotation on class level [ MH-12788 ][ #157 ] - UTF-8 encoding settings in OAI-PMH publication service remote [ MH-12616 ][ #152 ] - Admin UI Flexible Asset Upload override or fallback display text [ MH-12775 ][ #146 ] - Add JavaScript source map generation [ MH-12768 ][ #142 ] - Minor XACMLAuthorizationService fixes [ MH-12825 ][ #139 ] - Add markdownlint to Travis CI [ MH-12760 ][ #160 ] - Cross-link column date in events table to enable the start date filter [ MH-12789 ][ #158 ] - Remove tabs and trailing spaces in LTI tools [ MH-12509 ][ #151 ] - Enable HTTP basic auth in default config [ MH-12759 ][ #149 ] - More Control Over Workflows [ MH-12779 ][ #147 ] - Support X-Forwarded-Proto header [ MH-12649 ][ #138 ] - clone workflow operation handler [ MH-12764 ][ #137 ] - update license information for admin-ui [ MH-12763 ][ #136 ] - Minor Composer Fixes [ MH-12762 ][ #135 ] - Fix Spaces In Configuration Fallback For Synfig Install clean up woh documentation Make Travis check for tabs in pom.xml files Add Mkdocs To Travis Builds [ MH-12757 ][ #128 ] - Fix ClassCastException [ MH-12755 ][ #127 ] - Fix workflow-workflowoperation dependencies [ MH-12746 ][ #126 ] - Update Checkstyle [ MH-12746 ][ #125 ] - Update Apache HTTPComponents [ MH-12746 ][ #124 ] - Update Mina [ MH-12746 ][ #123 ] - Remove commons-logging [ MH-12746 ][ #122 ] - Update Jackson [ MH-12752 ][ #121 ] - Ignore VSCode project data [ MH-12751 ][ #120 ] - Add Travis Badge [ MH-12735 ][ #119 ] - Remove Undocumented Operations [ MH-12746 ][ #115 ] - Library Update [ MH-12742 ][ #113 ] - Update to Karaf 4.0.10 [ MH-12744 ][ #111 ] - Fix migration bundle dependencies [ MH-12739 ][ #109 ] - Transcription Service updated to support Paella [ MH-12737 ][ #108 ] - OAI-PMH publication service [ MH-12732 ][ #106 ] - Remove Unused Remote Service Registry [ MH-12731 ][ #105 ] - Improve Recreating Series Index [ MH-12730 ][ #104 ] - Workflow Index Rebuild Performance [ MH-12711 ][ #100 ] - improve xacml parser [ MH-12726 ][ #99 ] - Add description to theme [ MH-12704 ][ #98 ] - Captions support for paella [ MH-12718 ][ #97 ] - Animate Service [ MH-12713 ][ #95 ] - Series cannot be created [ MH-12705 ][ #87 ] - Fix scheduler hot-deployment [ MH-12701 ][ #84 ] - Paella: Localization files + crowdin config file [ MH-12692 ][ #83 ] - update maven bundle plugin for java8 [ MH-12663 ][ #81 ] - Don't search for non-existing WFR files [ MH-12694 ][ #80 ] - Save\" button in the editor now stays on the same page. [ MH-12693 ][ #77 ] - Notes on how to enable, upgrade to HTTPS [ MH-12675 ][ #76 ] - Send default startdate to backend also if it hasn't been changed. [ MH-12656 ][ #75 ] - Updates to Theodul Matomo (formerly Piwik) Plugin [ MH-12684 ][ #69 ] - Make License List Provider More Flexible [ MH-12683 ][ #68 ] - Improve Video Editor Tests [ MH-12681 ][ #66 ] - update media package series catalogs on event metadata update [ MH-12677 ][ #65 ] - Be less technical about displaying the version number [ MH-12674 ][ #63 ] - Remove unused hard-coded list providers [ MH-12665 ][ #62 ] - Sort table on startup [ MH-12649 ][ #59 ] - clone workflow operation handler [ MH-12668 ][ #58 ] - Update packages of admin ui build pipeline Use $timeout instead of $interval to resolve MH-12667 [ MH-12661 ][ #52 ] - Update angular-translate to 2.17.0 [ MH-12660 ][ #51 ] - Scheduling Events by Specifying End Time [ MH-12658 ][ #50 ] - Disable Jasmine for Theodul [ MH-12653 ][ #46 ] - Authorization service should use workspace#read() wherever possible [ MH-12600 ][ #45 ] - Move userdirectory stuff from bundle kernel to userdirectory [ MH-12648 ][ #42 ] - As a system administrator, I want to use different encoding \u2026 [ MH-12645 ][ #39 ] - Created an option to rebuild index for an specific service [ MH-12644 ][ #37 ] - External API index schema fixes [ MH-12538 ][ #36 ] - Remove obsolete ACL distribution service and WOH distribute-acl [ MH-12639 ][ #35 ] - update angular-chosen to 1.8.0 [ MH-11984 ][ #32 ] - Allow customization of the username-to-user-role mapping [ MH-12367 ][ #30 ] - Renaming all database tables [ MH-12633 ][ #29 ] - Fix version of maven-dependency-plugin [ MH-12544 ][ #26 ] - Play Deleted Segments in Video Editor [ MH-12575 ][ #25 ] - Upgrade to AngularJS 1.5.11 [ MH-12595 ][ #24 ] - Improve Publications Usability [ MH-12613 ][ #23 ] - New WorkflowOperationHandler 'create-event' [ MH-12628 ][ #20 ] - MH-12629, MH-12630, Minor database fixes [ MH-10560 ][ #19 ] - Live Scheduler Service [ MH-12615 ][ #17 ] - Improve the languages drop-down menu [ MH-12623 ][ #16 ] - Improve workflow dropdown menu [ MH-12621 ][ #15 ] - submit paella player [ MH-12624 ][ #11 ] - Fix link to Karaf remote debugging documentation Update debs.md [ MH-12472 ][ #8 ] - FFmpeg Composer Implementation [ MH-12502 ][ #7 ] - Do Not Leave Files In Workspace [ MH-12477 ][ #6 ] - Operation To Log Workflow State [ MH-12555 ][ #5 ] - Add support for Piwik Media Analytics [ MH-10016 ][ #4 ] - Default Workflow [ MH-12603 ][ #2 ] - Consistent Workflow IDs [ MH-12622 ][ #1 ] - Surefire Versions Should Not Diverge Opencast 4 Opencast 4.5 Released on Oktober 30, 2018 [NOJIRA] - Fix wrong example in publish-configure documentation [MH-13075] - make ACL entries unique prior to running ACL comparisons [MH-13068] - workflow delete instance stability improvement [MH-13055] - Stop making events with no ACL public on ingest [MH-13032] - Asset Upload fix for missing reset() [MH-12953] - stop loading editor.json twice [NOJIRA] - Update the release process docs Opencast 4.4 Released on May 31, 2018 [MH-12923] - ServiceRegistry does not close db connction [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins Opencast 4.3 Released on March 28, 2018 [MH-12774] - Fix differences in provided security configurations [MH-12773] - Fix that non-admins cannot add new assets [MH-12772] - Fix acces to assets for non-admins [MH-12789] - Remove tabs and trailing spaces in LTI tools [MH-12790] - Make LTI respect player configuration Opencast 4.2 Released on March 14, 2018 [MH-12766] - Metadata view and edit roles where at some places set incorrectly [MH-12765] - Navigating through series in the series details modal causes failing attempts to save ACLs [MH-12758] - Changing the ACLs does not trigger AssetManagerDecorators [MH-12747] - Heartbeat is broken [MH-12745] - Fix heartbeat config logging [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12728] - Add LAST-MODIFIED to ical event properties [MH-12727] - OptimisticLockException on worker node can cause jobs to be stuck in DISPATCHING state [MH-12725] - Series/Events ACL update causes scheduled recordings in the series/the events to disappear from CA calendar [MH-12717] - Series metadata update causes scheduled recordings in the series to disappear from CA calendar [MH-12711] - XACML Parser should be more robust [MH-12707] - Fix problem with non-strict mode in URL-Signing [MH-12706] - Old zombie workflows cannot be stopped, suspended etc. [MH-12668] - Update admin ui build pipeline [MH-12651] - Scheduling repeating events through Admin UI is very slow Opencast 4.1 Released on Februar 7, 2018 [MH-12695] - Improve Synchronization in WorkflowService [MH-12689] - Flickering filter: When loading the page, all filters briefly appear and disappear again [MH-12687] - Date filters not working [MH-12685] - Performance issue in filters [MH-12682] - TimelinePreview Concurrency Problem [MH-12676] - List provider service implementation is not thread-safe [MH-12673] - Content-Type is not set for JavaScript files [MH-12664] - Ensure series can be deleted [MH-12662] - Special characters in modal window titles are double-escaped [MH-12657] - Users of non-admin groups cannot create events [MH-12652] - Scheduler service needs to restrict queries to episodes owned by it [MH-12641] - Asset manager conflict checks are very slow [MH-12638] - Migration bundle needs to have a higher runlevel [MH-12637] - Remove event id from episode DC catalog during migration [MH-12632] - Make index rebuild robust [MH-12631] - Drop the ORGANIZER field from the ical feed [MH-12627] - Start Task copies files into workspace [MH-12620] - Document ActiveMQ memory requirements [MH-12610] - Navigating through events in the event details modal causes failing attempts to save ACLs [MH-12609] - As a user, I expect scheduling of events to be working [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12602] - External API gives 500 error for migrated series that do not have creator field [MH-12601] - Fast Workflow Does Not Attach Series Metadata [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12476] - Delay start of job dispatching on startup [MH-10016] - Cannot Change Default Workflow Opencast 4.0 Released on December 8, 2017 [MH-12597] - When reindexing, some events may incorrectly be displayed as \"Scheduled\" instead of \"Processed\" or \"Failed\" [MH-12596] - Video Editor Ignores Workspace [MH-12594] - Description field in metadata editor doesn't handle newlines properly [MH-12591] - AssetManager reindex produces \"No organization found!\" warnings [MH-12590] - Fix Workflow WOH Workspace Mock [MH-12589] - Fix Timelinepreview Dependencies [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12583] - Reduce frequency of index rebuild messages for comments and asset manager [MH-12579] - Simplify XACML Handling [MH-12578] - Color of Crosslinks Makes Tables Look Noisy [MH-12574] - Audio keeps playing when leaving the playback or editor page [MH-12573] - Unprivileged users cannot delete events [MH-12572] - Dependency Fixes [MH-12570] - Admin UI Regressions And Minor Bugs [MH-12569] - Don't fail hard if attempting to distribute a non-track media package element to streaming server [MH-12568] - EditableSingleValue Has Focus Issues [MH-12567] - Index Service Dependencies [MH-12566] - Remove Unused Participation List Provider [MH-12560] - Streaming media distribution does not work in a distributed cluster [MH-12559] - CSS: Delete And Retract Dialogs For Events Are Messed up [MH-12558] - CSS: Buttons in Confirm Modals Too Big [MH-12557] - CSS: Checkbox Alignment in Tables [MH-12556] - Video Editor CSS Enhancements [MH-12554] - Downloading translations from Crowdin doesn't work anymore [MH-12553] - As an administrator, I want to configure the order in which the different adaptive streaming video qualities are listed [MH-12552] - The \"delete\" button in the Admin UI may leave the \"preview\" artifacts undeleted [MH-12551] - Redo changes of MH-11660 that got lost in means of a regression [MH-12550] - hasActiveTransaction is triggered permantly for edited jobs [MH-12548] - Matterhorn Kernel Test Issues [MH-12547] - Group related settings in custom.properties [MH-12546] - 3.x to 4.0 upgrade is ugly [MH-12545] - Multi Value Editable Loses Value on Blur [MH-12543] - Adjust Log Level During Build Time [MH-12542] - Fix Ingest Service API Dependencies [MH-12541] - Events not searchable after migration if event was subject to a workflow with two publish-engage operations [MH-12540] - Add documentation for WOH failing [MH-12539] - Add documentation for WOH include [MH-12537] - Admin UI Asset upload: Order Assets as listed in properties file (vs alphabetical) [MH-12535] - Add language support for Hebrew [MH-12534] - Broken Labels In Default Workflow [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12529] - External API returns negative Event duration [MH-12526] - External (LDAP) users cannot not see their own role (ROLE_USER_XXXX) in the access policy of the events they create. [MH-12525] - Non-admin users cannot modify ACLs in their own events [MH-12523] - \"Submit\" button in retract modal is always disabled [MH-12522] - Improve Waveform Service Dependency Specification [MH-12520] - Duplicate Series When Double Clicking Create Button [MH-12519] - Improve Admin-NG Dependency Specification [MH-12518] - Ugly exception appears in stdout/Karaf console [MH-12517] - Some job data is not copied correctly [MH-12514] - Opencast Allows Multiple Simultaneous Workflows For Same Media Package [MH-12513] - MigrationService fails [MH-12512] - Frontend-Maven-Plugin configuration is missing the mandatory \"versionRange\" parameter [MH-12511] - Deleting an event with inconsistent search index state doesn't work [MH-12510] - System doesn't recover from ActiveMQ downtime [MH-12507] - Textanalyzer Has Nondeclared Dependencies [MH-12503] - Log statements do not require Object or String arrays to provide 3 parameters or more [MH-12500] - Fix incorrect usage of method \"URL#getFile()\" [MH-12499] - Admin UI event tools dialog can't be closed with the close button [MH-12498] - External API: Cannot get series if description field is empty [MH-12497] - Improve usability of admin UI forms [MH-12492] - AssetManager endpoint return server error on assets, which the user not allowed to read [MH-12489] - Failed test: MySQL DDL Scripts (Update) \ufffc [MH-12488] - Publish worklow always fail [MH-12480] - Waveform Operation Should Have Tests [MH-12479] - Waveform Operation Should Not leave Files In Workspace [MH-12475] - Make mimetypes consistent [MH-12470] - Prematurely deleted scheduler properties lead to undeletable events [MH-12469] - Auto Update OAIPMH republishes deleted Events [MH-12467] - Scheduled event fails due to not finding a workflow definition to use [MH-12465] - Propagate Changes of Series Extended Metadata to Events and OAI-PMH [MH-12463] - Hyphens in event/series search return no results [MH-12456] - Clean Up PathSupport [MH-12455] - FFmpeg does not terminate when Opencast is shut down [MH-12454] - PathSupport.changeFileExtension does not properly handle files with no extension [MH-12453] - TimelinePreview Path Handling [MH-12451] - Lock file utility method should throw exceptions [MH-12450] - Clean up *EncoderEngine code [MH-12449] - Ensure temporary files are deleted on composer failure [MH-12448] - Remove unconfigured send-mail WOH [MH-12447] - OAI-PMH autorepublish fails if series was deleted [MH-12446] - Do not leave ZIP files in workspace when a Workflow fails [MH-12445] - underlying code showing on metadata source tab when creating event [MH-12443] - editing event changes status from scheduled to finished [MH-12442] - Maven site is broken [MH-12436] - Add Christian Greweling to Comitters list [MH-12431] - Update Crowdin translations for r/4.x [MH-12428] - Performance Issue In Event Metadata [MH-12427] - Submit button in Editor typo [MH-12423] - Date Parse Error When Changing Certain Metadata [MH-12420] - Update frontend-maven-plugin [MH-12417] - Poor performace on scheduler /recordings/calendars [MH-12411] - Database user requires additional permissions [MH-12409] - Conductor logs ClassCastException when receiving DeleteSnapshot [MH-12407] - \"The task could not be created\" message by starting task on multiple events [MH-12406] - Splitting in the video editor while a video is playing causes time jump [MH-12401] - Video editor segment times stay blank (timing) [MH-12399] - Oaipmh Retract very slow [MH-12396] - Cannot select filter two times in a row from dropdown [MH-12395] - REST: Handle Scheduling Conflict [MH-12394] - Video editor allows the submission of an event with no active segments [MH-12390] - Gracefully handle unregistration of non-existing host [MH-12385] - Ingest Code Cleanup [MH-12382] - As a system administrator, I want to see the capture agent configuration in the user interface, so that I don't need to look into the database directly [MH-12380] - External API v1.0.0 Broken Due To StartDate Format Change [MH-12372] - Make waveform service more flexible by allowing pre- and post-filters to be configured [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12356] - As an administrator, I'd like to resolve or delete comments in workflows by comment reason only [MH-12355] - Include Wowza Adaptive Streaming Module in Opencast [MH-12354] - Admin UI Video Editor wont let you edit segements at the end [MH-12352] - Include support for user Groups in LDAP [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12349] - Exception handler should not throw an IO exception on deleting temporary directory [MH-12348] - As an administrator, I want to use the \"send-email\" WOH with multiple recipients and also use the CC and BCC fields [MH-12346] - Publications are not shown in the admin interface [MH-12330] - The series WOH only updates the series' title and ID on the episode's catalog, but sometimes more fields should be updated [MH-12328] - Update AngularJS from 1.3.x to 1.4.x [MH-12325] - Maven warning when building r/3.x [MH-12314] - As a developer, I expect the Admin UI tests being skipped if I build Opencast using -DskipTests [MH-12312] - Event Counter For \"Today\" [MH-12309] - Use Matching FontAwesome Icons [MH-12304] - Configurable Notification Durations [MH-12302] - Do Not Warn About Default Configuration [MH-12289] - Publish extended metadata to OAI-PMH [MH-12287] - prevent reload of Admin UI when opening the editor [MH-12286] - As an Opencast admin, I want to set workflow properties from an external script [MH-12284] - Unprivileged users cannot upload any files when creating or editing a theme [MH-12283] - Support MPEG DASH in Player [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12274] - Ingest service REST endpoint should be verbosable and expect input UTF-8 encoded [MH-12266] - As a user, I expect metadata changes to be propagated to third-party applications [MH-12259] - Ingest-download WOH fail on downloading publication elements [MH-12258] - Update angular-translate to version 2.15.2 [MH-12250] - Synchronize Dublin Core date created and start date in DC temporal [MH-12242] - Theodul: Quality selector does not display/load [MH-12234] - Cleanup WOH does not remove all files as it should do [MH-12227] - As a user, I don't want to be informed about services not being working correctly [MH-12223] - Oaipmh Publish is very slow [MH-12200] - Improve LDAP integration after the changes brought by MH-12016 [MH-12196] - Use a date and time picker instead of separate inputs for date and time in admin UI [MH-12191] - Add support for automated captions/transcripts (IBM Watson) [MH-12168] - As a user, I need cross-page links that help me to work more efficiently [MH-12166] - As a user, I'm not willing to perform that many clicks to actually use the filters [MH-12111] - Require Java 8 [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12099] - Wrong started date/time on workflow details view [MH-12082] - Contribute Asset Manager/Scheduler work (ETH) [MH-12052] - As an Administrator, I'd like to know that ActiveMQ is running properly [MH-12000] - Cross-tenant URL signing [MH-11703] - Service error states not immediately visible in admin UI [MH-11458] - Update translations from crowdin [MH-11274] - Workflow Operations of Scheduled Event are not editable [MH-11195] - Ability to Search on part of a Series Identifier, instead of just exact match [MH-11042] - Admin UI NG tests fail in +5:30 timezone [MH-10156] - Misspelling in LtiLaunchAuthenticationHandler.java Opencast 3.x Opencast 3.7 Released on Oct 16, 2018 [ MH-12982 ] - 3.0 database upgrade error [ MH-13022 ] - Fix LTI highly trusted keys being discarded [ MH-13034 ] - Add lis_person_sourcedid back as LTI source field for the username [ MH-13082 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13152 ] - Reduce Workflow Messages, backport of Lars fix for >=r/5.x [ MH-13156 ] - Set the auth scheme to digest for inter-server communication Opencast 3.6 Released on May 31, 2018 [MH-12910] - When switching between branches with different module naming schemes, the git tree is left unclean sometimes [MH-12860] - Opencast does not build at DEBUG logging level [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins [MH-12830] - Fix mvn site generation [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12441] - Fix multi-server configuration docs and config details [MH-12091] - Create a Capture Agent digest user with its own role Opencast 3.5 Released on February 6, 2018 [MH-12620] - Document ActiveMQ memory requirements [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12487] - Add job load settings to the default encoding profles [MH-12399] - Oaipmh Retract very slow Opencast 3.4 Released on December 4, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12516] - Oversize job acceptance logic is incorrect [MH-12505] - composer operations need to set job load from profile load when creating jobs [MH-12501] - Incorrect logging in inbox scanner [MH-12496] - Feeds point to removed embed player [MH-12494] - JMX bean unregistration causing stack traces in unit tests [MH-12478] - Waveform filenames are not unique [MH-12471] - Workspace Cleaner Minor Fix [MH-12464] - Job dispatching can be slowed down excessively by host loads query [MH-12439] - WorkspaceCleaner Should Clean All Files [MH-12437] - Admin UI ng fails mvn clean install if the node_modules exists [MH-12435] - Race condition when workspace file deletion removes collection [MH-12430] - Update Crowdin translations for r/3.x [MH-12422] - Adjust documentation to new Crowdin Opencast project [MH-12421] - Job dispatching halts because of http connection hang [MH-12415] - Improve performance of /api/events?withpublications=true [MH-12363] - org.json.simple.parser.JSONParser is not thread safe [MH-12000] - Cross-tenant URL signing [MH-11361] - date in engage is the creation date, not the recording date [MH-11042] - Admin UI NG tests fail in +5:30 timezone Opencast 3.3 Released on September 21, 2017 [MH-12383] - Upgrade/Unify Library Versions [MH-12413] - Don't present the user a previous/next item button if there is no previous/next item [MH-12405] - Catastrophic Oveload in Calendar generation [MH-12400] - Player: Embed Links disabled [MH-12393] - Retract workflow fails if run when a video is being played (with nfs storage) [MH-12389] - Set operation to failed when setting workflow to failed on exception path [MH-12386] - Update Postgresql Connector [MH-12384] - Catch possible NPE in FileSupport.delete() [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12364] - /broker/status endpoint returns incorrect 204 when ActiveMQ is shut down [MH-12362] - Less verbose logging for ExportWorkflowPropertiesWOH [MH-12360] - Race condition in workspace collection add and delete [MH-12359] - Milliseconds trim bug in videoeditor-workflowoperation formatTime() javaScript [MH-12358] - Only 6 series were displayed on the distribution node [MH-12353] - Theodul player does not load reliably after restart [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12329] - File copy can fail with jetty timeout [MH-12326] - Reduce log level for IllegalStateException in StaticResourceServlet [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12303] - Sort the REST endpoints alphabetically [MH-12131] - Migrate documentation of capture agent communication protocol to markdown [MH-12085] - Make file upload in Admin UI more flexible [MH-11768] - Timeline preview images Opencast 3.2 Released on August 16, 2017 [MH-12347] - Opencast generates invalid XML catalogs when a \"default\" (empty) Namespace is used. [MH-12345] - Ingest fails because /recordings/{id}/acls returns 500 if event has not ACLs [MH-12342] - A \"Scanner\" instance in the ExecuteServiceImpl class is not properly closed: possible resource leak [MH-12333] - Feed generator separates lists of tags incorrectly [MH-12327] - CAS Authentication is not working [MH-12324] - Reduce frequency of index update messages for rebuilds [MH-12318] - Remove Webconsole Default Installation [MH-12316] - IllegalStateException: Committed [MH-12315] - Database Query of Users from UserlistProvider is very slow [MH-12311] - Update Admin UI build tools [MH-12307] - OAI-PMH REST endpoint docs fix [MH-12305] - Admin UI should stop polling event stats if the event tab isn't shown [MH-12288] - Set default max idle time if not configured and log key pool parameters [MH-12280] - Create an Opencast group for Sakai instructors [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12275] - MH-12261 / Avoid race condition between index and cleanup operations [MH-12271] - MH-12261 / Update WFR put action to update files atomically [MH-12270] - Don't swallow unknown SMIL exceptions [MH-12263] - MH-12261 / FileSupport > link - copy file action should use overwrite argument (Throws FileFileAlreadyExists) [MH-12261] - Race condition leads to FileAlreadyExistsException and FileNotFoundException [MH-12079] - Misleading logging in some indexing message receivers [MH-12007] - Revive the Execute Service [MH-11542] - Failed test: Process video after cutting (Safari) [MH-10650] - Intermittent failure to detect hard links when starting a cluster [MH-10523] - Misleading exception parameter in getFileFromCollection Opencast 3.1 Released on July 14, 2017 [MH-12296] - getSeries Performance Issue [MH-12295] - Update Karaf to 4.0.9 [MH-12291] - Remove obsolete Speech Recognition API [MH-12279] - As a user, I expect the video editor to correctly visualize the audio track [MH-12253] - Example workflows are inconsistent in Formatting and Configuration of Publication Options [MH-12215] - Extended metadata should be applied on event create wizard [MH-12157] - Series index query performs bad on system with many series [MH-11742] - Document criteria for inclusion and exclusion of translations Opencast 3.0 Released on June 13, 2017 [MH-12257] - HttpsFilter is not called before OAuthProviderProcessingFilter [MH-12255] - OC cannot add PyCA capture agent when server ending with / [MH-12252] - LTI default launch goes to the wrong URL for sample tool [MH-12249] - Media Module: Paging forgets search parameters [MH-12248] - Capture Calendar Modification Caching Implementation is very Inefficient [MH-12247] - Archive Synchronization fix doesn't working in >=2.3 [MH-12235] - WOH partial-import: No track matching smil Track-id [MH-12230] - Notifications appear again although the user has closed them [MH-12228] - player controls: use dropup instead of a dropdown if controls are below the video [MH-12226] - Add documentation about configuration of publication channel names and icons [MH-12222] - As a user, I don't want an empty tab be presented to me since I don't necessarily understand, what that means [MH-12221] - As a user, I expect meaningful placeholder texts in the filter selection components [MH-12213] - Internal distribution fails if download url is not default [MH-12211] - As a service provider, I need to be able to deal with multiple users that have the same name [MH-12207] - Incorrect comment identifiers in some workflows [MH-12205] - Update version of javax.ws.rs - jsr311-api [MH-12204] - Rearrange the config [MH-12202] - ProxyMiddleware does ignore host port [MH-12199] - 3.x release notes mention \"comprehensive\" LDAP support, which is not (yet) true [MH-12198] - Remove outdated file location in LDAP documentation [MH-12197] - IllegalStateException: Response is committed [MH-12195] - Unprivileged users cannot view media package element details on Recordings->Events->\"Event Details\"->Assets->Media [MH-12193] - OAI-PMH distribution fails on adaptive streaming artifacts [MH-12189] - Sakai userdirectory provider is not properly bundled [MH-12183] - Theodul does not load [MH-12181] - As a course admin, I want to allow roles in the UI for ACLs that match a pattern [MH-12180] - Cannot specify ValuefFor probe-resolution woh [MH-12174] - The Admin UI temporarily displays wrong table content because data is not cleared upon page navigation [MH-12173] - The Admin UI temporarily displays wrong table content because data requests are not cancelled [MH-12170] - Safari does not display metadata once entered [MH-12169] - As a user, I expect search strings to match non-word boundaries in searchable dropdown lists [MH-12167] - As a user, I need to be able to search for values offered by the filters, so that I actually find the value I am looking for [MH-12156] - Fix version of matterhorn-engage-theodul-plugin-custom-piwik [MH-12153] - Reduce Database Space usage [MH-12149] - Upgrade Elastic Search to 1.7.6 [MH-12148] - Undocumented Archive WOH Requirements [MH-12147] - TOC links in REST docs overlap [MH-12142] - As a system administrator, I would like a documented hint that the user running Opencast needs RW access to the optional storage directory [MH-12141] - As service provider, I want to restrict access granted to tenant administrators [MH-12138] - Added release notes [MH-12137] - AWS S3 tries to distribute attachments from OAI-PMH distribution [MH-12133] - OAI-PMH Tests Fails Regularly [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12128] - REST docs are too eager to check for a valid value [MH-12126] - Fast workflow needs AWS distribution to default to false. [MH-12124] - Cutting a video multiple times results in multiple smil/cutting catalogs [MH-12121] - Update grunt-ng-annotate to 3.0.0 and grunt-contrib-uglify to 2.2.0 [MH-12120] - pub service oaipmh wants distribution api [MH-12117] - As an adopter I would like to get collect data with Piwik [MH-12115] - Republish Metadata to OAI-PMH fails [MH-12113] - Update outdated comment about the \"lifecycle-mapping\" plugin in the main pom.xml [MH-12112] - Update Node Version [MH-12110] - frontend-maven-plugin is executed on every module [MH-12109] - Creating comments does not work anymore [MH-12108] - Set Workflow Variables Based On Resolution [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12103] - As a producer, I want to be able to execute WOH partial-import on archived sources [MH-12102] - Add Workflow Variables Based On Media Properties [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12074] - Remove workflow MissedCaptureScanner and MissedIngestScanner [MH-12073] - Typo in rest_docs entry box [MH-12070] - Order the event counters to reflect the event lifecycle [MH-12067] - Initial REST Docs Search [MH-12066] - Missing feature.xml Installation [MH-12065] - Fix bundle info REST endpoint description [MH-12064] - Handle missing meta.abstract gracefully [MH-12060] - Simplify Default WOH [MH-12056] - As an Administrator, I'd like to add some custom roles for managing access [MH-12055] - Update REST Documentation Template [MH-12054] - Incorrect or misleading documentation about WOH conditional execution [MH-12049] - Update REST Documentation Overview [MH-12043] - Allow more then one additional authentication algorithms beside digest [MH-12038] - Fallback decoding for mediapackage date values in unixtime rather than W3CDTF [MH-12037] - NullPoiinterException when starting embedded Solr [MH-12035] - Setting Default Download Directory [MH-12034] - Make the UserAndRoleDirectoryService cache configurable [MH-12033] - Add indicator lights for capture agent status [MH-12032] - Add an authenticated ACL template [MH-12031] - Add additional docs for inspection WOH [MH-12029] - As a user, I want to use my existing AAI login for Opencast, too [MH-12023] - Make development builds faster [MH-12022] - /ingest/addTrackURL broken [MH-12019] - Ensure Test Files Are Deleted [MH-12017] - CoverImage WOH should provide metadata for recording start/end time [MH-12016] - Fix and improve user, group, role and provider handling [MH-12015] - Typo in External API role name [MH-12014] - Incorrect number of roles returned when limit is specified [MH-12013] - Contribute OAI-PMH work (ETH) [MH-12002] - Date & time format should be customizable in cover images [MH-11994] - UserIdRoleProvider should check user existence from user providers [MH-11993] - WOH partial-import should support output framerate [MH-11990] - Remove configuration file of removed module matterhorn-load-test [MH-11982] - As an Opencast administrator, I would like a dashboard counter for active recordings [MH-11979] - The video editor does not highlight the selected segment if it is cut [MH-11978] - Hotkeys for common tasks in Admin UI [MH-11977] - Remove Unused OSGI Bindings From IndexService [MH-11976] - Adjust DownloadDistribution Logs [MH-11975] - Update some maven plugins [MH-11971] - Update maven-surfire-test plugin to latest version [MH-11969] - Fullscreen button in embedded view of Theodul player missing after update to 2.2.4 [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11965] - Update to Karaf 4.0.8 [MH-11957] - Make availability check of WOH publish-configure configurable [MH-11956] - Allow fine-grained control of accurate frame count [MH-11954] - Fixing Javadoc Build [MH-11952] - HTML in Translations [MH-11944] - MH-11817 use keyboard shortcuts to control the editor [MH-11916] - Add convenience workflow instance variable to indicate whether a theme is involved [MH-11910] - WOH composite should be able to respect resolution of its input [MH-11904] - Missing IDClass Warnings [MH-11903] - Cannot Configure Authentication For Webconsole [MH-11902] - Update to latest 5.x MySQL connector [MH-11894] - Suppress context menu on video element [MH-11885] - Add support for search and filtering to Organization->Access Policies [MH-11881] - ArchiveRestEndpoint has conflicting endpoints [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11873] - org.ops4j.pax.web.pax-web-extender-whiteboard causes exception when shutting down [MH-11868] - redesign loginpages [MH-11861] - MH-11817 Change default view to editor in admin ui tools area [MH-11849] - Edit metadata fields by click inside and focus cursor in field [MH-11822] - Admin UI Video Editor - Improved Segment Controls [MH-11821] - Admin UI Video Editor - Comment and Metadata Editing [MH-11818] - Admin UI Video Editor - Improved playback and timeline [MH-11806] - Output Frame Rate on Concat Operation [MH-11797] - Upgrade Karaf to 4.0.6 [MH-11796] - Add support for watermarks to themes [MH-11782] - MH-11780 Create configure-by-dcterm workflow operation handler [MH-11781] - MH-11780 Create tag-by-dcterm workflow operation handler [MH-11780] - As a developer I want to be able to manipulate a workflow based on metadata in the Mediapackage [MH-11766] - enhance REST Ingest/addTrack Ingest/addCatalog Ingest/AddAttachment to add tags [MH-11761] - Captions for player [MH-11732] - Make distribution and retraction efficient [MH-11719] - When configuring LDAP with default file things are broken [MH-11717] - MH-11713 Not possible to add external roles to an ACL through the admin UI [MH-11715] - MH-11713 Externally provisioned roles should not be persisted [MH-11713] - Users may have roles in Opencast which are granted from an external system (e.g. LMS) [MH-11684] - WOH silence does not support tags [MH-11474] - Assigning a user to a certain \"ROLE_GROUP_<name>\" role does not really put the user in such group [MH-11466] - Improve handling of long strings in cover images [MH-11379] - Service to distribute delivery files to AWS S3 [MH-11229] - workflowoperation unit tests are incredible slow [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-10871] - Sakai User Provider for Opencast-Sakai integration [MH-10819] - When creating a new event, metadata field can only be edited by clicking on the pencil icon [MH-10753] - Stale database connection causes job failure [MH-10310] - Add ERROR state for capture agent Opencast 2.3.x Opencast 2.3.5 Released on December 04, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12269] - Clarify in the documentation the recommendation of setting dispatchinterval to 0 applies to non-admin nodes only [MH-12190] - Script injection in Media Module and Player [MH-12000] - Cross-tenant URL signing [MH-11042] - Admin UI NG tests fail in +5:30 timezone Opencast 2.3.4 Released on August 03, 2017 [MH-12183] - Theodul does not load [MH-12203] - Unescaped event and series titles when editing event or series (XSS) [MH-12242] - Theodul: Quality selector does not display/load [MH-12246] - Series WOH does not apply series DublinCore catalogs [MH-12249] - Media Module: Paging forgets search parameters Opencast 2.3.3 Released on May 02, 2017 [MH-10558] - Mime type not identified for matroska / mkv files [MH-10595] - Incident service returns internal server error if cascade=true requested for deleted workflow [MH-10747] - Inputs for capture device should be pre-selected [MH-11736] - Difference in start time displayed in overview and metadata details [MH-11811] - Opencast build fails when system timezone is set to PDT (Pacific Daylight Time) [MH-12048] - Series drop-down not sorted alphabetically in filter [MH-12069] - Deleting an event leaves behind orphaned comments [MH-12095] - Server default timezone can be incorrect [MH-12106] - Preserve user attributes from providers during authentication [MH-12107] - Improve performance of Servers table in Admin UI [MH-12118] - Paging in media module is broken [MH-12129] - Media module only works with english localized browsers [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12148] - Undocumented Archive WOH Requirements [MH-12150] - Matroska files are not recognized [MH-12158] - Workflow job dispatching failures [MH-12162] - JpaJob object toString override for better log messages [MH-12163] - Events with stopped workflows sometimes cannot be deleted [MH-12164] - Updating serviceregistry config while running leaves Opencast in a non-functional state [MH-12190] - Script injection in Media Module and Player Opencast 2.3.2 Released on March 22, 2017 [MH-11224] - Attempting to view source metadata through the new admin UI generates a stack trace [MH-11340] - Uncaught NullPointer Exception in Karaf console from com.entwinemedia.fn.data.json.SimpleSerializer.toJson [MH-11616] - Search Service will not remove mp from index if it is not found in database [MH-11743] - event.hasPreview() broken [MH-11760] - Event edit warning cannot be removed [MH-11790] - Slide Previews and slide text are not shown in Theodul Engage player [MH-11817] - Unhide volume controls in video-editor [MH-11819] - Admin UI Video Editor - Improved Zoom Controls [MH-12009] - Admin UI Video Editor: Segmentation lost after publishing [MH-12058] - Ingests fail if specified workflow does not exist [MH-12059] - Catch invalid dates when indexing [MH-12061] - Reduce the number of activemq messages and log entries during index rebuild [MH-12062] - Improve robustness of scheduler re-indexing [MH-12063] - Catch incomplete archive entries when indexing [MH-12072] - Wrong destinationId for External API message receiver [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12087] - Null bitrate can cause UI display of source media to fail [MH-12092] - Return event ID when event is created through Scheduler API [MH-12097] - SegmentVideoWorkflowOperation: Modules not included in Admin Presentation build. Opencast 2.3.1 Released on Janurary 25, 2017 [MH-11267] - Wrong notification text when deleting series [MH-11458] - Update translations from crowdin [MH-11687] - UI date formats are wrong for most of the English-speaking world [MH-11776] - CaptureAgentStateServiceImplTest incorrectly passes a non-long recording id, misses finding the NullPointer in Impl [MH-11960] - matterhorn-adminui-ng fails on first build [MH-11961] - Cannot access slidetext.xml should not break re-indexing [MH-11963] - Fix ingest REST docs [MH-11966] - Confusing AdminUI Groups Endpoint Documentation [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11983] - Only administrators should be allowed to assign the admin roles to other users [MH-11987] - Declare Admin UI Facade as module internal interface [MH-11988] - Advise to change karaf shutdown command in the docs [MH-11989] - Allow unknown as well as offline CAs to be removed via UI [MH-11992] - Compatibility issue when using contrib Wowza adaptive streaming module [MH-11998] - /info/me.json sometimes doesn't provide full information about the user [MH-12004] - Removing an recording does not remove all correspronding jobs [MH-12005] - UI shows inconsistent version due to missing version in cover-image-remote [MH-12006] - Security Issue Allowing Arbitrary Code Execution Opencast 2.3.0 Released on December 13, 2016 [MH-10342] - As an external device I want to immediate start and stop a capture [MH-11327] - De-couple smilImpl/wfrImpl from ingestImpl [MH-11378] - Conditionally synchronize Archive Service's add mediapackge [MH-11380] - As a customer, I want to integrate my third party application to Opencast, so that I can use Opencast content in my application [MH-11381] - Remove documentation of items that have never been implemented [MH-11411] - move dashboard to header [MH-11675] - Add documentation for External API to the Admin Guide [MH-11688] - Set java file encoding on startup [MH-11718] - As a producer, I want to be able to make workflow settings persistent so that I can reuse them later [MH-11725] - Give users a starting point how to report bugs [MH-11726] - Add AdminUI style guide to developer guide [MH-11728] - Use Apache Commons Lang 3 [MH-11729] - External API: Add documentation for Groups Endpoint [MH-11731] - Typofix Documentation [MH-11737] - Comment (mh_event_comment and mh_event_comment_reply) text field is VARCHAR(255) should be TEXT [MH-11740] - optimization of segmentation [MH-11741] - Admin UI has timezone issues [MH-11749] - External API: Add REST documentation for Endpoints [MH-11750] - Clean-Up Opencast Code Base [MH-11752] - Upgrade Karaf to 3.0.8 [MH-11756] - Admin UI NG Update CSS+HTML (1): FontAwesome, improve HTML, remove redundant images [MH-11763] - Counters hide series tab [MH-11772] - Admin UI source dropdowns inappropriately advance [MH-11774] - Admin UI Needs better documentation for debugging [MH-11775] - Library Update [MH-11783] - Custom publications labels not displayed when doing a mouse-over on Events->Published [MH-11784] - Remove Participation Management Code Pieces [MH-11786] - HttpsRequestWrapper wrongly sets the new URL [MH-11791] - As service provider I want to configure which kind of users can see the event counters [MH-11792] - NPM Proxy via Nexus [MH-11794] - NPM fails on first build [MH-11795] - Add support for title slides [MH-11799] - Maven bundle names too long [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files [MH-11802] - Opencast Logo is missing in Player [MH-11803] - Player redirect is missing [MH-11804] - No video controls in embed mode [MH-11808] - Pre-select workflow in case only one option is available [MH-11809] - Fix syntax error in encoding profile composite.http [MH-11812] - Fix security configuration for ROLE_UI_TASKS_CREATE [MH-11813] - Agent state REST endpoint documentation [MH-11815] - As a user I expect changes to be reflected in the Admin UI immediately [MH-11817] - Admin UI Video Editor - Bug Fixes [MH-11817] - Display video details in preview player/ editor of the admin ui [MH-11817] - Improve Button Hover Indication [MH-11817] - Make Next/Last Frame controls in videoeditor better recognizeable [MH-11827] - Recordings->Events->\"Event Details\"->Metadata: Incorrect translation used [MH-11828] - exception-handler-workflow not set correctly [MH-11829] - High memory usage on the admin server by dispatching jobs [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11834] - Unable to set capture agent configuration as JSON [MH-11836] - Additional ACL actions of series are missing when creating a new event in that series [MH-11837] - Unprivileged users have no access to fonts [MH-11839] - typo in Event Details: Comments [MH-11841] - Wait for NFS shares before start Opencast service [MH-11842] - Revert accidental downgrade of grunt version [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11857] - Fix log output \"Unable to delete non existing object %s/%s\" [MH-11862] - Search API handles roles wrong [MH-11863] - WOH analyze-tracks & WOH failing cause exceptions when shutting down Opencast [MH-11864] - WOH tag shall implement AbstractWorkflowOperationHandler [MH-11865] - Videoeditor Preview mixes in 2 Audiofiles [MH-11866] - Search box in Organization >> Groups not working [MH-11867] - Filter box in Organization >> Groups not working [MH-11869] - Deleting Series with 'Actions' is not working [MH-11870] - Wordlength in other languages except english too long [MH-11871] - ElasticSearch shall bind to 127.0.0.1 [MH-11875] - ActiveMQ should not listen to all hosts by default [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11883] - Larger files may remain in system temp directory [MH-11886] - login pages throw errors on loading unnecessary scripts [MH-11888] - Organization Filter uses Provider where table uses Type [MH-11889] - Row size too large [MH-11890] - MySQL Connector Version Should Be Consistent [MH-11891] - Event counters query large amounts of useless data [MH-11895] - \u201cAdd Event\u201d Wizard Input Fields Broken [MH-11896] - Java Warnings in AbstractEventEndpoint [MH-11897] - Remove Deprecated StringHelper [MH-11898] - Fix Technical Duration Calculation [MH-11899] - Prevent Requesting Event Objects Multiple Times [MH-11900] - Minor Index Service Fixes [MH-11905] - Publish Configure WOH incorrectly retracts publications [MH-11912] - No slider in playback video player [MH-11919] - WOH image claims SUCCEEDED when actually skipping [MH-11920] - WOH prepare-av: Misleading log message [MH-11921] - WOH partial-import looses partial audio tracks in specific cases [MH-11950] - Javadocs build error [MH-11955] - Add en-GB to Languages Opencast 2.2.x Opencast 2.2.5 Released on June 7, 2017 [MH-11983] - Only admins should be able to modify other admins [MH-12006] - Security Issue Allowing Arbitrary Code Execution [MH-11962] - Missing slidetext.xml should not break re-indexing Opencast 2.2.4 Released on October 13, 2016 [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11862] - Search API handles roles wrong [MH-11875] - ActiveMQ should not listen to all hosts by default Opencast 2.2.3 Released on October 13, 2016 [MH-11285] - Improve developers documentation: remote debugger with karaf [MH-11741] - Admin UI has timezone issues [MH-11771] - Improve section localization in developer guide [MH-11773] - Embed player does not use space very well and has scaling problems [MH-11774] - Admin UI Needs better documentation for debugging [MH-11777] - Event Details->Comments and Event Details->Assets don't work for unprivileged users [MH-11787] - Add release dates to changelog [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files Opencast 2.2.2 Released on September 14, 2016 [MH-11194] - created themes not showing up in series branding tab [MH-11572] - FFmpeg Inspection Service Test - accurateFrameCount [MH-11587] - SQL Error [MH-11714] - Fix unit test: Event controller #accessSave saves the event access [MH-11724] - Additional actions not available in create event wizard anymore [MH-11734] - Fix el7 RPM docs [MH-11735] - Fix Stream Security Documentation [MH-11744] - Actions->Start Task: Various localization bugs [MH-11748] - Inconsistent and incorrect use of translate directive [MH-11751] - Player won't work if there are no segments [MH-11755] - No quality selection in Theodul Player [MH-11759] - Make Inspector Unit Tests More Robust Opencast 2.2.1 Released on July 30, 2016 [MH-11092] - Every Browser has an other \"Remember me\" checkbox [MH-11169] - Trimming points not set correctly after workflow is finished [MH-11538] - \"No compatible source was found for this video\" videojs player error in iOS device [MH-11561] - Style (CSS): Setting a server in Maintenance (srv-det-01) [MH-11598] - Wizards should not re-use data that has entered before [MH-11644] - Missing Admin Interface Mock Data [MH-11653] - Jobs do not always proceed [MH-11655] - Jobs with high job load never get processed [MH-11659] - Warning is missing that metada and ACL cannot be edited while job is processing. [MH-11661] - Link on logo on the media module points to admin ui or welcome page, instead of something that is accessable for every user [MH-11664] - Incorrect Inconsistency status when built from tarball [MH-11665] - Systems->Servers & Systems->Services show wrong mean runtime and mean queue time [MH-11667] - Align main table content [MH-11668] - Missing segment previews let to an erro in the player [MH-11669] - Do not archive OCR texts [MH-11673] - Add documentation for additional ACL actions [MH-11674] - Add documentation for metadata configuration [MH-11679] - Page size cannot be changed in any table [MH-11681] - Add documentation for role-based visibility [MH-11682] - Remove useless roles from roles.txt [MH-11686] - Extended metadata tab not shown although user has the role ROLE_UI_EVENTS_DETAILS_METADATA_VIEW [MH-11690] - Various Documentation Improvements [MH-11692] - Remove Superfluous Mh-Db-Version [MH-11693] - Remove Superfluous Dependency Versions [MH-11694] - JavaDoc Generation Broken [MH-11702] - After an upgrade to 2.2.0, series are not displayed in the UI because the series creation date is now mandatory [MH-11720] - Opencast 2.2 requires Git to be installed at build time [MH-11727] - Fix unit test: adminNg.services.language #toLocalTime converts a zulu time string back to local time FAILED [MH-11730] - Make the automatic role prefix in LDAPUserProvider configurable Opencast 2.2.0 Released on June 15, 2016 [MH-9511] - Wrong log level in Tesseract [MH-9831] - ehcache and quartz phones home [MH-9950] - Update player dependencies [MH-10029] - Remove Unnecessary Image Conversion Step From TextAnalysisService [MH-10173] - Do not ignore exceptions when closing Closeable's [MH-10748] - Matterhorn has to be restarted to schedule an event on a new capture device [MH-10794] - Delete Action should be disabled if nothing is selected [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10870] - ActiveMQ Exceptions While Shutting Down Matterhorn [MH-10887] - Users can schedule events in the past [MH-10898] - Update Apache HttpComponents (3.1.7 \u2192 4.4.1) [MH-10923] - Theodul player : Filtering \"composite\" tags results in error when the composite workflow is used [MH-10942] - Events are not deselected after applying a task [MH-10965] - Theodul player : Videos not playable on IE10 [MH-10971] - Newly created Series don't show up in Series dropdown selection lists without page reload [MH-10978] - Unable to retract 'internal' publications [MH-10979] - Opencast needs to better distribute load across the available nodes [MH-10984] - Extend ingest service by partial upload [MH-11010] - Stream Security should be able to prevent cross-tenants access [MH-11014] - Add support for additional ACL actions [MH-11077] - The Publish Workflow will not retract already published material [MH-11097] - View modes not working correctly [MH-11107] - Group list pagination not working [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11139] - Unable to find mimetype for mkv [MH-11140] - Forward and backward buttons are greyed out [MH-11143] - Link to Media Module in Admin UI [MH-11148] - Search box layout incorrect: Icon overlaps text [MH-11156] - Users: Search box not implemented [MH-11157] - Groups: Search box not implemented [MH-11165] - Sorting does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11167] - Layout problem on Workflow Error Details view [MH-11183] - Capture->Locations: Search box not implemented [MH-11190] - Theodul Shortcuts: Description could be improved [MH-11191] - Event Details->Assets: Use human-readable units for duration, bitrates and sizes [MH-11192] - Audio level slider does not change audio level while dragging [MH-11199] - Playback & video editor don't work while workflow is running [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11222] - Replace System.out.println with logger [MH-11229] - workflowoperation unit tests are incredible slow [MH-11252] - Some service configuration files are stored in the wrong directory [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness [MH-11281] - Enhance WOH image to support extraction of multiple images using multiple encoding profiles from multiple sources [MH-11282] - Enhance WOH composite to support single video streams [MH-11287] - Update Apereo/Apache License List [MH-11289] - Change text extraction documentation or file name [MH-11294] - Create admin-worker and ingest distribution [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11300] - WOH partial-import looses partial audio tracks beginning at position zero [MH-11304] - Documentation for WOH partial-import and load configuration not listed in pages configuration [MH-11306] - Change job dispatcher sort order to: restart jobs, non-wf jobs, creation date [MH-11307] - Distribution Service is not on Presentation Node [MH-11310] - Document encoding profiles used by WOH partial-import [MH-11311] - Use existing encoding profiles in WOH partial-import example [MH-11312] - Fix Encode WOH Documentation [MH-11313] - Update Parallel Encode Profiles [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11322] - Update WebM Profiles [MH-11355] - Slide texts are not shown correctly in theodul player, except the first segment there a now slide texts shown (\"No slide text available\"). In the XML file the texts are correct [MH-11356] - Update Documentation Index Page [MH-11357] - Notifications are not removed after a while [MH-11358] - Dismiss Button for comments has an inconsistent design [MH-11363] - Notification that server is not reachable is missing [MH-11364] - Reasons in Comments section are no longer translated [MH-11368] - Changing to Chinese translation doesn't work [MH-11369] - Series filter displays series id instead of series title [MH-11374] - Videoeditor: Times are wrong in zoomed waveform view [MH-11385] - Metadata summary not showing any metadata at event creation [MH-11386] - Silence Detection / Video Editor Waveform bug [MH-11389] - security 1 [MH-11391] - Improve Flavor creation and parsing [MH-11392] - Sorting by series.created does not work correctly [MH-11401] - Hiding of columns is globally broken [MH-11404] - Group editor shows users and roles twice [MH-11405] - Pagination broken for groups table [MH-11409] - Translation key EVENTS.EVENTS.GENERAL.SELECT_WORKFLOW_EMPTY is missing [MH-11413] - AdminUI comment dialog translations missing [MH-11414] - Logger is missing from several modules [MH-11415] - Incorrect Urlsigning Module Name [MH-11416] - Specify Opencast's Requirements [MH-11417] - Tab names of modals not vertically centered [MH-11419] - Tables not drawn correctly [MH-11422] - add event tab titles not translated [MH-11427] - Can't get host details from Serviceregistry REST endpoint [MH-11428] - Default Workflow Option Does Not Work [MH-11430] - Prevent user from accidentally press \"Save & process\" in Video Editor multiple times [MH-11431] - Prevent users from accidentally pressing the Delete/Retract button multiple times [MH-11432] - JSHint settings are missing [MH-11434] - \"The task could not be created\" error notification always appear when starting a task on multiple events [MH-11435] - Fix code style errors in Gruntfile.js [MH-11436] - Matterhorn on Login/Welcome Page [MH-11437] - Resource Problems On Login Page [MH-11438] - Resource Problem on Welcome Page [MH-11439] - Event description not available in WOH cover-image [MH-11441] - Clicking on Logo in top left corner will nmot get you to the start page [MH-11443] - Seeking is not possible before pressing play button at least once?!? [MH-11446] - Remove eclipse-gemini repository from main pom.xml [MH-11447] - Scheduling conflicts reporting completely broken [MH-11448] - Tipps on developing on admin ui ng [MH-11450] - Fix Defaults For Documentation Links [MH-11453] - Correctly link the stream security documentation [MH-11457] - Remove duplicate keys from Admin UI english translation [MH-11458] - Update translations from crowdin [MH-11459] - Logger Logs Nullpointer on Error [MH-11462] - Cover WOH is not included in a useful way [MH-11464] - setting personal preferences in admin UI fails [MH-11468] - There are unused ressources [MH-11475] - Fix typos in English master translation [MH-11476] - Series->Actions->Delete displays wrong notifications [MH-11477] - Editing status of series displays wrong notification when saving fails for all series [MH-11480] - Replace horizontal ellipsis [MH-11481] - Workflows started by unprivileged users hang [MH-11492] - forward and backward section not working in safari [MH-11509] - Failed test: Sorting groups list (grp-lis-01) [MH-11511] - Failed test: Manual set time in textbook for IE11 [MH-11512] - hello world does not follow import statements rules [MH-11518] - Language selector is always displayed in system language [MH-11519] - Languages are only distinguished by main language [MH-11520] - Remove company logos [MH-11521] - ActiveMQ Library Configuration [MH-11522] - DataLoader Default Value [MH-11523] - Working file repository default value [MH-11524] - Distribution Service Default Values [MH-11532] - Wider language support in player [MH-11534] - Add language support for Chinese Simplified [MH-11535] - Add documentation about Crowdin to Developer Guide [MH-11536] - Remove Commercial Code From Core [MH-11537] - Execute Service WOH Cannot be Built [MH-11539] - Remove Old MH Logos in Favor of Opencast SVG Logos [MH-11544] - Admin UI links used inconsistently [MH-11546] - Pagination buttons too small for large numbers [MH-11548] - The \"Edit\" button at the top-right corner of the tables doesn't support localization [MH-11550] - Update Migration documentation 2.1 to 2.2 [MH-11554] - Filtering does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11555] - Localization of Recordings->Events and Recordings->Series buggy [MH-11556] - Failed test: Filter locations (T1733, Filter by status does not work) [MH-11559] - outdated shortcurts configuration prevents player from loading. [MH-11571] - Elasticsearch shutdown command handler crash opencast [MH-11573] - Do not hide warnings [MH-11574] - Jetty Error on Large Workflow Instances [MH-11575] - Inspection Service Tests Fail With Certain FFmpeg Versions [MH-11576] - Servlet Filter Improvements [MH-11578] - Improve default order of columns in Systems->Jobs [MH-11579] - Admin UI mockup data for Systems->Jobs incomplete [MH-11580] - Unit tests for Admin UI language selection broken [MH-11581] - Systems->Jobs table not working correctly [MH-11583] - Fix Code Style [MH-11588] - Create side-by-side preview for video editor [MH-11589] - Feedback button does not work [MH-11590] - The WorkflowServiceImpl constructor sets the \"waitForResources\" argument incorrectly [MH-11594] - Add language support for Galician [MH-11595] - Fix admin ui unit tests for tableService [MH-11597] - Building matterhorn-engage-theodul-plugin-video-videojs reports a lot of code style issues [MH-11600] - Failed test: i18n (gen-int-01) [MH-11601] - current language can have undefined state [MH-11604] - Date picker for setting up the schedule is always french [MH-11605] - Disabling link to mediaplayer creates a broken link and missing logo [MH-11606] - Add language support for Greek [MH-11608] - Add documentation for WOH cleanup [MH-11613] - WOH editor fails when input has uneven width or height [MH-11614] - Partial matches not working anymore [MH-11617] - Add language support for Dutch [MH-11620] - Non privileged user can not login on presentation node [MH-11623] - Server statistics: Slow Query [MH-11624] - Workflow owners do not necessarily have access to their workflows: user comparison fails [MH-11627] - NullPointerException when creating a new Solr index [MH-11629] - Hide Some Confusing Warnings [MH-11630] - Service registry lacks of getActiveJobs() function [MH-11631] - Remove columns \"Blacklisted from\" and \"Blacklisted until\" from Capture->Locations [MH-11632] - Library Bugfix Upgrade [MH-11636] - Adjust FFmpegComposer Logging for Newer FFmpeg Versions [MH-11637] - Add language support for Swedish [MH-11638] - Improve Encoding Profiles [MH-11639] - Media module login form has poor usability and bugs [MH-11642] - Remove binding to non-existing method in WOH analyze-tracks [MH-11643] - Add language support for Polish [MH-11645] - Open AdminUI menu links in new tab does not work [MH-11646] - Add documentation for WOH comment [MH-11652] - Unit tests for servicesController broken [MH-11654] - Failed ingest jobs block system from dispatching other jobs [MH-11656] - Add documentation for WOH copy [MH-11657] - Improve documentation for workflow execution conditions [MH-11658] - Better quality for video editor previews [MH-11663] - Hide Participation Management from UI since not yet working [MH-11666] - Not all WOH listed in WOH overview Opencast 2.1.x Opencast 2.1.2 Released on May 10, 2016 [MH-9831] - ehcache and quartz phones home [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11229] - workflowoperation unit tests are incredible slow [MH-11283] - post-mediapackage WOH breaks further processing [MH-11287] - Update Apereo/Apache License List [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11307] - Distribution Service is not on Presentation Node [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11323] - Workflow Docs are Incorrect [MH-11332] - Document acceptance criteria for proposals [MH-11356] - Update Documentation Index Page [MH-11377] - Opencast does not have an ingest assembly Opencast 2.1.1 Released on January 22, 2016 [MH-11107] - Group list pagination not working [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness Opencast 2.1.0 Released on December 22, 2015 [MH-10637] - Hello World service [MH-10651] - Workspace cleaner job param in wrong units (ms vs s) and wrong logic [MH-10714] - Two clock icons at the time stamp of a comment [MH-10805] - The confirmation dialog are not translated [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10874] - Plugin does not properly handle multiple keys [MH-10875] - Include search capabilities into mkdocs documentation build [MH-10890] - Update Apache Commons Lang (2.6 \u2192 3.4) [MH-10908] - Assemblie Module Names Too Long [MH-10908] - Consistency in Documentation: Presentation Server VS Engage Server [MH-10908] - Misconfigured Checkstyle Plug-in in Assemblies [MH-10919] - Top row for setting roles in the access policy for an event is not showing the right value [MH-10953] - Spanish layout is broken [MH-10955] - Make sure recent versions of mkdocs work [MH-10956] - Update Synchronize.js [MH-10985] - As an operator I want to check the health status of Opencast [MH-10986] - Scheduling around DST change fails [MH-10987] - Improve workflow query to accept paging by index [MH-10988] - Rewrite workspace to fix several small issues [MH-10989] - Improve working file repository stream response [MH-11007] - Remove 3rd party tool script [MH-11026] - Several invalid links in the Opencast User Guides [MH-11031] - Missing option to create new event using files ingested from the inbox [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-11051] - Fix WOH Documentation [MH-11069] - When creating new series, warning about read/write requirements is shown twice. [MH-11072] - The ACL editor needs enhanced validation [MH-11074] - Admin UI Test: New Event API Resource assembles the metadata for SCHEDULE_MULTIPLE with DST change is failing [MH-11083] - Clean-up Codebase after Karaf [MH-11085] - Make sure bundle cache is cleared when restarting [MH-11086] - Shorten File Names in Log Output [MH-11088] - translation error in theodul player [MH-11089] - Theodul player seems not to work with Internet Explorer at all [MH-11093] - single video screen size jump when clicked [MH-11094] - Problems in Theodul controls plugin due to wrong resolves of merge conflicts [MH-11095] - Make assemblies more user firedly [MH-11096] - Errors when loading admin-ng login page [MH-11099] - Removing one role from an Access Policy (acl-det-05) [MH-11101] - Creating a Theme with 2 bumper videos - In and Out (thm-new-01) [MH-11109] - Event details tab cannot handle long event titles well [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11111] - Formatting issues in \u201cTheodul Pass Player - URL Parameters\u201d [MH-11114] - Remove System.out.println from FileReadDeleteTest [MH-11120] - Several Services Fail During Shutdown [MH-11122] - Create Service Files (Systemd/SysV-Init) [MH-11126] - Fix Translation for 2.1 [MH-11133] - i18n: Theme Detail view layout broken in Spanish [MH-11135] - Create Release Manager Docs [MH-11137] - Comment reasons are not working correctly [MH-11138] - Clock icon displayed twice next to comment creation date [MH-11141] - Playback Speed in player needs more useful defaults [MH-11142] - fix translations for shortcuts [MH-11144] - update documentation regarding property for mediamodule logo [MH-11147] - Missing translations: FILTERS.USERS.PROVIDER.LABEL & FILTERS.USERS.ROLE.LABEL [MH-11149] - Filter locations: Translations FILTERS.AGENTS.NAME.LABEL & FILTERS.AGENTS.STATUS.LABEL missing [MH-11151] - Plaback speed from menu [MH-11152] - Editing ACL: Translation for USERS.ACLS.DETAILS.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11153] - Access Policy Details: Cannot navigate to previous or next ACL [MH-11154] - New Access Policy: Translation for USERS.ACLS.NEW.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11155] - ACL Editor: Role not displayed at all [MH-11158] - Playback Tool: Time can be edited, but editing has no effect [MH-11159] - Users sorting: Sort order for 'Name' not correct [MH-11160] - Create Group overwrites existing groups without warning [MH-11162] - security_sample_cas.xml in MH 2.0.1 Points to Wrong Welcome Page [MH-11166] - Number of rows not displayed on Systems->Servers [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11178] - Prevent FFmpeg Experimental AAC Encoder Bug to Affect Opencast [MH-11180] - Update video.js to latest 4.x version [MH-11181] - Flash streaming with multi-quality video does not work [MH-11185] - Event Details->Assets->: Asset size is always 0 [MH-11186] - Event Details->Assets->Media->Media Details: Superfluous row 'Flavor' [MH-11187] - Configuration->Themes: Number of rows not displayed correctly [MH-11189] - Actions->Start Task: User can press create button multiple times [MH-11193] - Setting audio level slider to \"zero\" does not set the actual audio level to \"zero\" [MH-11196] - REST docs cannot be found in new admin ui [MH-11198] - Event dashboard seems not to support i18n [MH-11201] - Maven Assembly Plug-in Listed Twice [MH-11202] - FFmpeg video editor operation is synchronized [MH-11212] - Main Pom Clean-Up [MH-11218] - Karaf based Solr configuration [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11223] - Remove unused files [MH-11234] - Admin-NG throws a couple of 404 errors [MH-11236] - Security ACL see security list [MH-11237] - Service files are missing [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11248] - Publish-Engage Workflow Operation Documentation is Missing Configuration Keys [MH-11249] - Apply-ACL WOH not properly replaced by Seried-WOH in Documentation [MH-11250] - Put temporary files in karaf data not in opencast.storage [MH-11251] - Capture-Admin Tests May Fail When Executed Too Fast [MH-11257] - Deprecated Mkdocs Config [MH-11258] - Make host configuration easier Opencast 2.0.x Opencast 2.0.2 Released on December 22, 2015 [MH-10235] - Users are unable to determine the Version of Matterhorn [MH-10484] - Remove Mediainfo from 3rd-Party-Tools [MH-10558] - Mime type not identified for matroska / mkv files [MH-10588] - Improve MySQL DDL to make it consistent again [MH-10759] - Write QA documentation for Access Policies [MH-10759] - Write QA documentation for Series [MH-10759] - Write QA documentation for Themes [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10918] - Improve the representation of the attachments/catalogs/media/publications in the event details [MH-10956] - Update Synchronize.js [MH-10964] - The Opencast start script does not work on Mac OS X [MH-10976] - Eclipse (m2e) throws NullPointerException erros due to a missing property in the pom.xml file [MH-11007] - Remove 3rd party tool script [MH-11007] - Switch subtitle embedder to FFmpeg [MH-11026] - Several invalid links in the Opencast User Guides [MH-11038] - Make ListProviderScanner Scanner Less verbose [MH-11048] - admin ui tries to load missing library [MH-11051] - Fix WOH Documentation [MH-11060] - ActiveMQ settings filename fix (r/2.0.x) [MH-11068] - Table 'mh_bundleinfo' doesn't exist [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11181] - Flash streaming with multi-quality video does not work [MH-11202] - FFmpeg video editor operation is synchronized [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11236] - Security ACL see security list [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11256] - Opencast docs do not build anymore Opencast 2.0.1 Released on September 3, 2015 [MH-10822] - Possible to create new access policy template without a role with read/write permissions [MH-10938] - Missing views counter in player [MH-10941] - Usertracking Service Missing Endpoint [MH-10955] - Make sure recent versions of mkdocs work [MH-10962] - Add missing licenses to NOTICES [MH-10968] - Add note about ffmpeg/libav on Ubuntu [MH-10975] - async loading of translations [MH-10995] - Gathering workflow statistics for JMX causes extreme performance issues Opencast 2.0.0 Released on July 17, 2015 [MH-9950] - \"Clean up\"/Split up nested functions in the core routine (core.js) [MH-9950] - Load CSS files in the core HTML file, not the JavaScript [MH-9950] - Scrolling is required to see the controls if they are configured to be below the video. [MH-9950] - Some Keys don't work [MH-9950] - Theodul Core Jasmine Tests Sometimes Failing [MH-10029] - FFmpeg based Videosegmenter [MH-10140] - Capture agent with no configuration is always shown as \"idle\" [MH-10202] - No ACL in new series when ingested a new mediapackage with a new series. [MH-10230] - Typos on the welcome page [MH-10332] - Remove Mediainfo Inspection Service [MH-10382] - Add a UI Element to Easily Unregister Capture Agents [MH-10419] - Improve user tracking tables [MH-10510] - Move Workflow Operation Handler into their own Packages [MH-10550] - Non-Interactive Foreground Mode For Matterhorn [MH-10572] - ShibbolethLoginHandler: 500 Error when login the first time [MH-10594] - Re-configure Start Scripts for Different Deployment Types [MH-10615] - Enable Optional Compiler Arguments [MH-10620] - Port Silence Detector from GStreamer to FFmpeg [MH-10622] - Wave Generation Improvement [MH-10623] - Set Sensible Default for Workspace Cleanup Period [MH-10624] - Fixes for FFmpeg Videosegmenter (Set Binary) [MH-10630] - Extending common functionality [MH-10631] - Scheduler service authorization handling [MH-10635] - Text extractor dead lock [MH-10640] - several problems with the metadata form to create a new event [MH-10656] - Login Screen: Placeholder and Focus [MH-10658] - Email template: diverse problems [MH-10664] - What is a template in Access Policy and how do I create it? [MH-10665] - 404 for variables.json [MH-10667] - Previous Button does not always work [MH-10681] - Time is missing when a workflow operation has been started and stopped [MH-10683] - Remove Capture Agent [MH-10683] - Remove the Capture Agent integration tests [MH-10684] - Admin UI seems only unresponsive if server is down [MH-10689] - I should get a warning, if I leave the Admin UI while I still create an event (upload a file) [MH-10698] - workflow after videoeditor does not produce any */delivery flavors [MH-10700] - Service Registry throws NPE exception on startup [MH-10704] - Workflows fail if adding themes [MH-10705] - Row counter in Jobs table is 1 too much [MH-10707] - Unit Test Failure [MH-10710] - NullPointerException in VideoSegmentationWOH [MH-10711] - OptimisticLockException after ingest [MH-10712] - Workflow cleanup out of memory error [MH-10713] - Cache util blocks forever [MH-10726] - Archive operation should use filesystem copy rather than http download [MH-10736] - Engage is currently broken and won't play videos but Theodule does [MH-10740] - NPE in ToolsEndpoint [MH-10746] - There is no event status column [MH-10758] - Issues found in production use of Theodul: changing icons, seeking in Chrome, using configured logos, wording, layout... [MH-10759] - Write QA documentation for Events [MH-10759] - Write QA documentation for Groups [MH-10759] - Write QA documentation for Servers [MH-10759] - Write QA documentation for Services [MH-10763] - Remove Old Confirations [MH-10765] - Operation details doesn't show operation attributes when state is instantiated [MH-10768] - Workflow operations table in the events details should refresh automatically [MH-10769] - Add (x) icon in the events and series tableview to allow deletion of single Events/Series [MH-10770] - Some captions of tabs are not yet translated [MH-10772] - Ensure that buttons order is consistent in the actions column [MH-10773] - Allow to have free-text value for presenters, contributors, organizers or publishers [MH-10774] - ACL editing should be locked on the Series level when events of the series are being processed [MH-10775] - All the roles with read/write rights can be deleted from the ACL editor in Events/Series details [MH-10776] - Include Spanish and French translation into Theodul. [MH-10780] - Specify Requirements [MH-10781] - Respect tags while filtering for suitable tracks in Theodul player [MH-10792] - Pom.xml Extra Modules [MH-10798] - Event Details tile shows hash identifier [MH-10799] - Videoeditor operation does not properly handle missing preview formats [MH-10804] - It is unclear in which timezone you schedule in the admin-ui [MH-10807] - New event POST request contains every series and user [MH-10808] - Disable Demo Users [MH-10810] - Rename upgrade script form 1.6 to 2.0 [MH-10812] - Use bundles.configuration.location in admin ng settings.yml [MH-10814] - Pressing play while buffering breaks player [MH-10816] - Move Message Broker Configuration to Global Config [MH-10821] - Severe Issue with Scheduled Events [MH-10829] - Unchecking \"Remember me\" checkbox has no effect when logged out. Pressing the browsers back button you're still logged in an d can use all functions. [MH-10836] - Issues with matterhorn-engage-theodul-plugin-archetype [MH-10837] - Bulk deletion of events doesn't work correctly [MH-10843] - different video qualities are not filtered correctly. [MH-10845] - Summary of \"Add Events\" and \"Add Series\" shows irrelevant data [MH-10847] - Missing with-role directive in \"Start Task\" option in Actions dropdown [MH-10848] - Event conflict endpoint returns Server error 500 [MH-10849] - Temporary videoeditor files get not deleted [MH-10850] - Interface MatterhornConstans has a typo [MH-10853] - Improve admin UI ng workflows [MH-10855] - Task Menu displays wrong UI [MH-10864] - Remove Trailing Spaces From Less Files [MH-10866] - Documentation: Incorrect Repository Links [MH-10868] - Linebreak before last segment in player [MH-10873] - capture-admin-service-impl tests randomly failing [MH-10876] - Admin UI NG makes calls to remote resources [MH-10880] - Remote base keeps try to call a service [MH-10881] - Wrong links to r/2.0.x on documentation page [MH-10884] - WokflowOperation getTimeInQueue should return 0 if value is NULL [MH-10888] - Theodul player: audio-only does not work - player checked for unavailable size. [MH-10901] - Execute Service is not in main pom.xml and will not be built [MH-10902] - ./modules/matterhorn-publication-service-youtube/ obsolete [MH-10905] - FFmpeg videoeditor only works with audio and video available [MH-10911] - Remove executable flag from non-executables [MH-10912] - Init scripts contain undefined references to DEBUG_PORT and DEBUG_SUSPEND [MH-10913] - Add Event: License Metadata Field Text [MH-10924] - Update to new Opencast logos [MH-10926] - Extensive PhantomJS warnings when building admin-ng [MH-10928] - Adjust loglevel in DictionaryService [MH-10929] - Cutting and Review are skipped when config is set to do so [MH-10930] - Fix missing German translation [MH-10934] - Once set, one cannot remove some metadata in the create event dialog [MH-10938] - Missing views counter in player [MH-10939] - Task Summary does not display configuration values [MH-10946] - Fix Opencast 2 Installation Guides [MH-10950] - Fix DDL Readme [MH-10952] - Fix matterhorn-execute-operations naming [MH-10957] - Add License Guide for Developers","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#opencast-10","text":"","title":"Opencast 10"},{"location":"changelog/#opencast-101","text":"Released on July 14th, 2021 [ #2830 ] - Remove Unnecessary Error Logging [ #2829 ] - Handle Ingest with Unavailable Media Package Element [ #2827 ] - Transformer Factory Identification [ #2816 ] - Remove all Java 8 packages in the Java upgrade guide [ #2815 ] - Fix publication of language tagged metadata [ #2813 ] - Don't Ask Developers to Register [ #2812 ] - Fix Possible NullPointerException During Ingest [ #2807 ] - Fix Prepare-AV Target Tag Handling [ #2805 ] - Remove Harvester Configuration [ #2791 ] - Fix Assembly Builds [ #2787 ] - Prevent workflow from failing if we have no logs [ #2776 ] - Fix Workflow Operation Documentation [ #2768 ] - Fix Upgrade Documentation [ #2766 ] - Document Opencast 10 RPM Install [ #2765 ] - Fix Wowza Streaming Misconfiguration [ #2764 ] - Remove Unused Dependency on Series Service [ #2763 ] - Hello World Configuration Example [ #2762 ] - Small additions and improvements in search service (for the upcoming Tobira module) [ #2761 ] - Prevent Users From Modifying ICLA Workflow [ #2748 ] - Simplify Publication Check [ #2747 ] - Fix jakarta.mail Dependency Problem [ #2740 ] - Fix Log Statements [ #2724 ] - Remove Usertracking from Worker [ #2721 ] - Update Admin Interface Dependencies [ #2720 ] - Fixed admin interface tests in certain timezones [ #2706 ] - Add Integration Tests [ #2698 ] - Improved Error Handling","title":"Opencast 10.1"},{"location":"changelog/#opencast-100","text":"Released on June 15th, 2021 [ #2741 ] - Add JVM Metrics to Release Notes [ #2730 ] - Use version variable in poms [ #2713 ] - Update Opencast Studio to 2021-06-11 [ #2708 ] - Add info about renamed enum name of search API to release notes [ #2694 ] - Add JVM metrics to metrics exporter [ #2691 ] - Document Start Task Endpoint [ #2677 ] - Move just the latest snapshot to S3 [ #2673 ] - Don't list docs twice [ #2667 ] - Removed Paella Player Play Button when pausing playback [ #2648 ] - Spelling Fixes [ #2647 ] - Fix broken distributions [ #2645 ] - Update to Elasticsearch 7.10.2 [ #2644 ] - Use millisecond precision in Solr date range queries (instead of secs) [ #2643 ] - Set modified date to deletion date when an event is deleted [ #2625 ] - Add Description to republish-metadata [ #2624 ] - Update ActiveMQ Client [ #2623 ] - Update CXF [ #2619 ] - Autoconfigure Job Dispatching [ #2554 ] - Retract publications before deleting events [ #2387 ] - Update Managed ACLs in Elasticsearch Indices directly [ #2354 ] - Update Themes in Elasticsearch Indices directly [ #2311 ] - Update Comments in ElasticSearch Indices directly [ #2612 ] - Add board members to governance page [ #2611 ] - Bump @types/node from 15.0.2 to 15.3.0 in /modules/lti [ #2610 ] - Bump i18next from 20.2.2 to 20.2.4 in /modules/lti [ #2609 ] - Bump react-bootstrap from 1.5.2 to 1.6.0 in /modules/lti [ #2608 ] - Bump react-select from 4.3.0 to 4.3.1 in /modules/lti [ #2607 ] - Bump @types/react-dom from 17.0.3 to 17.0.5 in /modules/lti [ #2606 ] - Bump bootstrap from 5.0.0 to 5.0.1 in /modules/lti [ #2605 ] - Fix Graphs in Documentation [ #2601 ] - Bump karma from 5.2.3 to 6.3.2 in /modules/admin-ui-frontend [ #2600 ] - Bump grunt-karma from 4.0.0 to 4.0.2 in /modules/admin-ui-frontend [ #2590 ] - New woh: conditional-config [ #2589 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/engage-ui [ #2588 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/engage-theodul-core [ #2587 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/runtime-info-ui [ #2586 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/runtime-info-ui-ng [ #2583 ] - Bump i18next-browser-languagedetector from 6.1.0 to 6.1.1 in /modules/lti [ #2582 ] - Bump bootstrap from 4.6.0 to 5.0.0 in /modules/lti [ #2581 ] - Bump @types/react from 17.0.4 to 17.0.5 in /modules/lti [ #2580 ] - Bump @types/node from 15.0.1 to 15.0.2 in /modules/lti [ #2579 ] - Bump node-sass from 5.0.0 to 6.0.0 in /modules/admin-ui-frontend [ #2578 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/admin-ui-frontend [ #2577 ] - Bump eslint from 7.25.0 to 7.26.0 in /modules/engage-paella-player [ #2572 ] - Dont index groups (fixes distributed develop) [ #2558 ] - Add organization ID to the S3 distribution object path [ #2555 ] - Add Java Version to Upgrade Docs [ #2551 ] - Bump @types/react from 17.0.3 to 17.0.4 in /modules/lti [ #2550 ] - Bump react-i18next from 11.8.13 to 11.8.15 in /modules/lti [ #2549 ] - Bump @types/node from 14.14.41 to 15.0.1 in /modules/lti [ #2548 ] - Bump @types/jest from 26.0.22 to 26.0.23 in /modules/lti [ #2547 ] - Bump i18next from 20.2.1 to 20.2.2 in /modules/lti [ #2542 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/engage-theodul-core [ #2541 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/runtime-info-ui [ #2540 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/runtime-info-ui-ng [ #2539 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/engage-ui [ #2538 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/admin-ui-frontend [ #2537 ] - Bump eslint from 7.24.0 to 7.25.0 in /modules/engage-paella-player [ #2533 ] - Bump grunt from 1.3.0 to 1.4.0 in /modules/admin-ui-frontend [ #2531 ] - Hand over Elasticsearch Index to Services for Index Rebuild [ #2529 ] - Expose some of the S3 client configuration for assets [ #2524 ] - Merge r/9.x into develop [ #2523 ] - Bump @types/node from 14.14.37 to 14.14.41 in /modules/lti [ #2522 ] - Bump @types/react-select from 4.0.14 to 4.0.15 in /modules/lti [ #2521 ] - Bump react-i18next from 11.8.12 to 11.8.13 in /modules/lti [ #2520 ] - Do not build against Java 8 [ #2518 ] - Update Note About commons-lang/2.x [ #2517 ] - Java Library Update [ #2515 ] - Update Prometheus Libraries [ #2514 ] - Update Database Driver [ #2508 ] - Remove standard check-availability for publication [ #2507 ] - Change Paella Usertracking Default [ #2505 ] - Bump underscore from 1.13.0 to 1.13.1 in /modules/engage-ui [ #2503 ] - Bump chromedriver from 89.0.0 to 90.0.0 in /modules/admin-ui-frontend [ #2495 ] - Bump js-yaml from 4.0.0 to 4.1.0 in /modules/engage-ui [ #2488 ] - Bump underscore from 1.12.1 to 1.13.0 in /modules/engage-ui [ #2487 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/engage-ui [ #2486 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/engage-theodul-core [ #2485 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/runtime-info-ui [ #2484 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/runtime-info-ui-ng [ #2483 ] - Bump i18next from 20.1.0 to 20.2.1 in /modules/lti [ #2482 ] - Bump @types/react-helmet from 6.1.0 to 6.1.1 in /modules/lti [ #2481 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/admin-ui-frontend [ #2480 ] - Bump eslint from 7.23.0 to 7.24.0 in /modules/engage-paella-player [ #2471 ] - Remove broken admin-frontend test [ #2469 ] - Bump @types/react-select from 3.0.21 to 4.0.14 in /modules/lti [ #2468 ] - Bump grunt-cli from 1.4.1 to 1.4.2 in /modules/admin-ui-frontend [ #2466 ] - Bump y18n from 4.0.0 to 4.0.1 in /modules/admin-ui-frontend [ #2465 ] - Exclude Dependabot from ICLA Check [ #2463 ] - Bump grunt-contrib-uglify from 5.0.0 to 5.0.1 in /modules/admin-ui-frontend [ #2461 ] - Bump y18n from 3.2.1 to 3.2.2 in /modules/engage-paella-player [ #2459 ] - Remove a duplicate dependency declaration [ #2458 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/engage-ui [ #2457 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/engage-theodul-core [ #2456 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/runtime-info-ui-ng [ #2455 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/runtime-info-ui [ #2454 ] - Bump @types/node from 14.14.35 to 14.14.37 in /modules/lti [ #2453 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/admin-ui-frontend [ #2452 ] - Bump eslint from 7.22.0 to 7.23.0 in /modules/engage-paella-player [ #2450 ] - Bump i18next from 19.9.2 to 20.1.0 in /modules/lti [ #2449 ] - Bump react-i18next from 11.8.10 to 11.8.12 in /modules/lti [ #2448 ] - Bump react and react-dom in /modules/lti [ #2447 ] - Bump i18next-browser-languagedetector from 6.0.1 to 6.1.0 in /modules/lti [ #2445 ] - Bump @types/jest from 26.0.21 to 26.0.22 in /modules/lti [ #2444 ] - Bump @types/react-dom from 17.0.2 to 17.0.3 in /modules/lti [ #2441 ] - fixed publish-configure argument in fast-HLS [ #2439 ] - Bump grunt-cli from 1.3.2 to 1.4.1 in /modules/admin-ui-frontend [ #2434 ] - Bump @fortawesome/free-solid-svg-icons from 5.15.2 to 5.15.3 in /modules/lti [ #2433 ] - Bump @fortawesome/fontawesome-svg-core from 1.2.34 to 1.2.35 in /modules/lti [ #2432 ] - Bump query-string from 6.14.1 to 7.0.0 in /modules/lti [ #2431 ] - Bump react-select from 4.2.1 to 4.3.0 in /modules/lti [ #2430 ] - Bump @types/node from 14.14.34 to 14.14.35 in /modules/lti [ #2429 ] - Bump @types/jest from 26.0.20 to 26.0.21 in /modules/lti [ #2426 ] - Bump @types/react-select from 3.0.21 to 4.0.13 in /modules/lti [ #2425 ] - Bump jasmine-core from 3.7.0 to 3.7.1 in /modules/admin-ui-frontend [ #2422 ] - Bump jasmine-core from 3.6.0 to 3.7.0 in /modules/admin-ui-frontend [ #2421 ] - Create Dependabot config file [ #2412 ] - Bump underscore from 1.12.0 to 1.12.1 in /modules/engage-ui [ #2408 ] - Bump react-scripts from 3.4.1 to 4.0.3 in /modules/lti [ #2406 ] - Bump @types/node from 14.14.32 to 14.14.34 in /modules/lti [ #2405 ] - Bump react-i18next from 11.8.9 to 11.8.10 in /modules/lti [ #2404 ] - Bump @types/react-dom from 17.0.1 to 17.0.2 in /modules/lti [ #2403 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/admin-ui-frontend [ #2402 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/runtime-info-ui [ #2401 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/engage-theodul-core [ #2400 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/engage-ui [ #2399 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/runtime-info-ui-ng [ #2398 ] - Bump eslint from 7.21.0 to 7.22.0 in /modules/engage-paella-player [ #2396 ] - Fix 9.x to develop merge conflicts [ #2392 ] - [Security] Bump yargs-parser from 5.0.0 to 5.0.1 in /modules/engage-paella-player [ #2389 ] - Bump i18next from 19.8.9 to 19.9.2 in /modules/lti [ #2388 ] - [Security] Bump elliptic from 6.5.3 to 6.5.4 in /modules/lti [ #2385 ] - Bump @types/react from 17.0.2 to 17.0.3 in /modules/lti [ #2384 ] - Bump react and react-dom in /modules/lti [ #2383 ] - Bump @types/node from 14.14.31 to 14.14.32 in /modules/lti [ #2382 ] - Bump react-i18next from 11.0.0 to 11.8.9 in /modules/lti [ #2381 ] - Bump react-select from 4.1.0 to 4.2.1 in /modules/lti [ #2380 ] - Bump chromedriver from 88.0.0 to 89.0.0 in /modules/admin-ui-frontend [ #2379 ] - Bump jquery from 3.5.1 to 3.6.0 in /modules/engage-ui [ #2378 ] - Bump jquery from 3.5.1 to 3.6.0 in /modules/runtime-info-ui-ng [ #2377 ] - Bump markdownlint-cli from 0.27.0 to 0.27.1 in /docs/guides [ #2376 ] - Bump jquery from 3.5.1 to 3.6.0 in /modules/runtime-info-ui [ #2375 ] - Bump markdownlint-cli from 0.26.0 to 0.27.0 in /docs/guides [ #2372 ] - Bump query-string from 6.14.0 to 6.14.1 in /modules/lti [ #2369 ] - Bump react-dom from 16.13.1 to 16.14.0 in /modules/lti [ #2367 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/admin-ui-frontend [ #2366 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/engage-theodul-core [ #2365 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/runtime-info-ui [ #2364 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/engage-paella-player [ #2363 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/engage-ui [ #2362 ] - Bump eslint from 7.20.0 to 7.21.0 in /modules/runtime-info-ui-ng [ #2350 ] - Bump react from 16.13.1 to 16.14.0 in /modules/lti [ #2349 ] - Bump @types/jest from 26.0.14 to 26.0.20 in /modules/lti [ #2348 ] - Bump typescript from 3.6.3 to 3.9.9 in /modules/lti [ #2347 ] - Bump @fortawesome/react-fontawesome from 0.1.11 to 0.1.14 in /modules/lti [ #2345 ] - Bump @types/react-dom from 16.9.8 to 17.0.1 in /modules/lti [ #2342 ] - Bump @types/node from 14.14.21 to 14.14.31 in /modules/lti [ #2341 ] - Bump i18next from 17.3.1 to 19.8.9 in /modules/lti [ #2337 ] - Bump url-parse from 1.4.7 to 1.5.1 in /modules/admin-ui-frontend [ #2333 ] - Added doc string to UserEndoint for the admin API [ #2326 ] - Bump @types/react from 16.9.50 to 17.0.2 in /modules/lti [ #2325 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/admin-ui-frontend [ #2324 ] - Bump grunt-contrib-cssmin from 3.0.0 to 4.0.0 in /modules/admin-ui-frontend [ #2323 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/runtime-info-ui-ng [ #2322 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/engage-ui [ #2321 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/runtime-info-ui [ #2320 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/engage-theodul-core [ #2319 ] - Bump eslint from 7.19.0 to 7.20.0 in /modules/engage-paella-player [ #2315 ] - Bump query-string from 6.13.1 to 6.14.0 in /modules/lti [ #2307 ] - Don't Store Documentation Redirect in History [ #2303 ] - Bump react-select from 3.1.0 to 4.1.0 in /modules/lti [ #2293 ] - Added the access_policy field to elasticsearch and made it searchable [ #2289 ] - Start Index Rebuild directly [ #2288 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/admin-ui-frontend [ #2287 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/engage-paella-player [ #2286 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/engage-theodul-core [ #2285 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/runtime-info-ui-ng [ #2284 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/runtime-info-ui [ #2283 ] - Bump eslint-plugin-header from 3.1.0 to 3.1.1 in /modules/engage-ui [ #2269 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/admin-ui-frontend [ #2268 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/runtime-info-ui [ #2267 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/engage-paella-player [ #2266 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/runtime-info-ui-ng [ #2265 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/engage-ui [ #2264 ] - Bump eslint from 7.18.0 to 7.19.0 in /modules/engage-theodul-core [ #2262 ] - Remove dom4j [ #2255 ] - Clean up PR review documentation [ #2252 ] - Bump bootstrap from 4.5.3 to 4.6.0 in /modules/lti [ #2250 ] - Bump chromedriver from 87.0.7 to 88.0.0 in /modules/admin-ui-frontend [ #2240 ] - [Security] Bump socket.io from 2.3.0 to 2.4.1 in /modules/admin-ui-frontend [ #2232 ] - Bump bower from 1.8.10 to 1.8.12 in /modules/admin-ui-frontend [ #2231 ] - Bump chromedriver from 87.0.5 to 87.0.7 in /modules/admin-ui-frontend [ #2230 ] - Don't ask Dependabot to sign ICLA [ #2229 ] - Bump @fortawesome/fontawesome-svg-core from 1.2.30 to 1.2.34 in /modules/lti [ #2227 ] - Bump @types/node from 14.11.2 to 14.14.21 in /modules/lti [ #2226 ] - [Security] Bump semver from 2.3.2 to 5.3.0 in /modules/admin-ui-frontend [ #2225 ] - [Security] Bump handlebars from 4.5.3 to 4.7.6 in /modules/admin-ui-frontend [ #2224 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/admin-ui-frontend [ #2223 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/runtime-info-ui [ #2222 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/engage-theodul-core [ #2221 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/engage-ui [ #2220 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/engage-paella-player [ #2219 ] - Bump eslint from 7.17.0 to 7.18.0 in /modules/runtime-info-ui-ng [ #2217 ] - Bump bower from 1.8.8 to 1.8.10 in /modules/admin-ui-frontend [ #2212 ] - Securing Static Files by Default [ #2211 ] - Refactor Index Rebuild [ #2210 ] - Document use of self-signed certificates [ #2209 ] - Check ICLA only on pull request [ #2208 ] - Fix user tracking duplicate session key error [ #2206 ] - Update Development Process [ #2200 ] - Bump chromedriver from 87.0.4 to 87.0.5 in /modules/admin-ui-frontend [ #2195 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/admin-ui-frontend [ #2194 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/runtime-info-ui-ng [ #2193 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/engage-theodul-core [ #2192 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/runtime-info-ui [ #2191 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/engage-ui [ #2190 ] - Bump eslint from 7.16.0 to 7.17.0 in /modules/engage-paella-player [ #2189 ] - Bump js-yaml from 3.14.1 to 4.0.0 in /modules/engage-ui [ #2175 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/admin-ui-frontend [ #2174 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/engage-theodul-core [ #2173 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/engage-ui [ #2172 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/runtime-info-ui [ #2171 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/engage-paella-player [ #2170 ] - Bump eslint from 7.15.0 to 7.16.0 in /modules/runtime-info-ui-ng [ #2163 ] - Added upload progressbar to the LTI upload tool [ #2159 ] - Bump markdownlint-cli from 0.25.0 to 0.26.0 in /docs/guides [ #2156 ] - Fix Google transcription service indefinite errors generation #1664 #2146 [ #2154 ] - Move governance document from website to docs [ #2151 ] - Fix paths to docker-compose development files [ #2144 ] - [Security] Bump ini from 1.3.5 to 1.3.8 in /modules/lti [ #2141 ] - [Security] Bump ini from 1.3.5 to 1.3.8 in /modules/admin-ui-frontend [ #2140 ] - [Security] Bump ini from 1.3.5 to 1.3.8 in /modules/engage-paella-player [ #2138 ] - Adding Step-by-Step to Config docs and Minor Documentation Changes [ #2126 ] - Bump js-yaml from 3.14.0 to 3.14.1 in /modules/engage-ui [ #2125 ] - Standardization of Tag and Flavor handling [ #2102 ] - Added link to recordings to docs landing page [ #2065 ] - Fixes Maven dependencies in remaining modules [ #2053 ] - Fixes Maven dependencies in modules: common-jpa-impl, common, and cover-image-impl [ #2052 ] - Check for Apereo CLA [ #2027 ] - Bump node-sass from 4.14.1 to 5.0.0 in /modules/admin-ui-frontend [ #2019 ] - Users in the admin ui filter can be reduced via regex now. [ #1959 ] - Bump bootstrap from 4.5.0 to 4.5.3 in /modules/lti [ #1955 ] - Remove Ingest service reference from duplicate event WOH [ #1938 ] - One place for streaming configuration [ #1909 ] - Enable ESLint for Theodul Player [ #1902 ] - Drop broken theodul-plugin-timeline-statistics [ #1877 ] - Extended CoverImageWOH to be able to use extended and series metadata [ #1784 ] - Bump i18next-browser-languagedetector from 3.1.1 to 6.0.1 in /modules/lti [ #1634 ] - LDAP Group Mapping","title":"Opencast 10.0"},{"location":"changelog/#opencast-9","text":"","title":"Opencast 9"},{"location":"changelog/#opencast-97","text":"Released on July 15th, 2021 [ #2793 ] - More HTML validation for AdminUI [ #2790 ] - Fix file permissions of start-opencast [ #2788 ] - Introduce Allinone Profile [ #2778 ] - Cut Marks Attachments [ #2771 ] - Documentation Deployment Conflicts [ #2770 ] - Link Video in Installation Guide [ #2736 ] - Fix processing of fast events [ #2723 ] - Limit Ingest Filename Length [ #2722 ] - Default for Access Control Entry Allow [ #2719 ] - Closing tags for non-void elements in Admin UI [ #2717 ] - Make Series Endpoint Accept Metadata Fields [ #2714 ] - Fix pagination in engage-ui [ #2710 ] - Recognize more input types in WF configuration [ #2678 ] - OAI-PMH Sets [ #2543 ] - Exclude user provider configuration for contributors list provider [ #2535 ] - Prevent Ingests with Illegal Data","title":"Opencast 9.7"},{"location":"changelog/#opencast-96","text":"Released on June 15th, 2021 [ #2734 ] - Prepare AV fix for fast workflow: add textual warning to docs [ #2719 ] - Closing tags for non-void elements in Admin UI [ #2718 ] - Closing tags for consecutive select elements [ #2715 ] - Update pull request template's URL [ #2714 ] - Fix pagination in engage-ui [ #2702 ] - Update Elasticsearch adopter documentation [ #2697 ] - Admin UI theme wizard fixed (fixes #2460) [ #2696 ] - Fix Media Package Series ACL Update [ #2695 ] - Fixes removing a series from an event [ #2692 ] - Admin UI editor segment list item delete button position fixed [ #2676 ] - Event status will not change after removing the workflow [ #2675 ] - Add workflow state for standalone editor [ #2665 ] - Removing references to registering on pkg.opencast.org since this is no longer required [ #2656 ] - Require EDIT role for editing metadata in Admin UI [ #2654 ] - Update examples in publish-configure WOH's docs [ #2653 ] - Meta publication handling by publish-configure WOH [ #2652 ] - change translation for the video file upload from the lti tool [ #2651 ] - fix language for the captions upload, als dfxp is supported now [ #2646 ] - Wording error in release notes regarding Amberscript transcriptions? [ #2630 ] - Update Adopter Registration [ #2629 ] - Add missing new line in Elasticsearch admin docs [ #2626 ] - Update new editor to release 2021-05-20 [ #2620 ] - Replacing remaining Freenode references with Matrix [ #2617 ] - Estimate number of frames if not declared in file [ #2615 ] - Ignore not found exception when automatically archiving to another storage [ #2614 ] - Fix variable always resolving to the default value even when set [ #2604 ] - Fix kernel test with running Opencast [ #2594 ] - Series list provider should use admin UI index [ #2574 ] - Silence detection should create media duration properties [ #2571 ] - Fixed display error for the start date filter in the Admin UI [ #2568 ] - Temporarily Ignore Failing Test [ #2566 ] - Add support for basic authentication with Elasticsearch [ #2563 ] - AmberScript WOH documentation updated [ #2562 ] - Add \"iFrame Resizer\" library to LTI tools [ #2490 ] - Multiple Creators in Series LTI Tool [ #2489 ] - Attachment is not a function LTI error fixed","title":"Opencast 9.6"},{"location":"changelog/#opencast-95","text":"Released on May 17th, 2021 [ #2602 ] - Fix Graphs in Documentation [ #2575 ] - Fixing unchecked directory list() call [ #2565 ] - Organization Fallback for UI Configuration [ #2544 ] - Remove unused org.opencastproject.export.distribution.ExportUi.cfg [ #2536 ] - Tesseract Option Documentation [ #2530 ] - macOS installation update [ #2526 ] - LTI Service Docs [ #2525 ] - Fix checkstyle violations in 11 modules [ #2516 ] - Fix Default Password [ #2512 ] - Add Build Date in User Interface [ #2502 ] - Handle multiple creators in Paella player [ #2501 ] - Handle multiple creators in Media Module [ #2493 ] - Fixed \"No response from service\" for videogrid [ #2489 ] - Attachment is not a function LTI error fixed [ #2435 ] - Added Download Dropdown to Series LTI-Tools [ #2344 ] - Auto-generate OAI-PMH database [ #2103 ] - Only persist users with specific LTI role","title":"Opencast 9.5"},{"location":"changelog/#opencast-94","text":"Released on April 19th, 2021 [ #2526 ] - LTI Service Docs [ #2509 ] - Fix checkstyle violations in 24 modules [ #2506 ] - Fix checkstyle violation in 4 search* modules [ #2500 ] - Make media package handle multi-byte Unicode characters [ #2497 ] - Fixes getting the version information behind a proxy [ #2494 ] - Fix Processing of Unicode Titles [ #2492 ] - Prevent NPE if mediapackage duration is null [ #2479 ] - Fix Memory Leak [ #2478 ] - Fixed test for daylight saving time [ #2475 ] - Enable Elasticsearch in docs [ #2473 ] - Document Hardware Requirements [ #2472 ] - Internal server error in workflow endpoint [ #2470 ] - fixed admin UI - displaying roles correctly when adding a new event to a series [ #2467 ] - Changed the content-type of the adopter POST request. [ #2464 ] - Use a different ServiceType for the Standalone Video Editor on the presentation Node [ #2443 ] - Bump guava from 24.1.1-jre to 30.1.1-jre [ #2437 ] - Updated new editor with new frontend-release 2021-03-24 [ #2427 ] - Revert \"No Matrix Build on Opencast 8\" [ #2424 ] - Fix checkstyle violations in 22 modules [ #2423 ] - Fix checkstyle violations for 3 series-service* modules [ #2420 ] - Fix checkstyle violations in lti and lti-service-impl [ #2419 ] - Fix checkstyle violations in 5 asset manager modules [ #2417 ] - Correct Series ACLs when Recreating the Search Service Index [ #2414 ] - Corrected configuration files in editor documentation [ #2413 ] - Link new features [ #2411 ] - Editor Documentation [ #2391 ] - Perform check-availibility WF check with system user [ #2332 ] - Fix resolution scaling by removing force_original_aspect_ratio [ #2318 ] - Serverless HLS leaves files open [ #2298 ] - Add infos about Wowza streaming configuration changes to upgrade guide [ #2112 ] - Fix admin interface not displaying the correct role [ #2103 ] - Only persist users with specific LTI role [ #1792 ] - Standalone downloads Paella plugin","title":"Opencast 9.4"},{"location":"changelog/#opencast-93","text":"Released on March 15th, 2021 [ #2395 ] - Fix Hardcoded Dependency Version [ #2394 ] - Editor Workflow Description [ #2373 ] - Fix code formatting for aws s3 distribution [ #2368 ] - Improve Email Workflow Operation [ #2361 ] - Handle image extraction from very short videos [ #2355 ] - Document and Test i18next in LTI Tools [ #2353 ] - OAI-PMH Primary Key Length [ #2343 ] - Fix LTI Tool Value Checks [ #2340 ] - Fix checkstyle violations in 5 distribution-* modules [ #2338 ] - Fix checkstyle violations in 5 publications-service-* modules [ #2335 ] - Distinguish Between Documentation and Configuration Checks [ #2331 ] - Simplify Conflict Check [ #2330 ] - Fix Search Capability in Documentation [ #2329 ] - Fixes Solr search failing when titles containing lots of upper case characters [ #2328 ] - Document publish-configure changes from #1663 in upgrade guide [ #2316 ] - Changed PartialImportWOH to ignore smil entries for tracks that don't exist [ #2301 ] - Run Tests Only If Necessary [ #2296 ] - Admin UI now shows a warning if it cannot reach Github [ #2277 ] - Add Event Metrics [ #2263 ] - Fix memory leak / performance in the LTI upload and job overview [ #2260 ] - Stand-Alone Video Editor [ #2248 ] - Selenium Tests for LTI Tools [ #2026 ] - Fix Job Dispatching Test","title":"Opencast 9.3"},{"location":"changelog/#opencast-92","text":"Released on February 15th, 2021 [ GHSA-vpc2-3wcv-qj4w#1 ] - Fix Engage Series Publication and Access [ #2309 ] - HTTPS / Port [ #2300 ] - Add Mermaid to Documentation [ #2299 ] - Fix Total Search Results [ #2295 ] - Limit Incident Text ID Text [ #2292 ] - Fix Adopter Registration Configuration [ #2291 ] - Shorten Adopter Registration Primary Key [ #2290 ] - Fix Exception if GitHub is Unreachable [ #2281 ] - Admin UI says current OC version unsupported when it can't reach GitHub [ #2275 ] - Fixed possible typo in database grants statement [ #2274 ] - Fix checkstyle violations for 7 modules [ #2273 ] - Fix checkstyle violations for 9 modules [ #2270 ] - Fix checkstyle violations for authorization-manager [ #2259 ] - Enforce indentation checkstyle [ #2258 ] - Fix Series Details [ #2257 ] - Add syncronization to the access of the not thread safe xml marshaller. [ #2249 ] - Test documentation only if necessary [ #2247 ] - LTI Tools Mock Data and UI Server [ #2245 ] - Default to server localhost also for multi tenancy [ #2244 ] - Fix NullPointerException when accessing series details [ #2243 ] - Fix Feeds REST Docs [ #2237 ] - Add checkstyle-enforced rule about bracing style (K&R style, braces are mandatory) [ #2216 ] - Add checkstyle-enforced line length limit (with most modules being excluded for now) [ #2203 ] - Improved Development Runtime Dependency Containers [ #2198 ] - List Upload Tool on LTI Landing Page [ #2188 ] - Inspect Media Size [ #2186 ] - No Decoration on Section Links [ #2185 ] - Copy to Clipboard Tooltip [ #2181 ] - Fix LTI Tool Documentation [ #2169 ] - Better Port Randomization [ #2168 ] - Fixes the lti captions upload together with the default ingest workflow #2167 [ #2166 ] - Add Firewall Documentation [ #2134 ] - Addressing (most of) the missing ES config documentation [ #2106 ] - Attempt to detect invalid DB credentials [ #2078 ] - Setting appropriate defaults for AWS S3 dist config, matching the docs [ #2055 ] - Metrics Exporter [ #2042 ] - More efficient retrieval of active jobs [ #1686 ] - Workflow Operation \"CutMarksToSmil\" [ #1017 ] - Securing Static Files","title":"Opencast 9.2"},{"location":"changelog/#opencast-91","text":"Released on December 16th, 2020 [ #2150 ] - Add note about Studio config changes to the 8->9 update guide [ #2133 ] - Update Debian install documentation [ #2160 ] - Fix Ingest by Non-privileged User","title":"Opencast 9.1"},{"location":"changelog/#opencast-90","text":"Released on December 15th, 2020 [ #2133 ] - Update Debian install documentation [ #2110 ] - Error Notification Style [ #2109 ] - Fix apache-httpd doc [ #2108 ] - Fix pagination for LTI series page [ #2107 ] - Use series ACL as default ACL for events in LTI upload tool if available [ #2086 ] - Move from Travis CI to GitHub Actions [ #2084 ] - Add null checker when publishing to streaming service [ #2083 ] - Reverting part of #1291 because this code is actually needed [ #2082 ] - Fix Video Editor (Start Workflow) [ #2077 ] - Fixing NPE exposed in PublishEngageWOH when publishing to AWS S3. [ #2074 ] - #1907 Fix Start Task [ #2056 ] - Add 'if-height-lt-' variable to resolution based encoding [ #2054 ] - Add I18n translation sample file to Paella episodesFromSeries plugin [ #2048 ] - Update lti landing page about series subtool [ #2044 ] - Add S3 presigned URL support [ #2043 ] - Add I18n support for text 'General' in 2 modals [ #2041 ] - Update Node [ #2039 ] - Show language of LTI tool depend on LTI param [ #2038 ] - Load all supported languages in LTI tool [ #2023 ] - Fix Broken Video Editor [ #2022 ] - Long Labels in Segment List [ #2009 ] - Fixing OpenJDK 11 builds by adding missing dependency. [ #2007 ] - Fix Broken Admin Interface Sub-Tabs [ #2006 ] - Update pull request to-do list [ #2005 ] - Synchronize merge conflict check [ #2000 ] - Better documentation for AAI DynamicLoginHandler [ #1982 ] - Update Media Package POST Operation [ #1981 ] - Remove Deprecated Process Executor [ #1970 ] - Update cURL Commands [ #1963 ] - Non-unique-files fix for Videogrid WOH [ #1950 ] - Update documentation for the Docker images [ #1939 ] - Update jakarta.xml.bind-api to 2.3.3 [ #1937 ] - Update adopter-registration-rest.xml to solve #1934 issue [ #1931 ] - Make copy-event-to-series workflow id configurable [ #1836 ] - Ensure User Roles [ #1910 ] - Test admin frontend only once on CI [ #1904 ] - Enforce Maven Dependency Checks on some more modules [ #1901 ] - OSGi Annotations and Configuration [ #1900 ] - Docs: admin-ui moved to admin-ui-frontend [ #1898 ] - Add preencode option to partialImport WOH [ #1897 ] - Bump markdownlint-cli from 0.23.2 to 0.24.0 in /docs/guides [ #1896 ] - Bump @types/react from 16.9.2 to 16.9.50 in /modules/lti [ #1895 ] - Development Runtime Dependency Containers [ #1890 ] - Fix error while searching episode by browser [ #1889 ] - Bump @types/react-select from 3.0.14 to 3.0.21 in /modules/lti [ #1888 ] - Bump bootbox from 5.4.0 to 5.4.1 in /modules/engage-ui [ #1886 ] - Remove Spring's Patched JDOM [ #1884 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/admin-ui-frontend [ #1883 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/engage-theodul-core [ #1882 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/runtime-info-ui [ #1881 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/engage-ui [ #1880 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/engage-paella-player [ #1879 ] - Bump eslint from 7.9.0 to 7.10.0 in /modules/runtime-info-ui-ng [ #1876 ] - OSGi Dependency Update [ #1875 ] - Update NodeJS [ #1874 ] - PostgreSQL and auto-generated databases [ #1873 ] - Bump karma from 5.2.2 to 5.2.3 in /modules/admin-ui-frontend [ #1872 ] - Fix Version Check [ #1871 ] - Workflow conditioner to handle floats correctly [ #1869 ] - Extend the documentation concerning multiple audio tracks [ #1868 ] - Bump @types/node from 12.7.5 to 14.11.2 in /modules/lti [ #1867 ] - Update Mock Data [ #1866 ] - Update to AngularJS 1.8 [ #1858 ] - User and role provider for Canvas LMS [ #1857 ] - Refactor Metadata classes (Updated version) [ #1854 ] - Bump @types/jest from 24.0.18 to 26.0.14 in /modules/lti [ #1844 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/admin-ui-frontend [ #1843 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/engage-ui [ #1841 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/runtime-info-ui [ #1840 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/engage-paella-player [ #1839 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/runtime-info-ui-ng [ #1838 ] - Bump eslint from 7.8.1 to 7.9.0 in /modules/engage-theodul-core [ #1833 ] - Add Merge Conflict Check [ #1831 ] - Clarify the documentation on when new source tracks can be added [ #1830 ] - Bump karma from 5.2.1 to 5.2.2 in /modules/admin-ui-frontend [ #1829 ] - Bump chromedriver from 85.0.0 to 85.0.1 in /modules/admin-ui-frontend [ #1825 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/admin-ui-frontend [ #1824 ] - Bump karma from 5.1.1 to 5.2.1 in /modules/admin-ui-frontend [ #1823 ] - Update Studio from 2020-06-25 to 2020-09-14 [ #1822 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/runtime-info-ui-ng [ #1819 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-theodul-core [ #1817 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-paella-player [ #1816 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-ui [ #1814 ] - Add a 'defaultValue' to getComponentContextProperty [ #1808 ] - Bump underscore from 1.10.2 to 1.11.0 in /modules/engage-ui [ #1801 ] - Remove Unused Servicewarnings Backend [ #1800 ] - Adopter Registration [ #1796 ] - Minimal message broker impl improvement [ #1795 ] - Login Autocomplete Instructions [ #1794 ] - Icon Cleanup [ #1791 ] - Add with acl option to series api [ #1790 ] - Request Lowercase Usernames in Moodle [ #1789 ] - Remove JDOM From Ingest Service [ #1788 ] - Properly parse boolean values [ #1773 ] - Ingest Service Cleanup [ #1772 ] - Role Prefix in Moodle User Provider [ #1771 ] - OSGi Annotations for Engage UI [ #1764 ] - LTI Context Role Prefix [ #1750 ] - HTTPS with Apache httpd [ #1746 ] - VideoGrid WOH [ #1743 ] - Bump @types/react-helmet from 5.0.16 to 6.1.0 in /modules/lti [ #1728 ] - Bump @types/react-dom from 16.9.0 to 16.9.8 in /modules/lti [ #1727 ] - Bump react-helmet from 5.2.1 to 6.1.0 in /modules/lti [ #1724 ] - Bump react-i18next from 10.13.2 to 11.0.0 in /modules/lti [ #1719 ] - Download button in theodul player [ #1684 ] - Partial Retract WOH [ #1636 ] - Support Serverless HLS [ #1615 ] - Aditive Filter for Api/events endpoint [ #1607 ] - Shibboleth dynamic login handler [ #1580 ] - TagWorkflowOperationHandler now allows wildcards in target flavor [ #1825 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/admin-ui-frontend [ #1824 ] - Bump karma from 5.1.1 to 5.2.1 in /modules/admin-ui-frontend [ #1822 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/runtime-info-ui-ng [ #1819 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-theodul-core [ #1817 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-paella-player [ #1816 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/engage-ui [ #1813 ] - Bump eslint from 7.7.0 to 7.8.1 in /modules/runtime-info-ui [ #1811 ] - Bump chromedriver from 84.0.1 to 85.0.0 in /modules/admin-ui-frontend [ #1810 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/admin-ui-frontend [ #1809 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/runtime-info-ui [ #1808 ] - Bump underscore from 1.10.2 to 1.11.0 in /modules/engage-ui [ #1807 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/engage-ui [ #1806 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/engage-theodul-core [ #1803 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/engage-paella-player [ #1802 ] - Bump eslint-plugin-header from 3.0.0 to 3.1.0 in /modules/runtime-info-ui-ng [ #1785 ] - Bump grunt from 1.2.1 to 1.3.0 in /modules/admin-ui-frontend [ #1781 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/engage-paella-player [ #1780 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/admin-ui-frontend [ #1777 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/engage-theodul-core [ #1776 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/engage-ui [ #1775 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/runtime-info-ui-ng [ #1774 ] - Bump eslint from 7.6.0 to 7.7.0 in /modules/runtime-info-ui [ #1768 ] - Remove Empty Test Classes [ #1766 ] - Fix minor typos [ #1765 ] - Bump karma-jasmine from 4.0.0 to 4.0.1 in /modules/admin-ui-frontend [ #1763 ] - Fix for issue 1280: Notification of Newer Opencast Version in Admin UI [ #1762 ] - Fixed a typo in es.upv.paella.opencast.loader.md [ #1761 ] - Bump karma-jasmine from 3.3.1 to 4.0.0 in /modules/admin-ui-frontend [ #1760 ] - User interface to sort by number of publications [ #1759 ] - Create admin user cleanup [ #1758 ] - Fix events sorted by publication [ #1742 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/engage-paella-player [ #1741 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/admin-ui-frontend [ #1739 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/runtime-info-ui [ #1738 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/engage-theodul-core [ #1737 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/engage-ui [ #1736 ] - Bump eslint from 7.5.0 to 7.6.0 in /modules/runtime-info-ui-ng [ #1734 ] - Bump autoprefixer from 9.8.5 to 9.8.6 in /modules/admin-ui-frontend [ #1722 ] - Bump karma from 5.1.0 to 5.1.1 in /modules/admin-ui-frontend [ #1717 ] - Bump karma-coverage from 2.0.2 to 2.0.3 in /modules/admin-ui-frontend [ #1715 ] - Bump jasmine-core from 3.5.0 to 3.6.0 in /modules/admin-ui-frontend [ #1714 ] - Bump chromedriver from 84.0.0 to 84.0.1 in /modules/admin-ui-frontend [ #1713 ] - Fixed double encoding of search-field in engage-ui [ #1710 ] - Added Elasticsearch dependency to developer installation guide [ #1709 ] - Use FontAwesome Icon [ #1708 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/engage-paella-player [ #1707 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/admin-ui-frontend [ #1706 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/engage-ui [ #1705 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/runtime-info-ui-ng [ #1704 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/runtime-info-ui [ #1703 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/lti [ #1702 ] - Bump eslint from 7.4.0 to 7.5.0 in /modules/engage-theodul-core [ #1701 ] - Window Selection Style [ #1700 ] - Document bundle:watch [ #1699 ] - Bump chromedriver from 83.0.1 to 84.0.0 in /modules/admin-ui-frontend [ #1698 ] - Bump grunt-contrib-connect from 2.1.0 to 3.0.0 in /modules/admin-ui-frontend [ #1697 ] - Bump grunt-contrib-uglify from 4.0.1 to 5.0.0 in /modules/admin-ui-frontend [ #1696 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/runtime-info-ui [ #1695 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/runtime-info-ui-ng [ #1694 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/lti [ #1693 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/engage-theodul-core [ #1692 ] - [Security] Bump lodash from 4.17.15 to 4.17.19 in /modules/engage-ui [ #1691 ] - Bump lodash from 4.17.15 to 4.17.19 in /modules/engage-paella-player [ #1689 ] - Bump autoprefixer from 9.8.4 to 9.8.5 in /modules/admin-ui-frontend [ #1687 ] - Bump grunt from 1.2.0 to 1.2.1 in /modules/admin-ui-frontend [ #1683 ] - Bump chromedriver from 83.0.0 to 83.0.1 in /modules/admin-ui-frontend [ #1681 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/engage-paella-player [ #1680 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/admin-ui-frontend [ #1679 ] - Bump grunt from 1.1.0 to 1.2.0 in /modules/admin-ui-frontend [ #1678 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/lti [ #1677 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/engage-ui [ #1676 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/runtime-info-ui [ #1675 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/engage-theodul-core [ #1674 ] - Bump eslint from 7.3.1 to 7.4.0 in /modules/runtime-info-ui-ng [ #1671 ] - Python < 3.0 requirement deleted [ #1670 ] - Python < 3.0 requirement deleted [ #1668 ] - Improved ffmpeg profile for extracting the last image of a video in P\u2026 [ #1666 ] - Bump markdownlint-cli from 0.23.1 to 0.23.2 in /docs/guides [ #1665 ] - Bump http-errors from 1.7.3 to 1.8.0 in /modules/engage-paella-player [ #1663 ] - Enable publish-configure to publish to streaming [ #1660 ] - Bump autoprefixer from 9.8.2 to 9.8.4 in /modules/admin-ui-frontend [ #1658 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/engage-paella-player [ #1656 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/admin-ui-frontend [ #1655 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/lti [ #1654 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/engage-theodul-core [ #1653 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/runtime-info-ui [ #1652 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/runtime-info-ui-ng [ #1651 ] - Bump eslint from 7.3.0 to 7.3.1 in /modules/engage-ui [ #1650 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/engage-paella-player [ #1649 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/admin-ui-frontend [ #1648 ] - Bump autoprefixer from 9.8.0 to 9.8.2 in /modules/admin-ui-frontend [ #1647 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/engage-ui [ #1646 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/runtime-info-ui [ #1645 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/lti [ #1644 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/engage-theodul-core [ #1643 ] - Bump eslint from 7.2.0 to 7.3.0 in /modules/runtime-info-ui-ng [ #1640 ] - Fix Capture Agent API REST Docs [ #1638 ] - Bump karma from 5.0.9 to 5.1.0 in /modules/admin-ui-frontend [ #1637 ] - Fix: Multiple identical workflow IDs prevent Opencast form starting properly [ #1635 ] - Admin UI embedding code [ #1632 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/engage-paella-player [ #1631 ] - Bump eslint from 7.1.0 to 7.2.0 in /modules/runtime-info-ui [ #1630 ] - Fix Series in Media Module [ #1629 ] - LTI User Data [ #1628 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/admin-ui-frontend [ #1627 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/engage-theodul-core [ #1626 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/lti [ #1625 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/engage-ui [ #1624 ] - Bump eslint from 6.8.0 to 7.2.0 in /modules/runtime-info-ui-ng [ #1623 ] - Update Node.js [ #1621 ] - [Security] Bump websocket-extensions from 0.1.3 to 0.1.4 in /modules/admin-ui-frontend [ #1619 ] - Bump angular from 1.7.9 to 1.8.0 in /modules/runtime-info-ui [ #1618 ] - Bump angular-route from 1.7.9 to 1.8.0 in /modules/runtime-info-ui [ #1614 ] - Bump karma-jasmine from 3.2.0 to 3.3.1 in /modules/admin-ui-frontend [ #1606 ] - Bump karma-jasmine from 3.1.1 to 3.2.0 in /modules/admin-ui-frontend [ #1605 ] - Update Several JavaScript Libraries [ #1601 ] - Bump js-yaml from 3.13.1 to 3.14.0 in /modules/engage-ui [ #1599 ] - Bump eslint from 6.8.0 to 7.1.0 in /modules/runtime-info-ui [ #1591 ] - Bump karma from 5.0.8 to 5.0.9 in /modules/admin-ui-frontend [ #1590 ] - Bump chromedriver from 81.0.0 to 83.0.0 in /modules/admin-ui-frontend [ #1587 ] - Bump karma from 5.0.5 to 5.0.8 in /modules/admin-ui-frontend [ #1585 ] - Bump http-proxy from 1.18.0 to 1.18.1 in /modules/engage-paella-player [ #1584 ] - Bump autoprefixer from 9.7.6 to 9.8.0 in /modules/admin-ui-frontend [ #1582 ] - Bump markdownlint-cli from 0.23.0 to 0.23.1 in /docs/guides [ #1569 ] - Bump karma from 5.0.4 to 5.0.5 in /modules/admin-ui-frontend [ #1567 ] - Update Python on Travis CI [ #1566 ] - Switching to Paella player by default [ #1563 ] - Bump node-sass from 4.14.0 to 4.14.1 in /modules/admin-ui-frontend [ #1562 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/runtime-info-ui-ng [ #1561 ] - Bump markdownlint-cli from 0.22.0 to 0.23.0 in /docs/guides [ #1560 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/runtime-info-ui [ #1559 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/engage-ui [ #1558 ] - Bump jquery from 3.5.0 to 3.5.1 in /modules/lti [ #1555 ] - Bump karma from 5.0.3 to 5.0.4 in /modules/admin-ui-frontend [ #1553 ] - Fix custom roles in admin ui [ #1552 ] - Bump karma from 5.0.2 to 5.0.3 in /modules/admin-ui-frontend [ #1549 ] - Resolution based encoding extension: if-width-or-height-geq- [ #1548 ] - #1541 adding write access parameter to events and series endpoint [ #1547 ] - Download paella source code from github instead of using npm + paella update to 6.4.3 [ #1544 ] - Bump node-sass from 4.13.1 to 4.14.0 in /modules/admin-ui-frontend [ #1536 ] - Typo correction [ #1531 ] - Bump karma from 4.4.1 to 5.0.2 in /modules/admin-ui-frontend [ #1530 ] - REST Docs: Ingest: WF parameters, WFIID deprecated [ #1524 ] - Bump grunt-karma from 3.0.2 to 4.0.0 in /modules/admin-ui-frontend [ #1523 ] - Documentation: OsgiAclServiceRestEndpoint [ #1522 ] - Bump karma-coverage from 2.0.1 to 2.0.2 in /modules/admin-ui-frontend [ #1521 ] - Bump chromedriver from 80.0.1 to 81.0.0 in /modules/admin-ui-frontend [ #1520 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/runtime-info-ui [ #1519 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/runtime-info-ui-ng [ #1518 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/lti [ #1517 ] - Bump jquery from 3.4.1 to 3.5.0 in /modules/engage-ui [ #1511 ] - Bump autoprefixer from 9.7.5 to 9.7.6 in /modules/admin-ui-frontend [ #1510 ] - Bump grunt-ng-annotate from 3.0.0 to 4.0.0 in /modules/admin-ui-frontend [ #1499 ] - Add NUT container format [ #1498 ] - Bump underscore from 1.9.2 to 1.10.2 in /modules/engage-ui [ #1497 ] - Documentation: Update asset-delete-woh.md [ #1490 ] - Make encoding profiles support odd widths and heights develop [ #1484 ] - Bump autoprefixer from 9.7.4 to 9.7.5 in /modules/admin-ui-frontend [ #1469 ] - Bump grunt from 1.0.4 to 1.1.0 in /modules/admin-ui-frontend [ #1466 ] - Bump mustache from 4.0.0 to 4.0.1 in /modules/lti [ #1465 ] - [Security] Bump minimist from 1.2.0 to 1.2.5 in /docs/guides [ #1464 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/engage-paella-player [ #1463 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/engage-theodul-core [ #1462 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/engage-ui [ #1461 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/lti [ #1460 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/runtime-info-ui-ng [ #1459 ] - [Security] Bump acorn from 7.1.0 to 7.1.1 in /modules/runtime-info-ui [ #1456 ] - Adding support for 360 video playback to paella player [ #1455 ] - Add bower_components/ to .gitignore file [ #1444 ] - Make Admin Interface Use npm ci [ #1443 ] - Allow Root In Bower (Again) [ #1440 ] - Update android-mms [ #1439 ] - Editor zooming improved [ #1431 ] - Override all POSIX language variables in Gruntfile.js [ #1430 ] - #1429 rewrite ServiceRegistryJpaImplTest to reduce TravisCI failures [ #1423 ] - Fix REST Documentation [ #1421 ] - Remove compose in favor of encode [ #1420 ] - Override all LANG and LC_ environment variables for stable tests [ #1419 ] - Set fixed LANG for stable tests. Fixes #1418 [ #1417 ] - Bump karma-jasmine from 3.1.0 to 3.1.1 in /modules/admin-ui-frontend [ #1416 ] - Bump chromedriver from 80.0.0 to 80.0.1 in /modules/admin-ui-frontend [ #1415 ] - Bump request from 2.88.0 to 2.88.2 in /modules/admin-ui-frontend [ #1413 ] - Remove Unused Admin Interface Ressources [ #1407 ] - Fix typo in LDAP documentation [ #1406 ] - Add CAS authentication to default XML config [ #1403 ] - Remove Outdated Shibboleth Configuration [ #1402 ] - Quick-links in documentation [ #1401 ] - Fix More Dependencies [ #1398 ] - Bump markdownlint-cli from 0.21.0 to 0.22.0 in /docs/guides [ #1397 ] - Silence Detector Cleanup [ #1396 ] - Image Extraction Without Stream Duration [ #1395 ] - Fix Image Extraction At Position Zero [ #1391 ] - Documentation: Text Extraction Configuration [ #1389 ] - Bump chromedriver from 79.0.2 to 80.0.0 in /modules/admin-ui [ #1388 ] - Return bibliographic start date of event via API [ #1387 ] - Speedup silence detection in case there is a video stream [ #1383 ] - Bump checkstyle from 8.21 to 8.29 [ #1382 ] - Show search results after changing chosen list [ #1381 ] - Remove get acl scheduler endpoint as it's not used [ #1378 ] - Bump chromedriver from 79.0.0 to 79.0.2 in /modules/admin-ui [ #1377 ] - Update to MariaDB Client [ #1376 ] - Create JpaUserReference for LTI user (update to 9.x) [ #1375 ] - Log the proper index name when updating the asset manager index [ #1371 ] - Split AdminUI in Java and JavaScript parts [ #1368 ] - More OSGi Service Annotations [ #1365 ] - Remove Drupal Based Pingback Service [ #1363 ] - Added the adopter registration form for statistics. [ #1361 ] - Bump node-sass from 4.13.0 to 4.13.1 in /modules/admin-ui [ #1360 ] - Bump mustache from 3.2.1 to 4.0.0 in /modules/lti [ #1355 ] - Bump autoprefixer from 9.7.3 to 9.7.4 in /modules/admin-ui [ #1354 ] - Addition of trim segment configuration and new documentation [ #1350 ] - Dependency Tests [ #1349 ] - Drop X-Opencast-Matterhorn-Authorization [ #1348 ] - Add AmberScript Transcription Service [ #1347 ] - LDAP Configuration [ #1346 ] - Adjust documentation regarding Elasticsearch setup [ #1344 ] - Bump karma-jasmine from 3.0.3 to 3.1.0 in /modules/admin-ui [ #1342 ] - Bump karma-jasmine from 3.0.1 to 3.0.3 in /modules/admin-ui [ #1334 ] - Bump karma-firefox-launcher from 1.2.0 to 1.3.0 in /modules/admin-ui [ #1332 ] - Bump karma-jasmine from 2.0.1 to 3.0.1 in /modules/admin-ui [ #1331 ] - Bump underscore from 1.9.1 to 1.9.2 in /modules/engage-ui [ #1330 ] - ESLint For Theodul Connection Plugin [ #1322 ] - Bump markdownlint-cli from 0.20.0 to 0.21.0 in /docs/guides [ #1317 ] - Bump mustache from 3.1.0 to 3.2.1 in /modules/lti [ #1316 ] - [Security] Bump handlebars from 4.2.0 to 4.5.3 in /modules/admin-ui [ #1314 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/engage-ui [ #1313 ] - Bump bootbox from 5.3.4 to 5.4.0 in /modules/engage-ui [ #1312 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/engage-paella-player [ #1311 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/engage-theodul-core [ #1310 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/runtime-info-ui [ #1309 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/admin-ui [ #1308 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/lti [ #1307 ] - Bump eslint from 6.7.2 to 6.8.0 in /modules/runtime-info-ui-ng [ #1298 ] - Bump markdownlint-cli from 0.19.0 to 0.20.0 in /docs/guides [ #1295 ] - Change npm install to npm ci [ #1293 ] - Actually update event workflow via API [ #1291 ] - Clean up unused code and ignored tests [ #1289 ] - Improve LTI: add create event and edit event, improve series tool [ #1288 ] - Java 11 Compatibility [ #1287 ] - Add option to remove running workflows, fix restdocs for delete requests [ #1283 ] - Fix hourly statistics export [ #1282 ] - Bump chromedriver from 78.0.1 to 79.0.0 in /modules/admin-ui [ #1277 ] - Fixed streaming distribution remote [ #1275 ] - Fix small typo in External API docs [ #1272 ] - Log progress of solr search reindex [ #1268 ] - Additional logging for ACL parse errors [ #1267 ] - Log the Ids of items being indexed [ #1264 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/engage-theodul-core [ #1263 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/lti [ #1262 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/runtime-info-ui-ng [ #1261 ] - Bump autoprefixer from 9.7.2 to 9.7.3 in /modules/admin-ui [ #1260 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/engage-ui [ #1259 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/admin-ui [ #1258 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/runtime-info-ui [ #1257 ] - Bump eslint from 6.7.1 to 6.7.2 in /modules/engage-paella-player [ #1255 ] - Update paella player to 6.3.2 [ #1254 ] - Map internal service host URLs to tenant-specific URLs [ #1252 ] - Make JPA Generated Database Match Script Generated Database [ #1250 ] - Drop Unused Tables [ #1249 ] - Documentation: Metadata fixes [ #1242 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/engage-paella-player [ #1241 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/engage-theodul-core [ #1240 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/admin-ui [ #1239 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/engage-ui [ #1238 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/runtime-info-ui [ #1237 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/runtime-info-ui-ng [ #1236 ] - Bump eslint from 6.6.0 to 6.7.1 in /modules/lti [ #1235 ] - Update selected components to use OSGI annotations [ #1234 ] - Add audio and video stream selectors for tracks to ExecuteMany WOH [ #1230 ] - Single image video fix [ #1226 ] - Implement StreamingDistributionService remotely [ #1225 ] - Bump autoprefixer from 9.7.1 to 9.7.2 in /modules/admin-ui [ #1222 ] - Bump paginationjs from 2.1.4 to 2.1.5 in /modules/lti [ #1211 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/admin-ui [ #1210 ] - Bump autoprefixer from 9.7.0 to 9.7.1 in /modules/admin-ui [ #1209 ] - Bump bootbox from 5.3.3 to 5.3.4 in /modules/engage-ui [ #1208 ] - Bump bootbox from 5.3.2 to 5.3.3 in /modules/engage-ui [ #1205 ] - Dropping SysV-Init [ #1198 ] - Introduce ESlint for Theodul Controls Plugin [ #1196 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/runtime-info-ui-ng [ #1195 ] - Bump http-proxy from 1.17.0 to 1.18.0 in /modules/engage-paella-player [ #1194 ] - Bump karma from 4.3.0 to 4.4.1 in /modules/admin-ui [ #1193 ] - Bump node-sass from 4.12.0 to 4.13.0 in /modules/admin-ui [ #1192 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/engage-ui [ #1191 ] - Bump autoprefixer from 9.6.1 to 9.7.0 in /modules/admin-ui [ #1190 ] - Bump chromedriver from 76.0.1 to 78.0.1 in /modules/admin-ui [ #1189 ] - Bump jasmine-core from 3.4.0 to 3.5.0 in /modules/admin-ui [ #1188 ] - Bump seedrandom from 3.0.3 to 3.0.5 in /modules/engage-ui [ #1187 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/engage-paella-player [ #1186 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/lti [ #1184 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/runtime-info-ui [ #1183 ] - Bump eslint from 6.5.0 to 6.6.0 in /modules/engage-theodul-core [ #1182 ] - Bump markdownlint-cli from 0.18.0 to 0.19.0 in /docs/guides [ #1179 ] - Make wowza configuration tenant-specific [ #1171 ] - Removed wrong comma in .json example [ #1163 ] - Improve embed code generation of Theodul player to create a fully responsive embed code fragment [ #1161 ] - fix #1158, add config properties to prevent XSS attacks on session co\u2026 [ #1159 ] - Removing old references to org.opencastproject.db.ddl.generate [ #1154 ] - Show users with same mail address and name [ #1150 ] - Workflow: update-previews: Add description [ #1149 ] - Workflow title: Update editor previews [ #1135 ] - Allow to overwrite setenv variables [ #1133 ] - Better JPA Annotation for Scheduler [ #1130 ] - Updated com.fasterxml.jackson from version 2.9.9 to 2.10.0. [ #1128 ] - Load series ACL-list step by step [ #1127 ] - Update accesspolicies.md: fixed grammar issues [ #1121 ] - Remove unnecessary ExceptionUtils.getStackTrace #1119 [ #1120 ] - Updates Service Registry dispatch interval property name and time unit [ #1118 ] - Removes String.format calls in logs [ #1109 ] - Extended statistics export [ #1107 ] - ESLint for Theodul Core [ #1106 ] - Update to ESLint 6.5.0 [ #1105 ] - Use JPA to auto-generate SQL schema [ #1104 ] - Login Response for JavaScript [ #1081 ] - Add modal to edit metadata of multiple events [ #1064 ] - Update to paella player 6.2.2 [ #1054 ] - Fix a bug in paella loader plugin when a track has no tags [ #1046 ] - Load all roles in Admin UI [ #1043 ] - Multiple audio tracks support on paella [ #1032 ] - Sort roles alphabetically in UI [ #1002 ] - S3 S3 compatibility - Endpoint configuration for Amazon S3 alternatives added [ #884 ] - Display global notifications as overlay","title":"Opencast 9.0"},{"location":"changelog/#opencast-8","text":"","title":"Opencast 8"},{"location":"changelog/#opencast-811","text":"Released on April 6th, 2021 [ #2418 ] - Update Test Server Builds [ #2416 ] - Restore \"8.x specific fixes for the markdown generation code\" [ #2415 ] - Revert \"8.x specific fixes for the markdown generation code\" [ #2409 ] - 8.x specific fixes for the markdown generation code [ #2310 ] - Gracefully handle missing Shibboleth User References [ #2261 ] - Handle broken encoding profiles without killing the ComposerService [ #2253 ] - Configure POST api/groups access correctly [ #2239 ] - Fix Typo in Branding Properties [ #2214 ] - Validate Ingested DublinCore Catalogs [ #2177 ] - Fix Sorting Series by Creators [ #2071 ] - Properly configure AWS S3 distribution on startup by default","title":"Opencast 8.11"},{"location":"changelog/#opencast-810","text":"Released on December 23rd, 2020 [ #2160 ] - Fix Ingest by Non-privileged User [ #2049 ] - Endtime of segments fixed in the editor","title":"Opencast 8.10"},{"location":"changelog/#opencast-89","text":"Released on December 8th, 2020 [ #2099 ] - Support faster playback rates in paella video player [ #2087 ] - Move from Travis CI to GitHub Actions (8.x) [ #2075 ] - Reduce IO Load When Starting a Workflow [ #2068 ] - JDK Support proposal (2020-11-11) documentation for 8.x [ #1988 ] - #1987 Admin UI event start filter datepicker timezone patch","title":"Opencast 8.9"},{"location":"changelog/#opencast-88","text":"Released on November 19th, 2020 [ #2075 ] - Reduce IO Load When Starting a Workflow [ #2072 ] - Update player.matomo.tracking.md [ #2067 ] - Solves #2034 (Execute-once subprocess issue) [ #2051 ] - Limit OpenMP Threads to Prevent Tesseract Blocking the System [ #2040 ] - Drop user login log level [ #2020 ] - Set the RFC 822 \"Date\" header field when sending an email (r/8.x) [ #2008 ] - Speed up preview encoding [ #1988 ] - #1987 Admin UI event start filter datepicker timezone patch [ #1954 ] - Fix Paella Player assuming track is audio-only when it's actually video and audio [ #1894 ] - Remove references to removed modules [ #1891 ] - Creating a new series doesn't send user collections anymore [ #1887 ] - Remove Dead OpenID Module","title":"Opencast 8.8"},{"location":"changelog/#opencast-87","text":"Released on September 27th, 2020 [ #1851 ] - Fix conflict checking for scheduled events in multitenant systems [ #1848 ] - Fix capture agent dropdown menus [ #1837 ] - Adding bugfix from #1668 to 8.x [ #1828 ] - Recommend https [ #1827 ] - Clean up basic configuration [ #1812 ] - Missing ACL after asset upload [ #1786 ] - Removed servicewarnings endpoint [ #1770 ] - Paella player should only list http(s) URLs in the download plugin [ #1756 ] - Change markdown CI checks to bash [ #1753 ] - Admin interface event API logs on user error [ #1735 ] - Added reloading of filters in users page","title":"Opencast 8.7"},{"location":"changelog/#opencast-86","text":"Released on August 5th, 2020 [ #1744 ] - Fix for issue 1616: User keep write permission on ACL template selection [ #1720 ] - Corrected title of user delete button [ #1711 ] - Fixes issue #1642: Drop-down menu does not disappear [ #1662 ] - Update Studio from 2020-05-20 to 2020-06-25 [ #1639 ] - Don't raise a NPE when the workflow creator was deleted","title":"Opencast 8.6"},{"location":"changelog/#opencast-85","text":"Released on June 15th, 2020 [ #1633 ] - Using ConcurrentHashMap for synchronizing LTI user login [ #1622 ] - Fix LTI Without Persistence [ #1620 ] - Fix Formatting [ #1612 ] - Use normal file appender instead of RandomAccessFile for logging [ #1611 ] - Fix LDAP Debug Logging [ #1593 ] - Update paella to 6.2.7","title":"Opencast 8.5"},{"location":"changelog/#opencast-84","text":"Released on May 22nd, 2020 [ #1593 ] - Update player Paella to 6.2.7 [ #1592 ] - Update Studio version to 2020-05-20 [ #1581 ] - Update Studio to 2020-05-14 [ #1578 ] - Add cutting to the default Studio workflow [ #1570 ] - Partial import muxing fix [ #1568 ] - Fix URL to Wowza documentation [ #1565 ] - Avoids normal user to delete series with events when option series.hasEvents.delete.allow is set to false [ #1550 ] - Be more lenient towards service failures [ #1543 ] - 403 Logout Option [ #1542 ] - Allow Admin UI Users to Access / [ #1540 ] - Studio workflow should archive prepared versioned of videos [ #1535 ] - Opencast server node name should be optional [ #1534 ] - Admin UI systems filters should be accessible by the corresponding roles [ #1532 ] - Fix race condition when creating or updating user references from LTI [ #1516 ] - Studio encoding profile performance improved [ #1515 ] - Studio-upload workflow should generate search preview images [ #1509 ] - Allow anonymous access to static Studio files [ #1508 ] - Fixed a typo in the Theodul Config [ #1500 ] - Adding documentation on how to use the multiserver docker-compose [ #1496 ] - Fix Adaptive Encoding [ #1492 ] - Update Studio (for bug fixes) and add docs for Studio [ #1488 ] - Make encoding profiles support odd widths/heights [ #1479 ] - Fix Theodul quality selection","title":"Opencast 8.4"},{"location":"changelog/#opencast-83","text":"Released on March 26th, 2020 [ #1492 ] - Update Studio (for bugfixes) and add docs for Studio [ #1489 ] - Workaround early lti session timeout [ #1488 ] - Make encoding profiles support odd widths/heights [ #1487 ] - Fix Studio login redirect [ #1485 ] - Custom Roles for LTI users [ #1483 ] - Read published files direct from filesystem if possible (completed) [ #1482 ] - Create JpaUserReference for LTI user (backport) [ #1480 ] - Preserve ACL On Workflow Errors [ #1479 ] - Fix Theodul quality selection [ #1478 ] - Studio upload optimized workflows [ #1476 ] - Fix Studio Redirect discarding GET Parameters [ #1475 ] - Fix Theodul Matomo plugin after configuration data structure change [ #1473 ] - Move OC Studio configuration to etc/ui-config and update Studio [ #1468 ] - Studio in admin-presentation","title":"Opencast 8.3"},{"location":"changelog/#opencast-82","text":"Released on March 14th, 2020 [ #1458 ] - Fix Image Extraction At Position Zero [ #1457 ] - Image Extraction Without Stream Duration [ #1454 ] - Fix HLS on iOS [ #1448 ] - Adding link to community workflow repository to the markdown docs [ #1446 ] - Disable 2 more instances of jmxremote param, #1445 [ #1441 ] - Remove databasemigration for Opencast 7 [ #1436 ] - integrate opencast studio [ #1433 ] - Series ACLs not propagating to individual events [ #1414 ] - Gracefully crash if there is no password stored [ #1409 ] - Asset Upload Title [ #1408 ] - Simplify Asset Upload Workflow [ #1399 ] - Gracefully Fail Hash Verification [ #1364 ] - Temination state service test [ #1359 ] - Fix workflow dropdown in start task [ #1327 ] - Video Segemntation On Short Videos [ #1301 ] - Fix event delete with existing publications [ #1248 ] - Fix conflict detection for non-admin users and for multiple events","title":"Opencast 8.2"},{"location":"changelog/#opencast-81","text":"Released on January 29, 2020 [ #1341 ] - Spring Framework Dependency Specification [ #1340 ] - LDAP User Directory Dependencies [ #1339 ] - Add Missing Karaf Features [ #1338 ] - Sakai User Directory Dependencies [ #1328 ] - AngularJS Components 1.7.9 [ #1326 ] - Fix Image Extraction From Short Videos [ #1321 ] - Fix URL Parameters in Theodul Player [ #1300 ] - Allow Root In Bower [ #1299 ] - Fix AWS WOH OSGI dependencies [ #1266 ] - Allow capture agent users to read properties of series","title":"Opencast 8.1"},{"location":"changelog/#fixed-security-issues","text":"CVE-2020-5231 \u2013 Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 \u2013 Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 \u2013 Hard-Coded Key Used For Remember-me Token CVE-2020-5230 \u2013 Unsafe Identifiers CVE-2020-5229 \u2013 Replace MD5 with bcrypt for password hashing CVE-2020-5228 \u2013 Public Access Via OAI-PMH","title":"Fixed Security Issues"},{"location":"changelog/#opencast-80","text":"Released on December 17, 2019 [ #1292 ] - Release notes for Opencast 8.0 [ #1290 ] - Fix for MP3 with embedded image [ #1286 ] - Fix Role For Assets Quick Access [ #1278 ] - Editor Thumbnail Default [ #1274 ] - Update Security Configuration [ #1269 ] - Fix processing of odd video width [ #1256 ] - Remove publishedhours default statistics provider [ #1245 ] - AngularJS 1.7.9 Security Update [ #1216 ] - Simplify Editor URL Signing [ #1212 ] - Update paella player to 6.2.4 [ #1207 ] - Enable Browser Tests [ #1206 ] - Temporarily Ignore Failing Test [ #1203 ] - Warn about using H2 [ #1202 ] - Overhaul RPM Installation Guide [ #1199 ] - Fix Crowdin Upload [ #1197 ] - Fix Theodul Embed Configuration [ #1167 ] - Migrate IBM Watson transcription to shared persistence [ #1153 ] - Keep generated SMIL for partial tracks [ #1151 ] - (#1008): Better crop detect test #1085 [ #1146 ] - Remove unnecessary global package-lock.json [ #1141 ] - Consider file extension of uploaded asset [ #1134 ] - Do not use stack-overflow logo [ #1131 ] - Issue1123 TEMP FIX for Paella Player Build error [ #1110 ] - Build failed on captions-impl tests for non english OS [ #1108 ] - Fix external API versioning for EventsEndpoint [ #1103 ] - Fix PostreSQL Support [ #1102 ] - Clean-up Fast Testing Workflow [ #1101 ] - Filter jobs by transcription service provider ID [ #1073 ] - close esc function for new event and new series modals [ #1067 ] - Publication Button show fix [ #1100 ] - Player Scroll/Zoom Overlay [ #1098 ] - Fix displaying tracks with no tags in player [ #1095 ] - Add a new optional date_expected column to the transcription job table [ #1094 ] - Smarter etc/ hints in documentation [ #1093 ] - Provide access to file contents in the WFR [ #1091 ] - Remove inaccurate url-pattern ${element_uri} [ #1090 ] - Elasticsearch access_policy field increased in size [ #1086 ] - Fix CI Builds (Crop Tests) [ #1084 ] - Fix Player ID Parameter Parsing [ #1082 ] - Docs readme extended. [ #1079 ] - Remove Workflow Operations from Worker [ #1078 ] - Fix database docs [ #1075 ] - Remove State Mapping \u201cImporting\u201d [ #1074 ] - Navbar icons toggle [ #1071 ] - Fix Pull Request Template [ #1070 ] - Temporarily Ignore Service Registry Test [ #1066 ] - Major developer docs update [ #1065 ] - Remove the RoleProvider.getRoles() method [ #1063 ] - Only events with write access [ #1062 ] - start on used port [ #1059 ] - Hide Column Stop By Default [ #1058 ] - Custom LTI Series Tool Styles [ #1057 ] - Update ESLint [ #1055 ] - Move to GitHub Issues [ #1053 ] - Update mustache [ #1052 ] - Update bootbox [ #1050 ] - && MH-13425 - Feeds-Tab / adds a new tab in series properties. [ #1048 ] - Add an optional build step to clean easily clean the frontend caches [ #1047 ] - ServiceRegistry not updating database correctly when dispatching jobs [ #1044 ] - clean node, node_modules and bower_components folders [ #1042 ] - Update Admin Interface JS Test Libraries [ #1041 ] - Update ESLint [ #1039 ] - paella can filter which tracks to load depending on the user's device [ #1037 ] - Update paella player to 6.2.0 [ #1034 ] - Update Translation Key for Published Hours [ #1033 ] - Direct link to assets tab [ #1030 ] - Configure max open files [ #1029 ] - Update admin interface JS libraries [ #1028 ] - Update Engage JS Libraries [ #1027 ] - Update Markdownlint [ #1023 ] - fix invisible icon for specific zoom level [ #1022 ] - Automatic publication of streaming URLs [ #1021 ] - Moving mediapackages needs to handle missing version information [ #1020 ] - Logging [ #1016 ] - Update Deprecated EqualsUtil.hash(\u2026) [ #1015 ] - IDEA Settings [ #1014 ] - Don't start opencast on a used port [ #1009 ] - Shell information for developer distribution [ #1008 ] - Crop service [ #1007 ] - Update several JS libraries [ #1006 ] - Improve metadata handling in backend [ #1005 ] - Fix dropdown menus [ #1004 ] - eslint 6.1.0 [ #1003 ] - Update karma [ #1001 ] - Access org properties from publish-configure WOH [ #998 ] - Concat Operation Graphics [ #997 ] - Update Development Process Documentation [ #996 ] - Update commons-text [ #995 ] - Composer Should Not Overwrite Files [ #994 ] - Added name of the configuration file where properties of login details are modified [ #992 ] - switch to compatible file type filter definitions [ #990 ] - Upgrade chromedriver [ #985 ] - Update grunt-concurrent [ #983 ] - Update ESLint [ #978 ] - Mh 13617 Duplicate encoding profiles for PrepareAV/SelectStreams [ #973 ] - Don't consider raw fields updated [ #972 ] - Improve setting values from dublin core catalog [ #971 ] - NOJIRA: Add ALTER to necessary MySQL permissions [ #970 ] - Fix hello-world modules [ #968 ] - Resolution Based, Conditional Encoding [ #967 ] - Introduce general CatalogUIAdapter [ #966 ] - Update frontend-maven-plugin [ #965 ] - Update Logger [ #964 ] - Update Checkstyle [ #963 ] - Update Paella Build Dependencies [ #962 ] - Update Chromedriver [ #961 ] - Update autoprefixer to 9.6.0 [ #960 ] - Update Markdownlint [ #959 ] - Update Admin Interface Test Framework [ #957 ] - Clean-up Static Resource Servlet [ #956 ] - Re-introduce Prepare AV [ #954 ] - Fix bundle versions [ #952 ] - Cleanup workflows [ #951 ] - More Dependency Checks\u2026 [ #950 ] - Tag elements retrieved from asset manager [ #949 ] - Termination State Service to integrate with AWS AutoScaling Lifecycle [ #948 ] - add health-check endpoint [ #945 ] - -publication [ #943 ] - color \"blue\" for links in the admin ui [ #942 ] - Theodul player ui config [ #941 ] - More dependency fixes [ #937 ] - Workflow Condition Parser Location [ #936 ] - Drop distribution-service-streaming [ #935 ] - Drop Distribution \u201cadminworker\u201d [ #934 ] - Drop Migration Distribution [ #931 ] - Assembly Configuration [ #929 ] - Check dependencies at build time [ #928 ] - Admin Interface Browser Tests [ #927 ] - Metadata Transfer Operation [ #926 ] - Remove unused code [ #925 ] - Media Module Dependency Management [ #924 ] - Jettison Dependency Management [ #923 ] - Introduce ESLint to Media Module [ #922 ] - Support for exclusion pattern for URL signing [ #921 ] - Officially support URL signing keys that handle multiple URL prefixes [ #920 ] - Streaming Module Cleanup [ #919 ] - Fix dependencies for statistics- and workflow-condition-parser [ #918 ] - Remove module 'dataloader' [ #917 ] - Remove obviously unused classes [ #908 ] - Admin interface dependency update [ #906 ] - Media Module Configuration [ #899 ] - Fix Login Page [ #898 ] - Fix Spelling of Flavor [ #895 ] - Update Tesseract Code [ #894 ] - NOJIRA Speed up statistics api tests [ #893 ] - Dependency Fixes [ #892 ] - Drop Custom Logger Configuration [ #891 ] - Unnecessary LineReader [ #890 ] - NOJIRA: Remove statistics provider configs [ #889 ] - Limit accepted file types when uploading assets [ #887 ] - Collect and visualize published hours of video [ #885 ] - Rework workflow conditions, add string data type [ #883 ] - Remove inclusion of non-existent scripts in Admin UI [ #882 ] - Navigation of statistics broken [ #881 ] - JavaScript Dependency Management [ #880 ] - Improve icons and wording in video editor [ #879 ] - statistics csv export [ #876 ] - Add Hourly Data Resolution For Statistics [ #874 ] - Role support for workflows [ #872 ] - Remove pseudo-mechanism for workflow definition registration [ #869 ] - Remove unused method WorkflowDefinition.isPublished [ #865 ] - Empty node name causes exception [ #864 ] - Multitenancy support for workflows [ #863 ] - Improve URL signing performance [ #862 ] - add single step event deletion [ #861 ] - Add option to configure state mappings for workflows [ #860 ] - Remove unused fields from search index [ #858 ] - Improve navigation in video editor when zoom is active [ #857 ] - resume on past table page when leaving video editor [ #854 ] - move ingest-download Operation to worker [ #851 ] - Highlight main table rows on hover [ #850 ] - Add node name to host registration as a UI searchable alternative to hostname [ #849 ] - Upgrade Admin Interface Libraries (Including AngularJS) [ #848 ] - Remove method canLogin from interface User [ #847 ] - Fix License and Documentation Links [ #846 ] - Automatically Launch Logs for dist-develop [ #842 ] - Harmonizing the column names [ #841 ] - Expand log messages to add error detail [ #834 ] - Introduce basic statistics visualization capabilities [ #831 ] - userprovider for the d2l brightspace LMS [ #826 ] - url query string incorrect [ #825 ] - Remove leftover service [ #824 ] - Use Username In Workflows [ #823 ] - Automatic caption using Google speech to text api [ #816 ] - Change the default composer job load from 0.8 to 1.5 [ #784 ] - Admin UI new event media upload progress bar [ #757 ] - Timelinepreviews process first one only","title":"Opencast 8.0"},{"location":"changelog/#opencast-7","text":"","title":"Opencast 7"},{"location":"changelog/#opencast-79","text":"Released on December 8, 2020 [ GHSA-44cw-p2hm-gpf6 ] Security: Disabled Hostname Verification [ #1964 ] - Docs: When the sidebar is hidden, the navigation links are disabled now [ #1922 ] - Remove Spring snapshot repository from main pom","title":"Opencast 7.9"},{"location":"changelog/#opencast-78","text":"Released on August 17, 2020 [ #1667 ] - Fix managed ACL filter in API [ #1659 ] - Updating Guava version [ #1657 ] - Fixed the video outline in the Theodul Player [ #1641 ] - Capture Agent Authentication Method [ #1595 ] - Gracefully Handle Missing Timeline Preview [ #1594 ] - Fix Calculation of Aspect Ratio [ #1589 ] - Engage: Theodul: Audio: Refer to correct items","title":"Opencast 7.8"},{"location":"changelog/#opencast-77","text":"Released on April 27, 2020 [ #1539 ] - Fix Karma Safari test in mac OS [ #1474 ] - Add comment to document remember me keys [ #1442 ] - Fix Remember-Me Authentication [ #1427 ] - 1281: Ignoring test which randomly fails in CI testing [ #1426 ] - Autodetect browsers for Admin UI tests, fix phantomJS OpenSSL issue [ #1425 ] - Don't duplicate publications [ #1380 ] - In fast, don't cleanup ACLs (see other workflows) [ #1379 ] - Use active, not episode ACL in scheduler service","title":"Opencast 7.7"},{"location":"changelog/#opencast-76","text":"Released on January 29, 2020 CVE-2020-5231 - Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 - Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 - Hard-Coded Key Used For Remember-me Token CVE-2020-5230 - Unsafe Identifiers CVE-2020-5228 - Public Access Via OAI-PMH [ #1358 ] - Switch To HTTPS Maven Repository [ #1353 ] - Handle empty fields from REST docs in EventHttpServletRequest [ #1352 ] - Remove unsafe option in ffmpeg command for SMIL processing [ #1343 ] - Fixes Admin-UI Presenter's column [ #1333 ] - Switch to mvn.opencast.org [ #1329 ] - Remove Spring Request Logger Configuration [ #1325 ] - Secure FPS For SMIL Processing [ #1318 ] - Remove Custom Plugin Repositories [ #1315 ] - Bump spring-security-oauth from 2.3.6.RELEASE to 2.3.7.RELEASE [ #1276 ] - Don't add the internal publication of the original event twice [ #1271 ] - Wrong encoding in video editor zoom box [ #1270 ] - S3 Distribution Fails [ #1265 ] - Some error operations referencing the wrong error-handler. [ #1246 ] - Remove default storage_id setting from asset Manager","title":"Opencast 7.6"},{"location":"changelog/#opencast-75","text":"Released on December 10, 2019 [ #1233 ] - Change bibliographicdate if technicaldate is changed. [ #1220 ] - Make Thumbnail Optional [ #1218 ] - [Documentation] Added path hint to upgrade.md [ #1170 ] - MH-9753: Prepare AV WOH can throw a NPE [ #1164 ] - CentOS basic installation guide rewording [ #1148 ] - VideoEditorServiceImpl: Fixed the file extension duplication with removeExtention from FilenameUtils. [ #1122 ] - fixes #1069 workflow tab shows scheduling info instead of workflows","title":"Opencast 7.5"},{"location":"changelog/#opencast-74","text":"Released on October 02, 2019 [ MH-13517 ][ #1092 ] - Set an absolute limit on Solr query size [ MH-13476 ][ #1088 ] - Filter capture agent roles for ACLs [ #1087 ] - Issue 1068, Stop job dispatcher before unregistering hosts, junit MH-13675 [ MH-13706 ][ #1072 ] - fix the date cell of the events overview table in the admin UI [ #1056 ] - NOISSUE: CAS security example is very out of date","title":"Opencast 7.4"},{"location":"changelog/#opencast-73","text":"Released on September 19, 2019 [ MH-13716 ][ #1061 ] - Update xmlsec [ MH-13715 ][ #1060 ] - Check Markdown for newline character [ #1056 ] - CAS security example is very out of date [ MH-13707 ][ #1051 ] - Watermark missing [ MH-13706 ][ #1049 ] - Show bibliographic event dates on the events overview page [ MH-13701 ][ #1040 ] - Interpret source-audio-name correctly for composite operation [ MH-13699 ][ #1038 ] - Fix Workflow Index Rebuild ACL Handling [ MH-13697 ][ #1036 ] - Workflow Index Rebuild Memory [ MH-13684 ][ #1024 ] - Do not include auth token in republished URLs [ MH-12533 ][ #714 ] - Re-introduce ability to avoid data loss during ingest","title":"Opencast 7.3"},{"location":"changelog/#opencast-72","text":"Released on August 02, 2019 [ MH-13662 ][ #1000 ] - Update LTI Information","title":"Opencast 7.2"},{"location":"changelog/#opencast-71","text":"Released on July 09, 2019 [ MH-13656 ][ #993 ] - Fix Scheduler Index Rebuild [ MH-13655 ][ #991 ] - Scheduler Message Logging [ MH-13653 ][ #989 ] - Fully Migrate Scheduled Events [ MH-13652 ][ #988 ] - Don't save unchanged values in dropdown menus [ MH-13651 ][ #987 ] - Don't call submit of SingleSelect twice [ MH-13650 ][ #986 ] - Scheduler Migration Performance [ MH-13646 ][ #982 ] - Delete scheduled events [ MH-13645 ][ #981 ] - Only send delete comments message if we delete something [ MH-13642 ][ #977 ] - Fix Index Update Logging [ MH-13639 ][ #976 ] - Admin interface does not handle missing metadata well [ MH-13638 ][ #975 ] - Update NPM [ MH-13619 ][ #958 ] - Fix Logging in Video Segmenter [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13610 ][ #947 ] - LDAP User Directory Fixes","title":"Opencast 7.1"},{"location":"changelog/#opencast-70","text":"Released on June 13, 2019 [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13602 ][ #940 ] - Update jackson-databind to fix CVE-2019-12086 [ MH-13599 ][ #938 ] - Select well supported mime type by default [ MH-13593 ][ #933 ] - Incorrect default waveform colors [ MH-13569 ][ #913 ] - Change of PlayerRedirection variable from to #{id} [ MH-13568 ][ #911 ] - Catch exception from overlapping RRule and return bad request [ MH-13566 ][ #910 ] - Accept duration as either string or number in scheduling JSON [ MH-13385 ][ #909 ] - Add release note about URL signing configuration changes [ MH-13375 ][ #907 ] - Handle empty-range errors correctly [ MH-13563 ][ #905 ] - Duplicated Variables in Media Module [ MH-13562 ][ #904 ] - ReferenceError in Media Module [ MH-13561 ][ #903 ] - Access to UI Configuration [ MH-13558 ][ #900 ] - Paella Track Filter [ MH-13554 ][ #897 ] - Theodul Zoom [ MH-13553 ][ #896 ] - Fix Paella Track Selection [ MH-13538 ][ #878 ] - Update jQuery [ MH-13531 ][ #873 ] - upgrade spring-security and jasig cas library to fix issue\u2026 [ MH-13529 ][ #871 ] - Don't warn about expected behavior [ MH-13528 ][ #870 ] - Non-Interactive FFmpeg [ MH-13525 ][ #867 ] - Update Admin Interface Libraries [ MH-13519 ][ #855 ] - Migrate mappings to Elastic Search 5.x [ MH-13505 ][ #844 ] - Update Admin Interface JavaScript Libraries [ MH-13504 ][ #843 ] - JavaScript Library Update [ MH-12047 ][ #832 ] - MH-13380 MH-13490 MH-13489 Add missing indexes [ MH-13477 ][ #819 ] - Faster Asset Manager Property Access [ MH-13465 ][ #807 ] - Prevent NullPointerException [ MH-13389 ][ #815 ] - More informative job load logging [ MH-13472 ][ #813 ] - Permissions for /play/ missing [ MH-13471 ][ #812 ] - Shibboleth SSO plugin to add roles for users on OC according to their EDUPERSONAFFILIATION. eg: \"ROLE_AAI_USER_AFFILIATION_student\" for \"student\" [ MH-13469 ][ #811 ] - Drop LastHeardFrom On Scheduler Messages [ MH-13468 ][ #810 ] - Capture Agent Registration Exception [ MH-13466 ][ #809 ] - Prevent Capture Agents From Modifying Metadata [ MH-13467 ][ #808 ] - opencast-security-cas feature can not be started [ #806 ] - extend the ingest-download-woh [ MH-12643 ][ #804 ] - Allow workspace to read from asset manager [ MH-13462 ][ #802 ] - Prevent Being Started By Root [ MH-13461 ][ #801 ] - Dependency Fixes & Dependency Checks [ MH-13460 ][ #800 ] - Update JavaScript Dependencies [ MH-13459 ][ #799 ] - Make Paella Use UI Configuration Service [ MH-13458 ][ #798 ] - Live Scheduler Dependencies [ MH-13457 ][ #797 ] - Dependency Update [ MH-13456 ][ #796 ] - Move Log Workflow Operation To Admin [ MH-13455 ][ #795 ] - Opencast Plug-in Features [ MH-13454 ][ #794 ] - Drop Unused Configuration Option Maps [ MH-13453 ][ #793 ] - Add more log output to WOH select-streams [ MH-13452 ][ #792 ] - Show creators correctly in delete modals [ MH-13450 ][ #790 ] - Remove unused class org.opencastproject.adminui.api.SortType [ MH-13448 ][ #789 ] - Make translation of creators consistent [ MH-13446 ][ #788 ] - Removed unfinished feature \"ACL transitions\" [ MH-13445 ][ #787 ] - Update Checkstyle [ MH-13443 ][ #783 ] - Don't use deprecated $http.success and $http.error methods [ MH-13439 ][ #782 ] - Dynamic Player Redirect [ MH-13438 ][ #781 ] - Simplify Streaming Format Check [ #780 ] - ACL documentation pointed to wrong config file [ MH-13436 ][ #778 ] - Improve error message for out of bounds image extraction [ MH-13421 ][ #776 ] - Remove unused workflowservice exceptions [ MH-13434 ][ #775 ] - Opencast Common Clean-up [ MH-13381 ][ #771 ] - Use Organization Identifier In Roles [ MH-13432 ][ #770 ] - Remove unused modals \"Job Details\" and \"Server Details\" [ MH-13431 ][ #769 ] - Remove unfinished feature \"Bulk Messaging\" [ MH-13430 ][ #768 ] - Fix Opencast Offline Builds [ MH-13428 ][ #766 ] - Remove unused library angular-scenario from admin ui tests [ MH-13426 ][ #765 ] - Remove unused Protractor end-to-end tests [ MH-13427 ][ #764 ] - Remove unused test resources [ MH-13381 ][ #763 ] - Use Organization Identifier in Workflows [ MH-13424 ][ #762 ] - Elasticsearch 5.6.15 [ MH-13423 ][ #761 ] - Possible NPE if debugging is enabled [ MH-13422 ][ #760 ] - Switch to markdownlint-cli [ MH-13420 ][ #759 ] - ngRepeat does not allow duplicates [ MH-13417 ][ #758 ] - UI Configuration Service Tests [ MH-13414 ][ #756 ] - extended metadata multivalue fields are not handled properly [ MH-13413 ][ #755 ] - UI Configuration Service Improvements [ MH-13412 ][ #754 ] - Deprecate PathSupport.concat(\u2026) [ MH-13411 ][ #753 ] - Fix UI Config Service Dependencies [ MH-13410 ][ #752 ] - Fix Broken Build Number [ MH-13397 ][ #751 ] - Remove unfinished feature \"Participation Management\" [ MH-13396 ][ #750 ] - Remove unfinished feature \"Location Blacklisting\" [ MH-13400 ][ #745 ] - Admin Index Test Cleanup [ MH-13399 ][ #744 ] - Update Elasticsearch Configuration [ MH-13395 ][ #742 ] - Remove unfinished feature \"Dashboard\" [ MH-13394 ][ #741 ] - Remove unfinished feature \"User Blacklisting\" [ MH-13393 ][ #738 ] - Remove leftover index resources [ MH-13392 ][ #737 ] - Added allowConflict parameter to methods and implemented [ #736 ] - Revert #523: Special handling of asset manager event removal [ MH-13390 ][ #735 ] - Quick-Filter by Presenter [ MH-13221 ][ #732 ] - Improve behaviour of single-select metadata fields [ MH-13385 ][ #731 ] - Simplify the configuration of the URL signing components [ MH-13384 ][ #730 ] - Remove duplicate joda-time dependency declaration [ MH-13277 ][ #729 ] - fix concurrent Map updates in scheduler [ MH-13382 ][ #727 ] - Minor Waveform Service Fixes [ MH-13379 ][ #726 ] - Simplify Mime Type Handling [ MH-13368 ][ #724 ] - Added color property to waveform operation handler [ MH-13376 ][ #722 ] - Fix OSGI Bindings [ MH-13374 ][ #720 ] - Update Node.js [ MH-13373 ][ #719 ] - Upgrade Admin Interface Libraries [ MH-13372 ][ #718 ] - Clean up orphaned asset manager properties [ MH-13371 ][ #717 ] - Drop unused angular-md5 [ MH-13370 ][ #716 ] - Don't configure unnecessary default credentials [ MH-13294 ][ #713 ] - Workflow for track replacement and cleanup Snapshots [ MH-13367 ][ #711 ] - External API series acl returns null pointer with missing acl [ #710 ] - adds an WOH, which can add catalogs to the MediaPackage of an workflow instance [ MH-13365 ][ #709 ] - inbox ingest into series and inbox retry [ MH-13364 ][ #707 ] - Fix hidden OSGI wiring errors [ #704 ] - Fixed a typo in the analyze-tracks description [ MH-13362 ][ #703 ] - Harmonize Admin Interface Menu Tooltips [ MH-13361 ][ #702 ] - Fix Scheduler Item Serialization [ MH-13360 ][ #701 ] - MH-13316: Watson transcripts improvements [ MH-13358 ][ #698 ] - Update JavaScript Dependencies [ #691 ] - Documentation: Developer Console: How to shutdown [ MH-13275 ][ #689 ] - Allows the workflow to select the audio track for composite videos [ MH-13350 ][ #688 ] - Theodul core HTML validation [ #687 ] - Documentation: Publish Engage Workflow OH [ MH-13344 ][ #685 ] - Enable AssetManager to reply NOT_MODIFIED [ #682 ] - add docs.opencast.org anchors for somewhat deep linking [ MH-13345 ][ #681 ] - Switch to Gson for Languages Endpoint [ MH-13342 ][ #678 ] - Don't try to create events with empty metadata [ #677 ] - Documentation: Dictionary service [ MH-13341 ][ #676 ] - Deleting Capture Agents Should Not Modify Users [ MH-13340 ][ #675 ] - Handle Empty Passwords [ MH-13339 ][ #674 ] - Handle Bad User Update Requests [ MH-13336 ][ #671 ] - Upgrade c3p0 [ #670 ] - Documentation: Analyze Audio WOH: Unbreak table [ MH-13331 ][ #667 ] - Fix ActiveMQ Defaults [ MH-13328 ][ #666 ] - Remove save button at top of videoeditor [ MH-13147 ][ #664 ] - OptimisticLockException in ServiceRegistry dispatchJob [ MH-13324 ][ #662 ] - Simplify Data Loader [ MH-13323 ][ #661 ] - Add documentation for list providers [ MH-13322 ][ #660 ] - Avoid . in Elasticsearch Field Names [ MH-13321 ][ #659 ] - Fix Series Item Serialization [ MH-13320 ][ #658 ] - Asset Manager Performance [ MH-13319 ][ #657 ] - Update Paella Binding Dependencies [ MH-13318 ][ #656 ] - Update to Apache Karaf 4.2.2 [ MH-13313 ][ #653 ] - Properly Use ACL Merge-Mode Configuration [ MH-13307 ][ #648 ] - Update Release Manager Documentation [ MH-13306 ][ #647 ] - Clean up MetadataUtils [ MH-13244 ][ #642 ] - Add override support to external api [ MH-13221 ][ #641 ] - Add placeholder to multi-select fields [ MH-13290 ][ #632 ] - Asset Manager Query Performance [ MH-13289 ][ #631 ] - Introduce Metadatafield Copy Constructor [ MH-13288 ][ #630 ] - Don't create incomplete metadata fields [ MH-13287 ][ #629 ] - Fix incorrect text metadatafield types [ MH-13286 ][ #628 ] - Remove unused functionality from MetadataField [ MH-13285 ][ #627 ] - Display workflow description [ #626 ] - Provide location of org.ops4j.pax.web.cfg [ MH-13284 ][ #625 ] - Update Elasticsearch to 2.x [ MH-12091 ][ #622 ] - Per-Tenant Capture Agent Users [ MH-13281 ][ #621 ] - Added property keep-last-snapshot for asset-delete WOH [ MH-13278 ][ #617 ] - Drop Unused Exception [ MH-13238 ][ #615 ] - don't throw related services straight into ERROR state just because job succeeded on current service [ MH-13277 ][ #614 ] - improve scheduler performance [ MH-13276 ][ #613 ] - Drop org.opencastproject.fun [ MH-13271 ][ #610 ] - Remove Useless ACL Check [ MH-13270 ][ #609 ] - Fix Message Item Serialization [ MH-13267 ][ #607 ] - Update Deprecated Code In UIRolesRoleProvider [ #605 ] - NOJIRA: Fix misspelled digest [ MH-13157 ][ #600 ] - Add multi-tenant support for all list providers [ MH-13262 ][ #596 ] - Changed for partial-error comment description to better description. [ MH-13261 ][ #595 ] - User Directory OSGI Service Definitions [ MH-13260 ][ #594 ] - Simplify Runtime Info UI [ MH-13259 ][ #593 ] - User/Role Directory Cleanup [ MH-13255 ][ #590 ] - Updated Deprecated Methods in Workspace Tests [ MH-13254 ][ #589 ] - Automate Dependency Checking [ MH-13253 ][ #588 ] - External Elasticsearch [ MH-13251 ][ #586 ] - Remove duplicate dependency [ MH-13247 ][ #582 ] - Deprecated Methods In Elasticsearch [ MH-12816 ][ #579 ] - Make waveform size configurable in WOH [ MH-13242 ][ #578 ] - Set disable_search_threshold for chosen globally [ MH-13241 ][ #577 ] - Filter Fileinstall Artifacts [ MH-13129 ][ #575 ] - More configuration options for thumbnails [ MH-13239 ][ #574 ] - Docs: Fix 'Edit on GitHub' link [ #573 ] - Documentation: Inbox [ MH-13234 ][ #565 ] - Workspace Deprecation Fixes [ MH-13231 ][ #564 ] - Allow entering multiple metadata values at once [ MH-13233 ][ #563 ] - add note about the jdk version use for build [ MH-13229 ][ #561 ] - External Library Updates [ MH-13227 ][ #559 ] - Update to Apache Karaf 4.2 [ MH-13226 ][ #558 ] - Update Docuemnation Landing Page [ MH-13224 ][ #556 ] - Drop commons-beanutils [ MH-13217 ][ #551 ] - pom.xml housekeeping [ MH-13213 ][ #548 ] - Separate External API Index [ MH-13212 ][ #546 ] - Fix external-api dependencies [ MH-13210 ][ #545 ] - Fix Deprecated IOUtils Usage [ #542 ] - Developer Installation Guide [ MH-13208 ][ #540 ] - Create a short contributor guide [ MH-13200 ][ #535 ] - Remove unused file acl-modal.html [ MH-13127 ][ #534 ] - Make table headers non-interactive by default [ MH-13198 ][ #529 ] - Properly Display Multiple Presenters [ MH-13197 ][ #528 ] - Separate Admin Interface Index [ MH-13195 ][ #526 ] - Fix Admin Interface Dependencies [ MH-13193 ][ #524 ] - Improve performance of event deletion (2) [ MH-13193 ][ #523 ] - Improve performance of event deletion (1) [ MH-13084 ][ #519 ] - Create a generic user interface configuration service [ MH-13054 ][ #518 ] - Update angular-ui-sortable, adapting build pipeline [ #515 ] - NOJIRA: Documentation: wait_timeout should be bigger than max.idle.time [ MH-13187 ][ #514 ] - Improve Track Stream Handling [ MH-13186 ][ #513 ] - Episode and Series ACL Handling [ MH-13185 ][ #511 ] - Don't include test web server [ MH-13183 ][ #505 ] - Add link to series details, out of the eventstable-view [ MH-13178 ][ #502 ] - Clean-up Series Dialog Code [ MH-13177 ][ #501 ] - Further Simplify MediaPackageElementFlavor [ MH-13175 ][ #499 ] - Remove Apache Tika for Generating Mimetypes [ MH-13174 ][ #498 ] - Simplify class MediaPackageElementFlavor [ MH-13155 ][ #497 ] - Make weekday preselection optional [ MH-13168 ][ #491 ] - Testcases to test a captureagent with Opencast integration. [ MH-13160 ][ #488 ] - Send actually required data in workflow messages [ MH-13161 ][ #483 ] - Simplify log statements [ MH-13158 ][ #480 ] - Use default functional interface for SecurityUtil#runAs [ MH-13153 ][ #477 ] - Workflow Service Code Cleanup [ MH-13151 ][ #475 ] - Update to Apache Karaf 4.1.6 [ MH-13148 ][ #472 ] - Internationalization support for series LTI tools [ MH-13140 ][ #466 ] - Clean-up REST Documentation Code [ MH-13061 ][ #450 ] - Display responsible person for workflows [ MH-13121 ][ #447 ] - Fix usertracking plugin in paella player [ MH-13124 ][ #446 ] - Unify linting for JavaScript and HTML [ MH-13082 ][ #440 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13098 ][ #430 ] - Add start-workflow WOH [ MH-13062 ][ #401 ] - Added credentials for the Ingest Service. [ MH-13000 ][ #398 ] - Group \u201cEdit scheduled\u201d events by weekday [ MH-12782 ][ #209 ] - As an unprivileged user, I only want to see series and events that I have write access to.","title":"Opencast 7.0"},{"location":"changelog/#opencast-6","text":"","title":"Opencast 6"},{"location":"changelog/#opencast-67","text":"Released on December 8, 2019 [ #1200 ] - Fix Crowdin Deployment [ #1143 ] - Upgrade jackson to 2.9.10 (6.x) [ #1142 ] - Update apache commons-compress to 1.19 [ #1132 ] - Fixed the \"hide\" button in the Documentation. [ #1080 ] - Documentation reworked [ #1035 ] - Pushing to Maven Central [ #1026 ] - Adding Ansible script documentation [ #1019 ] - SMIL tests fail when doctype url can't be resolved","title":"Opencast 6.7"},{"location":"changelog/#opencast-66","text":"Released on August 2, 2019 [ MH-13674 ][ #1013 ] - Fix Cutting [ MH-13673 ][ #1012 ] - Workflow options not visually aligned [ MH-13672 ][ #1011 ] - Editor Maximum Height [ MH-13671 ][ #1010 ] - OAI-PMH autorepublish fails due to invalid urls [ MH-13648 ][ #984 ] - Asset Manager Concurrecy Issue [ MH-13644 ][ #980 ] - Sometimes paella does not play audio [ MH-13643 ][ #979 ] - Update to Paella 6.1.4 [ MH-13637 ][ #974 ] - Asset manager endpoint fix [ MH-13633 ][ #969 ] - Update spring-security-oauth [ MH-13611 ][ #955 ] - Duplicate events fix","title":"Opencast 6.6"},{"location":"changelog/#opencast-65","text":"Released on June 14, 2019 [ MH-13607 ][ #946 ] - Show composite duration in video editor [ MH-13606 ][ #944 ] - Don't archive smil on publication [ MH-13601 ][ #939 ] - OAI-PMH database access syncronization [ MH-13575 ][ #916 ] - Update paella player to 6.1.3 [ MH-13573 ][ #914 ] - Add .factorypath to .gitignore [ MH-13560 ][ #902 ] - Admin Role in Moodle User Provider [ MH-13546 ][ #888 ] - textextraction performance improvement [ MH-13544 ][ #886 ] - Video editor shows incorrect notification [ MH-13536 ][ #877 ] - OAI-PMH Remote Broken [ MH-13533 ][ #875 ] - Document parameter \"sign\" of GET /api/events/{id}/publications/* [ MH-13526 ][ #868 ] - Show unequal tracks correctly in editor [ MH-13521 ][ #859 ] - Switch to openJDK 8 on Travis [ MH-13503 ][ #856 ] - Job Dispatch Fairness [ MH-13330 ][ #853 ] - The video editor does not always close after the user presses \"Publish\" [ MH-13511 ][ #852 ] - Adding events in parallel does not work correctly [ MH-13501 ][ #840 ] - Match against user pattern for loadUser() lookups [ MH-13495 ][ #839 ] - Ignore old requests instead of cancelling [ #837 ] - Fix adaptive streaming configuration guide [ MH-13492 ][ #833 ] - Add language support for Italian [ MH-13486 ][ #829 ] - Cleanup NOTICES 6.x [ MH-13485 ][ #828 ] - Update paella player to 6.1.2 [ #827 ] - Change url query syntax to ? [ MH-13476 ][ #818 ] - Filter capture agent roles for ACLs","title":"Opencast 6.5"},{"location":"changelog/#opencast-64","text":"Released on April 01, 2019 [ MH-13449 ][ cc11441 ] - MH-13449, upgrade spring-security-oauth libs [ MH-13464 ][ #805 ] - Update paella player to 6.1.0 [ MH-13463 ][ #803 ] - WOH select-streams does not hide audio track as expected [ MH-13444 ][ #786 ] - Insecure Series Creation [ MH-13387 ][ #777 ] - Get ACLs of finished workflows from AssetManager Document encoding-profiles parameter in ComposeWorkflowHandler [ MH-13429 ][ #767 ] - Make sure series LTI tool respects provided series custom param","title":"Opencast 6.4"},{"location":"changelog/#opencast-63","text":"Released on March 05, 2019 [ MH-13402 ][ #749 ] - WOH select-tracks does not work with audio-only input [ MH-13404 ][ #748 ] - Improve Workspace Logging [ MH-13401 ][ #747 ] - Fix icon in Paella Player [ MH-13388 ][ #734 ] - Updating job load values for composer service on worker nodes \u2026 [ MH-13378 ][ #725 ] - Add mimetype audio/m4a [ MH-13377 ][ #723 ] - Fix scheduler rrule TimeZone issue [ MH-12631 ][ #721 ] - Drop the ORGANIZER field from the ical feed [ MH-13369 ][ #715 ] - Delete Capture Agents [ MH-12177 ][ #712 ] - TimeZone threadsafe and bulk schedule across DST (NEW) [ MH-13355 ][ #700 ] - Increase the default timeout for TrustedHttpClientImpl [ MH-13359 ][ #699 ] - Adding UTF-8 encoding for all remote services [ MH-13357 ][ #697 ] - Enable being able to disable 2 confusing Admin UI metadata: \"duration\" & \"created\" [ MH-13356 ][ #696 ] - Unnecessary Snapshots [ MH-13347 ][ #695 ] - Don't always look for orphaned properties [ MH-13354 ][ #694 ] - Asset Manager Property Performance [ MH-13352 ][ #693 ] - Unnecessary Format [ MH-13310 ][ #692 ] - Simplify AQueryBuilderImpl#always [ #686 ] - Document workaround steps for authentication with IBM Watson STT [ MH-13147 ][ #683 ] - 6.x): OptimisticLockException in ServiceRegistry dispatchJob [ MH-13343 ][ #679 ] - Load track into workspace with unique ID [ MH-13338 ][ #673 ] - Elasticsearch Upgrade Documentation [ MH-13337 ][ #672 ] - Admin UI workflow status translation keys added [ MH-13329 ][ #668 ] - Removing a capture agent resets the password of all Opencast users [ MH-13326 ][ #663 ] - No file/directory found when taking snapshot [ MH-13315 ][ #655 ] - Don't destroy Notifications service on destruction of the Notifications directive [ MH-13312 ][ #654 ] - Do not show outdated conflict information","title":"Opencast 6.3"},{"location":"changelog/#opencast-62","text":"Released on January 24, 2019 [ MH-13309 ][ #649 ] - return empty list when finding findUsersByUserName when the name param is empty.","title":"Opencast 6.2"},{"location":"changelog/#opencast-61","text":"Released on January 12, 2019 [ MH-13305 ][ #646 ] - MacOS installation update [ MH-13304 ][ #645 ] - Multi-value consistent with multi-select [ MH-13302 ][ #644 ] - Don't save unnecessarily in Multi-Select [ MH-13301 ][ #643 ] - Don't require event.publisher since it is a readonly field [ MH-13300 ][ #640 ] - Display multi-value fields correctly on summary pages [ MH-13299 ][ #639 ] - Make multi-select fields consistent again [ MH-13295 ][ #635 ] - Handle null for presentable value extraction [ MH-13283 ][ #624 ] - Fix Custom CXF Error Handler [ MH-13248 ][ #623 ] - Allow hidden workflow parameters","title":"Opencast 6.1"},{"location":"changelog/#opencast-60","text":"Released on December 10, 2018 [ #620 ] - Remove dropped translations [ MH-13230 ][ #616 ] - remove the need for passing an Accept header with external api requests [ MH-13272 ][ #611 ] - fix missing roles [ MH-13266 ][ #606 ] - Start date cross link does not work correctly [ MH-13215 ][ #602 ] - WorkflowOperationTagUtil throws a null pointer [ MH-13245 ][ #601 ] - Paella player does not show a single presentation video [ MH-13252 ][ #587 ] - Ineffective Synchronization of Elasticsearch Startup [ MH-13221 ][ #585 ] - Improve multi-select metadata fields [ MH-13250 ][ #584 ] - Thumbnail feature does not work for unprivileged users [ MH-13249 ][ #583 ] - Invalid Group Endpoint Registration [ MH-13237 ][ #576 ] - Track previews do not work with stream security [ MH-13214 ][ #570 ] - Fix HTTP Digest Authentication [ MH-13232 ][ #562 ] - Fix potentially negative fade-out start [ MH-13228 ][ #560 ] - Homogeneous Width of Shortcut Icons [ MH-13225 ][ #557 ] - Fix for exception in live scheduler service when rebuilding the admin ui index [ MH-13222 ][ #554 ] - Some fixes to tiered storage asset manager [ MH-13209 ][ #544 ] - Put CAS Feature In Distributions [ MH-13150 ][ #541 ] - Add note about CAAM to release notes [ MH-13201 ][ #538 ] - Convert uploaded images to appropriate size and format [ MH-13206 ][ #537 ] - Use correct mouse cursor in filters [ MH-13205 ][ #536 ] - Document, fix and improve thumbnail support [ MH-13196 ][ #527 ] - Unregister Resource Servlets of Bundles to be Removed [ MH-13192 ][ #522 ] - Improve performance of list requests [ MH-13191 ][ #521 ] - Improve performance of retrieving groups [ MH-13188 ][ #516 ] - Update paella player 6.0.3 [ MH-13154 ][ #512 ] - Unify vertical spacing in wizards [ MH-13184 ][ #508 ] - Update request-digest [ #507 ] - Remove documentation about unused workflow pause role [ MH-13162 ][ #506 ] - Show all series in edit-scheduled-events [ MH-13179 ][ #503 ] - Fix Video Editor Preview Mode Default [ MH-13176 ][ #500 ] - Bug fix update of Jackson [ MH-13170 ][ #496 ] - Fix workflow not selected in event details [ MH-13171 ][ #495 ] - Fix workflow configuration settings being displayed incorrectly [ MH-13173 ][ #494 ] - Do not hardcode value of ACL override [ MH-13169 ][ #492 ] - Update bibliographic metadata when technical metadata changes [ MH-13166 ][ #489 ] - OAI-PMH Message Handler Performance [ MH-13164 ][ #487 ] - Load catalog for snapshot message effeciently [ MH-13130 ][ #486 ] - java.lang.ClassCastException in AdminUserAndGroupLoader when starting up [ MH-13163 ][ #484 ] - Fix empty REST documentation notes [ MH-13159 ][ #481 ] - Fix mattermost notification operation issues [ MH-13111 ][ #479 ] - Fix display of metadata in series creation summary [ MH-13110 ][ #478 ] - Fix display of metadata in event creation summary [ MH-13150 ][ #474 ] - Opencast 6.0 release notes [ MH-13149 ][ #473 ] - Timed tiered storage test fails on fast systems [ MH-13051 ][ #471 ] - Fix dropdown placeholders [ #470 ] - Fix rest docs of GroupsEndpoint [ MH-13141 ][ #469 ] - Correctly initialize stats service [ MH-13142 ][ #468 ] - Error parsing non-existent schedule [ MH-13135 ][ #467 ] - Pending requests are not cancelled as expected [ MH-13139 ][ #465 ] - Documentation for the event publisher metadata [ MH-12819 ][ #464 ] - change extract-text encoding profile for better OCR results\u2026 [ MH-13137 ][ #462 ] - Less extensive statistics configuration [ MH-13136 ][ #461 ] - Add Danish Translation [ MH-13133 ][ #459 ] - TypeError: Cannot read property 'results' of null [ MH-13092 ][ #458 ] - Fix failing scheduling for non-english browsers [ MH-13132 ][ #457 ] - Fix REST Docs Overview Rendering [ MH-13131 ][ #456 ] - Fix Feed Service REST Docs [ #455 ] - Remove misleading - sign in tag woh docs [ MH-13125 ][ #451 ] - Remove unused configuration keys [ MH-13123 ][ #448 ] - Update paella player 6.0.2 [ MH-13117 ][ #445 ] - Mark NPM managed modules as private packages [ MH-13116 ][ #444 ] - Fix typo in paella error message [ MH-13115 ][ #443 ] - Update Node, NPM and Libs [ MH-13114 ][ #442 ] - Fix broken REST docs [ MH-13113 ][ #441 ] - Drop unused HTML page [ MH-13025 ][ #439 ] - Fix workflow-definitions URL [ MH-13109 ][ #438 ] - Update Paella Player to 6.0.x [ MH-13107 ][ #436 ] - Update admin interface build dependencies [ MH-13106 ][ #435 ] - Add Moodle groups to Moodle role provider [ MH-13105 ][ #434 ] - Fix minor mattermost notification operation issues [ MH-13104 ][ #433 ] - Add linter for LTI tools [ MH-13103 ][ #432 ] - Runtime UI NG JavaScript Dependencies [ MH-13102 ][ #431 ] - Add linter (checkstyle) for JavaScript to engage-paella-player module [ MH-13097 ][ #429 ] - Added a configuration parameter to be able to send HTML emails [ MH-13101 ][ #428 ] - Update paella dependencies [ MH-13100 ][ #427 ] - fix series view in Paella [ MH-13099 ][ #426 ] - Warn when default credentials are being used [ MH-13096 ][ #425 ] - Set workflow variables with duplicated media package IDs [ MH-13095 ][ #424 ] - Add linter (checkstyle) for JavaScript [ MH-13083 ][ #423 ] - Unify modal navigation [ MH-13094 ][ #422 ] - Use global NPM repository [ MH-13090 ][ #420 ] - Added support for blacklisting languages from the admin UI [ MH-12699 ][ #419 ] - Remove opencast-paella binding dependency on Admin server [ MH-13088 ][ #417 ] - Update Several Dependencies [ MH-13087 ][ #416 ] - Update Runtime UI Libraries [ MH-13086 ][ #415 ] - Update LTI Series Tool [ MH-13079 ][ #413 ] - Introduce REST Interface for AssetManager Properties [ MH-13060 ][ #412 ] - Add i18n support for workflow, operations, job and services status [ MH-13073 ][ #411 ] - Don't split series metadata fields by , [ MH-13074 ][ #410 ] - Clean up asset manager REST endpoints [ MH-13072 ][ #409 ] - Remove broken ltitool player [ MH-13071 ][ #408 ] - Update markdown linter [ MH-13070 ][ #407 ] - Update JS build and test libraries [ MH-13064 ][ #399 ] - Encoding profile mimetypes are mostly ignored [ MH-13058 ][ #395 ] - Remove unused font libraries [ MH-12688 ][ #392 ] - Add translations for comment filter values [ MH-13045 ][ #391 ] - Add missing i18n translations [ MH-13040 ][ #388 ] - Make options fit \u201cActions\u201d drop-down [ MH-12810 ][ #387 ] - External API 1.1.0 - Add filters for new fields [ MH-13037 ][ #386 ] - Remove unused External API roles [ MH-12690 ][ #384 ] - Add i18n support for capture agent statuses [ MH-12761 ][ #382 ] - Fixed event to listen to \"plugin.events.captionsFound\". [ MH-13028 ][ #381 ] - Clean up mockup [ MH-13022 ][ #378 ] - fixed LTI highly trusted keys being discarded [ #376 ] - Update and improve documentation for reviews [ MH-13027 ][ #374 ] - Update angular-translate to 2.18.1 [ MH-13026 ][ #373 ] - Update Mac OS X 'Install from source' documentation [ MH-13025 ][ #372 ] - Add workflow API to external API [ MH-13024 ][ #371 ] - Video editor does not display information when being opened while an event is being processed [ #369 ] - Documentation: message-broker: binding localhost [ #368 ] - Documentation: Update security.https.md [ MH-13016 ][ #362 ] - Workflow display order not working in editor screen [ MH-13013 ][ #359 ] - Unused code in scheduler [ MH-13008 ][ #358 ] - Prefill other input of startdate filter [ MH-13012 ][ #357 ] - The iterable metadata values should not be splitted by , [ MH-13010 ][ #356 ] - Series-Service-Remote incorrect character encoding [ MH-13009 ][ #355 ] - Update translations [ MH-13007 ][ #354 ] - Clarify Scheduler Calendar cutoff units in REST docs [ MH-12829 ][ #348 ] - Make admin-ui statistics configurable [ MH-12998 ][ #346 ] - Clear conflicts when closing \u201cEdit Scheduled Events\u201d modal [ MH-12996 ][ #345 ] - Add header row to conflict table in \u201cEdit scheduled\u201d [ MH-12995 ][ #344 ] - Fix conflict check not detecting some conflicts [ MH-12990 ][ #343 ] - User switching: Privilege escalation too restrictive [ MH-12993 ][ #342 ] - REST docs for Admin UI Event endpoint broken [ MH-12994 ][ #341 ] - Make \u201cTitle\u201d in \u201cEdit scheduled\u201d non-mandatory [ MH-12992 ][ #340 ] - Trigger conflict check in \u201cEdit scheduled\u201d on \u201cNext\u201d [ MH-12989 ][ #338 ] - Add missing roles for actions->edit scheduled [ #336 ] - Update version info [ MH-12987 ][ #335 ] - Prohibit changing a scheduled event to be in the past [ MH-12985 ][ #332 ] - Fix incorrect warnings in event modals [ MH-12803 ][ #329 ] - Fix for mp 'start' when event is created (affects live scheduler service) [ MH-12980 ][ #328 ] - Update documentation landign page [ MH-12930 ][ #327 ] - Fill creator metadata field with actual user when new event [ MH-12977 ][ #322 ] - Fix data placeholders in edit scheduled events [ MH-11918 ][ #321 ] - AWS S3 Asset Storage [ MH-12975 ][ #320 ] - Inconsistent access control handling [ MH-12738 ][ #319 ] - Tiered Storage for the Asset Manager [ MH-12969 ][ #317 ] - Eclipse IDE import Opencast XML style preferences [ MH-12972 ][ #316 ] - Drop unused getAclAttachments [ MH-12969 ][ #314 ] - Ensure formatting of OSGI configuration [ #313 ] - NOJIRA-live-schedule-fix-issue-in-documatation [ MH-12965 ][ #311 ] - Add more logging data to metadata parse WARN [ MH-12961 ][ #308 ] - Remove unused JavaScript library bootstrap from Admin UI [ MH-12960 ][ #307 ] - Remove unused JavaScript library backbone.js from Admin UI [ MH-12959 ][ #306 ] - Remove unused JavaScript library visualsearch.js [ MH-12956 ][ #305 ] - Incorrect permission check when requesting indexed workflows [ MH-12958 ][ #301 ] - image-convert WOH [ MH-12607 ][ #299 ] - Multiencode [ MH-12955 ][ #298 ] - ffmpeg expect floating timestamp values separated by '.' [ MH-12949 ][ #294 ] - Fix spacing between action items [ MH-12946 ][ #292 ] - add event summary input translation [ MH-12948 ][ #291 ] - Directly read XACML files [ MH-12905 ][ #289 ] - Opencast does not startup anymore [ MH-12911 ][ #266 ] - Hotkey cheat sheet [ MH-12813 ][ #265 ] - Add audio and video track selection to video editor [ MH-12607 ][ #264 ] - Process-Smil - edit and encode to multiple delivery formats [ MH-12918 ][ #261 ] - Use Karaf generated jre.properties [ MH-12904 ][ #252 ] - Paella player 5.3 update [ MH-12829 ][ #237 ] - Fix broken sub tabs of Event Details->Assets [ MH-12889 ][ #236 ] - Intuitive Merging of Video Segments [ MH-12828 ][ #233 ] - re-enable Scheduler service conflicts json REST endpoint [ MH-12885 ][ #232 ] - Capture Agent Access Management [ MH-12877 ][ #231 ] - Add new modal to edit multiple scheduled events at once [ MH-12871 ][ #220 ] - Ability to use user names in to/cc/bcc fields in send-email woh [ MH-12869 ][ #219 ] - Remove superfluous playback tool [ MH-12829 ][ #218 ] - Switch and rename event details tabs [ MH-12814 ][ #208 ] - Manually Select And Upload Thumbnails [ MH-12815 ][ #197 ] - delete series with events option [ MH-12826 ][ #193 ] - Make workflow processing settings persistent [ MH-12823 ][ #182 ] - Log Configuration and GELF Log4J with graylog [ #181 ] - adapt tracking default options to respect the EU GDPR [ MH-12822 ][ #179 ] - Remove old OCv2x security context fix artifacts [ MH-12607 ][ #172 ] - Harvard DCE), Demux Operation [ MH-12607 ][ #171 ] - Harvard DCE), Lossless Concat Operation [ MH-12804 ][ #170 ] - Introduce displayOrder for workflow definitions [ MH-12797 ][ #168 ] - Explain UI actions (added missing tooltips) [ MH-12820 ][ #167 ] - Mattermost-notification-workflowoperationhandler [ #165 ] - Be less quiet about errors on Travis [ MH-12797 ][ #164 ] - Explain UI Actions [ MH-12794 ][ #162 ] - turn off matomo notification [ MH-12793 ][ #161 ] - Collapse multiple, redundant composer process methods [ MH-12647 ][ #155 ] - MH-12756 extend external api [ MH-12786 ][ #154 ] - Undistinguishable Entries in Groups Editor User List [ MH-12784 ][ #153 ] - External API: Accept header not specified correctly [ MH-12091 ][ #150 ] - Implement per-tenant digest user for capture agents [ MH-12703 ][ #89 ] - Add userdirectory for Moodle [ MH-11621 ][ #56 ] - Option to marshal empty values in DublinCore XML catalog.","title":"Opencast 6.0"},{"location":"changelog/#opencast-5","text":"","title":"Opencast 5"},{"location":"changelog/#opencast-55","text":"Released on April 1, 2019 [ MH-12603 ][ #746 ] - Take 'ng' out of the youtube composite operation [ MH-13386 ][ #733 ] - Event status calculation wrong assumption fixed [ MH-13383 ][ #728 ] - don't smooth the waveform in the editor [ MH-13366 ][ #708 ] - Add REFERENCES permission to standard Opencast GRANT statement [ MH-13363 ][ #706 ] - Publish to OAI-PMH an allready published mediapackage \u2026 [ MH-13333 ][ #669 ] - Do not import properties in publish WF","title":"Opencast 5.5"},{"location":"changelog/#opencast-54","text":"Released on January 24, 2019 [ MH-13311 ][ #652 ] - WOH cover-image is broken SUREFIRE-1588: Resolving compilation issue on Debian and related distros [ MH-13244 ][ #581 ] - Improve concurrency of OAIPMH republication","title":"Opencast 5.4"},{"location":"changelog/#opencast-53","text":"Released on January 11, 2019 [ MH-13297 ][ #638 ] - FasterXML Jackson Bugfix Update [ MH-13296 ][ #637 ] - Disable buttons of start task wizard while the tasks are being submitted [ MH-12290 ][ #636 ] - prevent SAXParserFactory and SAXParser class load lag in series listprovider [ MH-13269 ][ #608 ] - Handle Authorization Errors [ MH-13263 ][ #598 ] - Invalid Ingest Encoding [ MH-13257 ][ #597 ] - Fix outdated command line argument for tesseract >= 4.0.0 [ MH-13258 ][ #592 ] - Broken User Provider Removal [ MH-13256 ][ #591 ] - Waveform operation fails [ MH-13243 ][ #580 ] - Asset Manager ACL Cache Updates [ #572 ] - Documentation: Opencast 5.2 was released in Nov [ #571 ] - Documentation: Linkfixes in OC5.x upgrade guide [ MH-12332 ][ #567 ] - disable workflows whose tags don't explicitly match the source type, UPLOAD|SCHEDULE 5.x","title":"Opencast 5.3"},{"location":"changelog/#opencast-52","text":"Released on November 13, 2018 [ MH-13144 ][ #553 ] - only set Job startDate if no set before [ MH-13216 ][ #550 ] - Fix Documentation Pages [ MH-13211 ][ #547 ] - engage-ui: Fix live schedule bug: event available before schedule [ MH-13190 ][ #520 ] - Factor out JpaGroupRoleProvider JaxRs REST to mitigate load cycle race [ MH-13189 ][ #517 ] - Fix paella xss security isues in opencast 5.x [ MH-13167 ][ #490 ] - Republishing metadata does not update all metadata [ MH-13152 ][ #476 ] - Reduce Workflow Messages [ MH-13138 ][ #463 ] - Fix media module language configuration [ MH-13108 ][ #437 ] - Prevent permission problem in Travis cache [ MH-13091 ][ #421 ] - Concat operation problem with FFMPEG 4.x [ MH-13069 ][ #406 ] - Update problematic admin interface libraries [ MH-12976 ][ #389 ] - custom role patterns not working [ MH-12387 ][ #350 ] - Fix CAS","title":"Opencast 5.2"},{"location":"changelog/#opencast-51","text":"Released on September 3, 2018 [ MH-13067 ][ #404 ] - Configuration panel does not work for default workflow [ MH-13049 ][ #400 ] - Fix video editor zoom dropdown showing wrong value [ MH-13055 ][ #396 ] - Stop making events with no ACL public on ingest [ MH-13048 ][ #394 ] - Improve stability of the series index rebuild [ MH-13047 ][ #393 ] - Document using Nginx for HTTPS [ MH-13044 ][ #390 ] - Organization server configuration documentation [ MH-12016 ][ #379 ] - Scrolling role fetch [ MH-13031 ][ #377 ] - Active transaction notification on top [ MH-13029 ][ #375 ] - Don't show old notifications [ MH-13023 ][ #370 ] - Let default value fulfill requirement [ MH-13018 ][ #367 ] - re-add recordings json to 5x (includes MH-12828 re-add conflicts.json) [ MH-13020 ][ #366 ] - Read listproviders as UTF-8 [ MH-13017 ][ #363 ] - JS syntax error in publish workflow [ MH-13015 ][ #361 ] - 5.x database upgrade scripts [ MH-13014 ][ #360 ] - Don't show stale search results [ MH-13006 ][ #353 ] - Waveform operation cleanup creates problem with asynchronous NFS [ MH-13003 ][ #352 ] - Implement detection of already recorded (as opposed to yet to be recorded, scheduled) events by the index service [ MH-13005 ][ #351 ] - Skip waveform operation when no tracks [ MH-13001 ][ #347 ] - Fixed live scheduler service pom [ MH-12988 ][ #337 ] - delete-scheduled-live Fix for scheduled live event not deleted [ MH-12986 ][ #333 ] - Admin UI deployed debugging: include source in SourceMap files [ MH-12981 ][ #331 ] - fix for local admin-ui develop finding main.css [ MH-12979 ][ #325 ] - Automatically test ddl scripts [ MH-12978 ][ #324 ] - Fix data-placeholder in add event wizard [ MH-12974 ][ #318 ] - Access denial to event for unprivileged user [ MH-12970 ][ #315 ] - Senseless XACML parsing [ MH-12966 ][ #312 ] - Do not pre-select-from option in metadata property sheets [ MH-12963 ][ #310 ] - Localize dates/times in add-event summary [ MH-12950 ][ #309 ] - Fix for workflow with no acl in solr index NOJIRA: Skip install of Crowdin if it is already installed [ MH-12957 ][ #300 ] - Defaults on tab Source in Add Event wizards are broken [ MH-12954 ][ #297 ] - wrong date format in coverimage file","title":"Opencast 5.1"},{"location":"changelog/#opencast-50","text":"Released on June 12, 2018 [ MH-12952 ][ #295 ] - animate WOH dependency version fixed [ MH-12946 ][ #290 ] - Fix summary of add-event-dialog [ MH-12944 ][ #288 ] - Remove bashism from start script [ MH-12905 ][ #287 ] - TEMPORARY Karaf config assembly workaround (KARAF-5693) [ MH-12943 ][ #286 ] - Minor Paella config REST endpoint improvements [ MH-12942 ][ #285 ] - Paella player config REST endpoint should be accessible by anonymous user [ MH-12941 ][ #284 ] - Gracefully handle empty flavors [ MH-12940 ][ #283 ] - Ensure admin configuration is applied [ MH-12864 ][ #282 ] - Don't attempt to parse 'undefined' [ MH-12938 ][ #281 ] - Fix NullPointerException if no flavor is set [ MH-12937 ][ #280 ] - Correctly place admin UI test helper [ MH-12936 ][ #279 ] - Handle invalid flavors [ MH-12935 ][ #278 ] - Update Docker image repository documentation [ MH-12934 ][ #277 ] - Update translations [ MH-12933 ][ #276 ] - Link documentation from Systemd unit [ MH-12932 ][ #275 ] - Kernel Build Failure [ MH-12922 ][ #272 ] - Job load fixes [ MH-12929 ][ #271 ] - Change paella URL to /paella/ui [ MH-12928 ][ #270 ] - Mitigation for KARAF-5526 [ MH-12926 ][ #269 ] - Prevent cluttering of logs by invalid access [ MH-12924 ][ #268 ] - fix missing dropdown arrow [ MH-12919 ][ #262 ] - REST Docs Dependencies [ MH-12917 ][ #260 ] - Remove debug logging [ MH-12916 ][ #259 ] - Admin Interface Configuration Defaults [ MH-12914 ][ #258 ] - Remove deprecated IOUtils.closeQuietly [ MH-12913 ][ #257 ] - Fix Admin Interface Deprecation Warnings [ MH-12868 ][ #255 ] - Make frame-by-frame skipping function in the editor use the \"actual\" framerate [ MH-12908 ][ #251 ] - Fix escaping of spaces [ MH-12907 ][ #250 ] - Fix segmentation default job load [ MH-12906 ][ #249 ] - Composoer should ignore system specific output pathes like /dev/null [ MH-12902 ][ #248 ] - closing videoeditor should continue in events list [ MH-12901 ][ #247 ] - Fix YouTube publication job loads [ MH-12900 ][ #246 ] - Fix search service job loads [ MH-12899 ][ #245 ] - Fix streaming distribution job load defaults [ MH-12898 ][ #244 ] - Fix download distribution job load defaults [ MH-12897 ][ #243 ] - Improve visibility of selected segments in the videoeditor [ MH-12896 ][ #242 ] - Clarify default player configuration [ MH-12894 ][ #240 ] - Update markdownlint [ MH-12893 ][ #239 ] - Added ability to configure the job load for the aws s3 distribution service. [ MH-12892 ][ #238 ] - Added ability to configure the job load for the transcription service. [ MH-12888 ][ #235 ] - Missing FFmpeg on Travis CI [ MH-12887 ][ #234 ] - Only set job date completed and runtime once. [ MH-12883 ][ #230 ] - Maven build of admin-ui module without frontend profile [ MH-12882 ][ #229 ] - Fix org.w3c.dom.smil version [ MH-12881 ][ #228 ] - Remove deprecated method [ MH-12880 ][ #227 ] - Remove redundant OSGI declarations [ MH-12879 ][ #226 ] - Default location of paella configuration [ MH-12878 ][ #224 ] - Don't verify NPM cache to speed up build process [ MH-12874 ][ #223 ] - NotFoundException handling for OAI-PMH retract operation with non published event [ MH-12872 ][ #222 ] - event can not be deleted [ MH-12873 ][ #221 ] - Speed up test builds [ MH-12864 ][ #215 ] - Readonly mode of fields not working correctly in property sheets [ MH-12807 ][ #213 ] - Do not overwrite owner [ MH-12863 ][ #212 ] - Fix default owner in SMIL endpoint [ MH-12862 ][ #211 ] - Line break after required marker in REST docs [ MH-12834 ][ #207 ] - Central documentation for filtering, sorting and pagination [ MH-12833 ][ #204 ] - Consistently use External API as name [ MH-12852 ][ #203 ] - Required fields not indicated in the event details and series details modals [ MH-12843 ][ #200 ] - Fix \u201cAdd Event\u201d Tab Index Update main readme Fix tabs and trailing spaces in docs [ MH-12839 ][ #196 ] - fix all pom.xml [ MH-12837 ][ #194 ] - external series API ACL is required [ MH-12832 ][ #192 ] - Update to commons-collection4 [ MH-12836 ][ #191 ] - Fix event-comment dependencies not correctly specified [ MH-12831 ][ #190 ] - Fixing dependencies NOJIRA fix engage paella url security rules NOJIRA Localization developer guide updated [ MH-12780 ][ #184 ] - Fix sorting jobs by identifier in Systems->Jobs [ MH-12824 ][ #183 ] - Speed up mvn site T/clarify wording of user tracking in documentation [ MH-12818 ][ #177 ] - Improve Sox service tests NOJIRA Crowdin project configuration updated NOJIRA Crowdin documentation updated [ MH-12771 ][ #173 ] - Document fields of External API 1.0.0 [ MH-12795 ][ #163 ] - REST docs don't respect @Produces annotation on class level [ MH-12788 ][ #157 ] - UTF-8 encoding settings in OAI-PMH publication service remote [ MH-12616 ][ #152 ] - Admin UI Flexible Asset Upload override or fallback display text [ MH-12775 ][ #146 ] - Add JavaScript source map generation [ MH-12768 ][ #142 ] - Minor XACMLAuthorizationService fixes [ MH-12825 ][ #139 ] - Add markdownlint to Travis CI [ MH-12760 ][ #160 ] - Cross-link column date in events table to enable the start date filter [ MH-12789 ][ #158 ] - Remove tabs and trailing spaces in LTI tools [ MH-12509 ][ #151 ] - Enable HTTP basic auth in default config [ MH-12759 ][ #149 ] - More Control Over Workflows [ MH-12779 ][ #147 ] - Support X-Forwarded-Proto header [ MH-12649 ][ #138 ] - clone workflow operation handler [ MH-12764 ][ #137 ] - update license information for admin-ui [ MH-12763 ][ #136 ] - Minor Composer Fixes [ MH-12762 ][ #135 ] - Fix Spaces In Configuration Fallback For Synfig Install clean up woh documentation Make Travis check for tabs in pom.xml files Add Mkdocs To Travis Builds [ MH-12757 ][ #128 ] - Fix ClassCastException [ MH-12755 ][ #127 ] - Fix workflow-workflowoperation dependencies [ MH-12746 ][ #126 ] - Update Checkstyle [ MH-12746 ][ #125 ] - Update Apache HTTPComponents [ MH-12746 ][ #124 ] - Update Mina [ MH-12746 ][ #123 ] - Remove commons-logging [ MH-12746 ][ #122 ] - Update Jackson [ MH-12752 ][ #121 ] - Ignore VSCode project data [ MH-12751 ][ #120 ] - Add Travis Badge [ MH-12735 ][ #119 ] - Remove Undocumented Operations [ MH-12746 ][ #115 ] - Library Update [ MH-12742 ][ #113 ] - Update to Karaf 4.0.10 [ MH-12744 ][ #111 ] - Fix migration bundle dependencies [ MH-12739 ][ #109 ] - Transcription Service updated to support Paella [ MH-12737 ][ #108 ] - OAI-PMH publication service [ MH-12732 ][ #106 ] - Remove Unused Remote Service Registry [ MH-12731 ][ #105 ] - Improve Recreating Series Index [ MH-12730 ][ #104 ] - Workflow Index Rebuild Performance [ MH-12711 ][ #100 ] - improve xacml parser [ MH-12726 ][ #99 ] - Add description to theme [ MH-12704 ][ #98 ] - Captions support for paella [ MH-12718 ][ #97 ] - Animate Service [ MH-12713 ][ #95 ] - Series cannot be created [ MH-12705 ][ #87 ] - Fix scheduler hot-deployment [ MH-12701 ][ #84 ] - Paella: Localization files + crowdin config file [ MH-12692 ][ #83 ] - update maven bundle plugin for java8 [ MH-12663 ][ #81 ] - Don't search for non-existing WFR files [ MH-12694 ][ #80 ] - Save\" button in the editor now stays on the same page. [ MH-12693 ][ #77 ] - Notes on how to enable, upgrade to HTTPS [ MH-12675 ][ #76 ] - Send default startdate to backend also if it hasn't been changed. [ MH-12656 ][ #75 ] - Updates to Theodul Matomo (formerly Piwik) Plugin [ MH-12684 ][ #69 ] - Make License List Provider More Flexible [ MH-12683 ][ #68 ] - Improve Video Editor Tests [ MH-12681 ][ #66 ] - update media package series catalogs on event metadata update [ MH-12677 ][ #65 ] - Be less technical about displaying the version number [ MH-12674 ][ #63 ] - Remove unused hard-coded list providers [ MH-12665 ][ #62 ] - Sort table on startup [ MH-12649 ][ #59 ] - clone workflow operation handler [ MH-12668 ][ #58 ] - Update packages of admin ui build pipeline Use $timeout instead of $interval to resolve MH-12667 [ MH-12661 ][ #52 ] - Update angular-translate to 2.17.0 [ MH-12660 ][ #51 ] - Scheduling Events by Specifying End Time [ MH-12658 ][ #50 ] - Disable Jasmine for Theodul [ MH-12653 ][ #46 ] - Authorization service should use workspace#read() wherever possible [ MH-12600 ][ #45 ] - Move userdirectory stuff from bundle kernel to userdirectory [ MH-12648 ][ #42 ] - As a system administrator, I want to use different encoding \u2026 [ MH-12645 ][ #39 ] - Created an option to rebuild index for an specific service [ MH-12644 ][ #37 ] - External API index schema fixes [ MH-12538 ][ #36 ] - Remove obsolete ACL distribution service and WOH distribute-acl [ MH-12639 ][ #35 ] - update angular-chosen to 1.8.0 [ MH-11984 ][ #32 ] - Allow customization of the username-to-user-role mapping [ MH-12367 ][ #30 ] - Renaming all database tables [ MH-12633 ][ #29 ] - Fix version of maven-dependency-plugin [ MH-12544 ][ #26 ] - Play Deleted Segments in Video Editor [ MH-12575 ][ #25 ] - Upgrade to AngularJS 1.5.11 [ MH-12595 ][ #24 ] - Improve Publications Usability [ MH-12613 ][ #23 ] - New WorkflowOperationHandler 'create-event' [ MH-12628 ][ #20 ] - MH-12629, MH-12630, Minor database fixes [ MH-10560 ][ #19 ] - Live Scheduler Service [ MH-12615 ][ #17 ] - Improve the languages drop-down menu [ MH-12623 ][ #16 ] - Improve workflow dropdown menu [ MH-12621 ][ #15 ] - submit paella player [ MH-12624 ][ #11 ] - Fix link to Karaf remote debugging documentation Update debs.md [ MH-12472 ][ #8 ] - FFmpeg Composer Implementation [ MH-12502 ][ #7 ] - Do Not Leave Files In Workspace [ MH-12477 ][ #6 ] - Operation To Log Workflow State [ MH-12555 ][ #5 ] - Add support for Piwik Media Analytics [ MH-10016 ][ #4 ] - Default Workflow [ MH-12603 ][ #2 ] - Consistent Workflow IDs [ MH-12622 ][ #1 ] - Surefire Versions Should Not Diverge","title":"Opencast 5.0"},{"location":"changelog/#opencast-4","text":"","title":"Opencast 4"},{"location":"changelog/#opencast-45","text":"Released on Oktober 30, 2018 [NOJIRA] - Fix wrong example in publish-configure documentation [MH-13075] - make ACL entries unique prior to running ACL comparisons [MH-13068] - workflow delete instance stability improvement [MH-13055] - Stop making events with no ACL public on ingest [MH-13032] - Asset Upload fix for missing reset() [MH-12953] - stop loading editor.json twice [NOJIRA] - Update the release process docs","title":"Opencast 4.5"},{"location":"changelog/#opencast-44","text":"Released on May 31, 2018 [MH-12923] - ServiceRegistry does not close db connction [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins","title":"Opencast 4.4"},{"location":"changelog/#opencast-43","text":"Released on March 28, 2018 [MH-12774] - Fix differences in provided security configurations [MH-12773] - Fix that non-admins cannot add new assets [MH-12772] - Fix acces to assets for non-admins [MH-12789] - Remove tabs and trailing spaces in LTI tools [MH-12790] - Make LTI respect player configuration","title":"Opencast 4.3"},{"location":"changelog/#opencast-42","text":"Released on March 14, 2018 [MH-12766] - Metadata view and edit roles where at some places set incorrectly [MH-12765] - Navigating through series in the series details modal causes failing attempts to save ACLs [MH-12758] - Changing the ACLs does not trigger AssetManagerDecorators [MH-12747] - Heartbeat is broken [MH-12745] - Fix heartbeat config logging [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12728] - Add LAST-MODIFIED to ical event properties [MH-12727] - OptimisticLockException on worker node can cause jobs to be stuck in DISPATCHING state [MH-12725] - Series/Events ACL update causes scheduled recordings in the series/the events to disappear from CA calendar [MH-12717] - Series metadata update causes scheduled recordings in the series to disappear from CA calendar [MH-12711] - XACML Parser should be more robust [MH-12707] - Fix problem with non-strict mode in URL-Signing [MH-12706] - Old zombie workflows cannot be stopped, suspended etc. [MH-12668] - Update admin ui build pipeline [MH-12651] - Scheduling repeating events through Admin UI is very slow","title":"Opencast 4.2"},{"location":"changelog/#opencast-41","text":"Released on Februar 7, 2018 [MH-12695] - Improve Synchronization in WorkflowService [MH-12689] - Flickering filter: When loading the page, all filters briefly appear and disappear again [MH-12687] - Date filters not working [MH-12685] - Performance issue in filters [MH-12682] - TimelinePreview Concurrency Problem [MH-12676] - List provider service implementation is not thread-safe [MH-12673] - Content-Type is not set for JavaScript files [MH-12664] - Ensure series can be deleted [MH-12662] - Special characters in modal window titles are double-escaped [MH-12657] - Users of non-admin groups cannot create events [MH-12652] - Scheduler service needs to restrict queries to episodes owned by it [MH-12641] - Asset manager conflict checks are very slow [MH-12638] - Migration bundle needs to have a higher runlevel [MH-12637] - Remove event id from episode DC catalog during migration [MH-12632] - Make index rebuild robust [MH-12631] - Drop the ORGANIZER field from the ical feed [MH-12627] - Start Task copies files into workspace [MH-12620] - Document ActiveMQ memory requirements [MH-12610] - Navigating through events in the event details modal causes failing attempts to save ACLs [MH-12609] - As a user, I expect scheduling of events to be working [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12602] - External API gives 500 error for migrated series that do not have creator field [MH-12601] - Fast Workflow Does Not Attach Series Metadata [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12476] - Delay start of job dispatching on startup [MH-10016] - Cannot Change Default Workflow","title":"Opencast 4.1"},{"location":"changelog/#opencast-40","text":"Released on December 8, 2017 [MH-12597] - When reindexing, some events may incorrectly be displayed as \"Scheduled\" instead of \"Processed\" or \"Failed\" [MH-12596] - Video Editor Ignores Workspace [MH-12594] - Description field in metadata editor doesn't handle newlines properly [MH-12591] - AssetManager reindex produces \"No organization found!\" warnings [MH-12590] - Fix Workflow WOH Workspace Mock [MH-12589] - Fix Timelinepreview Dependencies [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12583] - Reduce frequency of index rebuild messages for comments and asset manager [MH-12579] - Simplify XACML Handling [MH-12578] - Color of Crosslinks Makes Tables Look Noisy [MH-12574] - Audio keeps playing when leaving the playback or editor page [MH-12573] - Unprivileged users cannot delete events [MH-12572] - Dependency Fixes [MH-12570] - Admin UI Regressions And Minor Bugs [MH-12569] - Don't fail hard if attempting to distribute a non-track media package element to streaming server [MH-12568] - EditableSingleValue Has Focus Issues [MH-12567] - Index Service Dependencies [MH-12566] - Remove Unused Participation List Provider [MH-12560] - Streaming media distribution does not work in a distributed cluster [MH-12559] - CSS: Delete And Retract Dialogs For Events Are Messed up [MH-12558] - CSS: Buttons in Confirm Modals Too Big [MH-12557] - CSS: Checkbox Alignment in Tables [MH-12556] - Video Editor CSS Enhancements [MH-12554] - Downloading translations from Crowdin doesn't work anymore [MH-12553] - As an administrator, I want to configure the order in which the different adaptive streaming video qualities are listed [MH-12552] - The \"delete\" button in the Admin UI may leave the \"preview\" artifacts undeleted [MH-12551] - Redo changes of MH-11660 that got lost in means of a regression [MH-12550] - hasActiveTransaction is triggered permantly for edited jobs [MH-12548] - Matterhorn Kernel Test Issues [MH-12547] - Group related settings in custom.properties [MH-12546] - 3.x to 4.0 upgrade is ugly [MH-12545] - Multi Value Editable Loses Value on Blur [MH-12543] - Adjust Log Level During Build Time [MH-12542] - Fix Ingest Service API Dependencies [MH-12541] - Events not searchable after migration if event was subject to a workflow with two publish-engage operations [MH-12540] - Add documentation for WOH failing [MH-12539] - Add documentation for WOH include [MH-12537] - Admin UI Asset upload: Order Assets as listed in properties file (vs alphabetical) [MH-12535] - Add language support for Hebrew [MH-12534] - Broken Labels In Default Workflow [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12529] - External API returns negative Event duration [MH-12526] - External (LDAP) users cannot not see their own role (ROLE_USER_XXXX) in the access policy of the events they create. [MH-12525] - Non-admin users cannot modify ACLs in their own events [MH-12523] - \"Submit\" button in retract modal is always disabled [MH-12522] - Improve Waveform Service Dependency Specification [MH-12520] - Duplicate Series When Double Clicking Create Button [MH-12519] - Improve Admin-NG Dependency Specification [MH-12518] - Ugly exception appears in stdout/Karaf console [MH-12517] - Some job data is not copied correctly [MH-12514] - Opencast Allows Multiple Simultaneous Workflows For Same Media Package [MH-12513] - MigrationService fails [MH-12512] - Frontend-Maven-Plugin configuration is missing the mandatory \"versionRange\" parameter [MH-12511] - Deleting an event with inconsistent search index state doesn't work [MH-12510] - System doesn't recover from ActiveMQ downtime [MH-12507] - Textanalyzer Has Nondeclared Dependencies [MH-12503] - Log statements do not require Object or String arrays to provide 3 parameters or more [MH-12500] - Fix incorrect usage of method \"URL#getFile()\" [MH-12499] - Admin UI event tools dialog can't be closed with the close button [MH-12498] - External API: Cannot get series if description field is empty [MH-12497] - Improve usability of admin UI forms [MH-12492] - AssetManager endpoint return server error on assets, which the user not allowed to read [MH-12489] - Failed test: MySQL DDL Scripts (Update) \ufffc [MH-12488] - Publish worklow always fail [MH-12480] - Waveform Operation Should Have Tests [MH-12479] - Waveform Operation Should Not leave Files In Workspace [MH-12475] - Make mimetypes consistent [MH-12470] - Prematurely deleted scheduler properties lead to undeletable events [MH-12469] - Auto Update OAIPMH republishes deleted Events [MH-12467] - Scheduled event fails due to not finding a workflow definition to use [MH-12465] - Propagate Changes of Series Extended Metadata to Events and OAI-PMH [MH-12463] - Hyphens in event/series search return no results [MH-12456] - Clean Up PathSupport [MH-12455] - FFmpeg does not terminate when Opencast is shut down [MH-12454] - PathSupport.changeFileExtension does not properly handle files with no extension [MH-12453] - TimelinePreview Path Handling [MH-12451] - Lock file utility method should throw exceptions [MH-12450] - Clean up *EncoderEngine code [MH-12449] - Ensure temporary files are deleted on composer failure [MH-12448] - Remove unconfigured send-mail WOH [MH-12447] - OAI-PMH autorepublish fails if series was deleted [MH-12446] - Do not leave ZIP files in workspace when a Workflow fails [MH-12445] - underlying code showing on metadata source tab when creating event [MH-12443] - editing event changes status from scheduled to finished [MH-12442] - Maven site is broken [MH-12436] - Add Christian Greweling to Comitters list [MH-12431] - Update Crowdin translations for r/4.x [MH-12428] - Performance Issue In Event Metadata [MH-12427] - Submit button in Editor typo [MH-12423] - Date Parse Error When Changing Certain Metadata [MH-12420] - Update frontend-maven-plugin [MH-12417] - Poor performace on scheduler /recordings/calendars [MH-12411] - Database user requires additional permissions [MH-12409] - Conductor logs ClassCastException when receiving DeleteSnapshot [MH-12407] - \"The task could not be created\" message by starting task on multiple events [MH-12406] - Splitting in the video editor while a video is playing causes time jump [MH-12401] - Video editor segment times stay blank (timing) [MH-12399] - Oaipmh Retract very slow [MH-12396] - Cannot select filter two times in a row from dropdown [MH-12395] - REST: Handle Scheduling Conflict [MH-12394] - Video editor allows the submission of an event with no active segments [MH-12390] - Gracefully handle unregistration of non-existing host [MH-12385] - Ingest Code Cleanup [MH-12382] - As a system administrator, I want to see the capture agent configuration in the user interface, so that I don't need to look into the database directly [MH-12380] - External API v1.0.0 Broken Due To StartDate Format Change [MH-12372] - Make waveform service more flexible by allowing pre- and post-filters to be configured [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12356] - As an administrator, I'd like to resolve or delete comments in workflows by comment reason only [MH-12355] - Include Wowza Adaptive Streaming Module in Opencast [MH-12354] - Admin UI Video Editor wont let you edit segements at the end [MH-12352] - Include support for user Groups in LDAP [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12349] - Exception handler should not throw an IO exception on deleting temporary directory [MH-12348] - As an administrator, I want to use the \"send-email\" WOH with multiple recipients and also use the CC and BCC fields [MH-12346] - Publications are not shown in the admin interface [MH-12330] - The series WOH only updates the series' title and ID on the episode's catalog, but sometimes more fields should be updated [MH-12328] - Update AngularJS from 1.3.x to 1.4.x [MH-12325] - Maven warning when building r/3.x [MH-12314] - As a developer, I expect the Admin UI tests being skipped if I build Opencast using -DskipTests [MH-12312] - Event Counter For \"Today\" [MH-12309] - Use Matching FontAwesome Icons [MH-12304] - Configurable Notification Durations [MH-12302] - Do Not Warn About Default Configuration [MH-12289] - Publish extended metadata to OAI-PMH [MH-12287] - prevent reload of Admin UI when opening the editor [MH-12286] - As an Opencast admin, I want to set workflow properties from an external script [MH-12284] - Unprivileged users cannot upload any files when creating or editing a theme [MH-12283] - Support MPEG DASH in Player [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12274] - Ingest service REST endpoint should be verbosable and expect input UTF-8 encoded [MH-12266] - As a user, I expect metadata changes to be propagated to third-party applications [MH-12259] - Ingest-download WOH fail on downloading publication elements [MH-12258] - Update angular-translate to version 2.15.2 [MH-12250] - Synchronize Dublin Core date created and start date in DC temporal [MH-12242] - Theodul: Quality selector does not display/load [MH-12234] - Cleanup WOH does not remove all files as it should do [MH-12227] - As a user, I don't want to be informed about services not being working correctly [MH-12223] - Oaipmh Publish is very slow [MH-12200] - Improve LDAP integration after the changes brought by MH-12016 [MH-12196] - Use a date and time picker instead of separate inputs for date and time in admin UI [MH-12191] - Add support for automated captions/transcripts (IBM Watson) [MH-12168] - As a user, I need cross-page links that help me to work more efficiently [MH-12166] - As a user, I'm not willing to perform that many clicks to actually use the filters [MH-12111] - Require Java 8 [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12099] - Wrong started date/time on workflow details view [MH-12082] - Contribute Asset Manager/Scheduler work (ETH) [MH-12052] - As an Administrator, I'd like to know that ActiveMQ is running properly [MH-12000] - Cross-tenant URL signing [MH-11703] - Service error states not immediately visible in admin UI [MH-11458] - Update translations from crowdin [MH-11274] - Workflow Operations of Scheduled Event are not editable [MH-11195] - Ability to Search on part of a Series Identifier, instead of just exact match [MH-11042] - Admin UI NG tests fail in +5:30 timezone [MH-10156] - Misspelling in LtiLaunchAuthenticationHandler.java","title":"Opencast 4.0"},{"location":"changelog/#opencast-3x","text":"","title":"Opencast 3.x"},{"location":"changelog/#opencast-37","text":"Released on Oct 16, 2018 [ MH-12982 ] - 3.0 database upgrade error [ MH-13022 ] - Fix LTI highly trusted keys being discarded [ MH-13034 ] - Add lis_person_sourcedid back as LTI source field for the username [ MH-13082 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13152 ] - Reduce Workflow Messages, backport of Lars fix for >=r/5.x [ MH-13156 ] - Set the auth scheme to digest for inter-server communication","title":"Opencast 3.7"},{"location":"changelog/#opencast-36","text":"Released on May 31, 2018 [MH-12910] - When switching between branches with different module naming schemes, the git tree is left unclean sometimes [MH-12860] - Opencast does not build at DEBUG logging level [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins [MH-12830] - Fix mvn site generation [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12441] - Fix multi-server configuration docs and config details [MH-12091] - Create a Capture Agent digest user with its own role","title":"Opencast 3.6"},{"location":"changelog/#opencast-35","text":"Released on February 6, 2018 [MH-12620] - Document ActiveMQ memory requirements [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12487] - Add job load settings to the default encoding profles [MH-12399] - Oaipmh Retract very slow","title":"Opencast 3.5"},{"location":"changelog/#opencast-34","text":"Released on December 4, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12516] - Oversize job acceptance logic is incorrect [MH-12505] - composer operations need to set job load from profile load when creating jobs [MH-12501] - Incorrect logging in inbox scanner [MH-12496] - Feeds point to removed embed player [MH-12494] - JMX bean unregistration causing stack traces in unit tests [MH-12478] - Waveform filenames are not unique [MH-12471] - Workspace Cleaner Minor Fix [MH-12464] - Job dispatching can be slowed down excessively by host loads query [MH-12439] - WorkspaceCleaner Should Clean All Files [MH-12437] - Admin UI ng fails mvn clean install if the node_modules exists [MH-12435] - Race condition when workspace file deletion removes collection [MH-12430] - Update Crowdin translations for r/3.x [MH-12422] - Adjust documentation to new Crowdin Opencast project [MH-12421] - Job dispatching halts because of http connection hang [MH-12415] - Improve performance of /api/events?withpublications=true [MH-12363] - org.json.simple.parser.JSONParser is not thread safe [MH-12000] - Cross-tenant URL signing [MH-11361] - date in engage is the creation date, not the recording date [MH-11042] - Admin UI NG tests fail in +5:30 timezone","title":"Opencast 3.4"},{"location":"changelog/#opencast-33","text":"Released on September 21, 2017 [MH-12383] - Upgrade/Unify Library Versions [MH-12413] - Don't present the user a previous/next item button if there is no previous/next item [MH-12405] - Catastrophic Oveload in Calendar generation [MH-12400] - Player: Embed Links disabled [MH-12393] - Retract workflow fails if run when a video is being played (with nfs storage) [MH-12389] - Set operation to failed when setting workflow to failed on exception path [MH-12386] - Update Postgresql Connector [MH-12384] - Catch possible NPE in FileSupport.delete() [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12364] - /broker/status endpoint returns incorrect 204 when ActiveMQ is shut down [MH-12362] - Less verbose logging for ExportWorkflowPropertiesWOH [MH-12360] - Race condition in workspace collection add and delete [MH-12359] - Milliseconds trim bug in videoeditor-workflowoperation formatTime() javaScript [MH-12358] - Only 6 series were displayed on the distribution node [MH-12353] - Theodul player does not load reliably after restart [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12329] - File copy can fail with jetty timeout [MH-12326] - Reduce log level for IllegalStateException in StaticResourceServlet [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12303] - Sort the REST endpoints alphabetically [MH-12131] - Migrate documentation of capture agent communication protocol to markdown [MH-12085] - Make file upload in Admin UI more flexible [MH-11768] - Timeline preview images","title":"Opencast 3.3"},{"location":"changelog/#opencast-32","text":"Released on August 16, 2017 [MH-12347] - Opencast generates invalid XML catalogs when a \"default\" (empty) Namespace is used. [MH-12345] - Ingest fails because /recordings/{id}/acls returns 500 if event has not ACLs [MH-12342] - A \"Scanner\" instance in the ExecuteServiceImpl class is not properly closed: possible resource leak [MH-12333] - Feed generator separates lists of tags incorrectly [MH-12327] - CAS Authentication is not working [MH-12324] - Reduce frequency of index update messages for rebuilds [MH-12318] - Remove Webconsole Default Installation [MH-12316] - IllegalStateException: Committed [MH-12315] - Database Query of Users from UserlistProvider is very slow [MH-12311] - Update Admin UI build tools [MH-12307] - OAI-PMH REST endpoint docs fix [MH-12305] - Admin UI should stop polling event stats if the event tab isn't shown [MH-12288] - Set default max idle time if not configured and log key pool parameters [MH-12280] - Create an Opencast group for Sakai instructors [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12275] - MH-12261 / Avoid race condition between index and cleanup operations [MH-12271] - MH-12261 / Update WFR put action to update files atomically [MH-12270] - Don't swallow unknown SMIL exceptions [MH-12263] - MH-12261 / FileSupport > link - copy file action should use overwrite argument (Throws FileFileAlreadyExists) [MH-12261] - Race condition leads to FileAlreadyExistsException and FileNotFoundException [MH-12079] - Misleading logging in some indexing message receivers [MH-12007] - Revive the Execute Service [MH-11542] - Failed test: Process video after cutting (Safari) [MH-10650] - Intermittent failure to detect hard links when starting a cluster [MH-10523] - Misleading exception parameter in getFileFromCollection","title":"Opencast 3.2"},{"location":"changelog/#opencast-31","text":"Released on July 14, 2017 [MH-12296] - getSeries Performance Issue [MH-12295] - Update Karaf to 4.0.9 [MH-12291] - Remove obsolete Speech Recognition API [MH-12279] - As a user, I expect the video editor to correctly visualize the audio track [MH-12253] - Example workflows are inconsistent in Formatting and Configuration of Publication Options [MH-12215] - Extended metadata should be applied on event create wizard [MH-12157] - Series index query performs bad on system with many series [MH-11742] - Document criteria for inclusion and exclusion of translations","title":"Opencast 3.1"},{"location":"changelog/#opencast-30","text":"Released on June 13, 2017 [MH-12257] - HttpsFilter is not called before OAuthProviderProcessingFilter [MH-12255] - OC cannot add PyCA capture agent when server ending with / [MH-12252] - LTI default launch goes to the wrong URL for sample tool [MH-12249] - Media Module: Paging forgets search parameters [MH-12248] - Capture Calendar Modification Caching Implementation is very Inefficient [MH-12247] - Archive Synchronization fix doesn't working in >=2.3 [MH-12235] - WOH partial-import: No track matching smil Track-id [MH-12230] - Notifications appear again although the user has closed them [MH-12228] - player controls: use dropup instead of a dropdown if controls are below the video [MH-12226] - Add documentation about configuration of publication channel names and icons [MH-12222] - As a user, I don't want an empty tab be presented to me since I don't necessarily understand, what that means [MH-12221] - As a user, I expect meaningful placeholder texts in the filter selection components [MH-12213] - Internal distribution fails if download url is not default [MH-12211] - As a service provider, I need to be able to deal with multiple users that have the same name [MH-12207] - Incorrect comment identifiers in some workflows [MH-12205] - Update version of javax.ws.rs - jsr311-api [MH-12204] - Rearrange the config [MH-12202] - ProxyMiddleware does ignore host port [MH-12199] - 3.x release notes mention \"comprehensive\" LDAP support, which is not (yet) true [MH-12198] - Remove outdated file location in LDAP documentation [MH-12197] - IllegalStateException: Response is committed [MH-12195] - Unprivileged users cannot view media package element details on Recordings->Events->\"Event Details\"->Assets->Media [MH-12193] - OAI-PMH distribution fails on adaptive streaming artifacts [MH-12189] - Sakai userdirectory provider is not properly bundled [MH-12183] - Theodul does not load [MH-12181] - As a course admin, I want to allow roles in the UI for ACLs that match a pattern [MH-12180] - Cannot specify ValuefFor probe-resolution woh [MH-12174] - The Admin UI temporarily displays wrong table content because data is not cleared upon page navigation [MH-12173] - The Admin UI temporarily displays wrong table content because data requests are not cancelled [MH-12170] - Safari does not display metadata once entered [MH-12169] - As a user, I expect search strings to match non-word boundaries in searchable dropdown lists [MH-12167] - As a user, I need to be able to search for values offered by the filters, so that I actually find the value I am looking for [MH-12156] - Fix version of matterhorn-engage-theodul-plugin-custom-piwik [MH-12153] - Reduce Database Space usage [MH-12149] - Upgrade Elastic Search to 1.7.6 [MH-12148] - Undocumented Archive WOH Requirements [MH-12147] - TOC links in REST docs overlap [MH-12142] - As a system administrator, I would like a documented hint that the user running Opencast needs RW access to the optional storage directory [MH-12141] - As service provider, I want to restrict access granted to tenant administrators [MH-12138] - Added release notes [MH-12137] - AWS S3 tries to distribute attachments from OAI-PMH distribution [MH-12133] - OAI-PMH Tests Fails Regularly [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12128] - REST docs are too eager to check for a valid value [MH-12126] - Fast workflow needs AWS distribution to default to false. [MH-12124] - Cutting a video multiple times results in multiple smil/cutting catalogs [MH-12121] - Update grunt-ng-annotate to 3.0.0 and grunt-contrib-uglify to 2.2.0 [MH-12120] - pub service oaipmh wants distribution api [MH-12117] - As an adopter I would like to get collect data with Piwik [MH-12115] - Republish Metadata to OAI-PMH fails [MH-12113] - Update outdated comment about the \"lifecycle-mapping\" plugin in the main pom.xml [MH-12112] - Update Node Version [MH-12110] - frontend-maven-plugin is executed on every module [MH-12109] - Creating comments does not work anymore [MH-12108] - Set Workflow Variables Based On Resolution [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12103] - As a producer, I want to be able to execute WOH partial-import on archived sources [MH-12102] - Add Workflow Variables Based On Media Properties [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12074] - Remove workflow MissedCaptureScanner and MissedIngestScanner [MH-12073] - Typo in rest_docs entry box [MH-12070] - Order the event counters to reflect the event lifecycle [MH-12067] - Initial REST Docs Search [MH-12066] - Missing feature.xml Installation [MH-12065] - Fix bundle info REST endpoint description [MH-12064] - Handle missing meta.abstract gracefully [MH-12060] - Simplify Default WOH [MH-12056] - As an Administrator, I'd like to add some custom roles for managing access [MH-12055] - Update REST Documentation Template [MH-12054] - Incorrect or misleading documentation about WOH conditional execution [MH-12049] - Update REST Documentation Overview [MH-12043] - Allow more then one additional authentication algorithms beside digest [MH-12038] - Fallback decoding for mediapackage date values in unixtime rather than W3CDTF [MH-12037] - NullPoiinterException when starting embedded Solr [MH-12035] - Setting Default Download Directory [MH-12034] - Make the UserAndRoleDirectoryService cache configurable [MH-12033] - Add indicator lights for capture agent status [MH-12032] - Add an authenticated ACL template [MH-12031] - Add additional docs for inspection WOH [MH-12029] - As a user, I want to use my existing AAI login for Opencast, too [MH-12023] - Make development builds faster [MH-12022] - /ingest/addTrackURL broken [MH-12019] - Ensure Test Files Are Deleted [MH-12017] - CoverImage WOH should provide metadata for recording start/end time [MH-12016] - Fix and improve user, group, role and provider handling [MH-12015] - Typo in External API role name [MH-12014] - Incorrect number of roles returned when limit is specified [MH-12013] - Contribute OAI-PMH work (ETH) [MH-12002] - Date & time format should be customizable in cover images [MH-11994] - UserIdRoleProvider should check user existence from user providers [MH-11993] - WOH partial-import should support output framerate [MH-11990] - Remove configuration file of removed module matterhorn-load-test [MH-11982] - As an Opencast administrator, I would like a dashboard counter for active recordings [MH-11979] - The video editor does not highlight the selected segment if it is cut [MH-11978] - Hotkeys for common tasks in Admin UI [MH-11977] - Remove Unused OSGI Bindings From IndexService [MH-11976] - Adjust DownloadDistribution Logs [MH-11975] - Update some maven plugins [MH-11971] - Update maven-surfire-test plugin to latest version [MH-11969] - Fullscreen button in embedded view of Theodul player missing after update to 2.2.4 [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11965] - Update to Karaf 4.0.8 [MH-11957] - Make availability check of WOH publish-configure configurable [MH-11956] - Allow fine-grained control of accurate frame count [MH-11954] - Fixing Javadoc Build [MH-11952] - HTML in Translations [MH-11944] - MH-11817 use keyboard shortcuts to control the editor [MH-11916] - Add convenience workflow instance variable to indicate whether a theme is involved [MH-11910] - WOH composite should be able to respect resolution of its input [MH-11904] - Missing IDClass Warnings [MH-11903] - Cannot Configure Authentication For Webconsole [MH-11902] - Update to latest 5.x MySQL connector [MH-11894] - Suppress context menu on video element [MH-11885] - Add support for search and filtering to Organization->Access Policies [MH-11881] - ArchiveRestEndpoint has conflicting endpoints [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11873] - org.ops4j.pax.web.pax-web-extender-whiteboard causes exception when shutting down [MH-11868] - redesign loginpages [MH-11861] - MH-11817 Change default view to editor in admin ui tools area [MH-11849] - Edit metadata fields by click inside and focus cursor in field [MH-11822] - Admin UI Video Editor - Improved Segment Controls [MH-11821] - Admin UI Video Editor - Comment and Metadata Editing [MH-11818] - Admin UI Video Editor - Improved playback and timeline [MH-11806] - Output Frame Rate on Concat Operation [MH-11797] - Upgrade Karaf to 4.0.6 [MH-11796] - Add support for watermarks to themes [MH-11782] - MH-11780 Create configure-by-dcterm workflow operation handler [MH-11781] - MH-11780 Create tag-by-dcterm workflow operation handler [MH-11780] - As a developer I want to be able to manipulate a workflow based on metadata in the Mediapackage [MH-11766] - enhance REST Ingest/addTrack Ingest/addCatalog Ingest/AddAttachment to add tags [MH-11761] - Captions for player [MH-11732] - Make distribution and retraction efficient [MH-11719] - When configuring LDAP with default file things are broken [MH-11717] - MH-11713 Not possible to add external roles to an ACL through the admin UI [MH-11715] - MH-11713 Externally provisioned roles should not be persisted [MH-11713] - Users may have roles in Opencast which are granted from an external system (e.g. LMS) [MH-11684] - WOH silence does not support tags [MH-11474] - Assigning a user to a certain \"ROLE_GROUP_<name>\" role does not really put the user in such group [MH-11466] - Improve handling of long strings in cover images [MH-11379] - Service to distribute delivery files to AWS S3 [MH-11229] - workflowoperation unit tests are incredible slow [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-10871] - Sakai User Provider for Opencast-Sakai integration [MH-10819] - When creating a new event, metadata field can only be edited by clicking on the pencil icon [MH-10753] - Stale database connection causes job failure [MH-10310] - Add ERROR state for capture agent","title":"Opencast 3.0"},{"location":"changelog/#opencast-23x","text":"","title":"Opencast 2.3.x"},{"location":"changelog/#opencast-235","text":"Released on December 04, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12269] - Clarify in the documentation the recommendation of setting dispatchinterval to 0 applies to non-admin nodes only [MH-12190] - Script injection in Media Module and Player [MH-12000] - Cross-tenant URL signing [MH-11042] - Admin UI NG tests fail in +5:30 timezone","title":"Opencast 2.3.5"},{"location":"changelog/#opencast-234","text":"Released on August 03, 2017 [MH-12183] - Theodul does not load [MH-12203] - Unescaped event and series titles when editing event or series (XSS) [MH-12242] - Theodul: Quality selector does not display/load [MH-12246] - Series WOH does not apply series DublinCore catalogs [MH-12249] - Media Module: Paging forgets search parameters","title":"Opencast 2.3.4"},{"location":"changelog/#opencast-233","text":"Released on May 02, 2017 [MH-10558] - Mime type not identified for matroska / mkv files [MH-10595] - Incident service returns internal server error if cascade=true requested for deleted workflow [MH-10747] - Inputs for capture device should be pre-selected [MH-11736] - Difference in start time displayed in overview and metadata details [MH-11811] - Opencast build fails when system timezone is set to PDT (Pacific Daylight Time) [MH-12048] - Series drop-down not sorted alphabetically in filter [MH-12069] - Deleting an event leaves behind orphaned comments [MH-12095] - Server default timezone can be incorrect [MH-12106] - Preserve user attributes from providers during authentication [MH-12107] - Improve performance of Servers table in Admin UI [MH-12118] - Paging in media module is broken [MH-12129] - Media module only works with english localized browsers [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12148] - Undocumented Archive WOH Requirements [MH-12150] - Matroska files are not recognized [MH-12158] - Workflow job dispatching failures [MH-12162] - JpaJob object toString override for better log messages [MH-12163] - Events with stopped workflows sometimes cannot be deleted [MH-12164] - Updating serviceregistry config while running leaves Opencast in a non-functional state [MH-12190] - Script injection in Media Module and Player","title":"Opencast 2.3.3"},{"location":"changelog/#opencast-232","text":"Released on March 22, 2017 [MH-11224] - Attempting to view source metadata through the new admin UI generates a stack trace [MH-11340] - Uncaught NullPointer Exception in Karaf console from com.entwinemedia.fn.data.json.SimpleSerializer.toJson [MH-11616] - Search Service will not remove mp from index if it is not found in database [MH-11743] - event.hasPreview() broken [MH-11760] - Event edit warning cannot be removed [MH-11790] - Slide Previews and slide text are not shown in Theodul Engage player [MH-11817] - Unhide volume controls in video-editor [MH-11819] - Admin UI Video Editor - Improved Zoom Controls [MH-12009] - Admin UI Video Editor: Segmentation lost after publishing [MH-12058] - Ingests fail if specified workflow does not exist [MH-12059] - Catch invalid dates when indexing [MH-12061] - Reduce the number of activemq messages and log entries during index rebuild [MH-12062] - Improve robustness of scheduler re-indexing [MH-12063] - Catch incomplete archive entries when indexing [MH-12072] - Wrong destinationId for External API message receiver [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12087] - Null bitrate can cause UI display of source media to fail [MH-12092] - Return event ID when event is created through Scheduler API [MH-12097] - SegmentVideoWorkflowOperation: Modules not included in Admin Presentation build.","title":"Opencast 2.3.2"},{"location":"changelog/#opencast-231","text":"Released on Janurary 25, 2017 [MH-11267] - Wrong notification text when deleting series [MH-11458] - Update translations from crowdin [MH-11687] - UI date formats are wrong for most of the English-speaking world [MH-11776] - CaptureAgentStateServiceImplTest incorrectly passes a non-long recording id, misses finding the NullPointer in Impl [MH-11960] - matterhorn-adminui-ng fails on first build [MH-11961] - Cannot access slidetext.xml should not break re-indexing [MH-11963] - Fix ingest REST docs [MH-11966] - Confusing AdminUI Groups Endpoint Documentation [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11983] - Only administrators should be allowed to assign the admin roles to other users [MH-11987] - Declare Admin UI Facade as module internal interface [MH-11988] - Advise to change karaf shutdown command in the docs [MH-11989] - Allow unknown as well as offline CAs to be removed via UI [MH-11992] - Compatibility issue when using contrib Wowza adaptive streaming module [MH-11998] - /info/me.json sometimes doesn't provide full information about the user [MH-12004] - Removing an recording does not remove all correspronding jobs [MH-12005] - UI shows inconsistent version due to missing version in cover-image-remote [MH-12006] - Security Issue Allowing Arbitrary Code Execution","title":"Opencast 2.3.1"},{"location":"changelog/#opencast-230","text":"Released on December 13, 2016 [MH-10342] - As an external device I want to immediate start and stop a capture [MH-11327] - De-couple smilImpl/wfrImpl from ingestImpl [MH-11378] - Conditionally synchronize Archive Service's add mediapackge [MH-11380] - As a customer, I want to integrate my third party application to Opencast, so that I can use Opencast content in my application [MH-11381] - Remove documentation of items that have never been implemented [MH-11411] - move dashboard to header [MH-11675] - Add documentation for External API to the Admin Guide [MH-11688] - Set java file encoding on startup [MH-11718] - As a producer, I want to be able to make workflow settings persistent so that I can reuse them later [MH-11725] - Give users a starting point how to report bugs [MH-11726] - Add AdminUI style guide to developer guide [MH-11728] - Use Apache Commons Lang 3 [MH-11729] - External API: Add documentation for Groups Endpoint [MH-11731] - Typofix Documentation [MH-11737] - Comment (mh_event_comment and mh_event_comment_reply) text field is VARCHAR(255) should be TEXT [MH-11740] - optimization of segmentation [MH-11741] - Admin UI has timezone issues [MH-11749] - External API: Add REST documentation for Endpoints [MH-11750] - Clean-Up Opencast Code Base [MH-11752] - Upgrade Karaf to 3.0.8 [MH-11756] - Admin UI NG Update CSS+HTML (1): FontAwesome, improve HTML, remove redundant images [MH-11763] - Counters hide series tab [MH-11772] - Admin UI source dropdowns inappropriately advance [MH-11774] - Admin UI Needs better documentation for debugging [MH-11775] - Library Update [MH-11783] - Custom publications labels not displayed when doing a mouse-over on Events->Published [MH-11784] - Remove Participation Management Code Pieces [MH-11786] - HttpsRequestWrapper wrongly sets the new URL [MH-11791] - As service provider I want to configure which kind of users can see the event counters [MH-11792] - NPM Proxy via Nexus [MH-11794] - NPM fails on first build [MH-11795] - Add support for title slides [MH-11799] - Maven bundle names too long [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files [MH-11802] - Opencast Logo is missing in Player [MH-11803] - Player redirect is missing [MH-11804] - No video controls in embed mode [MH-11808] - Pre-select workflow in case only one option is available [MH-11809] - Fix syntax error in encoding profile composite.http [MH-11812] - Fix security configuration for ROLE_UI_TASKS_CREATE [MH-11813] - Agent state REST endpoint documentation [MH-11815] - As a user I expect changes to be reflected in the Admin UI immediately [MH-11817] - Admin UI Video Editor - Bug Fixes [MH-11817] - Display video details in preview player/ editor of the admin ui [MH-11817] - Improve Button Hover Indication [MH-11817] - Make Next/Last Frame controls in videoeditor better recognizeable [MH-11827] - Recordings->Events->\"Event Details\"->Metadata: Incorrect translation used [MH-11828] - exception-handler-workflow not set correctly [MH-11829] - High memory usage on the admin server by dispatching jobs [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11834] - Unable to set capture agent configuration as JSON [MH-11836] - Additional ACL actions of series are missing when creating a new event in that series [MH-11837] - Unprivileged users have no access to fonts [MH-11839] - typo in Event Details: Comments [MH-11841] - Wait for NFS shares before start Opencast service [MH-11842] - Revert accidental downgrade of grunt version [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11857] - Fix log output \"Unable to delete non existing object %s/%s\" [MH-11862] - Search API handles roles wrong [MH-11863] - WOH analyze-tracks & WOH failing cause exceptions when shutting down Opencast [MH-11864] - WOH tag shall implement AbstractWorkflowOperationHandler [MH-11865] - Videoeditor Preview mixes in 2 Audiofiles [MH-11866] - Search box in Organization >> Groups not working [MH-11867] - Filter box in Organization >> Groups not working [MH-11869] - Deleting Series with 'Actions' is not working [MH-11870] - Wordlength in other languages except english too long [MH-11871] - ElasticSearch shall bind to 127.0.0.1 [MH-11875] - ActiveMQ should not listen to all hosts by default [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11883] - Larger files may remain in system temp directory [MH-11886] - login pages throw errors on loading unnecessary scripts [MH-11888] - Organization Filter uses Provider where table uses Type [MH-11889] - Row size too large [MH-11890] - MySQL Connector Version Should Be Consistent [MH-11891] - Event counters query large amounts of useless data [MH-11895] - \u201cAdd Event\u201d Wizard Input Fields Broken [MH-11896] - Java Warnings in AbstractEventEndpoint [MH-11897] - Remove Deprecated StringHelper [MH-11898] - Fix Technical Duration Calculation [MH-11899] - Prevent Requesting Event Objects Multiple Times [MH-11900] - Minor Index Service Fixes [MH-11905] - Publish Configure WOH incorrectly retracts publications [MH-11912] - No slider in playback video player [MH-11919] - WOH image claims SUCCEEDED when actually skipping [MH-11920] - WOH prepare-av: Misleading log message [MH-11921] - WOH partial-import looses partial audio tracks in specific cases [MH-11950] - Javadocs build error [MH-11955] - Add en-GB to Languages","title":"Opencast 2.3.0"},{"location":"changelog/#opencast-22x","text":"","title":"Opencast 2.2.x"},{"location":"changelog/#opencast-225","text":"Released on June 7, 2017 [MH-11983] - Only admins should be able to modify other admins [MH-12006] - Security Issue Allowing Arbitrary Code Execution [MH-11962] - Missing slidetext.xml should not break re-indexing","title":"Opencast 2.2.5"},{"location":"changelog/#opencast-224","text":"Released on October 13, 2016 [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11862] - Search API handles roles wrong [MH-11875] - ActiveMQ should not listen to all hosts by default","title":"Opencast 2.2.4"},{"location":"changelog/#opencast-223","text":"Released on October 13, 2016 [MH-11285] - Improve developers documentation: remote debugger with karaf [MH-11741] - Admin UI has timezone issues [MH-11771] - Improve section localization in developer guide [MH-11773] - Embed player does not use space very well and has scaling problems [MH-11774] - Admin UI Needs better documentation for debugging [MH-11777] - Event Details->Comments and Event Details->Assets don't work for unprivileged users [MH-11787] - Add release dates to changelog [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files","title":"Opencast 2.2.3"},{"location":"changelog/#opencast-222","text":"Released on September 14, 2016 [MH-11194] - created themes not showing up in series branding tab [MH-11572] - FFmpeg Inspection Service Test - accurateFrameCount [MH-11587] - SQL Error [MH-11714] - Fix unit test: Event controller #accessSave saves the event access [MH-11724] - Additional actions not available in create event wizard anymore [MH-11734] - Fix el7 RPM docs [MH-11735] - Fix Stream Security Documentation [MH-11744] - Actions->Start Task: Various localization bugs [MH-11748] - Inconsistent and incorrect use of translate directive [MH-11751] - Player won't work if there are no segments [MH-11755] - No quality selection in Theodul Player [MH-11759] - Make Inspector Unit Tests More Robust","title":"Opencast 2.2.2"},{"location":"changelog/#opencast-221","text":"Released on July 30, 2016 [MH-11092] - Every Browser has an other \"Remember me\" checkbox [MH-11169] - Trimming points not set correctly after workflow is finished [MH-11538] - \"No compatible source was found for this video\" videojs player error in iOS device [MH-11561] - Style (CSS): Setting a server in Maintenance (srv-det-01) [MH-11598] - Wizards should not re-use data that has entered before [MH-11644] - Missing Admin Interface Mock Data [MH-11653] - Jobs do not always proceed [MH-11655] - Jobs with high job load never get processed [MH-11659] - Warning is missing that metada and ACL cannot be edited while job is processing. [MH-11661] - Link on logo on the media module points to admin ui or welcome page, instead of something that is accessable for every user [MH-11664] - Incorrect Inconsistency status when built from tarball [MH-11665] - Systems->Servers & Systems->Services show wrong mean runtime and mean queue time [MH-11667] - Align main table content [MH-11668] - Missing segment previews let to an erro in the player [MH-11669] - Do not archive OCR texts [MH-11673] - Add documentation for additional ACL actions [MH-11674] - Add documentation for metadata configuration [MH-11679] - Page size cannot be changed in any table [MH-11681] - Add documentation for role-based visibility [MH-11682] - Remove useless roles from roles.txt [MH-11686] - Extended metadata tab not shown although user has the role ROLE_UI_EVENTS_DETAILS_METADATA_VIEW [MH-11690] - Various Documentation Improvements [MH-11692] - Remove Superfluous Mh-Db-Version [MH-11693] - Remove Superfluous Dependency Versions [MH-11694] - JavaDoc Generation Broken [MH-11702] - After an upgrade to 2.2.0, series are not displayed in the UI because the series creation date is now mandatory [MH-11720] - Opencast 2.2 requires Git to be installed at build time [MH-11727] - Fix unit test: adminNg.services.language #toLocalTime converts a zulu time string back to local time FAILED [MH-11730] - Make the automatic role prefix in LDAPUserProvider configurable","title":"Opencast 2.2.1"},{"location":"changelog/#opencast-220","text":"Released on June 15, 2016 [MH-9511] - Wrong log level in Tesseract [MH-9831] - ehcache and quartz phones home [MH-9950] - Update player dependencies [MH-10029] - Remove Unnecessary Image Conversion Step From TextAnalysisService [MH-10173] - Do not ignore exceptions when closing Closeable's [MH-10748] - Matterhorn has to be restarted to schedule an event on a new capture device [MH-10794] - Delete Action should be disabled if nothing is selected [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10870] - ActiveMQ Exceptions While Shutting Down Matterhorn [MH-10887] - Users can schedule events in the past [MH-10898] - Update Apache HttpComponents (3.1.7 \u2192 4.4.1) [MH-10923] - Theodul player : Filtering \"composite\" tags results in error when the composite workflow is used [MH-10942] - Events are not deselected after applying a task [MH-10965] - Theodul player : Videos not playable on IE10 [MH-10971] - Newly created Series don't show up in Series dropdown selection lists without page reload [MH-10978] - Unable to retract 'internal' publications [MH-10979] - Opencast needs to better distribute load across the available nodes [MH-10984] - Extend ingest service by partial upload [MH-11010] - Stream Security should be able to prevent cross-tenants access [MH-11014] - Add support for additional ACL actions [MH-11077] - The Publish Workflow will not retract already published material [MH-11097] - View modes not working correctly [MH-11107] - Group list pagination not working [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11139] - Unable to find mimetype for mkv [MH-11140] - Forward and backward buttons are greyed out [MH-11143] - Link to Media Module in Admin UI [MH-11148] - Search box layout incorrect: Icon overlaps text [MH-11156] - Users: Search box not implemented [MH-11157] - Groups: Search box not implemented [MH-11165] - Sorting does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11167] - Layout problem on Workflow Error Details view [MH-11183] - Capture->Locations: Search box not implemented [MH-11190] - Theodul Shortcuts: Description could be improved [MH-11191] - Event Details->Assets: Use human-readable units for duration, bitrates and sizes [MH-11192] - Audio level slider does not change audio level while dragging [MH-11199] - Playback & video editor don't work while workflow is running [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11222] - Replace System.out.println with logger [MH-11229] - workflowoperation unit tests are incredible slow [MH-11252] - Some service configuration files are stored in the wrong directory [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness [MH-11281] - Enhance WOH image to support extraction of multiple images using multiple encoding profiles from multiple sources [MH-11282] - Enhance WOH composite to support single video streams [MH-11287] - Update Apereo/Apache License List [MH-11289] - Change text extraction documentation or file name [MH-11294] - Create admin-worker and ingest distribution [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11300] - WOH partial-import looses partial audio tracks beginning at position zero [MH-11304] - Documentation for WOH partial-import and load configuration not listed in pages configuration [MH-11306] - Change job dispatcher sort order to: restart jobs, non-wf jobs, creation date [MH-11307] - Distribution Service is not on Presentation Node [MH-11310] - Document encoding profiles used by WOH partial-import [MH-11311] - Use existing encoding profiles in WOH partial-import example [MH-11312] - Fix Encode WOH Documentation [MH-11313] - Update Parallel Encode Profiles [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11322] - Update WebM Profiles [MH-11355] - Slide texts are not shown correctly in theodul player, except the first segment there a now slide texts shown (\"No slide text available\"). In the XML file the texts are correct [MH-11356] - Update Documentation Index Page [MH-11357] - Notifications are not removed after a while [MH-11358] - Dismiss Button for comments has an inconsistent design [MH-11363] - Notification that server is not reachable is missing [MH-11364] - Reasons in Comments section are no longer translated [MH-11368] - Changing to Chinese translation doesn't work [MH-11369] - Series filter displays series id instead of series title [MH-11374] - Videoeditor: Times are wrong in zoomed waveform view [MH-11385] - Metadata summary not showing any metadata at event creation [MH-11386] - Silence Detection / Video Editor Waveform bug [MH-11389] - security 1 [MH-11391] - Improve Flavor creation and parsing [MH-11392] - Sorting by series.created does not work correctly [MH-11401] - Hiding of columns is globally broken [MH-11404] - Group editor shows users and roles twice [MH-11405] - Pagination broken for groups table [MH-11409] - Translation key EVENTS.EVENTS.GENERAL.SELECT_WORKFLOW_EMPTY is missing [MH-11413] - AdminUI comment dialog translations missing [MH-11414] - Logger is missing from several modules [MH-11415] - Incorrect Urlsigning Module Name [MH-11416] - Specify Opencast's Requirements [MH-11417] - Tab names of modals not vertically centered [MH-11419] - Tables not drawn correctly [MH-11422] - add event tab titles not translated [MH-11427] - Can't get host details from Serviceregistry REST endpoint [MH-11428] - Default Workflow Option Does Not Work [MH-11430] - Prevent user from accidentally press \"Save & process\" in Video Editor multiple times [MH-11431] - Prevent users from accidentally pressing the Delete/Retract button multiple times [MH-11432] - JSHint settings are missing [MH-11434] - \"The task could not be created\" error notification always appear when starting a task on multiple events [MH-11435] - Fix code style errors in Gruntfile.js [MH-11436] - Matterhorn on Login/Welcome Page [MH-11437] - Resource Problems On Login Page [MH-11438] - Resource Problem on Welcome Page [MH-11439] - Event description not available in WOH cover-image [MH-11441] - Clicking on Logo in top left corner will nmot get you to the start page [MH-11443] - Seeking is not possible before pressing play button at least once?!? [MH-11446] - Remove eclipse-gemini repository from main pom.xml [MH-11447] - Scheduling conflicts reporting completely broken [MH-11448] - Tipps on developing on admin ui ng [MH-11450] - Fix Defaults For Documentation Links [MH-11453] - Correctly link the stream security documentation [MH-11457] - Remove duplicate keys from Admin UI english translation [MH-11458] - Update translations from crowdin [MH-11459] - Logger Logs Nullpointer on Error [MH-11462] - Cover WOH is not included in a useful way [MH-11464] - setting personal preferences in admin UI fails [MH-11468] - There are unused ressources [MH-11475] - Fix typos in English master translation [MH-11476] - Series->Actions->Delete displays wrong notifications [MH-11477] - Editing status of series displays wrong notification when saving fails for all series [MH-11480] - Replace horizontal ellipsis [MH-11481] - Workflows started by unprivileged users hang [MH-11492] - forward and backward section not working in safari [MH-11509] - Failed test: Sorting groups list (grp-lis-01) [MH-11511] - Failed test: Manual set time in textbook for IE11 [MH-11512] - hello world does not follow import statements rules [MH-11518] - Language selector is always displayed in system language [MH-11519] - Languages are only distinguished by main language [MH-11520] - Remove company logos [MH-11521] - ActiveMQ Library Configuration [MH-11522] - DataLoader Default Value [MH-11523] - Working file repository default value [MH-11524] - Distribution Service Default Values [MH-11532] - Wider language support in player [MH-11534] - Add language support for Chinese Simplified [MH-11535] - Add documentation about Crowdin to Developer Guide [MH-11536] - Remove Commercial Code From Core [MH-11537] - Execute Service WOH Cannot be Built [MH-11539] - Remove Old MH Logos in Favor of Opencast SVG Logos [MH-11544] - Admin UI links used inconsistently [MH-11546] - Pagination buttons too small for large numbers [MH-11548] - The \"Edit\" button at the top-right corner of the tables doesn't support localization [MH-11550] - Update Migration documentation 2.1 to 2.2 [MH-11554] - Filtering does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11555] - Localization of Recordings->Events and Recordings->Series buggy [MH-11556] - Failed test: Filter locations (T1733, Filter by status does not work) [MH-11559] - outdated shortcurts configuration prevents player from loading. [MH-11571] - Elasticsearch shutdown command handler crash opencast [MH-11573] - Do not hide warnings [MH-11574] - Jetty Error on Large Workflow Instances [MH-11575] - Inspection Service Tests Fail With Certain FFmpeg Versions [MH-11576] - Servlet Filter Improvements [MH-11578] - Improve default order of columns in Systems->Jobs [MH-11579] - Admin UI mockup data for Systems->Jobs incomplete [MH-11580] - Unit tests for Admin UI language selection broken [MH-11581] - Systems->Jobs table not working correctly [MH-11583] - Fix Code Style [MH-11588] - Create side-by-side preview for video editor [MH-11589] - Feedback button does not work [MH-11590] - The WorkflowServiceImpl constructor sets the \"waitForResources\" argument incorrectly [MH-11594] - Add language support for Galician [MH-11595] - Fix admin ui unit tests for tableService [MH-11597] - Building matterhorn-engage-theodul-plugin-video-videojs reports a lot of code style issues [MH-11600] - Failed test: i18n (gen-int-01) [MH-11601] - current language can have undefined state [MH-11604] - Date picker for setting up the schedule is always french [MH-11605] - Disabling link to mediaplayer creates a broken link and missing logo [MH-11606] - Add language support for Greek [MH-11608] - Add documentation for WOH cleanup [MH-11613] - WOH editor fails when input has uneven width or height [MH-11614] - Partial matches not working anymore [MH-11617] - Add language support for Dutch [MH-11620] - Non privileged user can not login on presentation node [MH-11623] - Server statistics: Slow Query [MH-11624] - Workflow owners do not necessarily have access to their workflows: user comparison fails [MH-11627] - NullPointerException when creating a new Solr index [MH-11629] - Hide Some Confusing Warnings [MH-11630] - Service registry lacks of getActiveJobs() function [MH-11631] - Remove columns \"Blacklisted from\" and \"Blacklisted until\" from Capture->Locations [MH-11632] - Library Bugfix Upgrade [MH-11636] - Adjust FFmpegComposer Logging for Newer FFmpeg Versions [MH-11637] - Add language support for Swedish [MH-11638] - Improve Encoding Profiles [MH-11639] - Media module login form has poor usability and bugs [MH-11642] - Remove binding to non-existing method in WOH analyze-tracks [MH-11643] - Add language support for Polish [MH-11645] - Open AdminUI menu links in new tab does not work [MH-11646] - Add documentation for WOH comment [MH-11652] - Unit tests for servicesController broken [MH-11654] - Failed ingest jobs block system from dispatching other jobs [MH-11656] - Add documentation for WOH copy [MH-11657] - Improve documentation for workflow execution conditions [MH-11658] - Better quality for video editor previews [MH-11663] - Hide Participation Management from UI since not yet working [MH-11666] - Not all WOH listed in WOH overview","title":"Opencast 2.2.0"},{"location":"changelog/#opencast-21x","text":"","title":"Opencast 2.1.x"},{"location":"changelog/#opencast-212","text":"Released on May 10, 2016 [MH-9831] - ehcache and quartz phones home [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11229] - workflowoperation unit tests are incredible slow [MH-11283] - post-mediapackage WOH breaks further processing [MH-11287] - Update Apereo/Apache License List [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11307] - Distribution Service is not on Presentation Node [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11323] - Workflow Docs are Incorrect [MH-11332] - Document acceptance criteria for proposals [MH-11356] - Update Documentation Index Page [MH-11377] - Opencast does not have an ingest assembly","title":"Opencast 2.1.2"},{"location":"changelog/#opencast-211","text":"Released on January 22, 2016 [MH-11107] - Group list pagination not working [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness","title":"Opencast 2.1.1"},{"location":"changelog/#opencast-210","text":"Released on December 22, 2015 [MH-10637] - Hello World service [MH-10651] - Workspace cleaner job param in wrong units (ms vs s) and wrong logic [MH-10714] - Two clock icons at the time stamp of a comment [MH-10805] - The confirmation dialog are not translated [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10874] - Plugin does not properly handle multiple keys [MH-10875] - Include search capabilities into mkdocs documentation build [MH-10890] - Update Apache Commons Lang (2.6 \u2192 3.4) [MH-10908] - Assemblie Module Names Too Long [MH-10908] - Consistency in Documentation: Presentation Server VS Engage Server [MH-10908] - Misconfigured Checkstyle Plug-in in Assemblies [MH-10919] - Top row for setting roles in the access policy for an event is not showing the right value [MH-10953] - Spanish layout is broken [MH-10955] - Make sure recent versions of mkdocs work [MH-10956] - Update Synchronize.js [MH-10985] - As an operator I want to check the health status of Opencast [MH-10986] - Scheduling around DST change fails [MH-10987] - Improve workflow query to accept paging by index [MH-10988] - Rewrite workspace to fix several small issues [MH-10989] - Improve working file repository stream response [MH-11007] - Remove 3rd party tool script [MH-11026] - Several invalid links in the Opencast User Guides [MH-11031] - Missing option to create new event using files ingested from the inbox [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-11051] - Fix WOH Documentation [MH-11069] - When creating new series, warning about read/write requirements is shown twice. [MH-11072] - The ACL editor needs enhanced validation [MH-11074] - Admin UI Test: New Event API Resource assembles the metadata for SCHEDULE_MULTIPLE with DST change is failing [MH-11083] - Clean-up Codebase after Karaf [MH-11085] - Make sure bundle cache is cleared when restarting [MH-11086] - Shorten File Names in Log Output [MH-11088] - translation error in theodul player [MH-11089] - Theodul player seems not to work with Internet Explorer at all [MH-11093] - single video screen size jump when clicked [MH-11094] - Problems in Theodul controls plugin due to wrong resolves of merge conflicts [MH-11095] - Make assemblies more user firedly [MH-11096] - Errors when loading admin-ng login page [MH-11099] - Removing one role from an Access Policy (acl-det-05) [MH-11101] - Creating a Theme with 2 bumper videos - In and Out (thm-new-01) [MH-11109] - Event details tab cannot handle long event titles well [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11111] - Formatting issues in \u201cTheodul Pass Player - URL Parameters\u201d [MH-11114] - Remove System.out.println from FileReadDeleteTest [MH-11120] - Several Services Fail During Shutdown [MH-11122] - Create Service Files (Systemd/SysV-Init) [MH-11126] - Fix Translation for 2.1 [MH-11133] - i18n: Theme Detail view layout broken in Spanish [MH-11135] - Create Release Manager Docs [MH-11137] - Comment reasons are not working correctly [MH-11138] - Clock icon displayed twice next to comment creation date [MH-11141] - Playback Speed in player needs more useful defaults [MH-11142] - fix translations for shortcuts [MH-11144] - update documentation regarding property for mediamodule logo [MH-11147] - Missing translations: FILTERS.USERS.PROVIDER.LABEL & FILTERS.USERS.ROLE.LABEL [MH-11149] - Filter locations: Translations FILTERS.AGENTS.NAME.LABEL & FILTERS.AGENTS.STATUS.LABEL missing [MH-11151] - Plaback speed from menu [MH-11152] - Editing ACL: Translation for USERS.ACLS.DETAILS.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11153] - Access Policy Details: Cannot navigate to previous or next ACL [MH-11154] - New Access Policy: Translation for USERS.ACLS.NEW.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11155] - ACL Editor: Role not displayed at all [MH-11158] - Playback Tool: Time can be edited, but editing has no effect [MH-11159] - Users sorting: Sort order for 'Name' not correct [MH-11160] - Create Group overwrites existing groups without warning [MH-11162] - security_sample_cas.xml in MH 2.0.1 Points to Wrong Welcome Page [MH-11166] - Number of rows not displayed on Systems->Servers [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11178] - Prevent FFmpeg Experimental AAC Encoder Bug to Affect Opencast [MH-11180] - Update video.js to latest 4.x version [MH-11181] - Flash streaming with multi-quality video does not work [MH-11185] - Event Details->Assets->: Asset size is always 0 [MH-11186] - Event Details->Assets->Media->Media Details: Superfluous row 'Flavor' [MH-11187] - Configuration->Themes: Number of rows not displayed correctly [MH-11189] - Actions->Start Task: User can press create button multiple times [MH-11193] - Setting audio level slider to \"zero\" does not set the actual audio level to \"zero\" [MH-11196] - REST docs cannot be found in new admin ui [MH-11198] - Event dashboard seems not to support i18n [MH-11201] - Maven Assembly Plug-in Listed Twice [MH-11202] - FFmpeg video editor operation is synchronized [MH-11212] - Main Pom Clean-Up [MH-11218] - Karaf based Solr configuration [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11223] - Remove unused files [MH-11234] - Admin-NG throws a couple of 404 errors [MH-11236] - Security ACL see security list [MH-11237] - Service files are missing [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11248] - Publish-Engage Workflow Operation Documentation is Missing Configuration Keys [MH-11249] - Apply-ACL WOH not properly replaced by Seried-WOH in Documentation [MH-11250] - Put temporary files in karaf data not in opencast.storage [MH-11251] - Capture-Admin Tests May Fail When Executed Too Fast [MH-11257] - Deprecated Mkdocs Config [MH-11258] - Make host configuration easier","title":"Opencast 2.1.0"},{"location":"changelog/#opencast-20x","text":"","title":"Opencast 2.0.x"},{"location":"changelog/#opencast-202","text":"Released on December 22, 2015 [MH-10235] - Users are unable to determine the Version of Matterhorn [MH-10484] - Remove Mediainfo from 3rd-Party-Tools [MH-10558] - Mime type not identified for matroska / mkv files [MH-10588] - Improve MySQL DDL to make it consistent again [MH-10759] - Write QA documentation for Access Policies [MH-10759] - Write QA documentation for Series [MH-10759] - Write QA documentation for Themes [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10918] - Improve the representation of the attachments/catalogs/media/publications in the event details [MH-10956] - Update Synchronize.js [MH-10964] - The Opencast start script does not work on Mac OS X [MH-10976] - Eclipse (m2e) throws NullPointerException erros due to a missing property in the pom.xml file [MH-11007] - Remove 3rd party tool script [MH-11007] - Switch subtitle embedder to FFmpeg [MH-11026] - Several invalid links in the Opencast User Guides [MH-11038] - Make ListProviderScanner Scanner Less verbose [MH-11048] - admin ui tries to load missing library [MH-11051] - Fix WOH Documentation [MH-11060] - ActiveMQ settings filename fix (r/2.0.x) [MH-11068] - Table 'mh_bundleinfo' doesn't exist [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11181] - Flash streaming with multi-quality video does not work [MH-11202] - FFmpeg video editor operation is synchronized [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11236] - Security ACL see security list [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11256] - Opencast docs do not build anymore","title":"Opencast 2.0.2"},{"location":"changelog/#opencast-201","text":"Released on September 3, 2015 [MH-10822] - Possible to create new access policy template without a role with read/write permissions [MH-10938] - Missing views counter in player [MH-10941] - Usertracking Service Missing Endpoint [MH-10955] - Make sure recent versions of mkdocs work [MH-10962] - Add missing licenses to NOTICES [MH-10968] - Add note about ffmpeg/libav on Ubuntu [MH-10975] - async loading of translations [MH-10995] - Gathering workflow statistics for JMX causes extreme performance issues","title":"Opencast 2.0.1"},{"location":"changelog/#opencast-200","text":"Released on July 17, 2015 [MH-9950] - \"Clean up\"/Split up nested functions in the core routine (core.js) [MH-9950] - Load CSS files in the core HTML file, not the JavaScript [MH-9950] - Scrolling is required to see the controls if they are configured to be below the video. [MH-9950] - Some Keys don't work [MH-9950] - Theodul Core Jasmine Tests Sometimes Failing [MH-10029] - FFmpeg based Videosegmenter [MH-10140] - Capture agent with no configuration is always shown as \"idle\" [MH-10202] - No ACL in new series when ingested a new mediapackage with a new series. [MH-10230] - Typos on the welcome page [MH-10332] - Remove Mediainfo Inspection Service [MH-10382] - Add a UI Element to Easily Unregister Capture Agents [MH-10419] - Improve user tracking tables [MH-10510] - Move Workflow Operation Handler into their own Packages [MH-10550] - Non-Interactive Foreground Mode For Matterhorn [MH-10572] - ShibbolethLoginHandler: 500 Error when login the first time [MH-10594] - Re-configure Start Scripts for Different Deployment Types [MH-10615] - Enable Optional Compiler Arguments [MH-10620] - Port Silence Detector from GStreamer to FFmpeg [MH-10622] - Wave Generation Improvement [MH-10623] - Set Sensible Default for Workspace Cleanup Period [MH-10624] - Fixes for FFmpeg Videosegmenter (Set Binary) [MH-10630] - Extending common functionality [MH-10631] - Scheduler service authorization handling [MH-10635] - Text extractor dead lock [MH-10640] - several problems with the metadata form to create a new event [MH-10656] - Login Screen: Placeholder and Focus [MH-10658] - Email template: diverse problems [MH-10664] - What is a template in Access Policy and how do I create it? [MH-10665] - 404 for variables.json [MH-10667] - Previous Button does not always work [MH-10681] - Time is missing when a workflow operation has been started and stopped [MH-10683] - Remove Capture Agent [MH-10683] - Remove the Capture Agent integration tests [MH-10684] - Admin UI seems only unresponsive if server is down [MH-10689] - I should get a warning, if I leave the Admin UI while I still create an event (upload a file) [MH-10698] - workflow after videoeditor does not produce any */delivery flavors [MH-10700] - Service Registry throws NPE exception on startup [MH-10704] - Workflows fail if adding themes [MH-10705] - Row counter in Jobs table is 1 too much [MH-10707] - Unit Test Failure [MH-10710] - NullPointerException in VideoSegmentationWOH [MH-10711] - OptimisticLockException after ingest [MH-10712] - Workflow cleanup out of memory error [MH-10713] - Cache util blocks forever [MH-10726] - Archive operation should use filesystem copy rather than http download [MH-10736] - Engage is currently broken and won't play videos but Theodule does [MH-10740] - NPE in ToolsEndpoint [MH-10746] - There is no event status column [MH-10758] - Issues found in production use of Theodul: changing icons, seeking in Chrome, using configured logos, wording, layout... [MH-10759] - Write QA documentation for Events [MH-10759] - Write QA documentation for Groups [MH-10759] - Write QA documentation for Servers [MH-10759] - Write QA documentation for Services [MH-10763] - Remove Old Confirations [MH-10765] - Operation details doesn't show operation attributes when state is instantiated [MH-10768] - Workflow operations table in the events details should refresh automatically [MH-10769] - Add (x) icon in the events and series tableview to allow deletion of single Events/Series [MH-10770] - Some captions of tabs are not yet translated [MH-10772] - Ensure that buttons order is consistent in the actions column [MH-10773] - Allow to have free-text value for presenters, contributors, organizers or publishers [MH-10774] - ACL editing should be locked on the Series level when events of the series are being processed [MH-10775] - All the roles with read/write rights can be deleted from the ACL editor in Events/Series details [MH-10776] - Include Spanish and French translation into Theodul. [MH-10780] - Specify Requirements [MH-10781] - Respect tags while filtering for suitable tracks in Theodul player [MH-10792] - Pom.xml Extra Modules [MH-10798] - Event Details tile shows hash identifier [MH-10799] - Videoeditor operation does not properly handle missing preview formats [MH-10804] - It is unclear in which timezone you schedule in the admin-ui [MH-10807] - New event POST request contains every series and user [MH-10808] - Disable Demo Users [MH-10810] - Rename upgrade script form 1.6 to 2.0 [MH-10812] - Use bundles.configuration.location in admin ng settings.yml [MH-10814] - Pressing play while buffering breaks player [MH-10816] - Move Message Broker Configuration to Global Config [MH-10821] - Severe Issue with Scheduled Events [MH-10829] - Unchecking \"Remember me\" checkbox has no effect when logged out. Pressing the browsers back button you're still logged in an d can use all functions. [MH-10836] - Issues with matterhorn-engage-theodul-plugin-archetype [MH-10837] - Bulk deletion of events doesn't work correctly [MH-10843] - different video qualities are not filtered correctly. [MH-10845] - Summary of \"Add Events\" and \"Add Series\" shows irrelevant data [MH-10847] - Missing with-role directive in \"Start Task\" option in Actions dropdown [MH-10848] - Event conflict endpoint returns Server error 500 [MH-10849] - Temporary videoeditor files get not deleted [MH-10850] - Interface MatterhornConstans has a typo [MH-10853] - Improve admin UI ng workflows [MH-10855] - Task Menu displays wrong UI [MH-10864] - Remove Trailing Spaces From Less Files [MH-10866] - Documentation: Incorrect Repository Links [MH-10868] - Linebreak before last segment in player [MH-10873] - capture-admin-service-impl tests randomly failing [MH-10876] - Admin UI NG makes calls to remote resources [MH-10880] - Remote base keeps try to call a service [MH-10881] - Wrong links to r/2.0.x on documentation page [MH-10884] - WokflowOperation getTimeInQueue should return 0 if value is NULL [MH-10888] - Theodul player: audio-only does not work - player checked for unavailable size. [MH-10901] - Execute Service is not in main pom.xml and will not be built [MH-10902] - ./modules/matterhorn-publication-service-youtube/ obsolete [MH-10905] - FFmpeg videoeditor only works with audio and video available [MH-10911] - Remove executable flag from non-executables [MH-10912] - Init scripts contain undefined references to DEBUG_PORT and DEBUG_SUSPEND [MH-10913] - Add Event: License Metadata Field Text [MH-10924] - Update to new Opencast logos [MH-10926] - Extensive PhantomJS warnings when building admin-ng [MH-10928] - Adjust loglevel in DictionaryService [MH-10929] - Cutting and Review are skipped when config is set to do so [MH-10930] - Fix missing German translation [MH-10934] - Once set, one cannot remove some metadata in the create event dialog [MH-10938] - Missing views counter in player [MH-10939] - Task Summary does not display configuration values [MH-10946] - Fix Opencast 2 Installation Guides [MH-10950] - Fix DDL Readme [MH-10952] - Fix matterhorn-execute-operations naming [MH-10957] - Add License Guide for Developers","title":"Opencast 2.0.0"},{"location":"releasenotes/","text":"Opencast 11: Release Notes Features TBA Improvements TBA Behaviour changes TBA API changes TBA Release Schedule TBA Release managers TBA","title":"Release Notes"},{"location":"releasenotes/#opencast-11-release-notes","text":"","title":"Opencast 11: Release Notes"},{"location":"releasenotes/#features","text":"TBA","title":"Features"},{"location":"releasenotes/#improvements","text":"TBA","title":"Improvements"},{"location":"releasenotes/#behaviour-changes","text":"TBA","title":"Behaviour changes"},{"location":"releasenotes/#api-changes","text":"TBA","title":"API changes"},{"location":"releasenotes/#release-schedule","text":"TBA","title":"Release Schedule"},{"location":"releasenotes/#release-managers","text":"TBA","title":"Release managers"},{"location":"upgrade/","text":"Upgrading Opencast from 10.x to 11.x This guide describes how to upgrade Opencast 10.x to 11.x. In case you need information about how to upgrade older versions of Opencast, please refer to older release notes . Stop your current Opencast instance TBA Start Opencast ??? TBA","title":"Upgrade"},{"location":"upgrade/#upgrading-opencast-from-10x-to-11x","text":"This guide describes how to upgrade Opencast 10.x to 11.x. In case you need information about how to upgrade older versions of Opencast, please refer to older release notes . Stop your current Opencast instance TBA Start Opencast","title":"Upgrading Opencast from 10.x to 11.x"},{"location":"upgrade/#_1","text":"TBA","title":"???"},{"location":"version-support/","text":"Supported Versions Opencast has a standing policy of supporting two major versions. This results in a roughly 1 year support cycle for any given major release due to our half year release cycle. Support, in this context, means development time: building fixes, applying them, and releasing those changes. For example, as of the time of writing we support versions 6.x, and 5.x. Once version 7.0 releases, version 5.x will no longer be supported, but 6.x will. gantt title Support of Opencast 5 and 6 dateFormat YYYY-MM-DD axisFormat %Y-%m section Opencast 5 Opencast 5.0 :2018-06-12, 2018-09-03 Opencast 5.1 :2018-11-13 Opencast 5.2 :2019-01-11 Opencast 5.3 :2019-01-24 Opencast 5.4 :2019-04-01 Opencast 5.5 :2019-06-13 section Opencast 6 Opencast 6.0 :2018-12-10, 2019-01-12 Opencast 6.1 :2019-01-24 Opencast 6.2 :2019-03-05 Opencast 6.3 :2019-04-01 Opencast 6.4 :2019-06-14 Opencast 6.5 :2019-08-02 Opencast 6.6 :2019-08-12 Opencast 6.7 :2019-12-17 The chart above shows the releases of Opencast 5 and 6 which overlap in a period of six month. The support of Opencast 5.5 ended with the release of Opencast 7.0 on June 6, 2019. Minor Versions We only support the latest minor version of any given major version. For example, once Opencast 7.1 is released, Opencast 7.0 is no longer supported. We take care to make updates between minor versions as smooth as possible. This means upgrades are usually very easy and it is recommended to upgrade on a regular basis.","title":"Version Support"},{"location":"version-support/#supported-versions","text":"Opencast has a standing policy of supporting two major versions. This results in a roughly 1 year support cycle for any given major release due to our half year release cycle. Support, in this context, means development time: building fixes, applying them, and releasing those changes. For example, as of the time of writing we support versions 6.x, and 5.x. Once version 7.0 releases, version 5.x will no longer be supported, but 6.x will. gantt title Support of Opencast 5 and 6 dateFormat YYYY-MM-DD axisFormat %Y-%m section Opencast 5 Opencast 5.0 :2018-06-12, 2018-09-03 Opencast 5.1 :2018-11-13 Opencast 5.2 :2019-01-11 Opencast 5.3 :2019-01-24 Opencast 5.4 :2019-04-01 Opencast 5.5 :2019-06-13 section Opencast 6 Opencast 6.0 :2018-12-10, 2019-01-12 Opencast 6.1 :2019-01-24 Opencast 6.2 :2019-03-05 Opencast 6.3 :2019-04-01 Opencast 6.4 :2019-06-14 Opencast 6.5 :2019-08-02 Opencast 6.6 :2019-08-12 Opencast 6.7 :2019-12-17 The chart above shows the releases of Opencast 5 and 6 which overlap in a period of six month. The support of Opencast 5.5 ended with the release of Opencast 7.0 on June 6, 2019.","title":"Supported Versions"},{"location":"version-support/#minor-versions","text":"We only support the latest minor version of any given major version. For example, once Opencast 7.1 is released, Opencast 7.0 is no longer supported. We take care to make updates between minor versions as smooth as possible. This means upgrades are usually very easy and it is recommended to upgrade on a regular basis.","title":"Minor Versions"},{"location":"configuration/","text":"Opencast Configuration Guides These guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look at the basic configuration guide . General Configuration Basic Configuration Database Configuration HTTPS Configuration Firewall Configuration Encoding Profile Configuration List Providers Load Configuration Log Configuration User Statistics and Privacy Configuration Message Broker Configuration Metadata Configuration Multi Tenancy Configuration Trim Segments Configuration Authentication, Authorizations, and User Management CAS Security Configuration LDAP Authentication and Authorization (without CAS) Moodle User Provider Sakai User Provider Brightspace User Provider Canvas LMS User Provider Authentication and Authorization Infrastructure (AAI) Access Control Lists Stream Security Serving Static Files Workflow Configuration Workflow Operation Handler External API Configuration OAI-PMH Configuration External Monitoring Admin UI Configuration Event Filters Manual Asset Upload Languages Statistics Thumbnails","title":"Overview"},{"location":"configuration/#opencast-configuration-guides","text":"These guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look at the basic configuration guide .","title":"Opencast Configuration Guides"},{"location":"configuration/#general-configuration","text":"Basic Configuration Database Configuration HTTPS Configuration Firewall Configuration Encoding Profile Configuration List Providers Load Configuration Log Configuration User Statistics and Privacy Configuration Message Broker Configuration Metadata Configuration Multi Tenancy Configuration Trim Segments Configuration Authentication, Authorizations, and User Management CAS Security Configuration LDAP Authentication and Authorization (without CAS) Moodle User Provider Sakai User Provider Brightspace User Provider Canvas LMS User Provider Authentication and Authorization Infrastructure (AAI) Access Control Lists Stream Security Serving Static Files Workflow Configuration Workflow Operation Handler External API Configuration OAI-PMH Configuration External Monitoring Admin UI Configuration Event Filters Manual Asset Upload Languages Statistics Thumbnails","title":"General Configuration"},{"location":"configuration/acl/","text":"Access Control List Configuration This document describes how Opencast stores and handles access control settings for series and episodes and what configuration options related to this are available. Access Control Lists An access control list (ACL) in the context of Opencast consists of a global deny rule (no one is allowed access) and a set of roles with rules attached to define access. Hence, it is effectively a white-listing of roles to grant access and it means that all roles and/or actions not defined in an access control list are denied access. For example, the following rule defines read access for role 1 and read/write access for role 2: role action access ROLE1 read true ROLE2 read true write true Opencast can also deny access locally (e.g. deny write access for role 1) which can be interesting if merging of ACLs is used. But this is not handled in the user interface and using this should therefore be avoided. System administrators are an exception to these rules. A user with ROLE_ADMIN will always be granted access, regardless of the rule-set attached to an event. Organizational administrators are also granted access in some cases. Global Rules In case an event has no custom access control list defined, a global rule set is associated with the event. The global rules consist only of the general deny rule. Hence, no access is allowed to anyone except administrators.. Series and Episode Rules Access control lists can be specified both on series and on episode level. This means that multiple rule sets can be attached to an episode which is part of a series. Opencast can handle this in multiple ways. The handling is specified by the merge mode configured in etc/org.opencastproject.authorization.xacml.XACMLAuthorizationService.cfg . It defines the relationship between series and episode access control lists, if both are attached to an event. If only one list is attached, its rules are always active. If multiple lists are attached, the following modes define Opencast's behavior: Merge Mode \u201coverride\u201d (Default) The episode ACL takes precedence over the series ACL. This means that the series ACL will be completely ignored as soon as the episode has an ACL, no matter what rules are set in either. This allows users to define general rules for a series which can be completely redefined on an episode and which are not influenced by changes later made to the series. This is also a very simple rule and thus easy to understand. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow Merge Mode \u201croles\u201d Series and episode ACLs are merged based on the roles defined within. If both the series and the episode define a rule for a specific role (user or group), the episode's rule takes precedence. Rules for roles defined in one ACL only are always part of the resulting active ACL. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow Merge Mode \u201cactions\u201d ACLs are merged based on the actions (read, write, \u2026) contained within both ACLs. If a rule is specified for a tuple of role and action in both ACLs, the rule specified in the episode ACL takes precedence. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow allow Switching Modes Switching modes is not necessarily simple since access control lists are cached at several places. Hence, while changing this value will have an immediate effect on newly processed videos, an index rebuild is inevitable to update cached data and republications to update old events may be necessary. Updating Series Permissions Depending on the admin interface configuration in etc/org.opencastproject.organization-mh_default_org.cfg , the admin interface behaves differently when series access control lists are modified and may also overwrite episode rules of that series. Possible modes of operation are: always: When modifying series permissions, automatically remove all permission rules specific to single episodes belonging to the series. This enforces that every episode has the rules of the series in effect as soon as they are changed. never: Only update the series permissions but never replace permissions set on event level. This may mean that updated rules have no effect on already existing events. optional (default): Like never but present users with a button in the series permission dialog which allows them to replace the event specific permissions easily if they want to. Templates Templates of access control lists can be specified for the administrative user interface. They are a convenient way to apply a defined set of rules all at once instead of applying each rule one after another. Templates stored in etc/acl/ are loaded at start-up for all organizations. Templates can also be created and managed in the admin interface. Additional Actions Opencast uses two default actions for access authorization on events: read allows a role to access (read the value of) objects write allows a role to modify (write to) objects More actions can be added but are usually ignored by Opencast. Though they may be handy to specify rules for external applications. In case you need other actions, you can configure the admin interface to allow adding additional ones. These are configured in etc/listprovides/acl.additional.actions.properties . For example, this would configure the two actions, Upload and Download , to be available in the permission editor of the admin interface: list.name=ACL.ACTIONS # This list provider allows you to configure custom actions that can be added # to ACLs. The default actions are read and write. # The pattern for adding them is # UI_LABEL=actionId # Upload=myorg_upload Download=myorg_downlaod Using a unique prefix for your custom actions like this example did with myorg_ is recommended to make it unlikely that later Opencast versions introduce the same action in a different context.","title":"Access Control Lists"},{"location":"configuration/acl/#access-control-list-configuration","text":"This document describes how Opencast stores and handles access control settings for series and episodes and what configuration options related to this are available.","title":"Access Control List Configuration"},{"location":"configuration/acl/#access-control-lists","text":"An access control list (ACL) in the context of Opencast consists of a global deny rule (no one is allowed access) and a set of roles with rules attached to define access. Hence, it is effectively a white-listing of roles to grant access and it means that all roles and/or actions not defined in an access control list are denied access. For example, the following rule defines read access for role 1 and read/write access for role 2: role action access ROLE1 read true ROLE2 read true write true Opencast can also deny access locally (e.g. deny write access for role 1) which can be interesting if merging of ACLs is used. But this is not handled in the user interface and using this should therefore be avoided. System administrators are an exception to these rules. A user with ROLE_ADMIN will always be granted access, regardless of the rule-set attached to an event. Organizational administrators are also granted access in some cases.","title":"Access Control Lists"},{"location":"configuration/acl/#global-rules","text":"In case an event has no custom access control list defined, a global rule set is associated with the event. The global rules consist only of the general deny rule. Hence, no access is allowed to anyone except administrators..","title":"Global Rules"},{"location":"configuration/acl/#series-and-episode-rules","text":"Access control lists can be specified both on series and on episode level. This means that multiple rule sets can be attached to an episode which is part of a series. Opencast can handle this in multiple ways. The handling is specified by the merge mode configured in etc/org.opencastproject.authorization.xacml.XACMLAuthorizationService.cfg . It defines the relationship between series and episode access control lists, if both are attached to an event. If only one list is attached, its rules are always active. If multiple lists are attached, the following modes define Opencast's behavior:","title":"Series and Episode Rules"},{"location":"configuration/acl/#merge-mode-override-default","text":"The episode ACL takes precedence over the series ACL. This means that the series ACL will be completely ignored as soon as the episode has an ACL, no matter what rules are set in either. This allows users to define general rules for a series which can be completely redefined on an episode and which are not influenced by changes later made to the series. This is also a very simple rule and thus easy to understand. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow","title":"Merge Mode \u201coverride\u201d (Default)"},{"location":"configuration/acl/#merge-mode-roles","text":"Series and episode ACLs are merged based on the roles defined within. If both the series and the episode define a rule for a specific role (user or group), the episode's rule takes precedence. Rules for roles defined in one ACL only are always part of the resulting active ACL. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow","title":"Merge Mode \u201croles\u201d"},{"location":"configuration/acl/#merge-mode-actions","text":"ACLs are merged based on the actions (read, write, \u2026) contained within both ACLs. If a rule is specified for a tuple of role and action in both ACLs, the rule specified in the episode ACL takes precedence. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow allow","title":"Merge Mode \u201cactions\u201d"},{"location":"configuration/acl/#switching-modes","text":"Switching modes is not necessarily simple since access control lists are cached at several places. Hence, while changing this value will have an immediate effect on newly processed videos, an index rebuild is inevitable to update cached data and republications to update old events may be necessary.","title":"Switching Modes"},{"location":"configuration/acl/#updating-series-permissions","text":"Depending on the admin interface configuration in etc/org.opencastproject.organization-mh_default_org.cfg , the admin interface behaves differently when series access control lists are modified and may also overwrite episode rules of that series. Possible modes of operation are: always: When modifying series permissions, automatically remove all permission rules specific to single episodes belonging to the series. This enforces that every episode has the rules of the series in effect as soon as they are changed. never: Only update the series permissions but never replace permissions set on event level. This may mean that updated rules have no effect on already existing events. optional (default): Like never but present users with a button in the series permission dialog which allows them to replace the event specific permissions easily if they want to.","title":"Updating Series Permissions"},{"location":"configuration/acl/#templates","text":"Templates of access control lists can be specified for the administrative user interface. They are a convenient way to apply a defined set of rules all at once instead of applying each rule one after another. Templates stored in etc/acl/ are loaded at start-up for all organizations. Templates can also be created and managed in the admin interface.","title":"Templates"},{"location":"configuration/acl/#additional-actions","text":"Opencast uses two default actions for access authorization on events: read allows a role to access (read the value of) objects write allows a role to modify (write to) objects More actions can be added but are usually ignored by Opencast. Though they may be handy to specify rules for external applications. In case you need other actions, you can configure the admin interface to allow adding additional ones. These are configured in etc/listprovides/acl.additional.actions.properties . For example, this would configure the two actions, Upload and Download , to be available in the permission editor of the admin interface: list.name=ACL.ACTIONS # This list provider allows you to configure custom actions that can be added # to ACLs. The default actions are read and write. # The pattern for adding them is # UI_LABEL=actionId # Upload=myorg_upload Download=myorg_downlaod Using a unique prefix for your custom actions like this example did with myorg_ is recommended to make it unlikely that later Opencast versions introduce the same action in a different context.","title":"Additional Actions"},{"location":"configuration/asset-manager/","text":"Asset Manager Configuration How can I use a different storage backend? Configure an alternate storage backend, and then either use the REST endpoints or the Move Storage workflow operation as part of a workflow. Note that the REST endpoints trigger workflows, the workflow operation handlers are generally only useful as part of an automated storage tiering system. REST Endpoints The REST endpoints can be accessed from $server_url/assets/docs . The value of $server_url is set during basic configuration . There is no other current user interface for storage tiering at this time. Config Options File System Based Asset Store Configure the file system based asset store in custom.properties . org.opencastproject.episode.rootdir The path where the file system based asset store of the default implementation stores the assets. This key is optional. org.opencastproject.storage.dir This is Opencast\u2019s general config key to configure the base path of everything storage related. If no storage directory is configured explicitly, the file system based asset store will use ${org.opencastproject.storage.dir}/archive as its base path.","title":"Asset Manager"},{"location":"configuration/asset-manager/#asset-manager-configuration","text":"","title":"Asset Manager Configuration"},{"location":"configuration/asset-manager/#how-can-i-use-a-different-storage-backend","text":"Configure an alternate storage backend, and then either use the REST endpoints or the Move Storage workflow operation as part of a workflow. Note that the REST endpoints trigger workflows, the workflow operation handlers are generally only useful as part of an automated storage tiering system.","title":"How can I use a different storage backend?"},{"location":"configuration/asset-manager/#rest-endpoints","text":"The REST endpoints can be accessed from $server_url/assets/docs . The value of $server_url is set during basic configuration . There is no other current user interface for storage tiering at this time.","title":"REST Endpoints"},{"location":"configuration/asset-manager/#config-options","text":"","title":"Config Options"},{"location":"configuration/asset-manager/#file-system-based-asset-store","text":"Configure the file system based asset store in custom.properties . org.opencastproject.episode.rootdir The path where the file system based asset store of the default implementation stores the assets. This key is optional. org.opencastproject.storage.dir This is Opencast\u2019s general config key to configure the base path of everything storage related. If no storage directory is configured explicitly, the file system based asset store will use ${org.opencastproject.storage.dir}/archive as its base path.","title":"File System Based Asset Store"},{"location":"configuration/basic/","text":"Basic Configuration The basic configuration guide will help you to adjust the settings strongly recommended for each Opencast installation. This is what you should do right after installing Opencast. While there are alternatives for some of these settings, this is the recommended setup. All settings changes are made to files residing in the Opencast configuration directory. The location of the configuration directory depends on how you installed Opencast. If you used the Linux packages, the location is /etc/opencast . Step 1: Setting the Server URL Find the property org.opencastproject.server.url in etc/custom.properties and set your domain name. The value must be set to the URL from which the server can be accessed later. org.opencastproject.server.url=https://example.opencast.org Note: This value will be written to all generated media packages and thus cannot be changed easily for already processed media. Please think about this setting carefully. Step 2: Setting Authentication Details Configure authentication and security details of Opencast, including the login credentials. For this, the important keys in the etc/custom.properties configuration file are: org.opencastproject.security.admin.user The user for the administrative account. This is set to admin by default. org.opencastproject.security.admin.pass The password for the administrative account. This is set to opencast by default. org.opencastproject.security.digest.user The user for the communication between Opencast nodes. It is sometimes also used by capture agents. This is set to opencast_system_account by default. org.opencastproject.security.digest.pass The password for the communication between Opencast nodes. It is sometimes also used by capture agents. This is set to CHANGE_ME by default. karaf.shutdown.command The security token used for shutting down Opencast. Set this to a random string. Make sure that these settings are identical on all nodes of the cluster. Step 3: Setting up Apache ActiveMQ Message Broker Opencast requires Apache ActiveMQ to relay messages between micro-services. For configuration details, please follow the: Apache ActiveMQ configuration guide Step 4: Database Configuration Opencast uses an integrated H2 database by default, which has certain drawbacks: It cannot be used for distributed set-ups Upgrading Opencast with this database is not possible The internal database will suffice for testing, however a stand-alone database is required for production uses. Details about the configuration can be found at: Database Configuration Step 5: Setting up Elasticsearch Opencast requires Elasticsearch. Instructions for installing Elasticsearch can be found in the installation documentation . Step 6: HTTPS Configuration This configuration is required in order to: Make Opencast available externally Secure connections from/to Opencast For this, follow one of the configuration guides for HTTPS . Step 7: Setting the Storage Directory (optional) If you want to use a specific location for storing media, metadata and other data, you can set the directory by changing org.opencastproject.storage.dir . org.opencastproject.storage.dir=/path/to/data/folder Often, an NFS mount is used for data storage. Make sure that the user running Opencast has read/write permissions to the storage directory. You can check that, for example, by running: sudo -u opencast touch /path/to/data/folder/test sudo -u opencast rm /path/to/data/folder/test Finish Installation If you came here as part of an installation, please head back to the installation guide you used for notes on how to run Opencast as a service.","title":"Basic"},{"location":"configuration/basic/#basic-configuration","text":"The basic configuration guide will help you to adjust the settings strongly recommended for each Opencast installation. This is what you should do right after installing Opencast. While there are alternatives for some of these settings, this is the recommended setup. All settings changes are made to files residing in the Opencast configuration directory. The location of the configuration directory depends on how you installed Opencast. If you used the Linux packages, the location is /etc/opencast .","title":"Basic Configuration"},{"location":"configuration/basic/#step-1-setting-the-server-url","text":"Find the property org.opencastproject.server.url in etc/custom.properties and set your domain name. The value must be set to the URL from which the server can be accessed later. org.opencastproject.server.url=https://example.opencast.org Note: This value will be written to all generated media packages and thus cannot be changed easily for already processed media. Please think about this setting carefully.","title":"Step 1: Setting the Server URL"},{"location":"configuration/basic/#step-2-setting-authentication-details","text":"Configure authentication and security details of Opencast, including the login credentials. For this, the important keys in the etc/custom.properties configuration file are: org.opencastproject.security.admin.user The user for the administrative account. This is set to admin by default. org.opencastproject.security.admin.pass The password for the administrative account. This is set to opencast by default. org.opencastproject.security.digest.user The user for the communication between Opencast nodes. It is sometimes also used by capture agents. This is set to opencast_system_account by default. org.opencastproject.security.digest.pass The password for the communication between Opencast nodes. It is sometimes also used by capture agents. This is set to CHANGE_ME by default. karaf.shutdown.command The security token used for shutting down Opencast. Set this to a random string. Make sure that these settings are identical on all nodes of the cluster.","title":"Step 2: Setting Authentication Details"},{"location":"configuration/basic/#step-3-setting-up-apache-activemq-message-broker","text":"Opencast requires Apache ActiveMQ to relay messages between micro-services. For configuration details, please follow the: Apache ActiveMQ configuration guide","title":"Step 3: Setting up Apache ActiveMQ Message Broker"},{"location":"configuration/basic/#step-4-database-configuration","text":"Opencast uses an integrated H2 database by default, which has certain drawbacks: It cannot be used for distributed set-ups Upgrading Opencast with this database is not possible The internal database will suffice for testing, however a stand-alone database is required for production uses. Details about the configuration can be found at: Database Configuration","title":"Step 4: Database Configuration"},{"location":"configuration/basic/#step-5-setting-up-elasticsearch","text":"Opencast requires Elasticsearch. Instructions for installing Elasticsearch can be found in the installation documentation .","title":"Step 5: Setting up Elasticsearch"},{"location":"configuration/basic/#step-6-https-configuration","text":"This configuration is required in order to: Make Opencast available externally Secure connections from/to Opencast For this, follow one of the configuration guides for HTTPS .","title":"Step 6: HTTPS Configuration"},{"location":"configuration/basic/#step-7-setting-the-storage-directory-optional","text":"If you want to use a specific location for storing media, metadata and other data, you can set the directory by changing org.opencastproject.storage.dir . org.opencastproject.storage.dir=/path/to/data/folder Often, an NFS mount is used for data storage. Make sure that the user running Opencast has read/write permissions to the storage directory. You can check that, for example, by running: sudo -u opencast touch /path/to/data/folder/test sudo -u opencast rm /path/to/data/folder/test","title":"Step 7: Setting the Storage Directory (optional)"},{"location":"configuration/basic/#finish-installation","text":"If you came here as part of an installation, please head back to the installation guide you used for notes on how to run Opencast as a service.","title":"Finish Installation"},{"location":"configuration/database/","text":"Database Configuration Opencast ships with embedded JDBC drivers for the H2, MySQL, MariaDB and PostgreSQL databases. The built-in H2 database is used by default and needs no configuration, but is not suited for production. H2 is not supported for updates or distributed systems. Use it for testing only! Requirements Before following this guide, you should have: Installed Opencast Followed the Basic Configuration instructions Step 1: Select a Database The EclipseLink JPA implementation which is used in Opencast supports several different databases, although some databases might require additional drivers. Official support only exists for MariaDB, MySQL, PostgreSQL and H2. Other database engines are not tested and specific issues will likely not be addressed. MariaDB is the recommended database engine. It is used by most adopters and is well tested. MySQL is supported but tested less than MariaDB. PostgreSQL support is experimental. H2 is not suitable for anything but testing and development. It cannot be used in distributed environments. Step 2: Set up the Database This step is not Opencast-specific and may be different depending on your scenario and system. The following is an example of database setup using MariaDB, followed by an example for PostgreSQL, and is assuming CentOS 8 as Linux distribution. Look at your distribution's documentation for setting up a database. MariaDB Install and start MariaDB: % dnf install mariadb mariadb-server % systemctl start mariadb.service % systemctl enable mariadb.service Finally, set root user credentials by running % mysql_secure_installation The first step is to create a database for Opencast. You can use any other database client, e.g. phpMyAdmin, for this as well. % mysql -u root -p You will be asked for the password of the user root. Next, create a database called opencast by executing: CREATE DATABASE opencast CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; Then create a user opencast with a password and grant it all necessary rights: GRANT ALL PRIVILEGES ON opencast.* TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password'; Limiting the granted privileges You can limit the granted privileges further if you want to. The rights granted here are sufficient to run Opencast: GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,ALTER,DROP,INDEX,TRIGGER,CREATE TEMPORARY TABLES,REFERENCES ON opencast.* TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password'; You can choose other names for the users and the database, and you should use a different password. In a distributed system, apart from 'username'@'localhost' (which would allow access from the local machine only), you should grant a external user access to the database by running the same command for a user like 'username'@'10.0.1.%' , where the 10.0.1.% specifies the IP range allowed to access the server. For more details on MariaDB user creation, have a look at MariaDB Reference Manual :: GRANT statement Finally, leave the client and restart the database server to enable the new user(s): % systemctl restart mariadb.service PostgreSQL Opencast's official PostgreSQL support is still marked as experimental. Install PostgreSQL, create a database and a user. You may need to enable password authentication in your pg_hba.conf first. Please refer to the PostgreSQL documentation for more details. sudo -u postgres psql postgres=# create database opencast; postgres=# create user opencast with encrypted password 'opencast_password'; postgres=# grant all privileges on database opencast to opencast; Step 4: Configure Opencast The following changes must be made in etc/custom.properties . Examples are provided for MariaDB/MySQL and PostgreSQL. Configure Opencast to use the JDBC driver for MariaDB or PostgreSQL. The MariaDB driver will also work for MySQL. # MariaDB/MySQL org.opencastproject.db.jdbc.driver=org.mariadb.jdbc.Driver # PostgreSQL org.opencastproject.db.jdbc.driver=org.postgresql.Driver Configure the host where Opencast will find the database ( 127.0.0.1 ) and the database name ( opencast ). # MariaDB/MySQL org.opencastproject.db.jdbc.url=jdbc:mysql://127.0.0.1/opencast?useMysqlMetadata=true # PostgreSQL org.opencastproject.db.jdbc.url=jdbc:postgresql://127.0.0.1/opencast Configure the database username and password. org.opencastproject.db.jdbc.user=opencast org.opencastproject.db.jdbc.pass=opencast_password Step 5: OAI-PMH Database (optional) The database tables are automatically generated by Opencast when they are needed. One exception to this is the OAI-PMH publication database which requires an additional trigger. Trying to generate the schema automatically will most likely fail. If you want to use OAI-PMH, you must create the necessary table manually. Use the following code to generate the OAI-PMH database table on MariaDB/MySQL. PostgreSQL is not yet supported. CREATE TABLE oc_oaipmh ( mp_id VARCHAR(128) NOT NULL, organization VARCHAR(128) NOT NULL, repo_id VARCHAR(255) NOT NULL, series_id VARCHAR(128), deleted tinyint(1) DEFAULT '0', modification_date DATETIME DEFAULT NULL, mediapackage_xml TEXT(65535) NOT NULL, PRIMARY KEY (mp_id, repo_id, organization), CONSTRAINT UNQ_oc_oaipmh UNIQUE (modification_date) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE INDEX IX_oc_oaipmh_modification_date ON oc_oaipmh (modification_date); -- set to current date and time on insert CREATE TRIGGER oc_init_oaipmh_date BEFORE INSERT ON `oc_oaipmh` FOR EACH ROW SET NEW.modification_date = NOW(); -- set to current date and time on update CREATE TRIGGER oc_update_oaipmh_date BEFORE UPDATE ON `oc_oaipmh` FOR EACH ROW SET NEW.modification_date = NOW();","title":"Database"},{"location":"configuration/database/#database-configuration","text":"Opencast ships with embedded JDBC drivers for the H2, MySQL, MariaDB and PostgreSQL databases. The built-in H2 database is used by default and needs no configuration, but is not suited for production. H2 is not supported for updates or distributed systems. Use it for testing only!","title":"Database Configuration"},{"location":"configuration/database/#requirements","text":"Before following this guide, you should have: Installed Opencast Followed the Basic Configuration instructions","title":"Requirements"},{"location":"configuration/database/#step-1-select-a-database","text":"The EclipseLink JPA implementation which is used in Opencast supports several different databases, although some databases might require additional drivers. Official support only exists for MariaDB, MySQL, PostgreSQL and H2. Other database engines are not tested and specific issues will likely not be addressed. MariaDB is the recommended database engine. It is used by most adopters and is well tested. MySQL is supported but tested less than MariaDB. PostgreSQL support is experimental. H2 is not suitable for anything but testing and development. It cannot be used in distributed environments.","title":"Step 1: Select a Database"},{"location":"configuration/database/#step-2-set-up-the-database","text":"This step is not Opencast-specific and may be different depending on your scenario and system. The following is an example of database setup using MariaDB, followed by an example for PostgreSQL, and is assuming CentOS 8 as Linux distribution. Look at your distribution's documentation for setting up a database.","title":"Step 2: Set up the Database"},{"location":"configuration/database/#mariadb","text":"Install and start MariaDB: % dnf install mariadb mariadb-server % systemctl start mariadb.service % systemctl enable mariadb.service Finally, set root user credentials by running % mysql_secure_installation The first step is to create a database for Opencast. You can use any other database client, e.g. phpMyAdmin, for this as well. % mysql -u root -p You will be asked for the password of the user root. Next, create a database called opencast by executing: CREATE DATABASE opencast CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; Then create a user opencast with a password and grant it all necessary rights: GRANT ALL PRIVILEGES ON opencast.* TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password'; Limiting the granted privileges You can limit the granted privileges further if you want to. The rights granted here are sufficient to run Opencast: GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,ALTER,DROP,INDEX,TRIGGER,CREATE TEMPORARY TABLES,REFERENCES ON opencast.* TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password'; You can choose other names for the users and the database, and you should use a different password. In a distributed system, apart from 'username'@'localhost' (which would allow access from the local machine only), you should grant a external user access to the database by running the same command for a user like 'username'@'10.0.1.%' , where the 10.0.1.% specifies the IP range allowed to access the server. For more details on MariaDB user creation, have a look at MariaDB Reference Manual :: GRANT statement Finally, leave the client and restart the database server to enable the new user(s): % systemctl restart mariadb.service","title":"MariaDB"},{"location":"configuration/database/#postgresql","text":"Opencast's official PostgreSQL support is still marked as experimental. Install PostgreSQL, create a database and a user. You may need to enable password authentication in your pg_hba.conf first. Please refer to the PostgreSQL documentation for more details. sudo -u postgres psql postgres=# create database opencast; postgres=# create user opencast with encrypted password 'opencast_password'; postgres=# grant all privileges on database opencast to opencast;","title":"PostgreSQL"},{"location":"configuration/database/#step-4-configure-opencast","text":"The following changes must be made in etc/custom.properties . Examples are provided for MariaDB/MySQL and PostgreSQL. Configure Opencast to use the JDBC driver for MariaDB or PostgreSQL. The MariaDB driver will also work for MySQL. # MariaDB/MySQL org.opencastproject.db.jdbc.driver=org.mariadb.jdbc.Driver # PostgreSQL org.opencastproject.db.jdbc.driver=org.postgresql.Driver Configure the host where Opencast will find the database ( 127.0.0.1 ) and the database name ( opencast ). # MariaDB/MySQL org.opencastproject.db.jdbc.url=jdbc:mysql://127.0.0.1/opencast?useMysqlMetadata=true # PostgreSQL org.opencastproject.db.jdbc.url=jdbc:postgresql://127.0.0.1/opencast Configure the database username and password. org.opencastproject.db.jdbc.user=opencast org.opencastproject.db.jdbc.pass=opencast_password","title":"Step 4: Configure Opencast"},{"location":"configuration/database/#step-5-oai-pmh-database-optional","text":"The database tables are automatically generated by Opencast when they are needed. One exception to this is the OAI-PMH publication database which requires an additional trigger. Trying to generate the schema automatically will most likely fail. If you want to use OAI-PMH, you must create the necessary table manually. Use the following code to generate the OAI-PMH database table on MariaDB/MySQL. PostgreSQL is not yet supported. CREATE TABLE oc_oaipmh ( mp_id VARCHAR(128) NOT NULL, organization VARCHAR(128) NOT NULL, repo_id VARCHAR(255) NOT NULL, series_id VARCHAR(128), deleted tinyint(1) DEFAULT '0', modification_date DATETIME DEFAULT NULL, mediapackage_xml TEXT(65535) NOT NULL, PRIMARY KEY (mp_id, repo_id, organization), CONSTRAINT UNQ_oc_oaipmh UNIQUE (modification_date) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; CREATE INDEX IX_oc_oaipmh_modification_date ON oc_oaipmh (modification_date); -- set to current date and time on insert CREATE TRIGGER oc_init_oaipmh_date BEFORE INSERT ON `oc_oaipmh` FOR EACH ROW SET NEW.modification_date = NOW(); -- set to current date and time on update CREATE TRIGGER oc_update_oaipmh_date BEFORE UPDATE ON `oc_oaipmh` FOR EACH ROW SET NEW.modification_date = NOW();","title":"Step 5: OAI-PMH Database (optional)"},{"location":"configuration/elasticsearch/","text":"Elasticsearch Configuration Elasticsearch powers the external API as well as the administrative user interface of Opencast. Configuring External Nodes Opencast's Elasticsearch settings can be found in the 'etc/custom.properties' configuration file. Relevant configuration keys are: org.opencastproject.elasticsearch.server.hostname org.opencastproject.elasticsearch.server.scheme org.opencastproject.elasticsearch.server.port org.opencastproject.elasticsearch.username org.opencastproject.elasticsearch.password Therefore only admin , adminpresentation , and allinone need to connect to Elasticsearch. username and password are optional. If configured, requests to Elasticsearch are secured by HTTP basic authentication (which is unsecure without TLS encryption). Refer to the Elasticsearch documentation to properly secure Elasticsearch. Version Please confer to the Linux installation guide for version information.","title":"Elasticsearch"},{"location":"configuration/elasticsearch/#elasticsearch-configuration","text":"Elasticsearch powers the external API as well as the administrative user interface of Opencast.","title":"Elasticsearch Configuration"},{"location":"configuration/elasticsearch/#configuring-external-nodes","text":"Opencast's Elasticsearch settings can be found in the 'etc/custom.properties' configuration file. Relevant configuration keys are: org.opencastproject.elasticsearch.server.hostname org.opencastproject.elasticsearch.server.scheme org.opencastproject.elasticsearch.server.port org.opencastproject.elasticsearch.username org.opencastproject.elasticsearch.password Therefore only admin , adminpresentation , and allinone need to connect to Elasticsearch. username and password are optional. If configured, requests to Elasticsearch are secured by HTTP basic authentication (which is unsecure without TLS encryption). Refer to the Elasticsearch documentation to properly secure Elasticsearch.","title":"Configuring External Nodes"},{"location":"configuration/elasticsearch/#version","text":"Please confer to the Linux installation guide for version information.","title":"Version"},{"location":"configuration/encoding/","text":"Encoding Profile Configuration A workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An operation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is encoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026 Opencast comes with a set of such profiles generating files for both online playback and download. These profiles are build to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying these profiles or building new ones often makes sense. This document will help you modify or augment Opencast's default encoding profiles for audio, video and still images. Default Profiles and Possible Settings This section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing at things you might want to change depending on your local set-up. A/V-Muxing: From lossless to safe The audio/video muxing ( profile.mux-av.work ) is applied if audio and video is sent to Opencast separately. The basic idea behind this is, to combine these separate files into one file which can later be converted in one step. Possible settings: If you get an audio and a video file separately, it is possible to just copy the streams and put them together into a new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no re-encoding is done. The question is: What a/v container format can/should you use for such an operation. You can try to use the video container the input video came in and just add the audio. This means that you will never have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4 container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxed in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast does at the moment. To circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv) regardless of the input. This would mean that Opencast can handle more combinations of a/v streams but you will always end up with a Matroska file after muxing. Of cause, you can then encode it to mp4, etc. later on. The safest option for muxing is to always re-encode the streams. It is far slower than re-using the existing bit streams. It also, always means a quality loss. Create an Encoding Profile This section will help you to understand how you can modify an existing profile or create a completely new one. Creating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles watch folder. Step 1: Encoding Profile Folder The <config_dir>/encoding folder allows you to quickly augment Opencast's existing behavior, simply by modifying or adding new configuration files. The file names should follow the pattern *.properties . Step 2: The Encoding Profile Encoding profiles consist of a set of key-value pairs that conform to the following pattern: profile.<name>.<context>.<property> = <value> For example: profile.mp4.http.name = Enocde Mp4 files for download All profiles should have the following properties: .name .input = [audio|visual|stream|image] .output = [audio|visual|stream|image] .suffix .ffmpeg.command For example: // My audio/video encoding profile profile.my-av-profile.http.name = my audio/video encoding profile profile.my-av-profile.http.input = visual profile.my-av-profile.http.output = visual profile.my-av-profile.http.suffix = -encoded.enc profile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix} The most important part of this profile is the ffmpeg.command . This line specifies FFmpeg command line options using #{expression} for string replacement. Step 3: FFmpeg To create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want to do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a look at the Official FFmpeg Wiki . For trying out new encoding settings, just call FFmpeg from the command line. Using a Profile Once defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode presenter using my audio/video encoding profile\"> <configurations> <configuration key=\"source-flavor\">presenter/work</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom, captioning</configuration> <configuration key=\"encoding-profile\">my-av-profile.http</configuration> </configuration> </operation> Have a look at the Workflow Configuration section for more details about workflows and workflow operations.","title":"Encoding"},{"location":"configuration/encoding/#encoding-profile-configuration","text":"A workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An operation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is encoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026 Opencast comes with a set of such profiles generating files for both online playback and download. These profiles are build to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying these profiles or building new ones often makes sense. This document will help you modify or augment Opencast's default encoding profiles for audio, video and still images.","title":"Encoding Profile Configuration"},{"location":"configuration/encoding/#default-profiles-and-possible-settings","text":"This section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing at things you might want to change depending on your local set-up.","title":"Default Profiles and Possible Settings"},{"location":"configuration/encoding/#av-muxing-from-lossless-to-safe","text":"The audio/video muxing ( profile.mux-av.work ) is applied if audio and video is sent to Opencast separately. The basic idea behind this is, to combine these separate files into one file which can later be converted in one step. Possible settings: If you get an audio and a video file separately, it is possible to just copy the streams and put them together into a new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no re-encoding is done. The question is: What a/v container format can/should you use for such an operation. You can try to use the video container the input video came in and just add the audio. This means that you will never have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4 container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxed in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast does at the moment. To circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv) regardless of the input. This would mean that Opencast can handle more combinations of a/v streams but you will always end up with a Matroska file after muxing. Of cause, you can then encode it to mp4, etc. later on. The safest option for muxing is to always re-encode the streams. It is far slower than re-using the existing bit streams. It also, always means a quality loss.","title":"A/V-Muxing: From lossless to safe"},{"location":"configuration/encoding/#create-an-encoding-profile","text":"This section will help you to understand how you can modify an existing profile or create a completely new one. Creating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles watch folder.","title":"Create an Encoding Profile"},{"location":"configuration/encoding/#step-1-encoding-profile-folder","text":"The <config_dir>/encoding folder allows you to quickly augment Opencast's existing behavior, simply by modifying or adding new configuration files. The file names should follow the pattern *.properties .","title":"Step 1: Encoding Profile Folder"},{"location":"configuration/encoding/#step-2-the-encoding-profile","text":"Encoding profiles consist of a set of key-value pairs that conform to the following pattern: profile.<name>.<context>.<property> = <value> For example: profile.mp4.http.name = Enocde Mp4 files for download All profiles should have the following properties: .name .input = [audio|visual|stream|image] .output = [audio|visual|stream|image] .suffix .ffmpeg.command For example: // My audio/video encoding profile profile.my-av-profile.http.name = my audio/video encoding profile profile.my-av-profile.http.input = visual profile.my-av-profile.http.output = visual profile.my-av-profile.http.suffix = -encoded.enc profile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix} The most important part of this profile is the ffmpeg.command . This line specifies FFmpeg command line options using #{expression} for string replacement.","title":"Step 2: The Encoding Profile"},{"location":"configuration/encoding/#step-3-ffmpeg","text":"To create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want to do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a look at the Official FFmpeg Wiki . For trying out new encoding settings, just call FFmpeg from the command line.","title":"Step 3: FFmpeg"},{"location":"configuration/encoding/#using-a-profile","text":"Once defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode presenter using my audio/video encoding profile\"> <configurations> <configuration key=\"source-flavor\">presenter/work</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom, captioning</configuration> <configuration key=\"encoding-profile\">my-av-profile.http</configuration> </configuration> </operation> Have a look at the Workflow Configuration section for more details about workflows and workflow operations.","title":"Using a Profile"},{"location":"configuration/external-api/","text":"External API Configuration The External API is an integral part of Opencast and therefore does not need to be enabled. To be able to access the External API, you need to configure a user that is authorized to do so. Perform the following steps to get the External API running: Enable basic authentication (see section Authentication) Create a new user or choose an existing user (administrative user interface) Authorize the user to access the External API (see section Authorization) Test whether access works (see section Testing) Authentication The External API currently only supports basic authentication. To enable basic authentication, uncomment the following blocks in /etc/security/mh_default_org.xml : <!-- Basic authentication <sec:custom-filter after=\"BASIC_AUTH_FILTER\" ref=\"basicAuthenticationFilter\" /> --> <!-- Basic authentication <bean id=\"basicEntryPoint\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationEntryPoint\"> <property name=\"realmName\" value=\"Opencast\"/> </bean> --> <!-- Basic authentication <bean id=\"basicAuthenticationFilter\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationFilter\"> <property name=\"authenticationManager\" ref=\"authenticationManager\"/> <property name=\"authenticationEntryPoint\" ref=\"basicEntryPoint\"/> </bean> --> Note: Since basic authentication involves sending unencrypted passwords over the network, it is strongly recommended to use HTTPS. Authorization The External API supports fine-grained access control on request level allowing it to be tailored to your specific needs. A number of roles are used to authorize access to individual endpoints. Those roles can be configured directly in the Opencast administrative user interface. Note: Users owning the role ROLE_ADMIN have full access to the External API. Base API ROLE METHOD URL ROLE_API GET /api /api/info/* /api/info/me/* /api/version /api/version/* Events API ROLE METHOD URL ROLE_API_EVENTS_CREATE POST /api/events ROLE_API_EVENTS_VIEW GET /api/events /api/events/* ROLE_API_EVENTS_EDIT PUT POST /api/events/* /api/events/* ROLE_API_EVENTS_DELETE DELETE /api/events/* ROLE_API_EVENTS_ACL_VIEW GET /api/events/*/acl ROLE_API_EVENTS_ACL_EDIT PUT POST /api/events/*/acl /api/events/*/acl/* ROLE_API_EVENTS_ACL_DELETE DELETE /api/events/*/acl/*/* ROLE_API_EVENTS_MEDIA_VIEW GET /api/events/*/media /api/events/*/media/* ROLE_API_EVENTS_METADATA_VIEW GET /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_EDIT PUT /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_DELETE DELETE /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_PUBLICATIONS_VIEW GET /api/events/*/publications /api/events/*/publications/* ROLE_API_EVENTS_SCHEDULING_EDIT PUT /api/events/*/scheduling ROLE_API_EVENTS_SCHEDULING_VIEW GET /api/events/*/scheduling Series API ROLE METHOD URL ROLE_API_SERIES_CREATE POST /api/series ROLE_API_SERIES_VIEW GET /api/series /api/series/* ROLE_API_SERIES_EDIT PUT /api/series/* ROLE_API_SERIES_ACL_VIEW GET /api/series/*/acl ROLE_API_SERIES_ACL_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_VIEW GET /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_DELETE DELETE /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_PROPERTIES_VIEW GET /api/series/*/properties ROLE_API_SERIES_PROPERTIES_EDIT PUT /api/series/*/properties ROLE_API_SERIES_DELETE DELETE /api/series/* Statistics API ROLE METHOD URL ROLE_API_STATISTICS_VIEW GET /api/statistics/providers /api/statistics/providers/* ROLE_API_STATISTICS_VIEW POST /api/statistics/data/query Groups API ROLE METHOD URL ROLE_API_GROUPS_CREATE POST /api/groups ROLE_API_GROUPS_VIEW GET /api/groups /api/groups/* ROLE_API_GROUPS_EDIT PUT POST /api/groups/* /api/groups/*/members/* ROLE_API_GROUPS_DELETE DELETE /api/groups/* Security API ROLE METHOD URL ROLE_API_SECURITY_EDIT POST /api/security/sign Agents API ROLE METHOD URL ROLE_API_CAPTURE_AGENTS_VIEW GET /api/agents /api/agents/* Administrative API ROLE METHOD URL ROLE_ADMIN POST /api/recreateIndex Workflow API ROLE METHOD URL ROLE_API_WORKFLOW_INSTANCE_CREATE POST /api/workflow ROLE_API_WORKFLOW_INSTANCE_VIEW GET /api/workflow /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_EDIT PUT /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_DELETE DELETE /api/workflow/* ROLE_API_WORKFLOW_DEFINITION_VIEW GET /api/workflow-definitions /api/workflow-definitions/* User- and Role-switching The External API supports user- and role-switching, i.e. it is possible to perform requests on behalf of another user or role. The be able to perform this kind of requests, the user doing the actual requests needs to own ROLE_SUDO. For more details on this API, please take a look at the developer documentation under External API. Testing curl -u <api-user>:<api-user-passowrd> <admin-node>/api/info/me should return a JSON containing information about the user api-user . Accessing Distribution Artefacts A major use case of the External API is to provide External Applications secure access to distribution artefacts. For this purpose, Opencast comes with a special workflow operation: WOH publish-configure (see ConfigurablePublishWorkflowOperationHandler ) creates publication elements that do not just contain a single URL to the publication channel, but also contain URLs for each of the attachments and tracks that have been published. Note: Secure access to distribution artefacts requires stream security to be enabled, see Stream Security Configuration .","title":"External API"},{"location":"configuration/external-api/#external-api-configuration","text":"The External API is an integral part of Opencast and therefore does not need to be enabled. To be able to access the External API, you need to configure a user that is authorized to do so. Perform the following steps to get the External API running: Enable basic authentication (see section Authentication) Create a new user or choose an existing user (administrative user interface) Authorize the user to access the External API (see section Authorization) Test whether access works (see section Testing)","title":"External API Configuration"},{"location":"configuration/external-api/#authentication","text":"The External API currently only supports basic authentication. To enable basic authentication, uncomment the following blocks in /etc/security/mh_default_org.xml : <!-- Basic authentication <sec:custom-filter after=\"BASIC_AUTH_FILTER\" ref=\"basicAuthenticationFilter\" /> --> <!-- Basic authentication <bean id=\"basicEntryPoint\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationEntryPoint\"> <property name=\"realmName\" value=\"Opencast\"/> </bean> --> <!-- Basic authentication <bean id=\"basicAuthenticationFilter\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationFilter\"> <property name=\"authenticationManager\" ref=\"authenticationManager\"/> <property name=\"authenticationEntryPoint\" ref=\"basicEntryPoint\"/> </bean> --> Note: Since basic authentication involves sending unencrypted passwords over the network, it is strongly recommended to use HTTPS.","title":"Authentication"},{"location":"configuration/external-api/#authorization","text":"The External API supports fine-grained access control on request level allowing it to be tailored to your specific needs. A number of roles are used to authorize access to individual endpoints. Those roles can be configured directly in the Opencast administrative user interface. Note: Users owning the role ROLE_ADMIN have full access to the External API. Base API ROLE METHOD URL ROLE_API GET /api /api/info/* /api/info/me/* /api/version /api/version/* Events API ROLE METHOD URL ROLE_API_EVENTS_CREATE POST /api/events ROLE_API_EVENTS_VIEW GET /api/events /api/events/* ROLE_API_EVENTS_EDIT PUT POST /api/events/* /api/events/* ROLE_API_EVENTS_DELETE DELETE /api/events/* ROLE_API_EVENTS_ACL_VIEW GET /api/events/*/acl ROLE_API_EVENTS_ACL_EDIT PUT POST /api/events/*/acl /api/events/*/acl/* ROLE_API_EVENTS_ACL_DELETE DELETE /api/events/*/acl/*/* ROLE_API_EVENTS_MEDIA_VIEW GET /api/events/*/media /api/events/*/media/* ROLE_API_EVENTS_METADATA_VIEW GET /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_EDIT PUT /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_DELETE DELETE /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_PUBLICATIONS_VIEW GET /api/events/*/publications /api/events/*/publications/* ROLE_API_EVENTS_SCHEDULING_EDIT PUT /api/events/*/scheduling ROLE_API_EVENTS_SCHEDULING_VIEW GET /api/events/*/scheduling Series API ROLE METHOD URL ROLE_API_SERIES_CREATE POST /api/series ROLE_API_SERIES_VIEW GET /api/series /api/series/* ROLE_API_SERIES_EDIT PUT /api/series/* ROLE_API_SERIES_ACL_VIEW GET /api/series/*/acl ROLE_API_SERIES_ACL_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_VIEW GET /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_DELETE DELETE /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_PROPERTIES_VIEW GET /api/series/*/properties ROLE_API_SERIES_PROPERTIES_EDIT PUT /api/series/*/properties ROLE_API_SERIES_DELETE DELETE /api/series/* Statistics API ROLE METHOD URL ROLE_API_STATISTICS_VIEW GET /api/statistics/providers /api/statistics/providers/* ROLE_API_STATISTICS_VIEW POST /api/statistics/data/query Groups API ROLE METHOD URL ROLE_API_GROUPS_CREATE POST /api/groups ROLE_API_GROUPS_VIEW GET /api/groups /api/groups/* ROLE_API_GROUPS_EDIT PUT POST /api/groups/* /api/groups/*/members/* ROLE_API_GROUPS_DELETE DELETE /api/groups/* Security API ROLE METHOD URL ROLE_API_SECURITY_EDIT POST /api/security/sign Agents API ROLE METHOD URL ROLE_API_CAPTURE_AGENTS_VIEW GET /api/agents /api/agents/* Administrative API ROLE METHOD URL ROLE_ADMIN POST /api/recreateIndex Workflow API ROLE METHOD URL ROLE_API_WORKFLOW_INSTANCE_CREATE POST /api/workflow ROLE_API_WORKFLOW_INSTANCE_VIEW GET /api/workflow /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_EDIT PUT /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_DELETE DELETE /api/workflow/* ROLE_API_WORKFLOW_DEFINITION_VIEW GET /api/workflow-definitions /api/workflow-definitions/* User- and Role-switching The External API supports user- and role-switching, i.e. it is possible to perform requests on behalf of another user or role. The be able to perform this kind of requests, the user doing the actual requests needs to own ROLE_SUDO. For more details on this API, please take a look at the developer documentation under External API.","title":"Authorization"},{"location":"configuration/external-api/#testing","text":"curl -u <api-user>:<api-user-passowrd> <admin-node>/api/info/me should return a JSON containing information about the user api-user .","title":"Testing"},{"location":"configuration/external-api/#accessing-distribution-artefacts","text":"A major use case of the External API is to provide External Applications secure access to distribution artefacts. For this purpose, Opencast comes with a special workflow operation: WOH publish-configure (see ConfigurablePublishWorkflowOperationHandler ) creates publication elements that do not just contain a single URL to the publication channel, but also contain URLs for each of the attachments and tracks that have been published. Note: Secure access to distribution artefacts requires stream security to be enabled, see Stream Security Configuration .","title":"Accessing Distribution Artefacts"},{"location":"configuration/firewall/","text":"Firewall Opencast relies on a lot of network communication and although not strictly necessary, it usually makes sense to configure a firewall for additional protection This describes a lot of the communication happening between servers in the most common use cases. In certain set-ups and with certain types of integrations, these may deviate slightly. General rules are: Users communicate with Opencast via HTTP(S) Capture agents communicate with Opencast via HTTP(S) Opencast nodes communicate among each other via HTTP(S) Often Elasticsearch and ActiveMQ are run on the admin node since this node communicates with these services exclusively All servers should get access to the storage infrastructure All Opencast nodes need database access A visual representation of the communication within a three-node cluster will look like this: Notes: The numbers in the diagram describe TCP ports \u00b9) Communication between users and workers is often not necessary \u00b2) If you use a database other than MariaDB, the port may differ Suggested Firewall Configurations Note that none of these instructions take additional services like SSH into account. They are focused just on what Opencast needs for communication. Simple For a very simple configuration catching most of the important attack vectors, implement the following firewall rules: Allow HTTP and HTTPS to all Opencast nodes from the outside Allow all TCP communication within the cluster Complex If you want a more complex, stricter set of rules: Allow external HTTP and HTTPS communication to admin, presentation and possibly ingest Allow all Opencast nodes to access the database Allow the admin node to access Elasticsearch Allow all nodes access to the storage infrastructure","title":"Firewall"},{"location":"configuration/firewall/#firewall","text":"Opencast relies on a lot of network communication and although not strictly necessary, it usually makes sense to configure a firewall for additional protection This describes a lot of the communication happening between servers in the most common use cases. In certain set-ups and with certain types of integrations, these may deviate slightly. General rules are: Users communicate with Opencast via HTTP(S) Capture agents communicate with Opencast via HTTP(S) Opencast nodes communicate among each other via HTTP(S) Often Elasticsearch and ActiveMQ are run on the admin node since this node communicates with these services exclusively All servers should get access to the storage infrastructure All Opencast nodes need database access A visual representation of the communication within a three-node cluster will look like this: Notes: The numbers in the diagram describe TCP ports \u00b9) Communication between users and workers is often not necessary \u00b2) If you use a database other than MariaDB, the port may differ","title":"Firewall"},{"location":"configuration/firewall/#suggested-firewall-configurations","text":"Note that none of these instructions take additional services like SSH into account. They are focused just on what Opencast needs for communication.","title":"Suggested Firewall Configurations"},{"location":"configuration/firewall/#simple","text":"For a very simple configuration catching most of the important attack vectors, implement the following firewall rules: Allow HTTP and HTTPS to all Opencast nodes from the outside Allow all TCP communication within the cluster","title":"Simple"},{"location":"configuration/firewall/#complex","text":"If you want a more complex, stricter set of rules: Allow external HTTP and HTTPS communication to admin, presentation and possibly ingest Allow all Opencast nodes to access the database Allow the admin node to access Elasticsearch Allow all nodes access to the storage infrastructure","title":"Complex"},{"location":"configuration/inbox/","text":"InboxScannerService Overview Besides ingesting media packages using the REST service of the IngestService, dedicated inbox directories located in the file system can be scanned by Opencast. This, for example, allows adding media packages to Opencast by copying it to a specific location using scripting/SFTP without the need for any HTTP traffic. Opencast periodically scans the specified location for new files. Each directory may result in digest for a separate organization or with a different default workflow. Step 1: Configure an InboxScannerService Adjust etc/org.opencastproject.ingest.scanner.InboxScannerService-inbox.cfg . The -inbox suffix of the file name is variable and multiple files can be created with different settings for different directories to be watched. Step 2: Testing the inbox In order to test the inbox scanner service, either put valid media package zip or a single media file into the scanned directory. Note that even if the poll interval is small, it may take a little longer until the media package is visible in the admin interface because extracting and/or copying the media files will take some time. Example media package Media packages contain media files and metadata files describing them. Opencast is able to generate media packages using the ZipWorkflowOperation . Create the following files: manifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <mediapackage xmlns:oc=\"http://mediapackage.opencastporject.org\"> <title>A media package courtesy by the inbox scanner.</title> <media> <track id=\"track-1\" type=\"presenter/source\"> <url>presenter.mkv</url> </track> <track id=\"track-2\" type=\"presentation/source\"> <url>presentation.mkv</url> </track> </media> <metadata> <catalog id=\"catalog-1\" type=\"dublincore/episode\"> <mimetype>text/xml</mimetype> <url>episode.xml</url> </catalog> </metadata> </mediapackage> Note: You can create a valid empty media package using the /ingest/createMediaPackage REST endpoint. episode.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:oc=\"http://www.opencastproject.org/matterhorn\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance/\" xsi:schemaLocation=\"http://www.opencastproject.org http://www.opencastproject.org/schema.xsd\"> <dcterms:title>A media package courtesy by the inbox scanner.</dcterms:title> </dublincore> presentation.mkv binary video file of your choice presenter.mkv binary video file of your choice Then run: zip -j --compression-method store oc-package.zip /path/to/files/* And move the zip media package file to your inbox directory: mv oc-package.zip /path/to/inbox/ You will now see Opencast working on your file: admin_1 | 2016-11-22 15:04:54,631 | INFO | (Ingestor:114) - Install [53e6bda0 thread=db] package.zip admin_1 | 2016-11-22 15:04:54,634 | INFO | (IngestServiceImpl:433) - Ingesting zipped mediapackage admin_1 | 2016-11-22 15:04:55,296 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,059 | INFO | (IngestServiceImpl:482) - Zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv stored at https://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,272 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/episode.xml in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,287 | INFO | (IngestServiceImpl:482) - Zip entry 17701/episode.xml stored at https://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,314 | INFO | (IngestServiceImpl:516) - Ingesting mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is named 'A media package courtesy by the inbox scanner.' admin_1 | 2016-11-22 15:06:30,315 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/track-1 is located at http://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,338 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/catalog-1 is located at http://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,339 | INFO | (IngestServiceImpl:544) - Initiating processing of ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1068) - Starting a new workflow with ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 based on workflow definition 'schedule-and-upload' admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1359) - Ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is processed using workflow template 'schedule-and-upload', specified during ingest admin_1 | 2016-11-22 15:06:30,354 | INFO | (IngestServiceImpl:1120) - Starting new workflow with ingested mediapackage '77bf879f-817e-403c-b35e-fd97dee31261' using the specified template 'schedule-and-upload' admin_1 | 2016-11-22 15:06:32,229 | INFO | (IngestServiceImpl:546) - Ingest of mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 done admin_1 | 2016-11-22 15:06:32,303 | INFO | (Ingestor$1$1:130) - Ingested package.zip as a mediapackage from inbox admin_1 | 2016-11-22 15:06:33,627 | INFO | (WorkflowServiceImpl:843) - [>a508b423] Scheduling workflow 17702 for execution admin_1 | 2016-11-22 15:06:38,720 | INFO | (DefaultsWorkflowOperationHandler:120) - Configuration key 'flagForCutting' of ... ... and the workflow continues Logs produced by Opencast 2.2.2 Docker","title":"Inbox"},{"location":"configuration/inbox/#inboxscannerservice","text":"","title":"InboxScannerService"},{"location":"configuration/inbox/#overview","text":"Besides ingesting media packages using the REST service of the IngestService, dedicated inbox directories located in the file system can be scanned by Opencast. This, for example, allows adding media packages to Opencast by copying it to a specific location using scripting/SFTP without the need for any HTTP traffic. Opencast periodically scans the specified location for new files. Each directory may result in digest for a separate organization or with a different default workflow.","title":"Overview"},{"location":"configuration/inbox/#step-1-configure-an-inboxscannerservice","text":"Adjust etc/org.opencastproject.ingest.scanner.InboxScannerService-inbox.cfg . The -inbox suffix of the file name is variable and multiple files can be created with different settings for different directories to be watched.","title":"Step 1: Configure an InboxScannerService"},{"location":"configuration/inbox/#step-2-testing-the-inbox","text":"In order to test the inbox scanner service, either put valid media package zip or a single media file into the scanned directory. Note that even if the poll interval is small, it may take a little longer until the media package is visible in the admin interface because extracting and/or copying the media files will take some time.","title":"Step 2: Testing the inbox"},{"location":"configuration/inbox/#example-media-package","text":"Media packages contain media files and metadata files describing them. Opencast is able to generate media packages using the ZipWorkflowOperation . Create the following files: manifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <mediapackage xmlns:oc=\"http://mediapackage.opencastporject.org\"> <title>A media package courtesy by the inbox scanner.</title> <media> <track id=\"track-1\" type=\"presenter/source\"> <url>presenter.mkv</url> </track> <track id=\"track-2\" type=\"presentation/source\"> <url>presentation.mkv</url> </track> </media> <metadata> <catalog id=\"catalog-1\" type=\"dublincore/episode\"> <mimetype>text/xml</mimetype> <url>episode.xml</url> </catalog> </metadata> </mediapackage> Note: You can create a valid empty media package using the /ingest/createMediaPackage REST endpoint. episode.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:oc=\"http://www.opencastproject.org/matterhorn\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance/\" xsi:schemaLocation=\"http://www.opencastproject.org http://www.opencastproject.org/schema.xsd\"> <dcterms:title>A media package courtesy by the inbox scanner.</dcterms:title> </dublincore> presentation.mkv binary video file of your choice presenter.mkv binary video file of your choice Then run: zip -j --compression-method store oc-package.zip /path/to/files/* And move the zip media package file to your inbox directory: mv oc-package.zip /path/to/inbox/ You will now see Opencast working on your file: admin_1 | 2016-11-22 15:04:54,631 | INFO | (Ingestor:114) - Install [53e6bda0 thread=db] package.zip admin_1 | 2016-11-22 15:04:54,634 | INFO | (IngestServiceImpl:433) - Ingesting zipped mediapackage admin_1 | 2016-11-22 15:04:55,296 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,059 | INFO | (IngestServiceImpl:482) - Zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv stored at https://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,272 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/episode.xml in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,287 | INFO | (IngestServiceImpl:482) - Zip entry 17701/episode.xml stored at https://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,314 | INFO | (IngestServiceImpl:516) - Ingesting mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is named 'A media package courtesy by the inbox scanner.' admin_1 | 2016-11-22 15:06:30,315 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/track-1 is located at http://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,338 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/catalog-1 is located at http://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,339 | INFO | (IngestServiceImpl:544) - Initiating processing of ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1068) - Starting a new workflow with ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 based on workflow definition 'schedule-and-upload' admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1359) - Ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is processed using workflow template 'schedule-and-upload', specified during ingest admin_1 | 2016-11-22 15:06:30,354 | INFO | (IngestServiceImpl:1120) - Starting new workflow with ingested mediapackage '77bf879f-817e-403c-b35e-fd97dee31261' using the specified template 'schedule-and-upload' admin_1 | 2016-11-22 15:06:32,229 | INFO | (IngestServiceImpl:546) - Ingest of mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 done admin_1 | 2016-11-22 15:06:32,303 | INFO | (Ingestor$1$1:130) - Ingested package.zip as a mediapackage from inbox admin_1 | 2016-11-22 15:06:33,627 | INFO | (WorkflowServiceImpl:843) - [>a508b423] Scheduling workflow 17702 for execution admin_1 | 2016-11-22 15:06:38,720 | INFO | (DefaultsWorkflowOperationHandler:120) - Configuration key 'flagForCutting' of ... ... and the workflow continues Logs produced by Opencast 2.2.2 Docker","title":"Example media package"},{"location":"configuration/listproviders/","text":"List Providers Opencast supports fully configurable key-value lists. To add a new list, simply create a file with the extension .properties in etc/listproviders . The list will be loaded or updated automatically. The Java properties file format is used with the following special keys to configure the list: Key Type Description Mandatory Default list.name String The list's unique identifier within a tenant yes n/a list.default String The name of the default key no n/a list.translatable Boolean Whether the values are supposed to be translatable no false list.org String The organization ID no \"*\" Note that it is up to the client to handle the keys list.default and list.translatable . Multi-Tenancy The key list.org can be used to configure lists for specific tenants in multi-tenant setups. It defaults to * which means that the list is available for all tenants. The following logic is used to locate a list with a given list name LISTNAME : Return the list LISTNAME specific to the current tenant If not found, return the list LISTNAME available for all tenants If not found, return no list While the filename of the list does not affect the list itself, we recommend to include the organization identifier in the filename. Example /etc/listproviders/mylist-org-a.properties list.name=MYLIST key=value /etc/listproviders/mylist-org-b.properties list.name=MYLIST list.org=org-b key-org-b=value-org-b On org-b , the key-value pair for the list MYLIST is [\"key-org-b\", \"value-org-b\"] due to the tenant specific configuration. On org-a , the key-value pair for the list MYLIST is [\"key\", \"value\"] . Since there is no tenant specific configuration for org-a , the defaults are used.","title":"List Providers"},{"location":"configuration/listproviders/#list-providers","text":"Opencast supports fully configurable key-value lists. To add a new list, simply create a file with the extension .properties in etc/listproviders . The list will be loaded or updated automatically. The Java properties file format is used with the following special keys to configure the list: Key Type Description Mandatory Default list.name String The list's unique identifier within a tenant yes n/a list.default String The name of the default key no n/a list.translatable Boolean Whether the values are supposed to be translatable no false list.org String The organization ID no \"*\" Note that it is up to the client to handle the keys list.default and list.translatable .","title":"List Providers"},{"location":"configuration/listproviders/#multi-tenancy","text":"The key list.org can be used to configure lists for specific tenants in multi-tenant setups. It defaults to * which means that the list is available for all tenants. The following logic is used to locate a list with a given list name LISTNAME : Return the list LISTNAME specific to the current tenant If not found, return the list LISTNAME available for all tenants If not found, return no list While the filename of the list does not affect the list itself, we recommend to include the organization identifier in the filename.","title":"Multi-Tenancy"},{"location":"configuration/listproviders/#example","text":"/etc/listproviders/mylist-org-a.properties list.name=MYLIST key=value /etc/listproviders/mylist-org-b.properties list.name=MYLIST list.org=org-b key-org-b=value-org-b On org-b , the key-value pair for the list MYLIST is [\"key-org-b\", \"value-org-b\"] due to the tenant specific configuration. On org-a , the key-value pair for the list MYLIST is [\"key\", \"value\"] . Since there is no tenant specific configuration for org-a , the defaults are used.","title":"Example"},{"location":"configuration/load/","text":"Load Configuration This guide will help you to set up the load configuration settings which are strongly recommended for each Opencast installation. These settings control how many jobs are running on your various hardware nodes. These settings can be left at their defaults initially, but as your installation grows you will likely wish to fine-tune these to get the best performance you can out of your hardware. Background: What is a load value Every job obviously imposes a certain amount of load on its processing system, the question is how can we quantify this? The settings this document will walk you through are estimates of the load placed on your system(s) by each job type. This means that every individual instance of that job type will count for a certain amount of load, and Opencast will refuse to process more than a certain configurable amount of load at any given time on a given node. These loads are tracked on a per-node basis, so a job running on one node imposes no load on another. As an example, say we have a worker with 8 cores. With Opencast 1.x all jobs, even expensive jobs like encoding, had an effective load value of 1.0. This meant that Opencast would schedule up to 8 encodes on worker 1! Obviously this is not ideal, since most encoding jobs consume multiple cores. Since Opencast 2.1 you can now specify on an encoding profile level how much load is imposed on a node. Likewise, all other jobs (video segmentation, publishing, etc) also now have configurable loads. Job loads can be any floating point value between 0.0, and Java's MAXFLOAT. Fractional loads are supported, since many of the jobs that Opencast spawns as a regular part of its workflows are very small. There is no sanity checking for the configured loads, aside from assuring they are not negative. This means that improperly set load values can cause deadlocks! Fortunately, this is easy to fix. See Troubleshooting for more details. Step 1: Determine your load values This is a very subjective process, but is arguably the most important: How much load does each job and encoding profile add to your system? We have tried our best to set useful loads for each job, however these are only estimates. If your installation has, for example, hardware assisted encoding then your encoding jobs may be very inexpensive. In general, it is safe to assume that the first load value from the output of uptime is a good estimate of the load imposed by a job. Note: These job loads are specific for each node in the cluster. This means that for any given job, each node can have a different load value associated. For instance, if worker A has no job load specified for its encoding profiles, and worker B has job loads specified then any encoding jobs created by A will have the default load (1.5), and jobs created by B will have a different, presumably higher load. There are edge cases where this may be useful, but in most cases this will only cause confusion. It is therefore highly recommended that these settings be put into your configuration management system, and be applied on a cluster level to ensure consistency across all nodes. Step 2: Setting the load values for system jobs Each Opencast instance has its own maximum load. By default this is set to the number of CPU cores present in the system. If you wish to change this, set the org.opencastproject.server.maxload key in config.properties to the maximum load you want this node to accept. Keep in mind that exceeding the number of CPU cores present in the system is not recommended. The load values for the non-encoding jobs are set in the configuration files in the etc directory. Search this directory for files that contain the string job.load to find the relevant configuration keys. These configuration keys control the load for each job type. For example, the job.load.download.distribute configuration key controls the load placed on the system when a download distribution job is running. Note: Ingest jobs are a special case in Opencast. Because of their immediate nature there is no way to limit the number of running jobs. However, these jobs will block other jobs from running on the ingest/admin nodes if enough ingests running concurrently. Step 3: Setting the load values for encoding profiles Each encoding profile can have a load value associated with it. By default, we have not set any, which means that the default value of 1.5 is used. To set the load associated with a profile, you simply add a .jobload key to the profile. For example, the composite encoding profile is prefixed with profile.composite.http . If we want to set a different job load than the default, we would create the profile.composite.http.jobload key, and set it to an appropriate job value. Step 4: Restart Opencast Many of these configuration files are only read on startup, so restarting Opencast is strongly recommended. Troubleshooting Help, my system has deadlocked, or there are jobs which are always queued even if the system is otherwise idle This can be caused by setting a job weight that exceeds the maximum load for all services of a given type. For example, if you have a single worker with 8 cores and set an encoding job to have a jobload of 9. Fortunately, there is a simple resolution to this issue. Jobs which have already been created do not update their load values, even after restarting Opencast. To resolve a deadlock caused by job loads follow these instructions. First determine the queued job's ID from the admin UI. This will be an integer greater than zero. We will call this $jobid. Once you have the job ID, follow these steps: Stop Opencast Log into your database Make sure you are using the right schema. Currently the default is called opencast Update the job's load This will look something like UPDATE oc_job SET job\\_load=0.0 WHERE id=$jobid Log out of your database Change the load specified in the configuration file to an appropriate value This may need to happen across all nodes! Restart Opencast","title":"Load"},{"location":"configuration/load/#load-configuration","text":"This guide will help you to set up the load configuration settings which are strongly recommended for each Opencast installation. These settings control how many jobs are running on your various hardware nodes. These settings can be left at their defaults initially, but as your installation grows you will likely wish to fine-tune these to get the best performance you can out of your hardware.","title":"Load Configuration"},{"location":"configuration/load/#background-what-is-a-load-value","text":"Every job obviously imposes a certain amount of load on its processing system, the question is how can we quantify this? The settings this document will walk you through are estimates of the load placed on your system(s) by each job type. This means that every individual instance of that job type will count for a certain amount of load, and Opencast will refuse to process more than a certain configurable amount of load at any given time on a given node. These loads are tracked on a per-node basis, so a job running on one node imposes no load on another. As an example, say we have a worker with 8 cores. With Opencast 1.x all jobs, even expensive jobs like encoding, had an effective load value of 1.0. This meant that Opencast would schedule up to 8 encodes on worker 1! Obviously this is not ideal, since most encoding jobs consume multiple cores. Since Opencast 2.1 you can now specify on an encoding profile level how much load is imposed on a node. Likewise, all other jobs (video segmentation, publishing, etc) also now have configurable loads. Job loads can be any floating point value between 0.0, and Java's MAXFLOAT. Fractional loads are supported, since many of the jobs that Opencast spawns as a regular part of its workflows are very small. There is no sanity checking for the configured loads, aside from assuring they are not negative. This means that improperly set load values can cause deadlocks! Fortunately, this is easy to fix. See Troubleshooting for more details.","title":"Background: What is a load value"},{"location":"configuration/load/#step-1-determine-your-load-values","text":"This is a very subjective process, but is arguably the most important: How much load does each job and encoding profile add to your system? We have tried our best to set useful loads for each job, however these are only estimates. If your installation has, for example, hardware assisted encoding then your encoding jobs may be very inexpensive. In general, it is safe to assume that the first load value from the output of uptime is a good estimate of the load imposed by a job. Note: These job loads are specific for each node in the cluster. This means that for any given job, each node can have a different load value associated. For instance, if worker A has no job load specified for its encoding profiles, and worker B has job loads specified then any encoding jobs created by A will have the default load (1.5), and jobs created by B will have a different, presumably higher load. There are edge cases where this may be useful, but in most cases this will only cause confusion. It is therefore highly recommended that these settings be put into your configuration management system, and be applied on a cluster level to ensure consistency across all nodes.","title":"Step 1: Determine your load values"},{"location":"configuration/load/#step-2-setting-the-load-values-for-system-jobs","text":"Each Opencast instance has its own maximum load. By default this is set to the number of CPU cores present in the system. If you wish to change this, set the org.opencastproject.server.maxload key in config.properties to the maximum load you want this node to accept. Keep in mind that exceeding the number of CPU cores present in the system is not recommended. The load values for the non-encoding jobs are set in the configuration files in the etc directory. Search this directory for files that contain the string job.load to find the relevant configuration keys. These configuration keys control the load for each job type. For example, the job.load.download.distribute configuration key controls the load placed on the system when a download distribution job is running. Note: Ingest jobs are a special case in Opencast. Because of their immediate nature there is no way to limit the number of running jobs. However, these jobs will block other jobs from running on the ingest/admin nodes if enough ingests running concurrently.","title":"Step 2: Setting the load values for system jobs"},{"location":"configuration/load/#step-3-setting-the-load-values-for-encoding-profiles","text":"Each encoding profile can have a load value associated with it. By default, we have not set any, which means that the default value of 1.5 is used. To set the load associated with a profile, you simply add a .jobload key to the profile. For example, the composite encoding profile is prefixed with profile.composite.http . If we want to set a different job load than the default, we would create the profile.composite.http.jobload key, and set it to an appropriate job value.","title":"Step 3: Setting the load values for encoding profiles"},{"location":"configuration/load/#step-4-restart-opencast","text":"Many of these configuration files are only read on startup, so restarting Opencast is strongly recommended.","title":"Step 4: Restart Opencast"},{"location":"configuration/load/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"configuration/load/#help-my-system-has-deadlocked-or-there-are-jobs-which-are-always-queued-even-if-the-system-is-otherwise-idle","text":"This can be caused by setting a job weight that exceeds the maximum load for all services of a given type. For example, if you have a single worker with 8 cores and set an encoding job to have a jobload of 9. Fortunately, there is a simple resolution to this issue. Jobs which have already been created do not update their load values, even after restarting Opencast. To resolve a deadlock caused by job loads follow these instructions. First determine the queued job's ID from the admin UI. This will be an integer greater than zero. We will call this $jobid. Once you have the job ID, follow these steps: Stop Opencast Log into your database Make sure you are using the right schema. Currently the default is called opencast Update the job's load This will look something like UPDATE oc_job SET job\\_load=0.0 WHERE id=$jobid Log out of your database Change the load specified in the configuration file to an appropriate value This may need to happen across all nodes! Restart Opencast","title":"Help, my system has deadlocked, or there are jobs which are always queued even if the system is otherwise idle"},{"location":"configuration/log/","text":"Log The settings for logging can be found in: .../etc/org.ops4j.pax.logging.cfg Each Log4J appender can be configured in a similar fashion to the graylog example down below. The following requirements have to be met: * It needs to be a Log4J appender * The used bundle needs to be a fragment-bundle Graylog To have all log data available and accessible in one central location one can use graylog. A guide to install graylog can be found here . Add gelfj-X.X.X.jar (works up to version 1.1.14) to the appropriate folder in the karaf system folder (e.g. /system/org/graylog2/gelfj/X.X.X/gelfj-X.X.X.jar ) The directory has the same structure as a maven repository! It is important that the appender jar is a valid fragment-bundle of org.ops4j.pax.logging.pax-logging-service . That means the jar MANIFEST.MF must contain this section Fragment-Host: org.ops4j.pax.logging.pax-logging-service . Add the following line at the beginning of the startup.properties file: mvn\\:org.graylog2/gelfj/X.X.X = 7 We use startlevel 7 here, because it's need to be loaded before the pax-logging . Add this custom logging configuration example to the org.ops4j.pax.logging.cfg file # Async wrapper for send queue in case of GELF destination is unavailable log4j.appender.gelfasync=org.apache.log4j.AsyncAppender log4j.appender.gelfasync.blocking=false log4j.appender.gelfasync.bufferSize=20000 log4j.appender.gelfasync.appenders=gelf # Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=<HOSTNAME OF GRAYLOG INPUT> log4j.appender.gelf.graylogPort=<PORT OF GRAYLOG INPUT> log4j.appender.gelf.originHost=<NAME OF SERVICE> log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'EXAMPLE-ENV', 'application': 'EXAMPLE-APP'} Note: The default protocol is UDP to use TCP instead, prefix hostname with tcp: . Add the new appender to the rootLogger log4j.rootLogger=WARN, stdout, osgi:*, gelfasync Example Configuration # Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=tcp:graylog.opencast.org log4j.appender.gelf.graylogPort=12290 log4j.appender.gelf.originHost=test.opencast.org log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'OPENCAST-TEST-ENV', 'application': 'OC-ADMIN'} You can find further GELF appender documentation here .","title":"Log"},{"location":"configuration/log/#log","text":"The settings for logging can be found in: .../etc/org.ops4j.pax.logging.cfg Each Log4J appender can be configured in a similar fashion to the graylog example down below. The following requirements have to be met: * It needs to be a Log4J appender * The used bundle needs to be a fragment-bundle","title":"Log"},{"location":"configuration/log/#graylog","text":"To have all log data available and accessible in one central location one can use graylog. A guide to install graylog can be found here . Add gelfj-X.X.X.jar (works up to version 1.1.14) to the appropriate folder in the karaf system folder (e.g. /system/org/graylog2/gelfj/X.X.X/gelfj-X.X.X.jar ) The directory has the same structure as a maven repository! It is important that the appender jar is a valid fragment-bundle of org.ops4j.pax.logging.pax-logging-service . That means the jar MANIFEST.MF must contain this section Fragment-Host: org.ops4j.pax.logging.pax-logging-service . Add the following line at the beginning of the startup.properties file: mvn\\:org.graylog2/gelfj/X.X.X = 7 We use startlevel 7 here, because it's need to be loaded before the pax-logging . Add this custom logging configuration example to the org.ops4j.pax.logging.cfg file # Async wrapper for send queue in case of GELF destination is unavailable log4j.appender.gelfasync=org.apache.log4j.AsyncAppender log4j.appender.gelfasync.blocking=false log4j.appender.gelfasync.bufferSize=20000 log4j.appender.gelfasync.appenders=gelf # Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=<HOSTNAME OF GRAYLOG INPUT> log4j.appender.gelf.graylogPort=<PORT OF GRAYLOG INPUT> log4j.appender.gelf.originHost=<NAME OF SERVICE> log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'EXAMPLE-ENV', 'application': 'EXAMPLE-APP'} Note: The default protocol is UDP to use TCP instead, prefix hostname with tcp: . Add the new appender to the rootLogger log4j.rootLogger=WARN, stdout, osgi:*, gelfasync","title":"Graylog"},{"location":"configuration/log/#example-configuration","text":"# Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=tcp:graylog.opencast.org log4j.appender.gelf.graylogPort=12290 log4j.appender.gelf.originHost=test.opencast.org log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'OPENCAST-TEST-ENV', 'application': 'OC-ADMIN'} You can find further GELF appender documentation here .","title":"Example Configuration"},{"location":"configuration/message-broker/","text":"Message Broker Configuration Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node). Required Version ActiveMQ 5.10 or above Installation There are multiple options for installing ActiveMQ: If you used the Opencast package repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository Newer Debian based operating systems contain a sufficiently new version, however the ActiveMQ configuration file will require modification to function correctly. You can download binary distributions from the Apache ActiveMQ website Configuration What you need to do: Set up the required message queues for Opencast Point all your Opencast nodes to your message broker. Configure authentication and access control The first task is easy. Opencast comes with an ActiveMQ configuration file, located at docs/scripts/activemq/activemq.xml (RPM repo: /usr/share/opencast/docs/scripts/activemq/activemq.xml ). This file will give you a basic configuration with all queues set-up and accepting connections from the local host over TCP port 61616 . Replacing the default ActiveMQ configuration with this file will already give you a fully functional ActiveMQ set-up for an all-in-one server. You will find the configuration in the usual locations, e.g. /etc/activemq/ . On Debian you first need to activate or create a new ActiveMQ instance. For more details on that see /usr/share/doc/activemq/README.Debian . Note that the default configuration needs to be adjusted for distributed set-ups since: ActiveMQ listens to localhost only ( activemq.xml ) Opencast tries to connect to ActiveMQ locally ( custom.properties ) No password is set ( activemq.xml , custom.properties ) 1. Connection The ActiveMQ connection is configured in Opencast's custom.properties file. The default configuration points to a local installation of ActiveMQ. You can easily configure this to point somewhere else: activemq.broker.url = failover://tcp://example.opencast.org:61616 2. Bind Host The default configuration tells ActiveMQ to listen to 127.0.0.1 only. On a distributed system, you want to set this to 0.0.0.0 to listen to all hosts by changing the transportConnector : <transportConnector name=\"openwire\" uri=\"tcp://127.0.0.1:61616?...\"/> 3. Username and Password ActiveMQ can secure its message queues by requiring login credentials. This section will go through the steps of setting up a username and a password. Have a look at the ActiveMQ security site for details about using alternative authentication and authorization providers. Step 1: Create ActiveMQ Admin User First, you need to create a new user that will have access to the queues. This is configured in the users.properties configuration file in the configuration directory for ActiveMQ. It is a list of the format username = password so, for example, we could create a new admin user with the following file contents: admin=password Step 2: Create ActiveMQ Admin Group The next step is to provide a group that will have our user in it and will secure access to the message queues. This is configured in the file groups.properties in the configuration directory for ActiveMQ. It is a list of the format group = user1,user2,\u2026 . For example: groups=user1,user2,user3 To set-up our new user to be a part of the admins group: admins=admin Step 3: Configure Users and Groups Configuration Files Next, we need to make sure that ActiveMQ is using our users.properties and groups.properties files to authenticate and authorize users. The login.config file should be in the ActiveMQ configuration directory and contain: activemq { org.apache.activemq.jaas.PropertiesLoginModule required org.apache.activemq.jaas.properties.user=\"users.properties\" org.apache.activemq.jaas.properties.group=\"groups.properties\"; }; Step 4: Configure Message Broker Security The final step to secure the ActiveMQ queues is to limit access to a specific group. This can be done by editing activemq.xml in the ActiveMQ configuration directory. In this file, we need to add some XML in between these tags: <broker></broker> We will add the following plugin configuration: <plugins> <jaasAuthenticationPlugin configuration=\"activemq\" /> <authorizationPlugin> <map> <authorizationMap> <authorizationEntries> <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/> </authorizationEntries> </authorizationMap> </map> </authorizationPlugin> </plugins> The jaasAuthenticationPlugin configures the broker to use our login.config file for the authentication. <jaasAuthenticationPlugin configuration=\"activemq\" /> The property: configuration=activemq needs to match the name given for surrounding object in login.config i.e. activemq{}; The authorizationEntry restricts read, write and admin access for queues and topics to members of the group admins. Step 5: Configure Opencast to Connect with Username and Password to Message Broker Now that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and password. The username and password used above need to be added to the custom.properties file of Opencast. There are two properties to set: activemq.broker.username=admin activemq.broker.password=password Firewall Do not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication. You probably want to allow communication over this port in your firewall on a distributed setup or explicitly forbid public access on an all-in-one installation. Memory settings When ActiveMQ is under heavy load it may require additional RAM. There are two places to change this: In docs/scripts/activemq/activemq.xml : ... <systemUsage> <systemUsage> <memoryUsage> <!--<memoryUsage percentOfJvmHeap=\"70\" />--> <memoryUsage limit=\"2048 MB\"/> ... This controls the allowed memory of ActiveMQ inside of its JVM instance. For more information see the ActiveMQ documentation In /usr/share/activemq/bin/env : ACTIVEMQ_OPTS_MEMORY=\"-Xms64M -Xmx4G\" These are the classic JVM minimum and maximum memory flags.","title":"Message Broker"},{"location":"configuration/message-broker/#message-broker-configuration","text":"Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node).","title":"Message Broker Configuration"},{"location":"configuration/message-broker/#required-version","text":"ActiveMQ 5.10 or above","title":"Required Version"},{"location":"configuration/message-broker/#installation","text":"There are multiple options for installing ActiveMQ: If you used the Opencast package repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository Newer Debian based operating systems contain a sufficiently new version, however the ActiveMQ configuration file will require modification to function correctly. You can download binary distributions from the Apache ActiveMQ website","title":"Installation"},{"location":"configuration/message-broker/#configuration","text":"What you need to do: Set up the required message queues for Opencast Point all your Opencast nodes to your message broker. Configure authentication and access control The first task is easy. Opencast comes with an ActiveMQ configuration file, located at docs/scripts/activemq/activemq.xml (RPM repo: /usr/share/opencast/docs/scripts/activemq/activemq.xml ). This file will give you a basic configuration with all queues set-up and accepting connections from the local host over TCP port 61616 . Replacing the default ActiveMQ configuration with this file will already give you a fully functional ActiveMQ set-up for an all-in-one server. You will find the configuration in the usual locations, e.g. /etc/activemq/ . On Debian you first need to activate or create a new ActiveMQ instance. For more details on that see /usr/share/doc/activemq/README.Debian . Note that the default configuration needs to be adjusted for distributed set-ups since: ActiveMQ listens to localhost only ( activemq.xml ) Opencast tries to connect to ActiveMQ locally ( custom.properties ) No password is set ( activemq.xml , custom.properties )","title":"Configuration"},{"location":"configuration/message-broker/#1-connection","text":"The ActiveMQ connection is configured in Opencast's custom.properties file. The default configuration points to a local installation of ActiveMQ. You can easily configure this to point somewhere else: activemq.broker.url = failover://tcp://example.opencast.org:61616","title":"1. Connection"},{"location":"configuration/message-broker/#2-bind-host","text":"The default configuration tells ActiveMQ to listen to 127.0.0.1 only. On a distributed system, you want to set this to 0.0.0.0 to listen to all hosts by changing the transportConnector : <transportConnector name=\"openwire\" uri=\"tcp://127.0.0.1:61616?...\"/>","title":"2. Bind Host"},{"location":"configuration/message-broker/#3-username-and-password","text":"ActiveMQ can secure its message queues by requiring login credentials. This section will go through the steps of setting up a username and a password. Have a look at the ActiveMQ security site for details about using alternative authentication and authorization providers.","title":"3. Username and Password"},{"location":"configuration/message-broker/#step-1-create-activemq-admin-user","text":"First, you need to create a new user that will have access to the queues. This is configured in the users.properties configuration file in the configuration directory for ActiveMQ. It is a list of the format username = password so, for example, we could create a new admin user with the following file contents: admin=password","title":"Step 1: Create ActiveMQ Admin User"},{"location":"configuration/message-broker/#step-2-create-activemq-admin-group","text":"The next step is to provide a group that will have our user in it and will secure access to the message queues. This is configured in the file groups.properties in the configuration directory for ActiveMQ. It is a list of the format group = user1,user2,\u2026 . For example: groups=user1,user2,user3 To set-up our new user to be a part of the admins group: admins=admin","title":"Step 2: Create ActiveMQ Admin Group"},{"location":"configuration/message-broker/#step-3-configure-users-and-groups-configuration-files","text":"Next, we need to make sure that ActiveMQ is using our users.properties and groups.properties files to authenticate and authorize users. The login.config file should be in the ActiveMQ configuration directory and contain: activemq { org.apache.activemq.jaas.PropertiesLoginModule required org.apache.activemq.jaas.properties.user=\"users.properties\" org.apache.activemq.jaas.properties.group=\"groups.properties\"; };","title":"Step 3: Configure Users and Groups Configuration Files"},{"location":"configuration/message-broker/#step-4-configure-message-broker-security","text":"The final step to secure the ActiveMQ queues is to limit access to a specific group. This can be done by editing activemq.xml in the ActiveMQ configuration directory. In this file, we need to add some XML in between these tags: <broker></broker> We will add the following plugin configuration: <plugins> <jaasAuthenticationPlugin configuration=\"activemq\" /> <authorizationPlugin> <map> <authorizationMap> <authorizationEntries> <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/> </authorizationEntries> </authorizationMap> </map> </authorizationPlugin> </plugins> The jaasAuthenticationPlugin configures the broker to use our login.config file for the authentication. <jaasAuthenticationPlugin configuration=\"activemq\" /> The property: configuration=activemq needs to match the name given for surrounding object in login.config i.e. activemq{}; The authorizationEntry restricts read, write and admin access for queues and topics to members of the group admins.","title":"Step 4: Configure Message Broker Security"},{"location":"configuration/message-broker/#step-5-configure-opencast-to-connect-with-username-and-password-to-message-broker","text":"Now that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and password. The username and password used above need to be added to the custom.properties file of Opencast. There are two properties to set: activemq.broker.username=admin activemq.broker.password=password","title":"Step 5: Configure Opencast to Connect with Username and Password to Message Broker"},{"location":"configuration/message-broker/#firewall","text":"Do not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication. You probably want to allow communication over this port in your firewall on a distributed setup or explicitly forbid public access on an all-in-one installation.","title":"Firewall"},{"location":"configuration/message-broker/#memory-settings","text":"When ActiveMQ is under heavy load it may require additional RAM. There are two places to change this: In docs/scripts/activemq/activemq.xml : ... <systemUsage> <systemUsage> <memoryUsage> <!--<memoryUsage percentOfJvmHeap=\"70\" />--> <memoryUsage limit=\"2048 MB\"/> ... This controls the allowed memory of ActiveMQ inside of its JVM instance. For more information see the ActiveMQ documentation In /usr/share/activemq/bin/env : ACTIVEMQ_OPTS_MEMORY=\"-Xms64M -Xmx4G\" These are the classic JVM minimum and maximum memory flags.","title":"Memory settings"},{"location":"configuration/metadata/","text":"Overview In Opencast, metadata is stored in so-called metadata catalogs. For each event or series, an arbitrary number of such configurable metadata catalogs can be managed. A common set of metadata has been standardized to form a common basis (standard metadata), whereas administrators can configure Opencast to support other metadata sets (extended metadata). This document provides an overview of Opencast's metadata capabilities and its configuration. Standard Metadata For both events and series, a common set of metadata is supported by Opencast out of the box. Since metadata catalogs are referenced from within media package, flavors can be used to identify a specific metadata catalog. The following flavors are treated by Opencast as standard metadata, meaning Opencast expects them to be present: dublincore/episode holds the standard metadata of an event dublincore/series holds the standard metadata of a series Opencast assumes specific metadata fields to be present in the standard metadata in means of defining hard-coded filters, table columns and search indices. To adjust the standard metadata to your specific needs, you can configure them in etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg and etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg . For details on how to configure metadata catalogs, see the section Metadata Catalog Configuration. As mentioned above, however, Opencast expects specific metadata fields to be present to work correctly. In case you want to map metadata specific to your use case, you might consider using the extended metadata capabilities of Opencast described in the next section. Extended Metadata For both events and series, Opencast supports an arbitrary number of customized metadata catalogs. To add extended metadata catalogs, create a configuration file with a valid filename of the form org.opencastproject.ui.metadata.CatalogUIAdapterFactory-<name>.cfg in etc/ . on the admin node. For details on how to configure metadata catalogs, see the section Metadata Catalog Configuration. Limitations: Cannot be sorted, searched or filtered Cannot be displayed in tables Metadata Catalog Configuration The metadata configuration file format can be logically split up into different parts: Part 1: General catalog information Configuration key Example Description type events Two different types of catalog UI adapters may be configured, such for events and others for series. organization mh_default_org A custom catalog definition is mapped 1:1 to an organization and is available to this one organization only. flavor mycompany/episode The catalog must be of a certain flavor. For a events catalog, the flavor consists of the form type/subtype whereas for series you only need to define the subtype. Attention: For series catalogs, the type (the part before the slash '/') is used as element type. title My Personal Catalog Name This is the title that is displayed in the UI. It should be something that is readable by humans. Part 2: XML serialization information The only supported serialization of catalogs is currently the XML file format. The file follows the recommendation of the Dublin Core Metadata Initiative. Configuration key Example Description xml.rootElement.name mycatalog The name of the XML root element xml.rootElement.namespace.URI http://myorg.com/metadata/catalog The URI of the XML namespace of the root element Namespace bindings To properly serialize to XML each prefix has to be bound to an XML namespace. Multiple namespace bindings can be configured, each identified by its unique name. Configuration key Example Description xml.namespaceBinding.{name}.URI http://myorg.com/metadata/terms The URI of the XML namespace xml.namespaceBinding.{name}.prefix myterms The prefix used to identify elements of the namespace Part 3: Catalog fields configuration {field-id} must be a unique identifier for each property for a given catalog and can be the same as the input or output id to make it easy to find. Configuration key Example Description property.{field-id}.inputID\u00b9 title The id used to identify this property in the catalog e.g. The name of the property inside the xml file of a Dublin Core catalog. If an outputID is not specified then this inputID is used for both the catalog and the front end id. This value is mandatory. property.{field-id}.outputID title The id used inside the json for this property. If this value is missing then the inputID will be used instead. property.{field-id}.namespace http://purl.org/dc/terms/ The URL that represents the namespace for this property. Different properties in the same catalog can have different namespaces. property.{field-id}.label\u00b9 \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\" or \"Event Title\" The label to show for this property in the UI. If there is a i18n support for a label that should be the value used so that it will be translated, if you don't mind it being locked to one translation just put that single value in. property.{field-id}.type\u00b9 text The type of the metadata field. property.{field-id}.pattern yyyy-MM-dd Applies to date and time types for now. It is used to format their values using the java DateTimeFormatter values\u00b2 property.{field-id}.delimiter ; For mixed_text and iterable_text type fields, a string at which inputs into the corresponding fields are split into individual values for easier bulk entry of lists. The default is no delimiter, in which case no splitting takes place. property.{field-id}.readOnly\u00b9 false If the property can be edited in the UI or if it should only be displayed. property.{field-id}.required\u00b9 true If the property has to have a value before the metadata can be saved (the UI's save button will be disabled until all of the required fields are entered) property.{field-id}.collectionID USERS The id of the list provider that will be used to validate the input in the backend. So for example entering a username that doesn't exist will throw an error in this case. property.{field-id}.listprovider USERS The id of the list provider that will be used as a drop down option for that field. So for example using the USERS list provider means that in the front end the user will be able to choose the field value from the list of users in Opencast. property.{field-id}.order 3 Defines the order of properties where this property should be oriented in the UI i.e. 0 means the property should come first, 1 means it should come second etc. Giving two properties the same number will cause them to be next to one another but doesn't guarantee one above or below the other. \u00b9 Mandatory field attribute \u00b2 See DateTimeFormatter Field types Type Description Example value in catalog Example value in UI JSON response example boolean Represents a true / false value in the UI that is represented by a check box. false false date A Java Date object that can include the year, month, day, hour, minute second ... and is formatted by the pattern value. 2014-12-10T16:29:43Z 2014-12-10 text A text input value for entering in one line of text. It supports more, it just won't increase in size for the interface. This is the Title This is the Title text_long A text area which allows for more than 1 row of text Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. { \"id\": \"notesEpisode\", \"readOnly\": false, \"value\": \"\", \"label\": \"Notes\", \"required\": false, \"type\":\"text_long\" } iterable_text A text input value for entering in a list of text objects that are comma separated in the front end but stored separately in the catalog. Adam,Basil,Lukas value : [\"Adam\",\"Basil\",\"Lukas\"] { \"id\": \"contributor\", \"readOnly\": true, \"value\": [\"Adam\", \"Basil\", \"Lukas\"], \"label\": \"Contributor(s)\", \"required\": false, \"type\": \"text\" } start_date The start date portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 2014-11-04 start_time The start time portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 19:00:00 duration The duration of the event portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 01:00:00 Workflow Configuration Since the extended metadata don't have the dublincore/* flavor, a tagging operation for the archive has to be added for the extended catalogs. In our examples below, we use ext/episode as a flavor, so the following operation should be added to the workflows <!-- Tag the extended metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging extended metadata catalogs for archival and/or publication\"> <configurations> <configuration key=\"source-flavors\">ext/*</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> If you want the extended metadata to be published the same way as the standard metadata, you can update the existing tagging operation for dublincore metadata the following way <!-- Tag the incoming metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging metadata catalogs for archival and publication\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,ext/*</configuration> <configuration key=\"target-tags\">+archive,+engage-download</configuration> </configurations> </operation> Configuring the events publisher metadata field The metadata field can be used in two ways, and its meaning varies slightly: The publisher is the creator of the event: when an event is created, this field is filled automatically with the logged in user. It cannot be modified on creation of the event nor later. The publisher is responsible for uploading the content but may not be the creator of the event in the UI: in this case, when the event is created, the publisher is selected from a list provider that includes the logged in user (selected by default) and it is also modifiable later, but then the logged in user is not selectable. The configuration is done in the file: etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg . First option is the default one and the configuration is as follows: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=true property.publisher.required=false property.publisher.order=16 To configure the second option: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=false property.publisher.required=true property.publisher.listprovider=YOUR_LIST_PROVIDER property.publisher.order=16 If you want to use the publishers as list provider, you must set up the provider in this way: property.publisher.listprovider=EVENTS.PUBLISHER In both cases, you can filter events by publisher.","title":"Metadata"},{"location":"configuration/metadata/#overview","text":"In Opencast, metadata is stored in so-called metadata catalogs. For each event or series, an arbitrary number of such configurable metadata catalogs can be managed. A common set of metadata has been standardized to form a common basis (standard metadata), whereas administrators can configure Opencast to support other metadata sets (extended metadata). This document provides an overview of Opencast's metadata capabilities and its configuration.","title":"Overview"},{"location":"configuration/metadata/#standard-metadata","text":"For both events and series, a common set of metadata is supported by Opencast out of the box. Since metadata catalogs are referenced from within media package, flavors can be used to identify a specific metadata catalog. The following flavors are treated by Opencast as standard metadata, meaning Opencast expects them to be present: dublincore/episode holds the standard metadata of an event dublincore/series holds the standard metadata of a series Opencast assumes specific metadata fields to be present in the standard metadata in means of defining hard-coded filters, table columns and search indices. To adjust the standard metadata to your specific needs, you can configure them in etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg and etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg . For details on how to configure metadata catalogs, see the section Metadata Catalog Configuration. As mentioned above, however, Opencast expects specific metadata fields to be present to work correctly. In case you want to map metadata specific to your use case, you might consider using the extended metadata capabilities of Opencast described in the next section.","title":"Standard Metadata"},{"location":"configuration/metadata/#extended-metadata","text":"For both events and series, Opencast supports an arbitrary number of customized metadata catalogs. To add extended metadata catalogs, create a configuration file with a valid filename of the form org.opencastproject.ui.metadata.CatalogUIAdapterFactory-<name>.cfg in etc/ . on the admin node. For details on how to configure metadata catalogs, see the section Metadata Catalog Configuration. Limitations: Cannot be sorted, searched or filtered Cannot be displayed in tables","title":"Extended Metadata"},{"location":"configuration/metadata/#metadata-catalog-configuration","text":"The metadata configuration file format can be logically split up into different parts:","title":"Metadata Catalog Configuration"},{"location":"configuration/metadata/#part-1-general-catalog-information","text":"Configuration key Example Description type events Two different types of catalog UI adapters may be configured, such for events and others for series. organization mh_default_org A custom catalog definition is mapped 1:1 to an organization and is available to this one organization only. flavor mycompany/episode The catalog must be of a certain flavor. For a events catalog, the flavor consists of the form type/subtype whereas for series you only need to define the subtype. Attention: For series catalogs, the type (the part before the slash '/') is used as element type. title My Personal Catalog Name This is the title that is displayed in the UI. It should be something that is readable by humans.","title":"Part 1: General catalog information"},{"location":"configuration/metadata/#part-2-xml-serialization-information","text":"The only supported serialization of catalogs is currently the XML file format. The file follows the recommendation of the Dublin Core Metadata Initiative. Configuration key Example Description xml.rootElement.name mycatalog The name of the XML root element xml.rootElement.namespace.URI http://myorg.com/metadata/catalog The URI of the XML namespace of the root element Namespace bindings To properly serialize to XML each prefix has to be bound to an XML namespace. Multiple namespace bindings can be configured, each identified by its unique name. Configuration key Example Description xml.namespaceBinding.{name}.URI http://myorg.com/metadata/terms The URI of the XML namespace xml.namespaceBinding.{name}.prefix myterms The prefix used to identify elements of the namespace","title":"Part 2: XML serialization information"},{"location":"configuration/metadata/#part-3-catalog-fields-configuration","text":"{field-id} must be a unique identifier for each property for a given catalog and can be the same as the input or output id to make it easy to find. Configuration key Example Description property.{field-id}.inputID\u00b9 title The id used to identify this property in the catalog e.g. The name of the property inside the xml file of a Dublin Core catalog. If an outputID is not specified then this inputID is used for both the catalog and the front end id. This value is mandatory. property.{field-id}.outputID title The id used inside the json for this property. If this value is missing then the inputID will be used instead. property.{field-id}.namespace http://purl.org/dc/terms/ The URL that represents the namespace for this property. Different properties in the same catalog can have different namespaces. property.{field-id}.label\u00b9 \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\" or \"Event Title\" The label to show for this property in the UI. If there is a i18n support for a label that should be the value used so that it will be translated, if you don't mind it being locked to one translation just put that single value in. property.{field-id}.type\u00b9 text The type of the metadata field. property.{field-id}.pattern yyyy-MM-dd Applies to date and time types for now. It is used to format their values using the java DateTimeFormatter values\u00b2 property.{field-id}.delimiter ; For mixed_text and iterable_text type fields, a string at which inputs into the corresponding fields are split into individual values for easier bulk entry of lists. The default is no delimiter, in which case no splitting takes place. property.{field-id}.readOnly\u00b9 false If the property can be edited in the UI or if it should only be displayed. property.{field-id}.required\u00b9 true If the property has to have a value before the metadata can be saved (the UI's save button will be disabled until all of the required fields are entered) property.{field-id}.collectionID USERS The id of the list provider that will be used to validate the input in the backend. So for example entering a username that doesn't exist will throw an error in this case. property.{field-id}.listprovider USERS The id of the list provider that will be used as a drop down option for that field. So for example using the USERS list provider means that in the front end the user will be able to choose the field value from the list of users in Opencast. property.{field-id}.order 3 Defines the order of properties where this property should be oriented in the UI i.e. 0 means the property should come first, 1 means it should come second etc. Giving two properties the same number will cause them to be next to one another but doesn't guarantee one above or below the other. \u00b9 Mandatory field attribute \u00b2 See DateTimeFormatter Field types Type Description Example value in catalog Example value in UI JSON response example boolean Represents a true / false value in the UI that is represented by a check box. false false date A Java Date object that can include the year, month, day, hour, minute second ... and is formatted by the pattern value. 2014-12-10T16:29:43Z 2014-12-10 text A text input value for entering in one line of text. It supports more, it just won't increase in size for the interface. This is the Title This is the Title text_long A text area which allows for more than 1 row of text Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. { \"id\": \"notesEpisode\", \"readOnly\": false, \"value\": \"\", \"label\": \"Notes\", \"required\": false, \"type\":\"text_long\" } iterable_text A text input value for entering in a list of text objects that are comma separated in the front end but stored separately in the catalog. Adam,Basil,Lukas value : [\"Adam\",\"Basil\",\"Lukas\"] { \"id\": \"contributor\", \"readOnly\": true, \"value\": [\"Adam\", \"Basil\", \"Lukas\"], \"label\": \"Contributor(s)\", \"required\": false, \"type\": \"text\" } start_date The start date portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 2014-11-04 start_time The start time portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 19:00:00 duration The duration of the event portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 01:00:00 Workflow Configuration Since the extended metadata don't have the dublincore/* flavor, a tagging operation for the archive has to be added for the extended catalogs. In our examples below, we use ext/episode as a flavor, so the following operation should be added to the workflows <!-- Tag the extended metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging extended metadata catalogs for archival and/or publication\"> <configurations> <configuration key=\"source-flavors\">ext/*</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> If you want the extended metadata to be published the same way as the standard metadata, you can update the existing tagging operation for dublincore metadata the following way <!-- Tag the incoming metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging metadata catalogs for archival and publication\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,ext/*</configuration> <configuration key=\"target-tags\">+archive,+engage-download</configuration> </configurations> </operation>","title":"Part 3: Catalog fields configuration"},{"location":"configuration/metadata/#configuring-the-events-publisher-metadata-field","text":"The metadata field can be used in two ways, and its meaning varies slightly: The publisher is the creator of the event: when an event is created, this field is filled automatically with the logged in user. It cannot be modified on creation of the event nor later. The publisher is responsible for uploading the content but may not be the creator of the event in the UI: in this case, when the event is created, the publisher is selected from a list provider that includes the logged in user (selected by default) and it is also modifiable later, but then the logged in user is not selectable. The configuration is done in the file: etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg . First option is the default one and the configuration is as follows: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=true property.publisher.required=false property.publisher.order=16 To configure the second option: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=false property.publisher.required=true property.publisher.listprovider=YOUR_LIST_PROVIDER property.publisher.order=16 If you want to use the publishers as list provider, you must set up the provider in this way: property.publisher.listprovider=EVENTS.PUBLISHER In both cases, you can filter events by publisher.","title":"Configuring the events publisher metadata field"},{"location":"configuration/monitoring/","text":"Monitoring To assist in the operation of Opencast an application health-check is available. This will quickly return the state of the specific node, whether it is running properly, has minor issues or is unavailable for some reason e.g. in maintenance mode. Regular calls to the health-check from whatever monitoring software you choose to use will give you confidence that the Opencast nodes are running correctly and alert you when they are not. For larger deployments the health-check can be used by load-balancers* and trigger fail-overs if one of the nodes goes down. * The only nodes that make sense to load-balance are the externally facing ones, ingest and presentation . Calling the Health-Check The Runtime module provides the health-check endpoint at /info/health and a simple HTTP GET request will return a HTTP status code indicating the health of the node and response in JSON providing further details. curl \"http://oc-admin.example.com/info/health\" The HTTP status code will just indicate whether the node is running or not, the response contains a status field that indicates the actual health of the node. The status can have the values pass , warn and fail . The response implements the health-check format proposed here https://inadarei.github.io/rfc-healthcheck . The table below shows the HTTP status codes the health-check status and the conditions for which they can occur. status notes HTTP code meaning pass n/a 200 All is OK warn service(s) in WARN state 200 Partially working service here warn services(s) in ERROR state 200 Look for service on another node fail maintenance 503 Node not available, try again later fail disabled 503 Node not available, try another node fail offline 503 Node not running, try another node In all cases where the health-check status is not pass the JSON response provides more details. A summary of the problem(s) are list in the notes field. In the case of services in non NORMAL states these are listing the checks field. An example response for a warn status is shown below { \"description\" : \"Opencast node's health status\", \"releaseId\" : \"8\", \"serviceId\" : \"http://oc-admin.example.com\", \"version\" : \"1\", \"status\" : \"warn\", \"notes\" : [ \"service(s) in WARN state\", \"service(s) in ERROR state\" ], \"checks\" : { \"service:states\" : [ { \"changed\" : \"Tue Jun 04 11:10:12 BST 2019\", \"links\" : { \"path\" : \"service1\" }, \"observedValue\" : \"WARNING\", \"componentId\" : \"service1\" }, { \"changed\" : \"Tue Jun 04 11:15:27 BST 2019\", \"links\" : { \"path\" : \"service2\" }, \"observedValue\" : \"ERROR\", \"componentId\" : \"service2\" } ] } }","title":"External Monitoring"},{"location":"configuration/monitoring/#monitoring","text":"To assist in the operation of Opencast an application health-check is available. This will quickly return the state of the specific node, whether it is running properly, has minor issues or is unavailable for some reason e.g. in maintenance mode. Regular calls to the health-check from whatever monitoring software you choose to use will give you confidence that the Opencast nodes are running correctly and alert you when they are not. For larger deployments the health-check can be used by load-balancers* and trigger fail-overs if one of the nodes goes down. * The only nodes that make sense to load-balance are the externally facing ones, ingest and presentation .","title":"Monitoring"},{"location":"configuration/monitoring/#calling-the-health-check","text":"The Runtime module provides the health-check endpoint at /info/health and a simple HTTP GET request will return a HTTP status code indicating the health of the node and response in JSON providing further details. curl \"http://oc-admin.example.com/info/health\" The HTTP status code will just indicate whether the node is running or not, the response contains a status field that indicates the actual health of the node. The status can have the values pass , warn and fail . The response implements the health-check format proposed here https://inadarei.github.io/rfc-healthcheck . The table below shows the HTTP status codes the health-check status and the conditions for which they can occur. status notes HTTP code meaning pass n/a 200 All is OK warn service(s) in WARN state 200 Partially working service here warn services(s) in ERROR state 200 Look for service on another node fail maintenance 503 Node not available, try again later fail disabled 503 Node not available, try another node fail offline 503 Node not running, try another node In all cases where the health-check status is not pass the JSON response provides more details. A summary of the problem(s) are list in the notes field. In the case of services in non NORMAL states these are listing the checks field. An example response for a warn status is shown below { \"description\" : \"Opencast node's health status\", \"releaseId\" : \"8\", \"serviceId\" : \"http://oc-admin.example.com\", \"version\" : \"1\", \"status\" : \"warn\", \"notes\" : [ \"service(s) in WARN state\", \"service(s) in ERROR state\" ], \"checks\" : { \"service:states\" : [ { \"changed\" : \"Tue Jun 04 11:10:12 BST 2019\", \"links\" : { \"path\" : \"service1\" }, \"observedValue\" : \"WARNING\", \"componentId\" : \"service1\" }, { \"changed\" : \"Tue Jun 04 11:15:27 BST 2019\", \"links\" : { \"path\" : \"service2\" }, \"observedValue\" : \"ERROR\", \"componentId\" : \"service2\" } ] } }","title":"Calling the Health-Check"},{"location":"configuration/multi.tenancy/","text":"Multi Tenancy Configuration Introduction A single Opencast instance can handle multiple tenants, each of which have their own recordings in the system. Opencast refers to tenants as organizations , and an HTTP request to the Opencast installation is mapped to an organization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names pointing to the same IP, for example: admin.example.org tenant1-admin.example.org tenant2-admin.example.org should all resolve to the same IP. A tenant configuration thus consists mainly of the DNS name that is mapped to that tenant. Default Setup Out of the box, Opencast has one tenant configured, called mh_default_org that is mapped to the server name localhost:8080 . As long as there is one tenant configuration only, Opencast will map every request to that tenant regardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to organizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast installation that cannot be mapped to any organization. Limitations Multi tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst organizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles. Adding A Tenant To add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security rules. For this example we have a three node install of admin.example.org , worker.example.org , and presentation.example.org . Assume that the new tenant is called tenant1 and should be mapped to tenant1-*.example.org . Step 1: Tenant Configuration Create a file called org.opencastproject.organization-tenant1.cfg in the etc/ directory of your Opencast installation, on each of the nodes. As an example, this is what the admin node looks like: id=tenant1 name=Tenant 1 port=8080 prop.org.opencastproject.host.admin.example.org=tenant1-admin.example.org prop.org.opencastproject.host.presentation.example.org=tenant1-presentation.example.org admin_role=ROLE_ADMIN anonymous_role=ROLE_ANONYMOUS # Admin and Presentation Server Urls prop.org.opencastproject.admin.ui.url=https://tenant1-admin.example.org prop.org.opencastproject.engage.ui.url=https://tenant1-presentation.example.org # Default properties for the user interface prop.logo_mediamodule=/engage/ui/img/logo/opencast-icon.svg prop.logo_player=/engage/ui/img/logo/opencast.svg There are more options available than in this example. The easiest way of creating that file is probably to create a copy of the already existing org.opencastproject.organization-mh_default_org.cfg . Note, the default organization file org.opencastproject.organization-mh_default_org.org must refer to the actual server names: prop.org.opencastproject.host.admin.example.org=admin.example.org prop.org.opencastproject.host.presentation.example.org=presentation.example.org This file sets the default organization that is selected. This is currently required because some Opencast components do not support multitenancy. Note that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be -1 in both files. Step 2: Security Configuration Create a file called tenant1.xml in /etc/security. This file specifies access rules for individual URLs that specify which roles are needed in order to access a given URL. In addition, it allows to define the directory services that are used to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add anything that can go into a Spring Security configuration. The easiest way of creating that file is probably to create a copy of the already existing mh_default_org.xml . Step 3: Other Configuration Two additional files should be copied: org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common-tenant1.cfg , and org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common-tenant1.cfg . In each of the new configuration files, change organization key to match the tenant id, and change the common-metadata key to false. Create a copy of the files for each tenant. Note: The original ...-common.cfg files must have their common-metadata keys set to true, otherwise metadata will only be available in one tenant and you will experience a number of odd errors.","title":"Multi Tenancy"},{"location":"configuration/multi.tenancy/#multi-tenancy-configuration","text":"","title":"Multi Tenancy Configuration"},{"location":"configuration/multi.tenancy/#introduction","text":"A single Opencast instance can handle multiple tenants, each of which have their own recordings in the system. Opencast refers to tenants as organizations , and an HTTP request to the Opencast installation is mapped to an organization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names pointing to the same IP, for example: admin.example.org tenant1-admin.example.org tenant2-admin.example.org should all resolve to the same IP. A tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.","title":"Introduction"},{"location":"configuration/multi.tenancy/#default-setup","text":"Out of the box, Opencast has one tenant configured, called mh_default_org that is mapped to the server name localhost:8080 . As long as there is one tenant configuration only, Opencast will map every request to that tenant regardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to organizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast installation that cannot be mapped to any organization.","title":"Default Setup"},{"location":"configuration/multi.tenancy/#limitations","text":"Multi tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst organizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.","title":"Limitations"},{"location":"configuration/multi.tenancy/#adding-a-tenant","text":"To add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security rules. For this example we have a three node install of admin.example.org , worker.example.org , and presentation.example.org . Assume that the new tenant is called tenant1 and should be mapped to tenant1-*.example.org .","title":"Adding A Tenant"},{"location":"configuration/multi.tenancy/#step-1-tenant-configuration","text":"Create a file called org.opencastproject.organization-tenant1.cfg in the etc/ directory of your Opencast installation, on each of the nodes. As an example, this is what the admin node looks like: id=tenant1 name=Tenant 1 port=8080 prop.org.opencastproject.host.admin.example.org=tenant1-admin.example.org prop.org.opencastproject.host.presentation.example.org=tenant1-presentation.example.org admin_role=ROLE_ADMIN anonymous_role=ROLE_ANONYMOUS # Admin and Presentation Server Urls prop.org.opencastproject.admin.ui.url=https://tenant1-admin.example.org prop.org.opencastproject.engage.ui.url=https://tenant1-presentation.example.org # Default properties for the user interface prop.logo_mediamodule=/engage/ui/img/logo/opencast-icon.svg prop.logo_player=/engage/ui/img/logo/opencast.svg There are more options available than in this example. The easiest way of creating that file is probably to create a copy of the already existing org.opencastproject.organization-mh_default_org.cfg . Note, the default organization file org.opencastproject.organization-mh_default_org.org must refer to the actual server names: prop.org.opencastproject.host.admin.example.org=admin.example.org prop.org.opencastproject.host.presentation.example.org=presentation.example.org This file sets the default organization that is selected. This is currently required because some Opencast components do not support multitenancy. Note that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be -1 in both files.","title":"Step 1: Tenant Configuration"},{"location":"configuration/multi.tenancy/#step-2-security-configuration","text":"Create a file called tenant1.xml in /etc/security. This file specifies access rules for individual URLs that specify which roles are needed in order to access a given URL. In addition, it allows to define the directory services that are used to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add anything that can go into a Spring Security configuration. The easiest way of creating that file is probably to create a copy of the already existing mh_default_org.xml .","title":"Step 2: Security Configuration"},{"location":"configuration/multi.tenancy/#step-3-other-configuration","text":"Two additional files should be copied: org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common-tenant1.cfg , and org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common-tenant1.cfg . In each of the new configuration files, change organization key to match the tenant id, and change the common-metadata key to false. Create a copy of the files for each tenant. Note: The original ...-common.cfg files must have their common-metadata keys set to true, otherwise metadata will only be available in one tenant and you will experience a number of odd errors.","title":"Step 3: Other Configuration"},{"location":"configuration/oaipmh/","text":"OAI-PMH Configuration Overview OAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists of two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server that exposes metadata to its client, the harvester. OAI-PMH repositories will be accessed using URLs of the form: <OAI-PMH server> + <OAI-PMH mount point> + <OAI-PMH Repository> Step 1: Configure the URL of the OAI-PMH server The property to configure the OAI-PMH server URL can be found in etc/org.opencastproject.organization-mh_default_org.cfg : prop.org.opencastproject.oaipmh.server.hosturl=http://localhost:8080 Step 2: Configure the OAI-PMH mount point The property to configure the OAI-PMH mount point can be found in etc/custom.properties : org.opencastproject.oaipmh.mountpoint=/oaipmh Step 3: Configure the OAI-PMH default repository In case the repository is not included in the URL, the OAI-PMH default repository will be selected. The property to configure the OAI-PMH default repository can be found in etc/org.opencastproject.oaipmh.server.OaiPmhServer.cfg default-repository=default Step 4: Allow access to OAI-PMH mount point Make sure that the OAI-PMH mount point is accessible. For example, if the OAI-PMH mount point has been set to /oaipmh , the following two lines <sec:intercept-url pattern=\"/oaipmh/**\" method=\"GET\" access=\"ROLE_ANONYMOUS\"/> <sec:intercept-url pattern=\"/oaipmh/**\" method=\"POST\" access=\"ROLE_ANONYMOUS\"/> should be present in etc/security/mh_default_org.xml . Note that the OAI-PMH specification demands both GET and POST requests and that it does not feature any access restrictions. If you need to restrict access to OAI-PMH consider using Spring security or an iptables approach. Step 5: Optionally configure OAI-PMH sets The OAI-PMH standard allow you to define sets. This can be used to filter data in your repository. An OAI-PMH set will be defined by a name, unique setSpec, optional description and a filter. The filters will be applied to the content of the published xml based elements and may contain one or more filter criteria. You can also define more than one filter for a specific set. Generally an OAI-PMH record is in the set if all set filters matches. A filter matches if any of the filter criteria matches. The filter criteria may be: contains , containsnot or match . Set definition configuration syntax: set.<set-id>.setSpec = setSpec value set.<set-id>.name = set name value set.<set-id>.description = optional set description set.<set-id>.filter.<filter-id>.flavor = set filter element flavor set.<set-id>.filter.<filter-id>.[<criteria-id>.]<criterion> = set filter criterion value # criteria-id should be set, if you provide more than one criteria for a filter Example configuration for a set definition with one filter and one criterion: set.public.setSpec = public set.public.name = Public Recordings set.public.filter.1.flavor = security/xacml+episode set.public.filter.1.contains = >ROLE_ANONYMOUS</ The OAI-PMH records in the set public contain the role ROLE_ANONYMOUS in the published episode ACL. Example configuration for a set definition with two filters and one or more criteria: set.openvideo.setSpec = open set.openvideo.name = Recordings with an open non commercial license set.openvideo.filter.1.flavor = security/xacml+episode set.openvideo.filter.1.contains = >ROLE_ANONYMOUS</ set.openvideo.filter.2.flavor = dublincore/episode set.openvideo.filter.2.0.contains = license>CC0</ set.openvideo.filter.2.1.contains = license>CC-BY</ set.openvideo.filter.2.2.contains = license>CC-BY-SA</ set.openvideo.filter.2.3.contains = license>CC-BY-NC</ set.openvideo.filter.2.4.contains = license>CC-BY-NC-SA</ The OAI-PMH records in the set \"open\" contain the role ROLE_ANONYMOUS in the published episode ACL and a CC0 or CC-BY derivate license without ND attribute. You can also define the second filter as one match criterion like: set.openvideo.filter.2.match = license>CC[0-](?:BY(?:-(?:(?!ND)[^-<]+))*)?< The match criterion tests are more CPU intensive as contains or containsnot criteria.","title":"OAI-PMH"},{"location":"configuration/oaipmh/#oai-pmh-configuration","text":"","title":"OAI-PMH Configuration"},{"location":"configuration/oaipmh/#overview","text":"OAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists of two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server that exposes metadata to its client, the harvester. OAI-PMH repositories will be accessed using URLs of the form: <OAI-PMH server> + <OAI-PMH mount point> + <OAI-PMH Repository>","title":"Overview"},{"location":"configuration/oaipmh/#step-1-configure-the-url-of-the-oai-pmh-server","text":"The property to configure the OAI-PMH server URL can be found in etc/org.opencastproject.organization-mh_default_org.cfg : prop.org.opencastproject.oaipmh.server.hosturl=http://localhost:8080","title":"Step 1: Configure the URL of the OAI-PMH server"},{"location":"configuration/oaipmh/#step-2-configure-the-oai-pmh-mount-point","text":"The property to configure the OAI-PMH mount point can be found in etc/custom.properties : org.opencastproject.oaipmh.mountpoint=/oaipmh","title":"Step 2: Configure the OAI-PMH mount point"},{"location":"configuration/oaipmh/#step-3-configure-the-oai-pmh-default-repository","text":"In case the repository is not included in the URL, the OAI-PMH default repository will be selected. The property to configure the OAI-PMH default repository can be found in etc/org.opencastproject.oaipmh.server.OaiPmhServer.cfg default-repository=default","title":"Step 3: Configure the OAI-PMH default repository"},{"location":"configuration/oaipmh/#step-4-allow-access-to-oai-pmh-mount-point","text":"Make sure that the OAI-PMH mount point is accessible. For example, if the OAI-PMH mount point has been set to /oaipmh , the following two lines <sec:intercept-url pattern=\"/oaipmh/**\" method=\"GET\" access=\"ROLE_ANONYMOUS\"/> <sec:intercept-url pattern=\"/oaipmh/**\" method=\"POST\" access=\"ROLE_ANONYMOUS\"/> should be present in etc/security/mh_default_org.xml . Note that the OAI-PMH specification demands both GET and POST requests and that it does not feature any access restrictions. If you need to restrict access to OAI-PMH consider using Spring security or an iptables approach.","title":"Step 4: Allow access to OAI-PMH mount point"},{"location":"configuration/oaipmh/#step-5-optionally-configure-oai-pmh-sets","text":"The OAI-PMH standard allow you to define sets. This can be used to filter data in your repository. An OAI-PMH set will be defined by a name, unique setSpec, optional description and a filter. The filters will be applied to the content of the published xml based elements and may contain one or more filter criteria. You can also define more than one filter for a specific set. Generally an OAI-PMH record is in the set if all set filters matches. A filter matches if any of the filter criteria matches. The filter criteria may be: contains , containsnot or match . Set definition configuration syntax: set.<set-id>.setSpec = setSpec value set.<set-id>.name = set name value set.<set-id>.description = optional set description set.<set-id>.filter.<filter-id>.flavor = set filter element flavor set.<set-id>.filter.<filter-id>.[<criteria-id>.]<criterion> = set filter criterion value # criteria-id should be set, if you provide more than one criteria for a filter Example configuration for a set definition with one filter and one criterion: set.public.setSpec = public set.public.name = Public Recordings set.public.filter.1.flavor = security/xacml+episode set.public.filter.1.contains = >ROLE_ANONYMOUS</ The OAI-PMH records in the set public contain the role ROLE_ANONYMOUS in the published episode ACL. Example configuration for a set definition with two filters and one or more criteria: set.openvideo.setSpec = open set.openvideo.name = Recordings with an open non commercial license set.openvideo.filter.1.flavor = security/xacml+episode set.openvideo.filter.1.contains = >ROLE_ANONYMOUS</ set.openvideo.filter.2.flavor = dublincore/episode set.openvideo.filter.2.0.contains = license>CC0</ set.openvideo.filter.2.1.contains = license>CC-BY</ set.openvideo.filter.2.2.contains = license>CC-BY-SA</ set.openvideo.filter.2.3.contains = license>CC-BY-NC</ set.openvideo.filter.2.4.contains = license>CC-BY-NC-SA</ The OAI-PMH records in the set \"open\" contain the role ROLE_ANONYMOUS in the published episode ACL and a CC0 or CC-BY derivate license without ND attribute. You can also define the second filter as one match criterion like: set.openvideo.filter.2.match = license>CC[0-](?:BY(?:-(?:(?!ND)[^-<]+))*)?< The match criterion tests are more CPU intensive as contains or containsnot criteria.","title":"Step 5: Optionally configure OAI-PMH sets"},{"location":"configuration/security.aai/","text":"Authentication and Authorization Infrastructure (AAI) Configuration This page describes how to configure Opencast to take advantage of the Authentication and Authorization Infrastructure (AAI). Prerequisites This guides assumes that you know how to setup and configure a Shibboleth Service Provider, i.e. you are assumed to already have performed the following steps: Registration of your Shibboleth Service Provider at your Shibboleth Federation Service Registry Setup and configuration of Shibboleth on the servers you want to use it Configuration of your web server In case you require help on this, contact the institution responsible for managing the Shibboleth Federation you are part of. An informative list of Shibboleth Federations can be found on: https://refeds.org/federations Step 1: Configuration of the AAI Login handler Opencast ships with a configurable AAI Login handler that needs to be adjusted to your environment. The configuration can be found in etc/org.opencastproject.security.aai.ConfigurableLoginHandler.cfg . First off all, enable the AAI login handler: enabled=true For bootstrapping purposes, you might want to configure the AAI bootstrap user: bootstrap.user.id=<AAI ID> That user will be assigned ROLE_ADMIN at login time. This enables you to access the administrative UI and configure user authorization without the need to fiddle with the database directly. Once user authorization has been setup, disable the AAI bootstrap user. Since the HTTP request header names required by the AAI login handler are specific to Shibboleth Federations, you will need to first adjust the following properties. Set the following header names to the correct values: header.given_name = \"<Name of Shibboleth attribute>\" header.surname = \"<Name of Shibboleth attribute>\" header.email = \"<Name of Shibboleth attribute>\" header.home_organization = \"<Name of Shibboleth attribute>\" Optionally, you can configure the name of some basic roles the AAI login handler will assign to authenticated users. The prefix of the user role will determine what unique role a given Shibboleth user has. The role is of the form role.user.prefix + Unique ID provided by Shibboleth . role.user.prefix = \"ROLE_AAI_USER_\" To indicate the AAI home organization a user belongs to, the organization membership role is assigned to the user. The role is of the form role.organization.prefix + Home Organization provided by Shibboleth + role.organization.suffix role.organization.prefix = \"ROLE_AAI_ORG_\" role.organization.suffix = \"_MEMBER\" To indicate the fact that a user has authenticated himself using Shibboleth, the login handler assigns the role as specified by the property role.federation . role.federation = \"ROLE_AAI_USER\" Step 2: Spring Security Configuration In order to take advantage of Shibboleth authentication, you will need to uncomment the following lines found in etc/security/mh_default_org.xml : The Shibboleth header authentication filter needs to be enabled to get access to the Shibboleth information within the HTTP request headers. <!-- Shibboleth header authentication filter --> <sec:custom-filter ref=\"shibbolethHeaderFilter\" position=\"PRE_AUTH_FILTER\"/> To ensure that a logout is not just logging out the user from the Opencast application but also from Shibboleth, you will need to configure the logout-success-url: <!-- Enables log out --> <sec:logout logout-success-url=\"/Shibboleth.sso/Logout?return=www.opencast.org\" /> IMPORTANT: In the section Shibboleth Support , be sure to adapt the value of principalRequestHeader to the respective name of the Shibboleth attribute you use in your Shibboleth Federation: <!-- ###################### --> <!-- # Shibboleth Support # --> <!-- ###################### --> <!-- General Shibboleth header extraction filter --> <bean id=\"shibbolethHeaderFilter\" class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\"> <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/> <property name=\"authenticationManager\" ref=\"authenticationManager\" /> <property name=\"userDetailsService\" ref=\"userDetailsService\" /> <property name=\"userDirectoryService\" ref=\"userDirectoryService\" /> <property name=\"shibbolethLoginHandler\" ref=\"configurableLoginHandler\" /> <property name=\"exceptionIfHeaderMissing\" value=\"false\" /> </bean> <!-- AAI specific header extractor and user generator --> <bean id=\"configurableLoginHandler\" class=\"org.opencastproject.security.aai.ConfigurableLoginHandler\"> <property name=\"securityService\" ref=\"securityService\" /> <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" /> </bean> <bean id=\"preauthAuthProvider\" class=\"org.springframework.security.web.authentication.preauth.PreAuthenticatedAuthenticationProvider\"> <property name=\"preAuthenticatedUserDetailsService\"> <bean id=\"userDetailsServiceWrapper\" class=\"org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> </bean> </property> </bean> Finally be sure to enable the user reference provider to enable support for externally provided users: <osgi:reference id=\"userReferenceProvider\" cardinality=\"1..1\" interface=\"org.opencastproject.userdirectory.api.UserReferenceProvider\" /> Since the Opencast login page is not used when Shibboleth authentication is in place, there is no point in redirecting unauthenticated requests to the Opencast login form. You can redirect them directly to the administrative user interface which is supposed to be protected by Shibboleth. <!-- Redirects unauthenticated requests to the login form --> <bean id=\"userEntryPoint\" class=\"org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint\"> <property name=\"loginFormUrl\" value=\"/admin-ng/index.html\" /> </bean> Last but not least, you need to add the preauthAuthProvider authentication provider to the authentication-manager : <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider ref=\"preauthAuthProvider\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"><sec:salt-source user-property=\"username\" /></sec:password-encoder> </sec:authentication-provider> </sec:authentication-manager> Step 3: Protecting HTML pages by Shibboleth It is important to understand that Shibboleth is only used to protect content that is accessed by human users. Access to APIs is protected by other means of authentication as, for example, digest authentication. To protect HTML pages, you will need to adapt the configuration of your web server: <LocationMatch \\.(htm|html)$> AuthType shibboleth ShibRequireSession On ShibUseHeaders On require valid-user </LocationMatch> Advanced SSO configuration: The DynamicLoginHandler To configure complex mappings of AAI attributes via SpEL in the mh_default_org.xml file, it is necessary to follow the same steps as above. Just change the bean reference of shibbolethLoginHandler to aaiLoginHandler in the shibbolethHeaderFilter : <bean id=\"shibbolethHeaderFilter\" class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\"> <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/> <property name=\"authenticationManager\" ref=\"authenticationManager\" /> <property name=\"userDetailsService\" ref=\"userDetailsService\" /> <property name=\"userDirectoryService\" ref=\"userDirectoryService\" /> <property name=\"shibbolethLoginHandler\" ref=\"aaiLoginHandler\" /> <property name=\"exceptionIfHeaderMissing\" value=\"false\" /> </bean> Activate the aaiLoginHandler bean and the attributeMapper bean <bean id=\"aaiLoginHandler\" class=\"org.opencastproject.security.aai.DynamicLoginHandler\"> <property name=\"securityService\" ref=\"securityService\" /> <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" /> <property name=\"attributeMapper\" ref=\"attributeMapper\" /> </bean> <bean id=\"attributeMapper\" class=\"org.opencastproject.security.aai.api.AttributeMapper\"> <property name=\"useHeader\" value=\"true\" /> <property name=\"multiValueDelimiter\" value=\";\" /> <property name=\"attributeMap\" ref=\"attributeMap\" /> <property name=\"aaiAttributes\" ref=\"aaiAttributes\" /> </bean> then, define all the attributes you may want to use, so the mapper gets populated at login e.g. <util:list id=\"aaiAttributes\" value-type=\"java.lang.String\"> <value>sn</value> <value>givenName</value> <value>mail</value> <value>homeOrganization</value> <value>eduPersonEntitlement</value> <value>eduPersonPrincipalName</value> <value>homeOrganization</value> </util:list> Opencast has a fairly simple account model that consists only of an username, display name and email address. Additionally an user may have some roles. For each of those attributes you define a map entry that refers to a list of mappings (username is mapped in the shibbolethHeaderFilter bean above). <util:map id=\"attributeMap\" map-class=\"java.util.HashMap\"> <entry key=\"roles\" value-ref=\"roleMapping\" /> <entry key=\"displayName\" value-ref=\"displayNameMapping\" /> <entry key=\"mail\" value-ref=\"mailMapping\" /> </util:map> Each attribute as treated as multi-value so you have to access single value attributes (like sn and givenName ) by accessing the first element of the list of values received via Shibboleth. For the email address and the displayName of an user the mapping is usually straight forward, see inline comments for further explanation: <!-- Use SpEL string concatenation to build a displayName from `sn` and `givenName` --> <util:list id=\"displayNameMapping\" value-type=\"java.lang.String\"> <value>['givenName'][0] + ' ' + ['sn'][0]</value> </util:list> <util:list id=\"mailMapping\" value-type=\"java.lang.String\"> <value>['mail'][0]</value> </util:list> The mail and the displayName of an user has only one value, but when it comes to the roles of an user you are able to produce an arbitrary number of roles using the whole power of SpEL and java.lang.String methods. See inline comments for further explanation and examples: <util:list id=\"roleMapping\" value-type=\"java.lang.String\"> <!-- assign every user the role ROLE_AAI_USER --> <value>'ROLE_AAI_USER'</value> <!-- assign every user the role ROLE_AAI_USER_<username>. For a user john.doe@example.org this will result in a ROLE_USER_JOHN_DOE_EXAMPLE_ORG since Opencast replaces all special chars in this case --> <value>'ROLE_AAI_USER_' + ['eduPersonPrincipalName']</value> <!-- if you implement a kind of DAC based access control you may want to produce an owner role. To get the same behaviour as for ROLE_AAI_USER_<username> above you may replace all special chars from the value of `eduPersonPrincipalName` and convert it to uppercase --> <value>('ROLE_AAI_OWNER_' + ['eduPersonPrincipalName']).replaceAll(\"[^a-zA-Z0-9]\",\"_\").toUpperCase()</value> <!-- an AAI user may provide the attribute homeOrganization. If so, assign an appropriate role. Otherwise not. --> <value>['homeOrganization'] != null ? 'ROLE_AAI_ORG_' + ['homeOrganization'] + '_MEMBER' : null</value> <!-- a sophisticated AAI approach would use entitlements to assign e.g. the admin role to authorized users --> <value>['eduPersonEntitlement'].contains('urn:mace:opencast.org:permission:shibboleth:opencast_admin') ? 'ROLE_ADMIN' : null</value> <!-- a less sophisticated approach would directly assign the admin role to users based on usernames (same as bootstrap user above) --> <value>['eduPersonPrincipalName'].contains('john.doe@example.org') ? 'ROLE_ADMIN' : null</value> <!-- to assing a common set of roles to a class of users, you may create a group (e.g. AAI_EDITOR) and assign some roles to it in the admin ui. So the group is the container of all the roles and you assign only the group to a user e.g. based on his affiliation, thus enabling a class of users for certain abilities in Opencast --> <value>['eduPersonScopedAffiliation'].contains('faculty@example.org') ? 'ROLE_GROUP_AAI_EDITOR' : null</value> </util:list> You may start by uncommenting the whole example in mh_default_org.xml .","title":"Authentication and Authorization Infrastructure (AAI)"},{"location":"configuration/security.aai/#authentication-and-authorization-infrastructure-aai-configuration","text":"This page describes how to configure Opencast to take advantage of the Authentication and Authorization Infrastructure (AAI).","title":"Authentication and Authorization Infrastructure (AAI) Configuration"},{"location":"configuration/security.aai/#prerequisites","text":"This guides assumes that you know how to setup and configure a Shibboleth Service Provider, i.e. you are assumed to already have performed the following steps: Registration of your Shibboleth Service Provider at your Shibboleth Federation Service Registry Setup and configuration of Shibboleth on the servers you want to use it Configuration of your web server In case you require help on this, contact the institution responsible for managing the Shibboleth Federation you are part of. An informative list of Shibboleth Federations can be found on: https://refeds.org/federations","title":"Prerequisites"},{"location":"configuration/security.aai/#step-1-configuration-of-the-aai-login-handler","text":"Opencast ships with a configurable AAI Login handler that needs to be adjusted to your environment. The configuration can be found in etc/org.opencastproject.security.aai.ConfigurableLoginHandler.cfg . First off all, enable the AAI login handler: enabled=true For bootstrapping purposes, you might want to configure the AAI bootstrap user: bootstrap.user.id=<AAI ID> That user will be assigned ROLE_ADMIN at login time. This enables you to access the administrative UI and configure user authorization without the need to fiddle with the database directly. Once user authorization has been setup, disable the AAI bootstrap user. Since the HTTP request header names required by the AAI login handler are specific to Shibboleth Federations, you will need to first adjust the following properties. Set the following header names to the correct values: header.given_name = \"<Name of Shibboleth attribute>\" header.surname = \"<Name of Shibboleth attribute>\" header.email = \"<Name of Shibboleth attribute>\" header.home_organization = \"<Name of Shibboleth attribute>\" Optionally, you can configure the name of some basic roles the AAI login handler will assign to authenticated users. The prefix of the user role will determine what unique role a given Shibboleth user has. The role is of the form role.user.prefix + Unique ID provided by Shibboleth . role.user.prefix = \"ROLE_AAI_USER_\" To indicate the AAI home organization a user belongs to, the organization membership role is assigned to the user. The role is of the form role.organization.prefix + Home Organization provided by Shibboleth + role.organization.suffix role.organization.prefix = \"ROLE_AAI_ORG_\" role.organization.suffix = \"_MEMBER\" To indicate the fact that a user has authenticated himself using Shibboleth, the login handler assigns the role as specified by the property role.federation . role.federation = \"ROLE_AAI_USER\"","title":"Step 1: Configuration of the AAI Login handler"},{"location":"configuration/security.aai/#step-2-spring-security-configuration","text":"In order to take advantage of Shibboleth authentication, you will need to uncomment the following lines found in etc/security/mh_default_org.xml : The Shibboleth header authentication filter needs to be enabled to get access to the Shibboleth information within the HTTP request headers. <!-- Shibboleth header authentication filter --> <sec:custom-filter ref=\"shibbolethHeaderFilter\" position=\"PRE_AUTH_FILTER\"/> To ensure that a logout is not just logging out the user from the Opencast application but also from Shibboleth, you will need to configure the logout-success-url: <!-- Enables log out --> <sec:logout logout-success-url=\"/Shibboleth.sso/Logout?return=www.opencast.org\" /> IMPORTANT: In the section Shibboleth Support , be sure to adapt the value of principalRequestHeader to the respective name of the Shibboleth attribute you use in your Shibboleth Federation: <!-- ###################### --> <!-- # Shibboleth Support # --> <!-- ###################### --> <!-- General Shibboleth header extraction filter --> <bean id=\"shibbolethHeaderFilter\" class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\"> <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/> <property name=\"authenticationManager\" ref=\"authenticationManager\" /> <property name=\"userDetailsService\" ref=\"userDetailsService\" /> <property name=\"userDirectoryService\" ref=\"userDirectoryService\" /> <property name=\"shibbolethLoginHandler\" ref=\"configurableLoginHandler\" /> <property name=\"exceptionIfHeaderMissing\" value=\"false\" /> </bean> <!-- AAI specific header extractor and user generator --> <bean id=\"configurableLoginHandler\" class=\"org.opencastproject.security.aai.ConfigurableLoginHandler\"> <property name=\"securityService\" ref=\"securityService\" /> <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" /> </bean> <bean id=\"preauthAuthProvider\" class=\"org.springframework.security.web.authentication.preauth.PreAuthenticatedAuthenticationProvider\"> <property name=\"preAuthenticatedUserDetailsService\"> <bean id=\"userDetailsServiceWrapper\" class=\"org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> </bean> </property> </bean> Finally be sure to enable the user reference provider to enable support for externally provided users: <osgi:reference id=\"userReferenceProvider\" cardinality=\"1..1\" interface=\"org.opencastproject.userdirectory.api.UserReferenceProvider\" /> Since the Opencast login page is not used when Shibboleth authentication is in place, there is no point in redirecting unauthenticated requests to the Opencast login form. You can redirect them directly to the administrative user interface which is supposed to be protected by Shibboleth. <!-- Redirects unauthenticated requests to the login form --> <bean id=\"userEntryPoint\" class=\"org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint\"> <property name=\"loginFormUrl\" value=\"/admin-ng/index.html\" /> </bean> Last but not least, you need to add the preauthAuthProvider authentication provider to the authentication-manager : <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider ref=\"preauthAuthProvider\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"><sec:salt-source user-property=\"username\" /></sec:password-encoder> </sec:authentication-provider> </sec:authentication-manager>","title":"Step 2: Spring Security Configuration"},{"location":"configuration/security.aai/#step-3-protecting-html-pages-by-shibboleth","text":"It is important to understand that Shibboleth is only used to protect content that is accessed by human users. Access to APIs is protected by other means of authentication as, for example, digest authentication. To protect HTML pages, you will need to adapt the configuration of your web server: <LocationMatch \\.(htm|html)$> AuthType shibboleth ShibRequireSession On ShibUseHeaders On require valid-user </LocationMatch>","title":"Step 3: Protecting HTML pages by Shibboleth"},{"location":"configuration/security.aai/#advanced-sso-configuration-the-dynamicloginhandler","text":"To configure complex mappings of AAI attributes via SpEL in the mh_default_org.xml file, it is necessary to follow the same steps as above. Just change the bean reference of shibbolethLoginHandler to aaiLoginHandler in the shibbolethHeaderFilter : <bean id=\"shibbolethHeaderFilter\" class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\"> <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/> <property name=\"authenticationManager\" ref=\"authenticationManager\" /> <property name=\"userDetailsService\" ref=\"userDetailsService\" /> <property name=\"userDirectoryService\" ref=\"userDirectoryService\" /> <property name=\"shibbolethLoginHandler\" ref=\"aaiLoginHandler\" /> <property name=\"exceptionIfHeaderMissing\" value=\"false\" /> </bean> Activate the aaiLoginHandler bean and the attributeMapper bean <bean id=\"aaiLoginHandler\" class=\"org.opencastproject.security.aai.DynamicLoginHandler\"> <property name=\"securityService\" ref=\"securityService\" /> <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" /> <property name=\"attributeMapper\" ref=\"attributeMapper\" /> </bean> <bean id=\"attributeMapper\" class=\"org.opencastproject.security.aai.api.AttributeMapper\"> <property name=\"useHeader\" value=\"true\" /> <property name=\"multiValueDelimiter\" value=\";\" /> <property name=\"attributeMap\" ref=\"attributeMap\" /> <property name=\"aaiAttributes\" ref=\"aaiAttributes\" /> </bean> then, define all the attributes you may want to use, so the mapper gets populated at login e.g. <util:list id=\"aaiAttributes\" value-type=\"java.lang.String\"> <value>sn</value> <value>givenName</value> <value>mail</value> <value>homeOrganization</value> <value>eduPersonEntitlement</value> <value>eduPersonPrincipalName</value> <value>homeOrganization</value> </util:list> Opencast has a fairly simple account model that consists only of an username, display name and email address. Additionally an user may have some roles. For each of those attributes you define a map entry that refers to a list of mappings (username is mapped in the shibbolethHeaderFilter bean above). <util:map id=\"attributeMap\" map-class=\"java.util.HashMap\"> <entry key=\"roles\" value-ref=\"roleMapping\" /> <entry key=\"displayName\" value-ref=\"displayNameMapping\" /> <entry key=\"mail\" value-ref=\"mailMapping\" /> </util:map> Each attribute as treated as multi-value so you have to access single value attributes (like sn and givenName ) by accessing the first element of the list of values received via Shibboleth. For the email address and the displayName of an user the mapping is usually straight forward, see inline comments for further explanation: <!-- Use SpEL string concatenation to build a displayName from `sn` and `givenName` --> <util:list id=\"displayNameMapping\" value-type=\"java.lang.String\"> <value>['givenName'][0] + ' ' + ['sn'][0]</value> </util:list> <util:list id=\"mailMapping\" value-type=\"java.lang.String\"> <value>['mail'][0]</value> </util:list> The mail and the displayName of an user has only one value, but when it comes to the roles of an user you are able to produce an arbitrary number of roles using the whole power of SpEL and java.lang.String methods. See inline comments for further explanation and examples: <util:list id=\"roleMapping\" value-type=\"java.lang.String\"> <!-- assign every user the role ROLE_AAI_USER --> <value>'ROLE_AAI_USER'</value> <!-- assign every user the role ROLE_AAI_USER_<username>. For a user john.doe@example.org this will result in a ROLE_USER_JOHN_DOE_EXAMPLE_ORG since Opencast replaces all special chars in this case --> <value>'ROLE_AAI_USER_' + ['eduPersonPrincipalName']</value> <!-- if you implement a kind of DAC based access control you may want to produce an owner role. To get the same behaviour as for ROLE_AAI_USER_<username> above you may replace all special chars from the value of `eduPersonPrincipalName` and convert it to uppercase --> <value>('ROLE_AAI_OWNER_' + ['eduPersonPrincipalName']).replaceAll(\"[^a-zA-Z0-9]\",\"_\").toUpperCase()</value> <!-- an AAI user may provide the attribute homeOrganization. If so, assign an appropriate role. Otherwise not. --> <value>['homeOrganization'] != null ? 'ROLE_AAI_ORG_' + ['homeOrganization'] + '_MEMBER' : null</value> <!-- a sophisticated AAI approach would use entitlements to assign e.g. the admin role to authorized users --> <value>['eduPersonEntitlement'].contains('urn:mace:opencast.org:permission:shibboleth:opencast_admin') ? 'ROLE_ADMIN' : null</value> <!-- a less sophisticated approach would directly assign the admin role to users based on usernames (same as bootstrap user above) --> <value>['eduPersonPrincipalName'].contains('john.doe@example.org') ? 'ROLE_ADMIN' : null</value> <!-- to assing a common set of roles to a class of users, you may create a group (e.g. AAI_EDITOR) and assign some roles to it in the admin ui. So the group is the container of all the roles and you assign only the group to a user e.g. based on his affiliation, thus enabling a class of users for certain abilities in Opencast --> <value>['eduPersonScopedAffiliation'].contains('faculty@example.org') ? 'ROLE_GROUP_AAI_EDITOR' : null</value> </util:list> You may start by uncommenting the whole example in mh_default_org.xml .","title":"Advanced SSO configuration: The DynamicLoginHandler"},{"location":"configuration/security.cas/","text":"Configure Central Authentication Service (CAS) Authentication Many campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide describes how to integrate Opencast into such a system. Step 1: Enable Opencast CAS feature First, you need to edit the file etc/org.apache.karaf.features.cfg and add the opencast-security-cas to the featuresBoot variable. featuresBoot = ..., opencast-security-cas Step 2: Security Configuration Edit the security configuration file at etc/security/mh_default_org.xml . In a multi-tenant set-up, you will have one configuration file for each tenant at etc/security/<organization_id>.xml . You need to comment or uncomment some sections in this file. All necessary changes are marked with a CAS Auth: tag. You can use the find function of your editor to find the parts of the file you need to modify. Add the necessary configuration values to the CAS section of the new security file. The comments should be self-explanatory. You must modify several settings in the sample to point to your CAS server: <bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\"> <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\"/> </bean> <bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\" /> <property name=\"ticketValidator\"> <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\"> <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" /> </bean> </property> <property name=\"key\" value=\"cas\"/> </bean> You will also need to set the public URL for your Opencast server: <bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\"> <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/> <property name=\"sendRenew\" value=\"false\"/> </bean> Authorization Now the system knows all the information necessary to authenticate users against CAS, but also need some authorization information, to tell which services the user is allowed to use and which resources is allowed to see and/or modify. You will need to configure a UserProvider to look up users as identified by CAS. LDAP User Provider, described in LDAP Security and Authorization Sakai User Provider Moodle User Provider Brightspace D2L User Provider Canvas LMS User Provider Further Information Original documentation from University of Saskatchewan: University of Saskatchewan CAS and LDAP integration","title":"Central Authentication Service (CAS)"},{"location":"configuration/security.cas/#configure-central-authentication-service-cas","text":"","title":"Configure Central Authentication Service (CAS)"},{"location":"configuration/security.cas/#authentication","text":"Many campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide describes how to integrate Opencast into such a system.","title":"Authentication"},{"location":"configuration/security.cas/#step-1-enable-opencast-cas-feature","text":"First, you need to edit the file etc/org.apache.karaf.features.cfg and add the opencast-security-cas to the featuresBoot variable. featuresBoot = ..., opencast-security-cas","title":"Step 1: Enable Opencast CAS feature"},{"location":"configuration/security.cas/#step-2-security-configuration","text":"Edit the security configuration file at etc/security/mh_default_org.xml . In a multi-tenant set-up, you will have one configuration file for each tenant at etc/security/<organization_id>.xml . You need to comment or uncomment some sections in this file. All necessary changes are marked with a CAS Auth: tag. You can use the find function of your editor to find the parts of the file you need to modify. Add the necessary configuration values to the CAS section of the new security file. The comments should be self-explanatory. You must modify several settings in the sample to point to your CAS server: <bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\"> <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\"/> </bean> <bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\" /> <property name=\"ticketValidator\"> <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\"> <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" /> </bean> </property> <property name=\"key\" value=\"cas\"/> </bean> You will also need to set the public URL for your Opencast server: <bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\"> <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/> <property name=\"sendRenew\" value=\"false\"/> </bean>","title":"Step 2: Security Configuration"},{"location":"configuration/security.cas/#authorization","text":"Now the system knows all the information necessary to authenticate users against CAS, but also need some authorization information, to tell which services the user is allowed to use and which resources is allowed to see and/or modify. You will need to configure a UserProvider to look up users as identified by CAS. LDAP User Provider, described in LDAP Security and Authorization Sakai User Provider Moodle User Provider Brightspace D2L User Provider Canvas LMS User Provider","title":"Authorization"},{"location":"configuration/security.cas/#further-information","text":"Original documentation from University of Saskatchewan: University of Saskatchewan CAS and LDAP integration","title":"Further Information"},{"location":"configuration/security.ldap/","text":"LDAP Authentication and Authorization This page describes how to use LDAP as an authentication and user provider Opencast. There are separate instructions on how to configure an LDAP-backed CAS server . Security Configuration Edit the security configuration file at etc/security/mh_default_org.xml . In a multi-tenant set-up, you will have one configuration file for each tenant at etc/security/<organization_id>.xml . You will find several commented out LDAP sections in this file. Uncomment them and fill in the necessary configuration values. The first relevant section defines a context source. This contains the basic login information that enables Opencast to request information about users from the LDAP server in order to authenticate them. <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> The next part tells the system how to search for users in LDAP: <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> As the previous snippet shows, there are two alternative ways to find users in your LDAP: Using the property userDnPatterns: This property accepts a list of search patterns to match against the user's DN. The patterns will be tried in order until a match is found. The placeholder {0} can be used to represent the username in such patterns. Using a userSearch filter: With the previous approach, it is not possible to find users whose login name is not part of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a filter. The filter requires three parameters: The first parameter specifies the \"root node\" where the searches will start from. The second one specifies the filter, where, again, the placeholder {0} will be substituted by the username during the searches. The third parameter should be the contextSource defined above. Both methods are not mutually exclusive \u2013 i.e. both can be activated at the same time, even though only the first one is uncommented in the sample file because it is the most usual. Next, uncomment the reference to Opencast's LDAP OSGI service, making sure to set the correct instanceId which needs to match the one used later in the LDAP service configuration. <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> Finally, enable the authentication provider by uncommenting: <sec:authentication-provider ref=\"ldapAuthProvider\" /> LDAP Service Configuration Make a copy of the file etc/org.opencastproject.userdirectory.ldap.cfg.template in the same directory and rename it as: org.opencastproject.userdirectory.ldap-<ID>.cfg \u2026where <ID> is a unique identifier for each LDAP connection. Now adjust the service configuration to your needs. The parameters in this file control the user authorization, i.e. how the roles obtained from LDAP are handled and assigned to the users. Combination with Existing authorization Mechanisms In the default configuration included in the security_sample_ldap.xml-example file, the LDAP is tried after the normal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the LDAP, the database will take precedence. The order is determined by the order in which the authentication providers appear on the security file. The relevant snippet is this: <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\">\u2026</sec:authentication-provider> <sec:authentication-provider ref=\"ldapAuthProvider\" /> </sec:authentication-manager> Adding more LDAP servers More LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary with their corresponding configurations. The new authentication providers must also be added to the providers list at the bottom of the file. Please see the example below: <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> <bean id=\"ldapAuthProvider\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <constructor-arg ref=\"authoritiesPopulator\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each context source instance --> <bean id=\"contextSource2\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <constructor-arg value=\"ldap://myldapserver:myport\" /> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <property name=\"password\" value=\"mypassword\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance --> <bean id=\"ldapAuthProvider2\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> <property name=\"userDnPatterns\"> <list> <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value> </list> </property> <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" /> <constructor-arg index=\"1\" value=\"(uid={0})\" /> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> </bean> </property> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <!-- PLEASE NOTE: the ref below must match the corresponding authoritiesPopulator --> <constructor-arg ref=\"authoritiesPopulator2\" /> </bean> <!-- [ ... SKIPPED LINES ... ] --> <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> <osgi:reference id=\"authoritiesPopulator2\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId2)\"/> <!-- [ ... SKIPPED LINES ... ] --> <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"> <sec:salt-source user-property=\"username\" /> </sec:password-encoder> </sec:authentication-provider> <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one --> <sec:authentication-provider ref=\"ldapAuthProvider2\" /> <sec:authentication-provider ref=\"ldapAuthProvider\" /> </sec:authentication-manager> Then, a separate .cfg must be generated for each of the configured providers, as explained here . Please make sure to configure the org.opencastproject.userdirectory.ldap.id parameter correctly. In this case, the values should be theId and theId2 , respectively.","title":"LDAP Authentication and Authorization (without CAS)"},{"location":"configuration/security.ldap/#ldap-authentication-and-authorization","text":"This page describes how to use LDAP as an authentication and user provider Opencast. There are separate instructions on how to configure an LDAP-backed CAS server .","title":"LDAP Authentication and Authorization"},{"location":"configuration/security.ldap/#security-configuration","text":"Edit the security configuration file at etc/security/mh_default_org.xml . In a multi-tenant set-up, you will have one configuration file for each tenant at etc/security/<organization_id>.xml . You will find several commented out LDAP sections in this file. Uncomment them and fill in the necessary configuration values. The first relevant section defines a context source. This contains the basic login information that enables Opencast to request information about users from the LDAP server in order to authenticate them. <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> The next part tells the system how to search for users in LDAP: <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> As the previous snippet shows, there are two alternative ways to find users in your LDAP: Using the property userDnPatterns: This property accepts a list of search patterns to match against the user's DN. The patterns will be tried in order until a match is found. The placeholder {0} can be used to represent the username in such patterns. Using a userSearch filter: With the previous approach, it is not possible to find users whose login name is not part of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a filter. The filter requires three parameters: The first parameter specifies the \"root node\" where the searches will start from. The second one specifies the filter, where, again, the placeholder {0} will be substituted by the username during the searches. The third parameter should be the contextSource defined above. Both methods are not mutually exclusive \u2013 i.e. both can be activated at the same time, even though only the first one is uncommented in the sample file because it is the most usual. Next, uncomment the reference to Opencast's LDAP OSGI service, making sure to set the correct instanceId which needs to match the one used later in the LDAP service configuration. <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> Finally, enable the authentication provider by uncommenting: <sec:authentication-provider ref=\"ldapAuthProvider\" />","title":"Security Configuration"},{"location":"configuration/security.ldap/#ldap-service-configuration","text":"Make a copy of the file etc/org.opencastproject.userdirectory.ldap.cfg.template in the same directory and rename it as: org.opencastproject.userdirectory.ldap-<ID>.cfg \u2026where <ID> is a unique identifier for each LDAP connection. Now adjust the service configuration to your needs. The parameters in this file control the user authorization, i.e. how the roles obtained from LDAP are handled and assigned to the users.","title":"LDAP Service Configuration"},{"location":"configuration/security.ldap/#combination-with-existing-authorization-mechanisms","text":"In the default configuration included in the security_sample_ldap.xml-example file, the LDAP is tried after the normal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the LDAP, the database will take precedence. The order is determined by the order in which the authentication providers appear on the security file. The relevant snippet is this: <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\">\u2026</sec:authentication-provider> <sec:authentication-provider ref=\"ldapAuthProvider\" /> </sec:authentication-manager>","title":"Combination with Existing authorization Mechanisms"},{"location":"configuration/security.ldap/#adding-more-ldap-servers","text":"More LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary with their corresponding configurations. The new authentication providers must also be added to the providers list at the bottom of the file. Please see the example below: <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> <bean id=\"ldapAuthProvider\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <constructor-arg ref=\"authoritiesPopulator\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each context source instance --> <bean id=\"contextSource2\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <constructor-arg value=\"ldap://myldapserver:myport\" /> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <property name=\"password\" value=\"mypassword\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance --> <bean id=\"ldapAuthProvider2\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> <property name=\"userDnPatterns\"> <list> <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value> </list> </property> <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" /> <constructor-arg index=\"1\" value=\"(uid={0})\" /> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> </bean> </property> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <!-- PLEASE NOTE: the ref below must match the corresponding authoritiesPopulator --> <constructor-arg ref=\"authoritiesPopulator2\" /> </bean> <!-- [ ... SKIPPED LINES ... ] --> <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> <osgi:reference id=\"authoritiesPopulator2\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId2)\"/> <!-- [ ... SKIPPED LINES ... ] --> <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"> <sec:salt-source user-property=\"username\" /> </sec:password-encoder> </sec:authentication-provider> <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one --> <sec:authentication-provider ref=\"ldapAuthProvider2\" /> <sec:authentication-provider ref=\"ldapAuthProvider\" /> </sec:authentication-manager> Then, a separate .cfg must be generated for each of the configured providers, as explained here . Please make sure to configure the org.opencastproject.userdirectory.ldap.id parameter correctly. In this case, the values should be theId and theId2 , respectively.","title":"Adding more LDAP servers"},{"location":"configuration/security/","text":"Security Configuration This document will help you configure the Opencast security policy. Introduction Opencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following diagram illustrates the flow of an HTTP request and response through these filters. The Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself with the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in etc/security , as described below. Configure Access To configure access roles and URL patterns for a tenant, modify etc/security/<tenant_identifier.xml> . If you are not hosting multiple tenants on your Opencast server or cluster, all configuration should be done in mh_default_org.xml . Some examples: <!-- Allow anonymous access to the welcome.html URLs --> <sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/> <!-- Allow anonymous GET to the search service, but not POST or PUT --> <sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' /> <!-- Allow users with the admin role to do anything --> <sec:intercept-url pattern='/**' access='ROLE_ADMIN'/> Authentication Provider Opencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI service registry. You can use this simple provider as is, loading users into the oc_user and oc_role database tables, and specifying an administrative username and password in custom.properties : org.opencastproject.security.digest.user=opencast_system_account org.opencastproject.security.digest.pass=CHANGE_ME User and Role Providers Opencast allows user and role information to be supplied from external systems through user and role providers. Four user providers are available by default: LDAP User Provider, described in LDAP Security and Authorization Sakai User Provider Moodle User Provider Brightspace D2L User Provider Canvas LMS User Provider The set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's database, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the userdirectory-jpa jar with the userdirectory-ldap jar. Further Authentication Configuration Configure Central Authentication Service (CAS) Configure LDAP Authentication and Authorization Configure Authentication and Authorization Infrastructure (AAI)","title":"General Security"},{"location":"configuration/security/#security-configuration","text":"This document will help you configure the Opencast security policy.","title":"Security Configuration"},{"location":"configuration/security/#introduction","text":"Opencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following diagram illustrates the flow of an HTTP request and response through these filters. The Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself with the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in etc/security , as described below.","title":"Introduction"},{"location":"configuration/security/#configure-access","text":"To configure access roles and URL patterns for a tenant, modify etc/security/<tenant_identifier.xml> . If you are not hosting multiple tenants on your Opencast server or cluster, all configuration should be done in mh_default_org.xml . Some examples: <!-- Allow anonymous access to the welcome.html URLs --> <sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/> <!-- Allow anonymous GET to the search service, but not POST or PUT --> <sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' /> <!-- Allow users with the admin role to do anything --> <sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>","title":"Configure Access"},{"location":"configuration/security/#authentication-provider","text":"Opencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI service registry. You can use this simple provider as is, loading users into the oc_user and oc_role database tables, and specifying an administrative username and password in custom.properties : org.opencastproject.security.digest.user=opencast_system_account org.opencastproject.security.digest.pass=CHANGE_ME","title":"Authentication Provider"},{"location":"configuration/security/#user-and-role-providers","text":"Opencast allows user and role information to be supplied from external systems through user and role providers. Four user providers are available by default: LDAP User Provider, described in LDAP Security and Authorization Sakai User Provider Moodle User Provider Brightspace D2L User Provider Canvas LMS User Provider The set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's database, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the userdirectory-jpa jar with the userdirectory-ldap jar.","title":"User and Role Providers"},{"location":"configuration/security/#further-authentication-configuration","text":"Configure Central Authentication Service (CAS) Configure LDAP Authentication and Authorization Configure Authentication and Authorization Infrastructure (AAI)","title":"Further Authentication Configuration"},{"location":"configuration/security.user.brightspace/","text":"What it does The Brightspace User Provider enriches Opencast users with a set of roles made up of the user's membership in Brightspace courses, of the form ROLE_courseID . For example, an Opencast user who is also a Brightspace user and a member of the Brightspace course myCourseID will be granted the Opencast role ROLE_myCourseID . Step 1: Configure the User Provider To enable the Brightspace User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg Edit the configuration file to set your Brightspace URL and the credentials needed for making authenticated API calls. # The organization for this provider org.opencastproject.userdirectory.brightspace.org=mh_default_org # The URL for the Brightspace REST webservice org.opencastproject.userdirectory.brightspace.url=https://brightspace-api # properties for authentication in brightspace api org.opencastproject.userdirectory.brightspace.systemuser.id=system-user-id org.opencastproject.userdirectory.brightspace.systemuser.key=system-user-key org.opencastproject.userdirectory.brightspace.application.id=application-id org.opencastproject.userdirectory.brightspace.application.key=application-key # The maximum number of users to cache #org.opencastproject.userdirectory.brightspace.cache.size=1000 # The maximum number of minutes to cache a user #org.opencastproject.userdirectory.brightspace.cache.expiration=60 Step 2: Verify Granted Access Verify that the Brightspace User Provider starts up with the correct Brightspace URL by looking for a log entry like this: (BrightspaceUserProviderInstance:143) - Creating new BrightspaceUserProviderInstance(pid=org.opencastproject.userdirectory.brightspace.378cdff4-825f-4b60-b1ed-33f75aa7f265, url= ... , cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Brightspace system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Brightspace user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.brightspace=DEBUG","title":"Brightspace User Provider"},{"location":"configuration/security.user.brightspace/#what-it-does","text":"The Brightspace User Provider enriches Opencast users with a set of roles made up of the user's membership in Brightspace courses, of the form ROLE_courseID . For example, an Opencast user who is also a Brightspace user and a member of the Brightspace course myCourseID will be granted the Opencast role ROLE_myCourseID .","title":"What it does"},{"location":"configuration/security.user.brightspace/#step-1-configure-the-user-provider","text":"To enable the Brightspace User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg Edit the configuration file to set your Brightspace URL and the credentials needed for making authenticated API calls. # The organization for this provider org.opencastproject.userdirectory.brightspace.org=mh_default_org # The URL for the Brightspace REST webservice org.opencastproject.userdirectory.brightspace.url=https://brightspace-api # properties for authentication in brightspace api org.opencastproject.userdirectory.brightspace.systemuser.id=system-user-id org.opencastproject.userdirectory.brightspace.systemuser.key=system-user-key org.opencastproject.userdirectory.brightspace.application.id=application-id org.opencastproject.userdirectory.brightspace.application.key=application-key # The maximum number of users to cache #org.opencastproject.userdirectory.brightspace.cache.size=1000 # The maximum number of minutes to cache a user #org.opencastproject.userdirectory.brightspace.cache.expiration=60","title":"Step 1: Configure the User Provider"},{"location":"configuration/security.user.brightspace/#step-2-verify-granted-access","text":"Verify that the Brightspace User Provider starts up with the correct Brightspace URL by looking for a log entry like this: (BrightspaceUserProviderInstance:143) - Creating new BrightspaceUserProviderInstance(pid=org.opencastproject.userdirectory.brightspace.378cdff4-825f-4b60-b1ed-33f75aa7f265, url= ... , cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Brightspace system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Brightspace user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.brightspace=DEBUG","title":"Step 2: Verify Granted Access"},{"location":"configuration/security.user.canvas/","text":"What it does The Canvas LMS User Provider enriches Opencast users with a set of roles made up of the user's membership in Canvas sites, of the form SITEID_Role. For example, an Opencast user who is also a Canvas user and a member of the Canvas site CourseID with the Canvas role Student will be granted the Opencast role CourseID_Learner . The mapping of Canvas sites and roles to Opencast roles is consistent with the site and role mapping used by the LTI endpoint. The Canvas User Provider can therefore be used with LTI or another method of authenticating users. The Canvas Role Provider allows Canvas site and role combinations to be used in Event and Series ACLs. For example, the role CourseID_Learner can be added to a Series ACL to grant access to the Series to members of the CourseID site in Canvas. Requirements The Canvas User Provider requires a token of a user who has at least the following permissions of an account role in a Canvas instance. Users - manage login details : Required for getting site list of a given user. Users - view list : Required for getting details of a given user. Step 1 Edit etc/org.apache.karaf.features.cfg and make sure the opencast-canvas feature is listed in the featuresBoot option. Step 2 To enable the Canvas User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.canvas.CanvasUserRoleProvider.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.canvas.CanvasUserRoleProvider.cfg Edit the configuration file to set your Canvas URL, and the token of the admin user: # The URL and login token for Canvas LMS org.opencastproject.userdirectory.canvas.url=https://demo.instructure.com/ org.opencastproject.userdirectory.canvas.token=token_of_a_user_with_sufficient_privilege Step 3 Verify that the Canvas User Provider starts up with the correct Canvas URL by looking for a log entry like this: (CanvasUserRoleProvider:116) - Activating CanvasUserRoleProvider(url=https://demo.instructure.com, cacheSize=1000, cacheExpiration=60, instructorRoles=[teacher, ta], ignoredUserNames=[admin, anonymous] Then login to Opencast using a username which also exists in your Canvas system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab. If necessary, you can increase the logging detail from the Canvas user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j2.logger.canvas.name = org.opencastproject.userdirectory.canvas log4j2.logger.canvas.level = DEBUG Step 4 You can use the group role name ROLE_GROUP_CANVAS in Event or Series ACLs for all Canvas users and ROLE_GROUP_CANVAS_INSTRUCTOR for all Canvas instructors.","title":"Canvas User Provider"},{"location":"configuration/security.user.canvas/#what-it-does","text":"The Canvas LMS User Provider enriches Opencast users with a set of roles made up of the user's membership in Canvas sites, of the form SITEID_Role. For example, an Opencast user who is also a Canvas user and a member of the Canvas site CourseID with the Canvas role Student will be granted the Opencast role CourseID_Learner . The mapping of Canvas sites and roles to Opencast roles is consistent with the site and role mapping used by the LTI endpoint. The Canvas User Provider can therefore be used with LTI or another method of authenticating users. The Canvas Role Provider allows Canvas site and role combinations to be used in Event and Series ACLs. For example, the role CourseID_Learner can be added to a Series ACL to grant access to the Series to members of the CourseID site in Canvas.","title":"What it does"},{"location":"configuration/security.user.canvas/#requirements","text":"The Canvas User Provider requires a token of a user who has at least the following permissions of an account role in a Canvas instance. Users - manage login details : Required for getting site list of a given user. Users - view list : Required for getting details of a given user.","title":"Requirements"},{"location":"configuration/security.user.canvas/#step-1","text":"Edit etc/org.apache.karaf.features.cfg and make sure the opencast-canvas feature is listed in the featuresBoot option.","title":"Step 1"},{"location":"configuration/security.user.canvas/#step-2","text":"To enable the Canvas User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.canvas.CanvasUserRoleProvider.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.canvas.CanvasUserRoleProvider.cfg Edit the configuration file to set your Canvas URL, and the token of the admin user: # The URL and login token for Canvas LMS org.opencastproject.userdirectory.canvas.url=https://demo.instructure.com/ org.opencastproject.userdirectory.canvas.token=token_of_a_user_with_sufficient_privilege","title":"Step 2"},{"location":"configuration/security.user.canvas/#step-3","text":"Verify that the Canvas User Provider starts up with the correct Canvas URL by looking for a log entry like this: (CanvasUserRoleProvider:116) - Activating CanvasUserRoleProvider(url=https://demo.instructure.com, cacheSize=1000, cacheExpiration=60, instructorRoles=[teacher, ta], ignoredUserNames=[admin, anonymous] Then login to Opencast using a username which also exists in your Canvas system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab. If necessary, you can increase the logging detail from the Canvas user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j2.logger.canvas.name = org.opencastproject.userdirectory.canvas log4j2.logger.canvas.level = DEBUG","title":"Step 3"},{"location":"configuration/security.user.canvas/#step-4","text":"You can use the group role name ROLE_GROUP_CANVAS in Event or Series ACLs for all Canvas users and ROLE_GROUP_CANVAS_INSTRUCTOR for all Canvas instructors.","title":"Step 4"},{"location":"configuration/security.user.moodle/","text":"What it does The Moodle User Provider enriches Opencast users with a set of roles made up of the user's membership in Moodle courses, of the form COURSEID_Role. For example, an Opencast user who is also a Moodle user and a member of the Moodle course myCourseID with the Moodle capability tool/opencast:learner will be granted the Opencast role myCourseID_Learner . Analogously, users with the capability tool/opencast:instructor will receive the Opencast role myCourseID_Instructor . Note that by default, Moodle course IDs are opaque ID values such as 10765 . The ROLE_GROUP_MOODLE Opencast group role is granted to all users that also exist in Moodle. The mapping of Moodle courses and capabilities to Opencast roles is consistent with the course and role mapping used by the LTI endpoint. The Moodle User Provider can therefore be used with LTI or another method of authenticating users. The Moodle Role Provider allows Moodle course and capability combinations to be used in Event and Series ACLs. For example, the role myCourseID_Learner can be added to a Series ACL to grant access to the Series to members of the myCourseID course in Moodle. Requirements The Moodle User Provider requires the moodle-tool_opencast plug-in that extends Moodle with the necessary API functions and capabilities. As this plug-in also provides base settings for additional Moodle plug-ins, the user is asked to provide Opencast API login information during the installation. The values can be arbitrary, if only the Moodle User Provider should be configured. After the installation, a new user with the capabilities webservice/rest:use , tool/opencast:externalapi , moodle/user:viewalldetails , moodle/user:viewdetails and moodle/site:accessallgroups has to be created. Then generate a new web service token and add that user to the \"Opencast web service\" service. Step 1 Edit etc/org.apache.karaf.features.cfg and make sure the opencast-moodle feature is listed in the featuresBoot option. Step 2 To enable the Moodle User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg Edit the configuration file to set your Moodle URL and the web service token of the Moodle user that should be used for API calls. # The URL and token for the Moodle REST webservice org.opencastproject.userdirectory.moodle.url=http://localhost/webservice/rest/server.php org.opencastproject.userdirectory.moodle.token=mytoken1234abcdef Step 3 Verify that the Moodle User Provider starts up with the correct Moodle URL by looking for a log entry like this: (MoodleUserProviderInstance:143) - Creating new MoodleUserProviderInstance(pid=org.opencastproject.userdirectory.moodle.378cdff4-825f-4b60-b1ed-33f75aa7f265, url=http://localhost/webservice/rest/server.php, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Moodle system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Moodle user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.moodle=DEBUG Step 4 You can grant additional roles to all Moodle users in Opencast by creating a group with the name 'Moodle'. You can then add additional roles to this group, which will be inherited by all Moodle users. You can also use the group role name ROLE_GROUP_MOODLE in Event or Series ACLs.","title":"Moodle User Provider"},{"location":"configuration/security.user.moodle/#what-it-does","text":"The Moodle User Provider enriches Opencast users with a set of roles made up of the user's membership in Moodle courses, of the form COURSEID_Role. For example, an Opencast user who is also a Moodle user and a member of the Moodle course myCourseID with the Moodle capability tool/opencast:learner will be granted the Opencast role myCourseID_Learner . Analogously, users with the capability tool/opencast:instructor will receive the Opencast role myCourseID_Instructor . Note that by default, Moodle course IDs are opaque ID values such as 10765 . The ROLE_GROUP_MOODLE Opencast group role is granted to all users that also exist in Moodle. The mapping of Moodle courses and capabilities to Opencast roles is consistent with the course and role mapping used by the LTI endpoint. The Moodle User Provider can therefore be used with LTI or another method of authenticating users. The Moodle Role Provider allows Moodle course and capability combinations to be used in Event and Series ACLs. For example, the role myCourseID_Learner can be added to a Series ACL to grant access to the Series to members of the myCourseID course in Moodle.","title":"What it does"},{"location":"configuration/security.user.moodle/#requirements","text":"The Moodle User Provider requires the moodle-tool_opencast plug-in that extends Moodle with the necessary API functions and capabilities. As this plug-in also provides base settings for additional Moodle plug-ins, the user is asked to provide Opencast API login information during the installation. The values can be arbitrary, if only the Moodle User Provider should be configured. After the installation, a new user with the capabilities webservice/rest:use , tool/opencast:externalapi , moodle/user:viewalldetails , moodle/user:viewdetails and moodle/site:accessallgroups has to be created. Then generate a new web service token and add that user to the \"Opencast web service\" service.","title":"Requirements"},{"location":"configuration/security.user.moodle/#step-1","text":"Edit etc/org.apache.karaf.features.cfg and make sure the opencast-moodle feature is listed in the featuresBoot option.","title":"Step 1"},{"location":"configuration/security.user.moodle/#step-2","text":"To enable the Moodle User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg Edit the configuration file to set your Moodle URL and the web service token of the Moodle user that should be used for API calls. # The URL and token for the Moodle REST webservice org.opencastproject.userdirectory.moodle.url=http://localhost/webservice/rest/server.php org.opencastproject.userdirectory.moodle.token=mytoken1234abcdef","title":"Step 2"},{"location":"configuration/security.user.moodle/#step-3","text":"Verify that the Moodle User Provider starts up with the correct Moodle URL by looking for a log entry like this: (MoodleUserProviderInstance:143) - Creating new MoodleUserProviderInstance(pid=org.opencastproject.userdirectory.moodle.378cdff4-825f-4b60-b1ed-33f75aa7f265, url=http://localhost/webservice/rest/server.php, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Moodle system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Moodle user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.moodle=DEBUG","title":"Step 3"},{"location":"configuration/security.user.moodle/#step-4","text":"You can grant additional roles to all Moodle users in Opencast by creating a group with the name 'Moodle'. You can then add additional roles to this group, which will be inherited by all Moodle users. You can also use the group role name ROLE_GROUP_MOODLE in Event or Series ACLs.","title":"Step 4"},{"location":"configuration/security.user.sakai/","text":"What it does The Sakai User Provider enriches Opencast users with a set of roles made up of the user's membership in Sakai sites, of the form SITEID_Role. For example, an Opencast user who is also a Sakai user and a member of the Sakai site mysiteid with the Sakai role Student will be granted the Opencast role mysiteid_Learner . Note that by default, Sakai site IDs are opaque GUID values such as d02f250e-be2d-4b72-009a-161d66ed6df9 . The mapping of Sakai sites and roles to Opencast roles is consistent with the site and role mapping used by the LTI endpoint. The Sakai User Provider can therefore be used with LTI or another method of authenticating users. The Sakai Role Provider allows Sakai site and role combinations to be used in Event and Series ACLs. For example, the role mysiteid_Learner can be added to a Series ACL to grant access to the Series to members of the mysiteid site in Sakai. Requirements The Sakai User Provider requires Sakai 11.0 or later, and an admin-equivalent account on the Sakai instance. Step 1 Edit etc/org.apache.karaf.features.cfg and make sure the opencast-sakai feature is listed in the featuresBoot option. Step 2 To enable the Sakai User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg Edit the configuration file to set your Sakai URL, and the username and password of the admin user on the Sakai system: sakai.url=https://mysakai.my.domain sakai.user=opencast sakai.password=CHANGE_ME Step 3 Verify that the Sakai User Provider starts up with the correct Sakai URL by looking for a log entry like this: (SakaiUserProviderInstance:154) - Creating new SakaiUserProviderInstance(pid=org.opencastproject.userdirectory.sakai.f1fad141-8cc8-41ee-b514-8dad00984af6, url=https://mysakai.my.domain, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Sakai system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab. If necessary, you can increase the logging detail from the Sakai user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.sakai=DEBUG Step 4 You can grant additional roles to all Sakai users in Opencast by creating a group with the title 'Sakai'. You can then add additional roles to this group, which will be inherited by all Sakai users. You can also use the group role name ROLE_GROUP_SAKAI in Event or Series ACLs.","title":"Sakai User Provider"},{"location":"configuration/security.user.sakai/#what-it-does","text":"The Sakai User Provider enriches Opencast users with a set of roles made up of the user's membership in Sakai sites, of the form SITEID_Role. For example, an Opencast user who is also a Sakai user and a member of the Sakai site mysiteid with the Sakai role Student will be granted the Opencast role mysiteid_Learner . Note that by default, Sakai site IDs are opaque GUID values such as d02f250e-be2d-4b72-009a-161d66ed6df9 . The mapping of Sakai sites and roles to Opencast roles is consistent with the site and role mapping used by the LTI endpoint. The Sakai User Provider can therefore be used with LTI or another method of authenticating users. The Sakai Role Provider allows Sakai site and role combinations to be used in Event and Series ACLs. For example, the role mysiteid_Learner can be added to a Series ACL to grant access to the Series to members of the mysiteid site in Sakai.","title":"What it does"},{"location":"configuration/security.user.sakai/#requirements","text":"The Sakai User Provider requires Sakai 11.0 or later, and an admin-equivalent account on the Sakai instance.","title":"Requirements"},{"location":"configuration/security.user.sakai/#step-1","text":"Edit etc/org.apache.karaf.features.cfg and make sure the opencast-sakai feature is listed in the featuresBoot option.","title":"Step 1"},{"location":"configuration/security.user.sakai/#step-2","text":"To enable the Sakai User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg Edit the configuration file to set your Sakai URL, and the username and password of the admin user on the Sakai system: sakai.url=https://mysakai.my.domain sakai.user=opencast sakai.password=CHANGE_ME","title":"Step 2"},{"location":"configuration/security.user.sakai/#step-3","text":"Verify that the Sakai User Provider starts up with the correct Sakai URL by looking for a log entry like this: (SakaiUserProviderInstance:154) - Creating new SakaiUserProviderInstance(pid=org.opencastproject.userdirectory.sakai.f1fad141-8cc8-41ee-b514-8dad00984af6, url=https://mysakai.my.domain, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Sakai system. Verify the roles granted to the user by opening the URL OPENCAST-URL/info/me.json in a new browser tab. If necessary, you can increase the logging detail from the Sakai user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.sakai=DEBUG","title":"Step 3"},{"location":"configuration/security.user.sakai/#step-4","text":"You can grant additional roles to all Sakai users in Opencast by creating a group with the title 'Sakai'. You can then add additional roles to this group, which will be inherited by all Sakai users. You can also use the group role name ROLE_GROUP_SAKAI in Event or Series ACLs.","title":"Step 4"},{"location":"configuration/serving-static-files/","text":"Serving Static Files Opencast comes with a central service for serving static content as well as providing capabilities like byte-range requests for seeking in larger media files. This service is used by almost all publications. The publish-enage , publish-oaipmh and publish-configurable operations are just a few examples of code relying on this. The service itself acts just like a web server and will serve any file in a specific folder if no authentication is configured to be required. Note that most of the files generated by Opencast are intentionally named in a way which makes them extremely hard to guess so that even when authentication checks are disabled, the file names still work like a share link and no one can just browse all available files. Usually, at least the following paths are delivered by this service: /static/ api /<media-package-id>/\u2026 /static/ engage-player /<media-package-id>/\u2026 /static/ internal /<media-package-id>/\u2026 /static/ oaipmh-default /<media-package-id>/\u2026 Securing Static Files The static file service has a plug-in mechanism which allows modules to claim specific patterns to protect its content. If this is enabled, access is denied to all files which are not claimed by such a plug-in. An example for a service providing protection is the search service which claims all /static/engage-player/\u2026 links and checks the access control lists published to Engage before allowing access. The configuration options for requiring authentication can be found in the service's configuration file at etc/org.opencastproject.fsresources.StaticResourceServlet.cfg . An alternative method to this is Opencast's token based authorization system which allows (and requires) to defer all security checks to external systems. Available Static File Authorization Plug-ins Simple Configurable Static File Authorization The configurable authorization plug-in allows to simply grant access to an arbitrary amount of pre-configured patterns. This can be used to easily allow access to a custom publication channel. By default, this allows access to OAI-PMH publications. The configuration for this plug-in can be found in etc/org.opencastproject.fsresources.SimpleConfigurableStaticFileAuthorization.cfg . Search Service / Engage Publication The \u201cengage\u201d publication is the publication to media module and player. The publication usually includes an access control list which is checked by both user interfaces (really by the underlying search service). The search service contains a static file authorization plug-in which also checks the files used by those interfaces (preview images, videos, \u2026) against the same access control lists, making sure that file links are not extracted and passed around. The pattern protected by the search service is /static/ engage-player /<media-package-id>/\u2026 For performance reasons, access control lists are cached for one minute per user, meaning that there may be a short delay when changing access control. Asset Manager (External API, Admin Interface, Internal) The admin interface and external API have their own publication channels. Access to these resources is based on access control lists stored in the asset manager which therefore comes with a static file authorization plug-in. The patterns to protect can be configured. By default, the asset manager static file authorization plug-in will protect the URL pattern /static/ api /<media-package-id>/\u2026 and /static/ internal /<media-package-id>/\u2026 Performance Optimization By default Opencast's static file service is reading files from the hard disk through its own code and then serving those files using the built-in Jetty HTTP server. This works perfectly fine, and is robust even on larger installations. Nevertheless, it is far from being the fastest option when it comes to serving static file content. Other projects, such as Nginx, have specialized in this and are much more performant. That is why the static file service supports X-Accel to defer the file transfer to Nginx while keeping the authentication and authorization parts in Opencast. The configuration to activate this feature can be found in the service configuration file at etc/org.opencastproject.fsresources.StaticResourceServlet.cfg : x.accel.redirect=/protected Configuring a path in this option will make Opencast return a X-Accel-Redirect header for the requested static file prefixed by the configured value instead of serving the actual content. This will be picked up by Nginx if it is used as reverse proxy and treated as an internal redirect to the actual files. Thus, for this to work, there needs to be a matching internal location configuration like this: location /protected { internal; alias /srv/opencast/downloads/; }","title":"Serving Static Files"},{"location":"configuration/serving-static-files/#serving-static-files","text":"Opencast comes with a central service for serving static content as well as providing capabilities like byte-range requests for seeking in larger media files. This service is used by almost all publications. The publish-enage , publish-oaipmh and publish-configurable operations are just a few examples of code relying on this. The service itself acts just like a web server and will serve any file in a specific folder if no authentication is configured to be required. Note that most of the files generated by Opencast are intentionally named in a way which makes them extremely hard to guess so that even when authentication checks are disabled, the file names still work like a share link and no one can just browse all available files. Usually, at least the following paths are delivered by this service: /static/ api /<media-package-id>/\u2026 /static/ engage-player /<media-package-id>/\u2026 /static/ internal /<media-package-id>/\u2026 /static/ oaipmh-default /<media-package-id>/\u2026","title":"Serving Static Files"},{"location":"configuration/serving-static-files/#securing-static-files","text":"The static file service has a plug-in mechanism which allows modules to claim specific patterns to protect its content. If this is enabled, access is denied to all files which are not claimed by such a plug-in. An example for a service providing protection is the search service which claims all /static/engage-player/\u2026 links and checks the access control lists published to Engage before allowing access. The configuration options for requiring authentication can be found in the service's configuration file at etc/org.opencastproject.fsresources.StaticResourceServlet.cfg . An alternative method to this is Opencast's token based authorization system which allows (and requires) to defer all security checks to external systems.","title":"Securing Static Files"},{"location":"configuration/serving-static-files/#available-static-file-authorization-plug-ins","text":"","title":"Available Static File Authorization Plug-ins"},{"location":"configuration/serving-static-files/#simple-configurable-static-file-authorization","text":"The configurable authorization plug-in allows to simply grant access to an arbitrary amount of pre-configured patterns. This can be used to easily allow access to a custom publication channel. By default, this allows access to OAI-PMH publications. The configuration for this plug-in can be found in etc/org.opencastproject.fsresources.SimpleConfigurableStaticFileAuthorization.cfg .","title":"Simple Configurable Static File Authorization"},{"location":"configuration/serving-static-files/#search-service-engage-publication","text":"The \u201cengage\u201d publication is the publication to media module and player. The publication usually includes an access control list which is checked by both user interfaces (really by the underlying search service). The search service contains a static file authorization plug-in which also checks the files used by those interfaces (preview images, videos, \u2026) against the same access control lists, making sure that file links are not extracted and passed around. The pattern protected by the search service is /static/ engage-player /<media-package-id>/\u2026 For performance reasons, access control lists are cached for one minute per user, meaning that there may be a short delay when changing access control.","title":"Search Service / Engage Publication"},{"location":"configuration/serving-static-files/#asset-manager-external-api-admin-interface-internal","text":"The admin interface and external API have their own publication channels. Access to these resources is based on access control lists stored in the asset manager which therefore comes with a static file authorization plug-in. The patterns to protect can be configured. By default, the asset manager static file authorization plug-in will protect the URL pattern /static/ api /<media-package-id>/\u2026 and /static/ internal /<media-package-id>/\u2026","title":"Asset Manager (External API, Admin Interface, Internal)"},{"location":"configuration/serving-static-files/#performance-optimization","text":"By default Opencast's static file service is reading files from the hard disk through its own code and then serving those files using the built-in Jetty HTTP server. This works perfectly fine, and is robust even on larger installations. Nevertheless, it is far from being the fastest option when it comes to serving static file content. Other projects, such as Nginx, have specialized in this and are much more performant. That is why the static file service supports X-Accel to defer the file transfer to Nginx while keeping the authentication and authorization parts in Opencast. The configuration to activate this feature can be found in the service configuration file at etc/org.opencastproject.fsresources.StaticResourceServlet.cfg : x.accel.redirect=/protected Configuring a path in this option will make Opencast return a X-Accel-Redirect header for the requested static file prefixed by the configured value instead of serving the actual content. This will be picked up by Nginx if it is used as reverse proxy and treated as an internal redirect to the actual files. Thus, for this to work, there needs to be a matching internal location configuration like this: location /protected { internal; alias /srv/opencast/downloads/; }","title":"Performance Optimization"},{"location":"configuration/stream-security/","text":"Configuration of Stream Security To get an introduction to stream security before deploying, please read the overview at: Stream Security Overview It is important to note that if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible. On a high level, to use Stream security, these steps are required: Install and configure the URL signing service and signing providers Configure Opencast services (and, optionally, 3rd party services) that use the signing infrastructure to sign requests Install and configure verification components URL Signing Service Installation There are three modules that are built by default and need to be present on each Opencast node in order to initiate URL signing: urlsigning-common urlsigning-service-api urlsigning-service-impl If these modules are present, the URL signing service will be available, to which the URL signing providers can then register themselves. Minimal Configuration Example This is a minimal configuration example which requires valid tokens for all static file downloads: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg : enabled=true url.regex.files=.*localhost:8080/static/.* etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg key.default.secret=THISISNOSECUREKEY key.default.url=http://localhost:8080/static/ etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg : key.default=THISISNOSECUREKEY Configuration of Signing Providers The GenericUrlSigningProvider that comes with Opencast has its own configuration file: etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg All signing providers follow the same configuration structure and support multiple configuration blocks, providing the settings for separate distributions (i.e. download or streaming servers, services or paths). Each signing key configuration consists of the following attributes: Key ID: Key identifier, e.g. demoKeyOne Key secret: Key value, e.g. 25DA2BA549CB62EF297977845259A . The key-length is not predefined, but a key length of at least 128 bit is recommended. Any larger value will not increase security of the underlying algorithm URL prefix: The URL signing provider will only sign URLs that start with this value. This allows to support multiple distributions and different key pairs Organization: Keys can be restricted to organizations so that different organizations use different keys. This attribute is optional. If not specified, the key can be used by all organizations A typical configuration looks like this: key.demoKeyOne.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyOne.url=http://download.opencast.org/engage key.demoKeyTwo.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo.url=http://download.opencast.org/custom key.demoKeyTwo.organization=mh_default_org It is also possible to use one key for multiple URL prefixes: key.demoKeyThree.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyThree.url.http=http://download.opencast.org/custom key.demoKeyThree.url.https=https://download.opencast.org/custom key.demoKeyThree.url.streaming=http://streaming.opencast.org/custom key.demoKeyThree.organization=mh_default_org A Java regular expression can be defined to identify URLs to be excluded from URL signing. Any URL that matches this anchored regex will not be signed. exclude.url.pattern=.*/.*/unprotected/.*/.* Configuration of URL Signing Timeout Values Once stream security is turned on by configuring the signing providers, multiple different services within Opencast will be signing URLs, and while some services are signing on behalf of administrative users working in the Opencast administrative user interface, others are signing URLs in order to grant access to learners playing back video content i.e. the functionality we have been talking about up to now. This section explains how to best configure URLs to ensure that they expire at the right time. This might be required if the default valid times do not seem secure enough or is more secure than needed. Signing for external access The lifetime of the signed URLs can be configured by setting a custom value for the property url.signing.expires.seconds that defines the validity in seconds. The default valid time is 7200 seconds (2 hours). The signed URLs can also be configured to restrict access to the user\u2019s IP address by setting the property url.signing.use.client.ip to true. By default this is disabled. Overview of configuration files for services that are able to automatically sign URLs on behalf of users: URLs That Are Signed Configuration File Name Video player content org.opencastproject.security.urlsigning.SigningMediaPackageSerializer.cfg Admin UI links org.opencastproject.adminui.endpoint.OsgiEventEndpoint.cfg Preview and editor files org.opencastproject.adminui.endpoint.ToolsEndpoint.cfg The URLs will be signed by the first signing provider that will accept the URL\u2019s path based upon the signing provider\u2019s configuration. This makes it flexible to support many different scenarios. For example, we could configure the signing provider to have one key for any URL that begins with one scheme, such as http, which would cover all of the URLs to be signed with a single key. Or it could be configured so that each different scheme and hostname pair would have a different keys protecting each host\u2019s URLs separately etc. Having the timing configurations separate from the key configuration allows the different types of URLs to be signed differently depending on the needs of the users without needing to configure this timing for all of the different keys. Signing for Opencast-internal access Signing of requests for internal use is performed by a core component called TrustedHttpClientImpl , which is used to establish all internal HTTP connections. More specifically, the HTTP client needs access to internal storage areas such as the working file repository as well as to distributed artifacts on the downloads and streaming servers, all of which are protected by verification components. The default expiration time for signed internal requests is 60 seconds. This can be changed by setting a value in seconds for the org.opencastproject.security.internal.url.signing.duration property in the custom.properties configuration file. Since those URLs are signed right before the request is made, the valid time of 60 seconds should be sufficiently long. Configuration of Verification Components The verification components ensure that only valid and correctly signed URLs are accessible at any given time. URLs which are not properly signed or have expired will be rejected. Out of the box, Opencast provides an internal verification component: Opencast internal UrlSigningFilter The following section is dedicated to the installation and configuration of the Opencast internal UrlSigningFilter. The stream security architecture allows the implementation for URL verification for third-party applications which are not covered in this documentation. Configuration of Opencast verification filter The Servlet filter providing the verification of requests to Opencast internal resources is implemented in the bundles: urlsigning-verifier-service-api urlsigning-verifier-service-impl The filter uses a set of regular expressions to determine which requests to an Opencast instance need to be verified. Installation The bundles are built by default and as soon as they are running in Opencast, the filter is active, and ready to be enabled. Configuration Two things need to be configured for the Opencast verification filter: key pairs used to verify the signatures paths and endpoints that need to be protected The configuration is located at: etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg Example: key.demoKeyOne=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo=C843C21ECF59F2B38872A1BCAA774 The entries in this file need to have the same values for the signing providers configuration. The second step is to configure the filter defining the endpoints to be protected. The configuration file is located at: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg The configuration defaults to a set of regular expressions which match all of the endpoints that serve files, and avoid protecting endpoints that only serve data. Therefore, the remaining step is enabling the filter by setting the property enabled to true and determining whether strict or non-strict verification of the resource is required. Note that strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If turned off, only the path to the resource will be considered. So if the resource http://httpdserver:8080/the/full/path/video.mp4 is requested, only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. As mentioned before, this is useful when using a load balancer so that the requested host name does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number. Example: enabled=true strict=true url.regex.collection=.*files\\/collection\\/.* url.regex.mediapackage=.*files\\/mediapackage\\/.* url.regex.staticfiles=(?\\=(.*staticfiles.*))(?=^(?!.*staticfiles.*url|.*docs.*).*$)(.*) url.regex.archive=.*archive\\/archive\\/mediapackage\\/.*\\/.*\\/.* url.regex.static=.*static.* Testing Once all components of Stream Security are installed and properly configured, it is important to verify that the system is working as expected. It is especially important to try to access resources that should not be accessible. The following explains how to test if Stream Security has been correctly configured. Step 1: Creating Signed URLs with Signing Endpoint The signing service provides a REST endpoint, which allows for the signing of arbitrary URLs. For manual use it is recommended to visit the endpoint\u2019s documentation page at http://localhost:8080/signing/docs . Is the URL accepted? Check if the URL to be signed is accepted by the signing service (or by one of its signing providers respectively) by using the /signing/accepts endpoint. If that is not the case, the configuration of the signing providers should be checked again to ensure that at least one signing provider is responsible for the URL in question. If the service is fully operational, the response code will be 200 OK and the response body either true (accepted) or false (refused). Step 2: Signing the URL On the same documentation page URLs can be signed using the /signing/sign endpoint, and the access policy may be specified in that form as well. With this, several scenarios can be tested. Examples are: URLs that have already expired or will expire at a known date URLs that are not yet valid (if you provided a validFrom data in the access policy) URLs that are missing some or all of the signing parameters (policy, keyId or signature) URLs that are attempting to use signing parameters (policy and signature) from a different signed URL Step 3: Verifying the URL The signed URLs can then be passed to the appropriate testing tool (web browser, cURL, player, \u2026) to test the functionality of the verification component(s). The following table is the return codes associated with different rejection conditions: Case Return Code If any of the query string parameters are missing or are the wrong case / spelt incorrectly Bad Request (400) If any of the required policy variables are missing Bad Request (400) No encryption key that matches the KeyID known by the plugin Bad Request (400) The Policy and Signature don\u2019t match in any way Forbidden (403) If client IP is specified and doesn\u2019t match Forbidden (403) The current time has passed the DateGreaterThan, the time the URL expires Gone (410) The current time is before the DateLessThan, the time the URL becomes available Gone (410) The components that verify a URL is signed will run before a request is checked to be valid, so if a non-existent URL is signed for example, the above conditions will need to be fixed before a missing (404) response code will be returned. Step 4: Inspect policy The generated policy which is added to the signed URLs can be inspected. It needs to be decoded from Base64 and the result must be a JSON document that contains exactly the values which have been passed during signing. Decoding this Base64 encoded policy eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRh dGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0 \u2026would result in this JSON document (policy): { \"Statement\":{ \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\", \"Condition\":{ \"DateLessThan\":1425170777000, \"DateGreaterThan\":1425084379000, \"IpAddress\":\"10.0.0.1\" } } } Inspecting and modifying the policy is useful for advanced testing, such as: URLs where the policy was modified after signing URLs where the policy was modified and resigned with a different key Further information For an overview of Stream Security: Stream Security Overview For further developer information, please have a look at the stream security section in the developer guide.","title":"Stream Security"},{"location":"configuration/stream-security/#configuration-of-stream-security","text":"To get an introduction to stream security before deploying, please read the overview at: Stream Security Overview It is important to note that if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible. On a high level, to use Stream security, these steps are required: Install and configure the URL signing service and signing providers Configure Opencast services (and, optionally, 3rd party services) that use the signing infrastructure to sign requests Install and configure verification components","title":"Configuration of Stream Security"},{"location":"configuration/stream-security/#url-signing-service-installation","text":"There are three modules that are built by default and need to be present on each Opencast node in order to initiate URL signing: urlsigning-common urlsigning-service-api urlsigning-service-impl If these modules are present, the URL signing service will be available, to which the URL signing providers can then register themselves.","title":"URL Signing Service Installation"},{"location":"configuration/stream-security/#minimal-configuration-example","text":"This is a minimal configuration example which requires valid tokens for all static file downloads: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg : enabled=true url.regex.files=.*localhost:8080/static/.* etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg key.default.secret=THISISNOSECUREKEY key.default.url=http://localhost:8080/static/ etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg : key.default=THISISNOSECUREKEY","title":"Minimal Configuration Example"},{"location":"configuration/stream-security/#configuration-of-signing-providers","text":"The GenericUrlSigningProvider that comes with Opencast has its own configuration file: etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg All signing providers follow the same configuration structure and support multiple configuration blocks, providing the settings for separate distributions (i.e. download or streaming servers, services or paths). Each signing key configuration consists of the following attributes: Key ID: Key identifier, e.g. demoKeyOne Key secret: Key value, e.g. 25DA2BA549CB62EF297977845259A . The key-length is not predefined, but a key length of at least 128 bit is recommended. Any larger value will not increase security of the underlying algorithm URL prefix: The URL signing provider will only sign URLs that start with this value. This allows to support multiple distributions and different key pairs Organization: Keys can be restricted to organizations so that different organizations use different keys. This attribute is optional. If not specified, the key can be used by all organizations A typical configuration looks like this: key.demoKeyOne.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyOne.url=http://download.opencast.org/engage key.demoKeyTwo.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo.url=http://download.opencast.org/custom key.demoKeyTwo.organization=mh_default_org It is also possible to use one key for multiple URL prefixes: key.demoKeyThree.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyThree.url.http=http://download.opencast.org/custom key.demoKeyThree.url.https=https://download.opencast.org/custom key.demoKeyThree.url.streaming=http://streaming.opencast.org/custom key.demoKeyThree.organization=mh_default_org A Java regular expression can be defined to identify URLs to be excluded from URL signing. Any URL that matches this anchored regex will not be signed. exclude.url.pattern=.*/.*/unprotected/.*/.*","title":"Configuration of Signing Providers"},{"location":"configuration/stream-security/#configuration-of-url-signing-timeout-values","text":"Once stream security is turned on by configuring the signing providers, multiple different services within Opencast will be signing URLs, and while some services are signing on behalf of administrative users working in the Opencast administrative user interface, others are signing URLs in order to grant access to learners playing back video content i.e. the functionality we have been talking about up to now. This section explains how to best configure URLs to ensure that they expire at the right time. This might be required if the default valid times do not seem secure enough or is more secure than needed.","title":"Configuration of URL Signing Timeout Values"},{"location":"configuration/stream-security/#signing-for-external-access","text":"The lifetime of the signed URLs can be configured by setting a custom value for the property url.signing.expires.seconds that defines the validity in seconds. The default valid time is 7200 seconds (2 hours). The signed URLs can also be configured to restrict access to the user\u2019s IP address by setting the property url.signing.use.client.ip to true. By default this is disabled. Overview of configuration files for services that are able to automatically sign URLs on behalf of users: URLs That Are Signed Configuration File Name Video player content org.opencastproject.security.urlsigning.SigningMediaPackageSerializer.cfg Admin UI links org.opencastproject.adminui.endpoint.OsgiEventEndpoint.cfg Preview and editor files org.opencastproject.adminui.endpoint.ToolsEndpoint.cfg The URLs will be signed by the first signing provider that will accept the URL\u2019s path based upon the signing provider\u2019s configuration. This makes it flexible to support many different scenarios. For example, we could configure the signing provider to have one key for any URL that begins with one scheme, such as http, which would cover all of the URLs to be signed with a single key. Or it could be configured so that each different scheme and hostname pair would have a different keys protecting each host\u2019s URLs separately etc. Having the timing configurations separate from the key configuration allows the different types of URLs to be signed differently depending on the needs of the users without needing to configure this timing for all of the different keys.","title":"Signing for external access"},{"location":"configuration/stream-security/#signing-for-opencast-internal-access","text":"Signing of requests for internal use is performed by a core component called TrustedHttpClientImpl , which is used to establish all internal HTTP connections. More specifically, the HTTP client needs access to internal storage areas such as the working file repository as well as to distributed artifacts on the downloads and streaming servers, all of which are protected by verification components. The default expiration time for signed internal requests is 60 seconds. This can be changed by setting a value in seconds for the org.opencastproject.security.internal.url.signing.duration property in the custom.properties configuration file. Since those URLs are signed right before the request is made, the valid time of 60 seconds should be sufficiently long.","title":"Signing for Opencast-internal access"},{"location":"configuration/stream-security/#configuration-of-verification-components","text":"The verification components ensure that only valid and correctly signed URLs are accessible at any given time. URLs which are not properly signed or have expired will be rejected. Out of the box, Opencast provides an internal verification component: Opencast internal UrlSigningFilter The following section is dedicated to the installation and configuration of the Opencast internal UrlSigningFilter. The stream security architecture allows the implementation for URL verification for third-party applications which are not covered in this documentation.","title":"Configuration of Verification Components"},{"location":"configuration/stream-security/#configuration-of-opencast-verification-filter","text":"The Servlet filter providing the verification of requests to Opencast internal resources is implemented in the bundles: urlsigning-verifier-service-api urlsigning-verifier-service-impl The filter uses a set of regular expressions to determine which requests to an Opencast instance need to be verified.","title":"Configuration of Opencast verification filter"},{"location":"configuration/stream-security/#installation","text":"The bundles are built by default and as soon as they are running in Opencast, the filter is active, and ready to be enabled.","title":"Installation"},{"location":"configuration/stream-security/#configuration","text":"Two things need to be configured for the Opencast verification filter: key pairs used to verify the signatures paths and endpoints that need to be protected The configuration is located at: etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg Example: key.demoKeyOne=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo=C843C21ECF59F2B38872A1BCAA774 The entries in this file need to have the same values for the signing providers configuration. The second step is to configure the filter defining the endpoints to be protected. The configuration file is located at: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg The configuration defaults to a set of regular expressions which match all of the endpoints that serve files, and avoid protecting endpoints that only serve data. Therefore, the remaining step is enabling the filter by setting the property enabled to true and determining whether strict or non-strict verification of the resource is required. Note that strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If turned off, only the path to the resource will be considered. So if the resource http://httpdserver:8080/the/full/path/video.mp4 is requested, only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. As mentioned before, this is useful when using a load balancer so that the requested host name does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number. Example: enabled=true strict=true url.regex.collection=.*files\\/collection\\/.* url.regex.mediapackage=.*files\\/mediapackage\\/.* url.regex.staticfiles=(?\\=(.*staticfiles.*))(?=^(?!.*staticfiles.*url|.*docs.*).*$)(.*) url.regex.archive=.*archive\\/archive\\/mediapackage\\/.*\\/.*\\/.* url.regex.static=.*static.*","title":"Configuration"},{"location":"configuration/stream-security/#testing","text":"Once all components of Stream Security are installed and properly configured, it is important to verify that the system is working as expected. It is especially important to try to access resources that should not be accessible. The following explains how to test if Stream Security has been correctly configured.","title":"Testing"},{"location":"configuration/stream-security/#step-1-creating-signed-urls-with-signing-endpoint","text":"The signing service provides a REST endpoint, which allows for the signing of arbitrary URLs. For manual use it is recommended to visit the endpoint\u2019s documentation page at http://localhost:8080/signing/docs .","title":"Step 1: Creating Signed URLs with Signing Endpoint"},{"location":"configuration/stream-security/#is-the-url-accepted","text":"Check if the URL to be signed is accepted by the signing service (or by one of its signing providers respectively) by using the /signing/accepts endpoint. If that is not the case, the configuration of the signing providers should be checked again to ensure that at least one signing provider is responsible for the URL in question. If the service is fully operational, the response code will be 200 OK and the response body either true (accepted) or false (refused).","title":"Is the URL accepted?"},{"location":"configuration/stream-security/#step-2-signing-the-url","text":"On the same documentation page URLs can be signed using the /signing/sign endpoint, and the access policy may be specified in that form as well. With this, several scenarios can be tested. Examples are: URLs that have already expired or will expire at a known date URLs that are not yet valid (if you provided a validFrom data in the access policy) URLs that are missing some or all of the signing parameters (policy, keyId or signature) URLs that are attempting to use signing parameters (policy and signature) from a different signed URL","title":"Step 2: Signing the URL"},{"location":"configuration/stream-security/#step-3-verifying-the-url","text":"The signed URLs can then be passed to the appropriate testing tool (web browser, cURL, player, \u2026) to test the functionality of the verification component(s). The following table is the return codes associated with different rejection conditions: Case Return Code If any of the query string parameters are missing or are the wrong case / spelt incorrectly Bad Request (400) If any of the required policy variables are missing Bad Request (400) No encryption key that matches the KeyID known by the plugin Bad Request (400) The Policy and Signature don\u2019t match in any way Forbidden (403) If client IP is specified and doesn\u2019t match Forbidden (403) The current time has passed the DateGreaterThan, the time the URL expires Gone (410) The current time is before the DateLessThan, the time the URL becomes available Gone (410) The components that verify a URL is signed will run before a request is checked to be valid, so if a non-existent URL is signed for example, the above conditions will need to be fixed before a missing (404) response code will be returned.","title":"Step 3: Verifying the URL"},{"location":"configuration/stream-security/#step-4-inspect-policy","text":"The generated policy which is added to the signed URLs can be inspected. It needs to be decoded from Base64 and the result must be a JSON document that contains exactly the values which have been passed during signing. Decoding this Base64 encoded policy eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRh dGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0 \u2026would result in this JSON document (policy): { \"Statement\":{ \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\", \"Condition\":{ \"DateLessThan\":1425170777000, \"DateGreaterThan\":1425084379000, \"IpAddress\":\"10.0.0.1\" } } } Inspecting and modifying the policy is useful for advanced testing, such as: URLs where the policy was modified after signing URLs where the policy was modified and resigned with a different key","title":"Step 4: Inspect policy"},{"location":"configuration/stream-security/#further-information","text":"For an overview of Stream Security: Stream Security Overview For further developer information, please have a look at the stream security section in the developer guide.","title":"Further information"},{"location":"configuration/trim-segments/","text":"Trim Segments This documentation describes how to configure Opencast to trim the start and end of a video as a default. By default, when trimming a video there are no trim segments at the start and at the end of the video. Adding trim segments would help resolve the issue of out of sync audio and video. The video from a network camera is encoded (e.g. H264) which means when data is captured it could be between key frames and therefore video and audio could be out of sync when it gets processed by FFmpeg. Setting the Configuration prop.admin.editor.segment.start_length Description: Length of trim segment at the beginning of each video. Format: An integer. Default: 0 Measurement: Milliseconds. prop.admin.editor.segment.end_length=3000 Description: Length of trim segment at the end of each video. Format: An integer. Default: 0 Measurement: Milliseconds. prop.admin.editor.segment.minimum_length=1000 Description: The minimum length of any one segment. Format: An integer. Default: 0 Measurement: Milliseconds. prop.admin.editor.previewmode.default=true Description: If the preview mode in the video editor is enabled per default. Format: Boolean Default: true","title":"Trim Segments"},{"location":"configuration/trim-segments/#trim-segments","text":"This documentation describes how to configure Opencast to trim the start and end of a video as a default. By default, when trimming a video there are no trim segments at the start and at the end of the video. Adding trim segments would help resolve the issue of out of sync audio and video. The video from a network camera is encoded (e.g. H264) which means when data is captured it could be between key frames and therefore video and audio could be out of sync when it gets processed by FFmpeg.","title":"Trim Segments"},{"location":"configuration/trim-segments/#setting-the-configuration","text":"","title":"Setting the Configuration"},{"location":"configuration/trim-segments/#propadmineditorsegmentstart_length","text":"Description: Length of trim segment at the beginning of each video. Format: An integer. Default: 0 Measurement: Milliseconds.","title":"prop.admin.editor.segment.start_length"},{"location":"configuration/trim-segments/#propadmineditorsegmentend_length3000","text":"Description: Length of trim segment at the end of each video. Format: An integer. Default: 0 Measurement: Milliseconds.","title":"prop.admin.editor.segment.end_length=3000"},{"location":"configuration/trim-segments/#propadmineditorsegmentminimum_length1000","text":"Description: The minimum length of any one segment. Format: An integer. Default: 0 Measurement: Milliseconds.","title":"prop.admin.editor.segment.minimum_length=1000"},{"location":"configuration/trim-segments/#propadmineditorpreviewmodedefaulttrue","text":"Description: If the preview mode in the video editor is enabled per default. Format: Boolean Default: true","title":"prop.admin.editor.previewmode.default=true"},{"location":"configuration/user-statistics.and.privacy/","text":"User Statistics and Privacy There exists a newer and more complete tracking service using Matomo included as a module . The Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for the footprint feature of the player and for the optional analytics component. Note that enabling all of the tracking options may result in legal problems depending on your country's privacy laws and the type of service you are running. The settings for tracking user data can be found in: .../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg Tracking of user data can be controlled on two levels. First, tracking can be generally activated or deactivated. Second, if it is activated, the data being tracked can be defined. org.opencastproject.usertracking.detailedtrack defines if the user tracking JavaScript code is loaded and data about user actions are being sent to and stored by Opencast. Deactivating this will effectively stop all tracking. This may effect features like the footprints in the Opencast player. Default: true . If tracking is still activated, the following keys may be used to define the kind of data that is being tracked. The keys have no effect if tracking is turned off. Key Data to be tracked Default value org.opencastproject.usertracking.log.ip IP addresses false org.opencastproject.usertracking.log.user login names of users false org.opencastproject.usertracking.log.session Browser session-IDs false If you want to use the footprint feature but do not want to store any user specific data you can turn the tracking of IP addresses, usernames and session-IDs off.","title":"User Statistics and Privacy Configuration"},{"location":"configuration/user-statistics.and.privacy/#user-statistics-and-privacy","text":"There exists a newer and more complete tracking service using Matomo included as a module . The Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for the footprint feature of the player and for the optional analytics component. Note that enabling all of the tracking options may result in legal problems depending on your country's privacy laws and the type of service you are running. The settings for tracking user data can be found in: .../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg Tracking of user data can be controlled on two levels. First, tracking can be generally activated or deactivated. Second, if it is activated, the data being tracked can be defined. org.opencastproject.usertracking.detailedtrack defines if the user tracking JavaScript code is loaded and data about user actions are being sent to and stored by Opencast. Deactivating this will effectively stop all tracking. This may effect features like the footprints in the Opencast player. Default: true . If tracking is still activated, the following keys may be used to define the kind of data that is being tracked. The keys have no effect if tracking is turned off. Key Data to be tracked Default value org.opencastproject.usertracking.log.ip IP addresses false org.opencastproject.usertracking.log.user login names of users false org.opencastproject.usertracking.log.session Browser session-IDs false If you want to use the footprint feature but do not want to store any user specific data you can turn the tracking of IP addresses, usernames and session-IDs off.","title":"User Statistics and Privacy"},{"location":"configuration/workflow/","text":"Create a Custom Workflow Creating custom workflows can be complex. Some members of the community have contributed their production workflows to a public repo. Community Workflow Repository Please feel free to contribute your workflows when you have Opencast in production! This document will help you get started with creating your own Opencast workflows. For a list of available workflow operations, see: List of Workflow Operation Handler Overview A Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their repetition in a given workflow. Workflow operations can be configured using configuration elements. The use of string replacement in configuration values allows workflows to dynamically adapt to a given input or user decision. Document Opencast workflows are defined in XML. The structure of a Opencast workflow looks like this: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id></id> <title></title> <tags></tags> <description></description> <displayOrder></displayOrder> <!-- Operations --> <operations> <operation></operation> ... </operations> </definition> Create a Workflow This section will walk you through creating a custom workflow, which will encode ingested tracks to defined output format. Step 1: Encoding Profiles First create or select the encoding profiles you want to use. For more details on this, have a look at the Encoding Profile Configuration Guide . For this guide we assume that we have an encoding profile mov-low.http which creates a distribution format definition for mp4 video and a feed-cover.http encoding profile to create thumbnail images for the videos. Step 2: Describe the Workflow Start by naming the workflow and giving it a meaningful description: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id>example</id> <!-- Optionally specify an organization --> <organization>mh_default_org</organization> <!-- optionally specify roles for this workflow --> <roles> <role>ROLE_ADMIN</role> </roles> <title>Encode Mp4, Distribute and Publish</title> <tags> <!-- Tell the UI where to show this workflow --> <tag>upload</tag> <tag>schedule</tag> <tag>archive</tag> </tags> <description> 1. Encode to Mp4 and thumbnail. 2. Distribute to local repository. 3. Publish to search index. </description> <displayOrder>10</displayOrder> <!-- Operations --> <operations></operations> </definition> The id is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier is unique among all endpoints in the system (except in multitenant workflows, see organization below). The organization specifies the organization this workflow is valid for (thus, it only makes sense in multitenant installations). If there are two workflows with the same id, the one corresponding to the user\u2019s organization is always chosen. This pertains workflow dropdowns (for example, the \u201cAdd new event\u201d dropdown) as well as workflows included in other workflows via the include workflow operation handler. The roles define which user roles are allowed to see and start this workflow (a user needs one of the roles provided in the definition). If this is omitted or no roles are specified, everyone can see and start the workflow (provided the organization constraints are satisfied). Also, users with ROLE_ADMIN can see and start every workflow. Note that the workflows included in Opencast do not set roles. The tags define where the user interfaces may use these workflows. Useful tags are: upload : Usable for uploaded media schedule : Usable for scheduled events archive : Usable for archived media delete : Usable for deletion of events with publications editor : Usable from the video editor The displayOrder is an integer that indicates in what order workflow definitions shall be displayed by clients. If omitted, the displayOrder defaults to 0 . Clients are expected to list workflow definitions in descending order. The description allows you to describe the workflow in detail. Blank lines are formatted as newlines, while single line breaks are ignored so that the XML remains compact and readable even with long paragraphs. Step 3: Inspect the Media The first operation will be to inspect the media for technical metadata, such as format and length: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> <operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media package\"> </operation> </operations> </definition> The fail-on-error attribute is a boolean determining whether the workflow will throw an error to the exception-handler-workflow or simply proceed with the remaining operations. Step 4: Encoding The next operations will encode the media to the Mp4 format: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> ... <!-- encode: mp4 --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to mp4\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to mp4\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"target-flavor\">presentation/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> </operations> </definition> The target-tags attribute causes the resulting media to be tagged. For example, this could be used to define these media as input for other operations, using their source-tags attribute. The encoding-profile attribute refers to an encoding profile defined in etc/encoding . Step 5: Encode to Thumbnail The next operations will create thumbnails from the media: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> ... <!-- encode: images --> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> </operations> </definition> The time attribute determines the approximate frame of the source media is used. The time unit is in seconds. Step 6: Distribute the Media The next operation copies the encoded media to the Opencast distribution channel: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> <!-- distribute: local --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute media to the local distribution channel\"> <configurations> <configuration key=\"download-source-tags\">publish,rss,atom</configuration> <configuration key=\"streaming-source-tags\"></configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation> </operations> </definition> The publish-engage operation uses all media tagged as rss or atom as input. Accept User Input Workflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to select optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition must: use the ${variable} notation in the workflow definition contain a custom configuration panel. Here is an example of a configurable operation: <operation id=\"...\" if=\"${somevar}\"> ... </operation> The attribute if specifies the execution condition in means of the operation only being executed if that condition evaluates to true. You can find more details on conditional execution in the next section. Once the operation is configured to accept a variable, we need to describe how to gather the value from the administrative user. The <configuration_panel> element of a workflow definitions describes this user interface snippet. A simple configuration panel could look like this: <configuration_panel> <![CDATA[ <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" /> <label for=\"someaction\">Execute some operation?</label> ]]> </configuration_panel> The checkbox in this <configuration_panel> will now be displayed in the administrative tools, and the user's selection will be used to replace the ${someaction} variable in the workflow. This input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do not load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent this, the defaults operation can be used. Conditional Execution The attribute if of the operation element can be used to specify a condition to control whether the workflow operation should be executed. This so-called execution condition is a boolean expression of the following form: <expression> ::= <term> [\"OR\" <expression>] <term> ::= <value> [\"AND\" <term>] <value> ::= [\"NOT\"]* ( \"(\" <expression> \")\" | <relation> | <bool-literal> ) <relation> ::= <relation-factor> <rel-literal> <relation-factor> <relation-factor> ::= <operation> | <atom> <operation> ::= <atom> <op-literal> <atom> <rel-literal> ::= \">=\" | \">\" | \"<=\" | \"<\" | \"==\" | \"!=\" <op-literal> ::= \"+\" | \"-\" | \"*\" | \"/\" <bool-literal> ::= \"true\" | \"false\" <atom> ::= <number> | <string> As the formal description above explains, such boolean expressions may contain\u2026 \u2026the boolean constants true and false . \u2026numbers, which may contain a decimal point. \u2026strings, which must be surrounded by single-quotes. Escaping of single quotes is supported, just use two single quotes next to each other: 'foo''bar' \u2026as well as references to the variables of the workflow instance that contain these data types. Variables are enclosed in in ${} , as shown below. A default value may be specified for a variable, after the name, separated by a colon, as such: ${foo:1} . The default value will be used in case the variable doesn\u2019t exist. If no default value is specified, false will be used. This, of course, only makes sense in boolean contexts. Be aware to specify a default value in relations such as ${foo} < ${bar} . Example for simple boolean expressions: <operation id=\"...\" if=\"${variableName1} AND NOT (${variableName2} OR ${variableName3})\"> \u2026 </operation> Example for string comparisons: <operation id=\"...\" if=\"${captureAgentVendor} == 'ACME Corporation'\"> \u2026 </operation> Note that operations containing strings and numbers are somewhat well-behaved, for example, the following operation gets executed because 3 is converted to a string and then added to the string '4' : <operation id=\"...\" if=\"3+'4' == '34'\"> \u2026 </operation> Note that XML requires certain characters like the < and > operators to be written as XML entities. Even if they are used quoted in attributes. The following table shows all those characters: \" \u2192 &quot; ' \u2192 &apos; < \u2192 &lt; > \u2192 &gt; & \u2192 &amp; Example: <operation id=\"...\" if=\"${yresolution} &gt; 720\"> \u2026 </operation> Thumbnail Support The Admin UI comes with explicit support for thumbnails that are supposed to represent events visually, e.g. in lists of events as commonly used in video portals and other similar systems. To make it possible to implement the required processing and retain flexibility, the Admin UI will store the following information in variables of workflow instances: Variable Description thumbnailType The type of the thumbnail as number (see table below) thumbnailPosition The time position in case of snapshot thumbnails thumbnailTrack The source track in case of snapshot thumbnails Thumbnail Type Description 0 The default thumbnail shall be extracted at a configured time position 1 The thumbnail has been uploaded and is stored in the asset manager as media package attachment 2 The thumbnail shall be extracted at a given time position from a given track To fully support the thumbnail feature, your workflows should take care of creating the different types of thumbnails and be consistent to the Admin UI thumbnail configuration (see Thumbnail Configuration ) Test the Workflow The easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast automatically and will be available in Opencast a few seconds later.","title":"Workflow"},{"location":"configuration/workflow/#create-a-custom-workflow","text":"Creating custom workflows can be complex. Some members of the community have contributed their production workflows to a public repo. Community Workflow Repository Please feel free to contribute your workflows when you have Opencast in production! This document will help you get started with creating your own Opencast workflows. For a list of available workflow operations, see: List of Workflow Operation Handler","title":"Create a Custom Workflow"},{"location":"configuration/workflow/#overview","text":"A Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their repetition in a given workflow. Workflow operations can be configured using configuration elements. The use of string replacement in configuration values allows workflows to dynamically adapt to a given input or user decision.","title":"Overview"},{"location":"configuration/workflow/#document","text":"Opencast workflows are defined in XML. The structure of a Opencast workflow looks like this: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id></id> <title></title> <tags></tags> <description></description> <displayOrder></displayOrder> <!-- Operations --> <operations> <operation></operation> ... </operations> </definition>","title":"Document"},{"location":"configuration/workflow/#create-a-workflow","text":"This section will walk you through creating a custom workflow, which will encode ingested tracks to defined output format.","title":"Create a Workflow"},{"location":"configuration/workflow/#step-1-encoding-profiles","text":"First create or select the encoding profiles you want to use. For more details on this, have a look at the Encoding Profile Configuration Guide . For this guide we assume that we have an encoding profile mov-low.http which creates a distribution format definition for mp4 video and a feed-cover.http encoding profile to create thumbnail images for the videos.","title":"Step 1: Encoding Profiles"},{"location":"configuration/workflow/#step-2-describe-the-workflow","text":"Start by naming the workflow and giving it a meaningful description: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id>example</id> <!-- Optionally specify an organization --> <organization>mh_default_org</organization> <!-- optionally specify roles for this workflow --> <roles> <role>ROLE_ADMIN</role> </roles> <title>Encode Mp4, Distribute and Publish</title> <tags> <!-- Tell the UI where to show this workflow --> <tag>upload</tag> <tag>schedule</tag> <tag>archive</tag> </tags> <description> 1. Encode to Mp4 and thumbnail. 2. Distribute to local repository. 3. Publish to search index. </description> <displayOrder>10</displayOrder> <!-- Operations --> <operations></operations> </definition> The id is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier is unique among all endpoints in the system (except in multitenant workflows, see organization below). The organization specifies the organization this workflow is valid for (thus, it only makes sense in multitenant installations). If there are two workflows with the same id, the one corresponding to the user\u2019s organization is always chosen. This pertains workflow dropdowns (for example, the \u201cAdd new event\u201d dropdown) as well as workflows included in other workflows via the include workflow operation handler. The roles define which user roles are allowed to see and start this workflow (a user needs one of the roles provided in the definition). If this is omitted or no roles are specified, everyone can see and start the workflow (provided the organization constraints are satisfied). Also, users with ROLE_ADMIN can see and start every workflow. Note that the workflows included in Opencast do not set roles. The tags define where the user interfaces may use these workflows. Useful tags are: upload : Usable for uploaded media schedule : Usable for scheduled events archive : Usable for archived media delete : Usable for deletion of events with publications editor : Usable from the video editor The displayOrder is an integer that indicates in what order workflow definitions shall be displayed by clients. If omitted, the displayOrder defaults to 0 . Clients are expected to list workflow definitions in descending order. The description allows you to describe the workflow in detail. Blank lines are formatted as newlines, while single line breaks are ignored so that the XML remains compact and readable even with long paragraphs.","title":"Step 2: Describe the Workflow"},{"location":"configuration/workflow/#step-3-inspect-the-media","text":"The first operation will be to inspect the media for technical metadata, such as format and length: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> <operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media package\"> </operation> </operations> </definition> The fail-on-error attribute is a boolean determining whether the workflow will throw an error to the exception-handler-workflow or simply proceed with the remaining operations.","title":"Step 3: Inspect the Media"},{"location":"configuration/workflow/#step-4-encoding","text":"The next operations will encode the media to the Mp4 format: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> ... <!-- encode: mp4 --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to mp4\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to mp4\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"target-flavor\">presentation/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> </operations> </definition> The target-tags attribute causes the resulting media to be tagged. For example, this could be used to define these media as input for other operations, using their source-tags attribute. The encoding-profile attribute refers to an encoding profile defined in etc/encoding .","title":"Step 4: Encoding"},{"location":"configuration/workflow/#step-5-encode-to-thumbnail","text":"The next operations will create thumbnails from the media: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> ... <!-- encode: images --> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> </operations> </definition> The time attribute determines the approximate frame of the source media is used. The time unit is in seconds.","title":"Step 5: Encode to Thumbnail"},{"location":"configuration/workflow/#step-6-distribute-the-media","text":"The next operation copies the encoded media to the Opencast distribution channel: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> <!-- distribute: local --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute media to the local distribution channel\"> <configurations> <configuration key=\"download-source-tags\">publish,rss,atom</configuration> <configuration key=\"streaming-source-tags\"></configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation> </operations> </definition> The publish-engage operation uses all media tagged as rss or atom as input.","title":"Step 6: Distribute the Media"},{"location":"configuration/workflow/#accept-user-input","text":"Workflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to select optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition must: use the ${variable} notation in the workflow definition contain a custom configuration panel. Here is an example of a configurable operation: <operation id=\"...\" if=\"${somevar}\"> ... </operation> The attribute if specifies the execution condition in means of the operation only being executed if that condition evaluates to true. You can find more details on conditional execution in the next section. Once the operation is configured to accept a variable, we need to describe how to gather the value from the administrative user. The <configuration_panel> element of a workflow definitions describes this user interface snippet. A simple configuration panel could look like this: <configuration_panel> <![CDATA[ <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" /> <label for=\"someaction\">Execute some operation?</label> ]]> </configuration_panel> The checkbox in this <configuration_panel> will now be displayed in the administrative tools, and the user's selection will be used to replace the ${someaction} variable in the workflow. This input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do not load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent this, the defaults operation can be used.","title":"Accept User Input"},{"location":"configuration/workflow/#conditional-execution","text":"The attribute if of the operation element can be used to specify a condition to control whether the workflow operation should be executed. This so-called execution condition is a boolean expression of the following form: <expression> ::= <term> [\"OR\" <expression>] <term> ::= <value> [\"AND\" <term>] <value> ::= [\"NOT\"]* ( \"(\" <expression> \")\" | <relation> | <bool-literal> ) <relation> ::= <relation-factor> <rel-literal> <relation-factor> <relation-factor> ::= <operation> | <atom> <operation> ::= <atom> <op-literal> <atom> <rel-literal> ::= \">=\" | \">\" | \"<=\" | \"<\" | \"==\" | \"!=\" <op-literal> ::= \"+\" | \"-\" | \"*\" | \"/\" <bool-literal> ::= \"true\" | \"false\" <atom> ::= <number> | <string> As the formal description above explains, such boolean expressions may contain\u2026 \u2026the boolean constants true and false . \u2026numbers, which may contain a decimal point. \u2026strings, which must be surrounded by single-quotes. Escaping of single quotes is supported, just use two single quotes next to each other: 'foo''bar' \u2026as well as references to the variables of the workflow instance that contain these data types. Variables are enclosed in in ${} , as shown below. A default value may be specified for a variable, after the name, separated by a colon, as such: ${foo:1} . The default value will be used in case the variable doesn\u2019t exist. If no default value is specified, false will be used. This, of course, only makes sense in boolean contexts. Be aware to specify a default value in relations such as ${foo} < ${bar} . Example for simple boolean expressions: <operation id=\"...\" if=\"${variableName1} AND NOT (${variableName2} OR ${variableName3})\"> \u2026 </operation> Example for string comparisons: <operation id=\"...\" if=\"${captureAgentVendor} == 'ACME Corporation'\"> \u2026 </operation> Note that operations containing strings and numbers are somewhat well-behaved, for example, the following operation gets executed because 3 is converted to a string and then added to the string '4' : <operation id=\"...\" if=\"3+'4' == '34'\"> \u2026 </operation> Note that XML requires certain characters like the < and > operators to be written as XML entities. Even if they are used quoted in attributes. The following table shows all those characters: \" \u2192 &quot; ' \u2192 &apos; < \u2192 &lt; > \u2192 &gt; & \u2192 &amp; Example: <operation id=\"...\" if=\"${yresolution} &gt; 720\"> \u2026 </operation>","title":"Conditional Execution"},{"location":"configuration/workflow/#thumbnail-support","text":"The Admin UI comes with explicit support for thumbnails that are supposed to represent events visually, e.g. in lists of events as commonly used in video portals and other similar systems. To make it possible to implement the required processing and retain flexibility, the Admin UI will store the following information in variables of workflow instances: Variable Description thumbnailType The type of the thumbnail as number (see table below) thumbnailPosition The time position in case of snapshot thumbnails thumbnailTrack The source track in case of snapshot thumbnails Thumbnail Type Description 0 The default thumbnail shall be extracted at a configured time position 1 The thumbnail has been uploaded and is stored in the asset manager as media package attachment 2 The thumbnail shall be extracted at a given time position from a given track To fully support the thumbnail feature, your workflows should take care of creating the different types of thumbnails and be consistent to the Admin UI thumbnail configuration (see Thumbnail Configuration )","title":"Thumbnail Support"},{"location":"configuration/workflow/#test-the-workflow","text":"The easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast automatically and will be available in Opencast a few seconds later.","title":"Test the Workflow"},{"location":"configuration/admin-ui/asset-upload/","text":"Asset Upload Options Description This guide will help you customize manual upload asset options for the Admin UI. Opencast event media packages reference several different types of assets. These may include video file tracks, metadata catalogs, image files and class handout notes. Some assets are automatically created through workflow events. Others need to be manually attached to the mediapackage. An example of automatically created assets are navigation slides. An example of a manually attached assets are handout notes. This guide describes how to customize the Admin UI to support new asset upload options. Default Setup Out of the box, Opencast provides preconfigured asset and source upload configuration. The configuration is a listprovider properties file: etc/listproviders/event.upload.asset.options.properties Two source types are enabled by default for use in the Admin UI. EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\\ \"id\":\"track_presenter\",\\ \"type\":\"track\",\\ \"flavorType\":\"presenter\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 1} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\\ \"id\":\"track_presentation\",\\ \"type\":\"track\",\\ \"flavorType\":\"presentation\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 2} Source upload options as displayed in the Admin UI Create event: Asset flavor and sub-flavor are used by default Opencast workflows. When you add new asset types, you may need to adjust workflows to process the new asset flavor. These workflow variables are available to workflows started by the create event or add asset action: Variable Name Type Description uploadedSearchPreview boolean true if manually uploaded preview image, false otherwise. Used to prevent image extraction overwrite in compose operation downloadSourceflavorsExist boolean true if download-source-flavors variable exists, false otherwise. Identifies existence of download-source-flavors variable for tagging download-source-flavors comma separated list A convenience variable that lists manually uploaded asset flavors. Example of variables in a workflow: <!-- Tag any optionally uploaded assets --> <operation id=\"tag\" if=\"${downloadSourceflavorsExist}\" exception-handler-workflow=\"partial-error\" description=\"Tagging uploaded assets for distribution\"> <configurations> <configuration key=\"source-flavors\">${download-source-flavors}</configuration> <configuration key=\"target-tags\">+engage-download</configuration> </configurations> </operation> How to Enable Preconfigured Asset Options Catalogs and attachments can be added to new and existing events. New source tracks can only be defined for the upload of new events. Some predefined catalog and attachment examples are commented out in the properties file. You can uncomment any of these to make them upload options in the Admin UI. The default workflow publish-uploaded-assets will automatically distribute, publish, and archive uploaded assets on existing events. # Attachments and catalogs upload options are for new and existing events. # Only one file can be uploaded for each of these options, the uploaded file replaces existing elements of the same # type and flavor in the mediapackage. # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_DFXP={\"id\":\"catalog_captions_dfxp\", \"type\": \"catalog\", # \"flavorType\": \"captions\", \"flavorSubType\": \"timedtext\", \"displayOrder\": 2} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT={\"id\":\"attachment_captions_webvtt\", # \"type\": \"attachment\", \"flavorType\": \"text\", \"flavorSubType\": \"webvtt\", \"displayOrder\": 3} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CLASS_HANDOUT_NOTES={\"id\": \"attachment_class_handout_notes\", # \"type\": \"attachment\", \"flavorType\": \"attachment\", \"flavorSubType\": \"notes\", \"displayOrder\": 4} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.SMIL={\"id\":\"catalog_smil\", \"type\":\"catalog\", \"flavorType\": \"smil\", # \"flavorSubType\": \"smil\", \"displayOrder\": 5} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.PREVIEW_IMAGE={\"id\":\"attachment_preview_image\", # \"type\":\"attachment\", \"flavorType\": \"presenter\",\"flavorSubType\": \"search+preview\", \"displayOrder\": 6} EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID=publish-uploaded-assets # The video source track upload options are only for new events. # Unlike the other assets, multiple source tracks can be uploaded for a single flavor. # The MULTIPLE_PARTS example shows how to enable choosing multiple source files for a single flavor. In this case, # a fictional \"multipart/part+source\". # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.MULTIPLE_PARTS={\"id\": \"track_parts\",\"type\":\"track\", # \"flavorType\": \"multipart\", \"flavorSubType\": \"part+source\", \"multiple\":true, \"displayOrder\": 10} # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.AUDIO_ONLY={\"id\": \"track_audio\",\"type\":\"track\", # \"flavorType\": \"presenter-audio\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 11} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\"id\": \"track_presenter\",\"type\":\"track\", \"flavorType\":\"presenter\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 12} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\"id\": \"track_presentation\",\"type\":\"track\", \"flavorType\":\"presentation\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 13} How to Upload Assets in the Admin UI After enabling an upload option, a new navigation area becomes visible in the \"Create event\", called \"Asset Upload\". Assets can be uploaded to new events. The \"Asset Upload\" navigation disappears for scheduled events. Assets cannot be uploaded for scheduled events until after the scheduled event is processed. The manually uploaded assets appear in the Create event summary To Upload an asset to an existing event, go into the existing event details Assets tab, and click \"Add Asset >\" link The option selection is the same as for Create event, except the \"Add Asset\" button automatically executes the workflow defined by EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID How to Create a New Asset Option The following steps will assist you in creating a new asset upload option. As mentioned before, only catalog and attachments can be added to existing events. New source types can be added to new events. Tasks: Modify etc/listproviders/event.upload.asset.options.properties For the title of the options displayed in the admin interface, either: add a translation for the new asset name to modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... or add a title field to the upload specification Modify your workflow from etc/workflows/... Test your changes The following steps describe how to change the properties configuration. Step 1. Determine your new option type and processing needs There are 3 asset upload types: track is a media source such as video file catalog is an XML formatted metadata file attachment can be any type of file. For example jpeg, pdf, text, etc. Tracks are usually associated with workflow processing. If you need special processing with your custom track flavors, update or create workflows to work with your new track flavor. Attachments and Catalogs, such as smil files, can also be used for processing. If you only need to publish manually uploaded assets with a unique flavor, this is already built into the default workflows. Step 2. Add your new option to the list configuration You add your new asset upload configuration as a row to this file: etc/listproviders/event.upload.asset.options.properties Copy an existing row as a template for your new asset. Retain the property key prefix EVENTS.EVENTS.NEW.SOURCE. or EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION. Your unique asset identifier will follow the last dot after the prefix, in all capital alphabetical characters. Underbars are allowed. CONFIGURATION values are in JSON object format. Attribute Example Description id track_presenter One of \"attachment\" or \"catalog\" or \"track\", underbar (_), unique text (no spaces) type track One of \"attachment\" or \"catalog\" or \"track\" to designate asset type (must match id prefix) flavorType presentation The primary flavor type. Used to reference asset in workflows, player, and media module flavorSubType source The sub flavor type. Used to identify the sub flavor of this flavor type multiple false true or false, used by the admin UI to enable single or multiple file input selection displayOrder 32 Integer number, used by the admin UI to sort the display of upload options in the UI displayOverride 'My New Catalog' A short asset title which overrides all translations displayFallback 'My New Catalog' A short asset title which displays when no translation is found displayOverride.SHORT 'Video of a Presenter' A short source title which overrides all translations displayFallback.SHORT 'Video of a Presenter' A short source title which displays when no translation is found displayOverride.DETAIL 'A recording that showing the lecturer speaking' A longer source description which overrides all translation displayFallback.DETAIL 'A recording that showing the lecturer speaking' A longer source description which displays when no translation is found accept 'video/*,.png' A list of accepted file formats as taken by the HTML \\<input>'s accept field. This field is optional. This has to be a list of comma separated values. Each value of the list can either be a IANA MediaType or a file ending. The parameter key is internationalized as the display text in the admin UI ref: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/ Step 3. Add translation for the new option The option property key is internationalized for display in the Admin UI. Add a translation for the option property when adding new option, otherwise the Admin UI will display the raw key. The translation language files are located: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... Example of US English translation for EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT : modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/lang-en_US.json { ... \"EVENTS\": { ... \"EVENTS\": { ... \"NEW\": { ... \"UPLOAD_ASSET\": { ... \"CAPTIONS_WEBVTT\" : \"Captions WebVTT\", ... Now you are ready to test and deploy.","title":"Manual Asset Upload"},{"location":"configuration/admin-ui/asset-upload/#asset-upload-options","text":"","title":"Asset Upload Options"},{"location":"configuration/admin-ui/asset-upload/#description","text":"This guide will help you customize manual upload asset options for the Admin UI. Opencast event media packages reference several different types of assets. These may include video file tracks, metadata catalogs, image files and class handout notes. Some assets are automatically created through workflow events. Others need to be manually attached to the mediapackage. An example of automatically created assets are navigation slides. An example of a manually attached assets are handout notes. This guide describes how to customize the Admin UI to support new asset upload options.","title":"Description"},{"location":"configuration/admin-ui/asset-upload/#default-setup","text":"Out of the box, Opencast provides preconfigured asset and source upload configuration. The configuration is a listprovider properties file: etc/listproviders/event.upload.asset.options.properties Two source types are enabled by default for use in the Admin UI. EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\\ \"id\":\"track_presenter\",\\ \"type\":\"track\",\\ \"flavorType\":\"presenter\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 1} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\\ \"id\":\"track_presentation\",\\ \"type\":\"track\",\\ \"flavorType\":\"presentation\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 2} Source upload options as displayed in the Admin UI Create event: Asset flavor and sub-flavor are used by default Opencast workflows. When you add new asset types, you may need to adjust workflows to process the new asset flavor. These workflow variables are available to workflows started by the create event or add asset action: Variable Name Type Description uploadedSearchPreview boolean true if manually uploaded preview image, false otherwise. Used to prevent image extraction overwrite in compose operation downloadSourceflavorsExist boolean true if download-source-flavors variable exists, false otherwise. Identifies existence of download-source-flavors variable for tagging download-source-flavors comma separated list A convenience variable that lists manually uploaded asset flavors. Example of variables in a workflow: <!-- Tag any optionally uploaded assets --> <operation id=\"tag\" if=\"${downloadSourceflavorsExist}\" exception-handler-workflow=\"partial-error\" description=\"Tagging uploaded assets for distribution\"> <configurations> <configuration key=\"source-flavors\">${download-source-flavors}</configuration> <configuration key=\"target-tags\">+engage-download</configuration> </configurations> </operation>","title":"Default Setup"},{"location":"configuration/admin-ui/asset-upload/#how-to-enable-preconfigured-asset-options","text":"Catalogs and attachments can be added to new and existing events. New source tracks can only be defined for the upload of new events. Some predefined catalog and attachment examples are commented out in the properties file. You can uncomment any of these to make them upload options in the Admin UI. The default workflow publish-uploaded-assets will automatically distribute, publish, and archive uploaded assets on existing events. # Attachments and catalogs upload options are for new and existing events. # Only one file can be uploaded for each of these options, the uploaded file replaces existing elements of the same # type and flavor in the mediapackage. # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_DFXP={\"id\":\"catalog_captions_dfxp\", \"type\": \"catalog\", # \"flavorType\": \"captions\", \"flavorSubType\": \"timedtext\", \"displayOrder\": 2} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT={\"id\":\"attachment_captions_webvtt\", # \"type\": \"attachment\", \"flavorType\": \"text\", \"flavorSubType\": \"webvtt\", \"displayOrder\": 3} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CLASS_HANDOUT_NOTES={\"id\": \"attachment_class_handout_notes\", # \"type\": \"attachment\", \"flavorType\": \"attachment\", \"flavorSubType\": \"notes\", \"displayOrder\": 4} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.SMIL={\"id\":\"catalog_smil\", \"type\":\"catalog\", \"flavorType\": \"smil\", # \"flavorSubType\": \"smil\", \"displayOrder\": 5} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.PREVIEW_IMAGE={\"id\":\"attachment_preview_image\", # \"type\":\"attachment\", \"flavorType\": \"presenter\",\"flavorSubType\": \"search+preview\", \"displayOrder\": 6} EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID=publish-uploaded-assets # The video source track upload options are only for new events. # Unlike the other assets, multiple source tracks can be uploaded for a single flavor. # The MULTIPLE_PARTS example shows how to enable choosing multiple source files for a single flavor. In this case, # a fictional \"multipart/part+source\". # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.MULTIPLE_PARTS={\"id\": \"track_parts\",\"type\":\"track\", # \"flavorType\": \"multipart\", \"flavorSubType\": \"part+source\", \"multiple\":true, \"displayOrder\": 10} # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.AUDIO_ONLY={\"id\": \"track_audio\",\"type\":\"track\", # \"flavorType\": \"presenter-audio\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 11} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\"id\": \"track_presenter\",\"type\":\"track\", \"flavorType\":\"presenter\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 12} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\"id\": \"track_presentation\",\"type\":\"track\", \"flavorType\":\"presentation\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 13}","title":"How to Enable Preconfigured Asset Options"},{"location":"configuration/admin-ui/asset-upload/#how-to-upload-assets-in-the-admin-ui","text":"After enabling an upload option, a new navigation area becomes visible in the \"Create event\", called \"Asset Upload\". Assets can be uploaded to new events. The \"Asset Upload\" navigation disappears for scheduled events. Assets cannot be uploaded for scheduled events until after the scheduled event is processed. The manually uploaded assets appear in the Create event summary To Upload an asset to an existing event, go into the existing event details Assets tab, and click \"Add Asset >\" link The option selection is the same as for Create event, except the \"Add Asset\" button automatically executes the workflow defined by EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID","title":"How to Upload Assets in the Admin UI"},{"location":"configuration/admin-ui/asset-upload/#how-to-create-a-new-asset-option","text":"The following steps will assist you in creating a new asset upload option. As mentioned before, only catalog and attachments can be added to existing events. New source types can be added to new events. Tasks: Modify etc/listproviders/event.upload.asset.options.properties For the title of the options displayed in the admin interface, either: add a translation for the new asset name to modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... or add a title field to the upload specification Modify your workflow from etc/workflows/... Test your changes The following steps describe how to change the properties configuration.","title":"How to Create a New Asset Option"},{"location":"configuration/admin-ui/asset-upload/#step-1-determine-your-new-option-type-and-processing-needs","text":"There are 3 asset upload types: track is a media source such as video file catalog is an XML formatted metadata file attachment can be any type of file. For example jpeg, pdf, text, etc. Tracks are usually associated with workflow processing. If you need special processing with your custom track flavors, update or create workflows to work with your new track flavor. Attachments and Catalogs, such as smil files, can also be used for processing. If you only need to publish manually uploaded assets with a unique flavor, this is already built into the default workflows.","title":"Step 1. Determine your new option type and processing needs"},{"location":"configuration/admin-ui/asset-upload/#step-2-add-your-new-option-to-the-list-configuration","text":"You add your new asset upload configuration as a row to this file: etc/listproviders/event.upload.asset.options.properties Copy an existing row as a template for your new asset. Retain the property key prefix EVENTS.EVENTS.NEW.SOURCE. or EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION. Your unique asset identifier will follow the last dot after the prefix, in all capital alphabetical characters. Underbars are allowed. CONFIGURATION values are in JSON object format. Attribute Example Description id track_presenter One of \"attachment\" or \"catalog\" or \"track\", underbar (_), unique text (no spaces) type track One of \"attachment\" or \"catalog\" or \"track\" to designate asset type (must match id prefix) flavorType presentation The primary flavor type. Used to reference asset in workflows, player, and media module flavorSubType source The sub flavor type. Used to identify the sub flavor of this flavor type multiple false true or false, used by the admin UI to enable single or multiple file input selection displayOrder 32 Integer number, used by the admin UI to sort the display of upload options in the UI displayOverride 'My New Catalog' A short asset title which overrides all translations displayFallback 'My New Catalog' A short asset title which displays when no translation is found displayOverride.SHORT 'Video of a Presenter' A short source title which overrides all translations displayFallback.SHORT 'Video of a Presenter' A short source title which displays when no translation is found displayOverride.DETAIL 'A recording that showing the lecturer speaking' A longer source description which overrides all translation displayFallback.DETAIL 'A recording that showing the lecturer speaking' A longer source description which displays when no translation is found accept 'video/*,.png' A list of accepted file formats as taken by the HTML \\<input>'s accept field. This field is optional. This has to be a list of comma separated values. Each value of the list can either be a IANA MediaType or a file ending. The parameter key is internationalized as the display text in the admin UI ref: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/","title":"Step 2. Add your new option to the list configuration"},{"location":"configuration/admin-ui/asset-upload/#step-3-add-translation-for-the-new-option","text":"The option property key is internationalized for display in the Admin UI. Add a translation for the option property when adding new option, otherwise the Admin UI will display the raw key. The translation language files are located: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... Example of US English translation for EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT : modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/lang-en_US.json { ... \"EVENTS\": { ... \"EVENTS\": { ... \"NEW\": { ... \"UPLOAD_ASSET\": { ... \"CAPTIONS_WEBVTT\" : \"Captions WebVTT\", ... Now you are ready to test and deploy.","title":"Step 3. Add translation for the new option"},{"location":"configuration/admin-ui/capture-agent-access/","text":"Capture Agent Access Control Opencast allows restrictions considering what a user or group of users can do with capture agents to be configured. This is no security feature and does not guarantee that users cannot access any of the functionality. There are three kinds of access restriction levels: Unrestricted Access: Full access to all capture agents Restricted Access: No access to any capture agent Selective Access: Selected access to a subset of capture agents Unrestricted Access Users that have the global administration role ( ROLE_ADMIN ) or the organization administration role (value depends on configuration) always have access to all capture agents. Restricted Access Unprivileged users by default have no permission to modify anything that is relevant to control capture agents. Those users cannot: Edit scheduling information of scheduled events (Events->Event Details->Scheduling is read-only) Edit workflow configuration of scheduled events (Events->Event Details->Processing is read-only) Schedule new events (Events->Add Event->Source will only allow upload) Delete scheduled events (Events->Actions->Delete and Events->Action->Delete) Remove capture agents (Locations->Locations->Action->Remove) Selective Access It is possible to selectively allow specific users or groups of users to access subsets of capture agents. Each capture agent has a role which is derived from its id by removing all non-alphanumerical characters and prepending the prefix ROLE_CAPTURE_AGENT_ . If a user with restricted access owns the roles of a set of given capture agents, the user has selective access to those capture agents. Example Capture agent ID: OpencastsCaptureAgent Derived role: ROLE_CAPTURE_AGENT_OPENCASTSCAPTUREAGENT If the user Bob with restricted access has the role ROLE_CAPTURE_AGENT_OPENCASTSCAPTUREAGENT , Bob is allowed to control the capture agent with the id Opencast's Capture Agent .","title":"Capture-Agent Access"},{"location":"configuration/admin-ui/capture-agent-access/#capture-agent-access-control","text":"Opencast allows restrictions considering what a user or group of users can do with capture agents to be configured. This is no security feature and does not guarantee that users cannot access any of the functionality. There are three kinds of access restriction levels: Unrestricted Access: Full access to all capture agents Restricted Access: No access to any capture agent Selective Access: Selected access to a subset of capture agents","title":"Capture Agent Access Control"},{"location":"configuration/admin-ui/capture-agent-access/#unrestricted-access","text":"Users that have the global administration role ( ROLE_ADMIN ) or the organization administration role (value depends on configuration) always have access to all capture agents.","title":"Unrestricted Access"},{"location":"configuration/admin-ui/capture-agent-access/#restricted-access","text":"Unprivileged users by default have no permission to modify anything that is relevant to control capture agents. Those users cannot: Edit scheduling information of scheduled events (Events->Event Details->Scheduling is read-only) Edit workflow configuration of scheduled events (Events->Event Details->Processing is read-only) Schedule new events (Events->Add Event->Source will only allow upload) Delete scheduled events (Events->Actions->Delete and Events->Action->Delete) Remove capture agents (Locations->Locations->Action->Remove)","title":"Restricted Access"},{"location":"configuration/admin-ui/capture-agent-access/#selective-access","text":"It is possible to selectively allow specific users or groups of users to access subsets of capture agents. Each capture agent has a role which is derived from its id by removing all non-alphanumerical characters and prepending the prefix ROLE_CAPTURE_AGENT_ . If a user with restricted access owns the roles of a set of given capture agents, the user has selective access to those capture agents. Example Capture agent ID: OpencastsCaptureAgent Derived role: ROLE_CAPTURE_AGENT_OPENCASTSCAPTUREAGENT If the user Bob with restricted access has the role ROLE_CAPTURE_AGENT_OPENCASTSCAPTUREAGENT , Bob is allowed to control the capture agent with the id Opencast's Capture Agent .","title":"Selective Access"},{"location":"configuration/admin-ui/event-filters/","text":"Events Filters Configuration At the top right of the admin UI a set of predefined filters for events are available, displayed with a description and the amount of events currently matching that filter. By default, the following filters are visible: Statistic Description Yesterday All events with a start date sometime yesterday. Today All events with a start date sometime today. Tomorrow All events with a start date sometime tomorrow. Scheduled All events with status Scheduled . Recording All events with status Recording . Running All events with status Running . Paused All events with status Paused . Failed All events with status Failed . Todo All events with status Finished and open comments. Finished All events with status Finished . Filters can be added or removed by editing the file etc/listproviders/adminui.stats.properties . For example, the Finished filter is defined as follows: FINISHED=\\ {\"filters\": [{\"name\": \"status\", \"filter\": \"FILTERS.EVENTS.STATUS.LABEL\", \\ \"value\": \"EVENTS.EVENTS.STATUS.PROCESSED\"}],\\ \"description\": \"DASHBOARD.FINISHED\",\\ \"order\":12} filters defines a list containing at least one filter. Each filter is defined with a name that defines the event property to filter on for the backend a filter that defines the event property to filter on for the frontend and the value that property is supposed to have description contains the (possibly translated) description displayed in the UI order controls the order the filters are shown in the UI Filters with relative time spans For defining filters that contain a relative time span like yesterday or this week value can contain an object instead of a string. This object has to contain a relativeDateSpan property which itself contains the fields from , to and unit . The unit defines the unit of time that is being considered, e.g. hour , day , week , month or year , while from and to specify the beginning and end of the time span by defining an integer offset relative to the current hour, day, ... depending on the unit. So if the unit is defined as day , 0 is the current day while -1 is yesterday and 1 is tomorrow. If the unit is week instead, 0 is the current week while -1 is the last and 1 the next week, and so on. Every date/time unit below the one defined by unit depends on whether the offset is defined by to or from . So if the unit is day , from: -1 would be the beginning of yesterday (so the time is 00:00:00 in the user's timezone) while to: -1 would be the end of yesterday (23:59:59). If the unit is week , from: -1 is the beginning of last week (which day is the first day of the week is defined by the user's locale) and to: 0 would be the end of this week, so a filter defined as LAST_TWO_WEEKS=\\ {\"filters\": [{\"name\": \"startDate\", \"filter\":\"FILTERS.EVENTS.START_DATE\", \"value\": {\"relativeDateSpan\": {\"from\": \"-2\", \"to\": \"0\", \"unit\": \"week\"}}}],\\ \"description\": \"DATES.LAST_TWO_WEEKS\",\\ \"order\":15} would cover all events whose start dates occur sometime during the last or current week. This functionality is implemented with the library Moment.js by adding the values of to or from to the current date and time while considering the defined unit. A list of valid unit strings can be found in the documentation . To be considered Since only one unit can be defined per filter, time spans like the beginning of this month until tomorrow are currently not possible. Be advised that a too big amount of filters can lead to filters disappearing from view depending on the width of the user's screen.","title":"Event Filters"},{"location":"configuration/admin-ui/event-filters/#events-filters-configuration","text":"At the top right of the admin UI a set of predefined filters for events are available, displayed with a description and the amount of events currently matching that filter. By default, the following filters are visible: Statistic Description Yesterday All events with a start date sometime yesterday. Today All events with a start date sometime today. Tomorrow All events with a start date sometime tomorrow. Scheduled All events with status Scheduled . Recording All events with status Recording . Running All events with status Running . Paused All events with status Paused . Failed All events with status Failed . Todo All events with status Finished and open comments. Finished All events with status Finished . Filters can be added or removed by editing the file etc/listproviders/adminui.stats.properties . For example, the Finished filter is defined as follows: FINISHED=\\ {\"filters\": [{\"name\": \"status\", \"filter\": \"FILTERS.EVENTS.STATUS.LABEL\", \\ \"value\": \"EVENTS.EVENTS.STATUS.PROCESSED\"}],\\ \"description\": \"DASHBOARD.FINISHED\",\\ \"order\":12} filters defines a list containing at least one filter. Each filter is defined with a name that defines the event property to filter on for the backend a filter that defines the event property to filter on for the frontend and the value that property is supposed to have description contains the (possibly translated) description displayed in the UI order controls the order the filters are shown in the UI","title":"Events Filters Configuration"},{"location":"configuration/admin-ui/event-filters/#filters-with-relative-time-spans","text":"For defining filters that contain a relative time span like yesterday or this week value can contain an object instead of a string. This object has to contain a relativeDateSpan property which itself contains the fields from , to and unit . The unit defines the unit of time that is being considered, e.g. hour , day , week , month or year , while from and to specify the beginning and end of the time span by defining an integer offset relative to the current hour, day, ... depending on the unit. So if the unit is defined as day , 0 is the current day while -1 is yesterday and 1 is tomorrow. If the unit is week instead, 0 is the current week while -1 is the last and 1 the next week, and so on. Every date/time unit below the one defined by unit depends on whether the offset is defined by to or from . So if the unit is day , from: -1 would be the beginning of yesterday (so the time is 00:00:00 in the user's timezone) while to: -1 would be the end of yesterday (23:59:59). If the unit is week , from: -1 is the beginning of last week (which day is the first day of the week is defined by the user's locale) and to: 0 would be the end of this week, so a filter defined as LAST_TWO_WEEKS=\\ {\"filters\": [{\"name\": \"startDate\", \"filter\":\"FILTERS.EVENTS.START_DATE\", \"value\": {\"relativeDateSpan\": {\"from\": \"-2\", \"to\": \"0\", \"unit\": \"week\"}}}],\\ \"description\": \"DATES.LAST_TWO_WEEKS\",\\ \"order\":15} would cover all events whose start dates occur sometime during the last or current week. This functionality is implemented with the library Moment.js by adding the values of to or from to the current date and time while considering the defined unit. A list of valid unit strings can be found in the documentation .","title":"Filters with relative time spans"},{"location":"configuration/admin-ui/event-filters/#to-be-considered","text":"Since only one unit can be defined per filter, time spans like the beginning of this month until tomorrow are currently not possible. Be advised that a too big amount of filters can lead to filters disappearing from view depending on the width of the user's screen.","title":"To be considered"},{"location":"configuration/admin-ui/languages/","text":"Language Configuration The admin UI is translated into a number of languages by default. If you wish to restrict the languages available to your users, add the relevant locale code to etc/org.opencastproject.adminui.endpoint.LanguageServiceEndpoint.cfg .","title":"Languages"},{"location":"configuration/admin-ui/languages/#language-configuration","text":"The admin UI is translated into a number of languages by default. If you wish to restrict the languages available to your users, add the relevant locale code to etc/org.opencastproject.adminui.endpoint.LanguageServiceEndpoint.cfg .","title":"Language Configuration"},{"location":"configuration/admin-ui/role-based-visibility/","text":"Role-Based Visibility Opencast supports a powerful mechanism that allows to provide users selective access to the administrative user interface. Using that mechanism, it is possible to configure what parts of the UI (and therefore functionality) are visible to a given user based on the user's roles. Hence, we call that mechanism role-based visibility. This is no security feature and does not guarantee that users cannot access any of the functionality. How To Use The best practice to assign a larger set of roles to a user is to use Opencast's support for user groups. This way, you can define a group whose roles provide access to the parts of the UI you want to provide access to. Given such a group, you can just add users to that group and they will get all the roles of the group which includes roles that allow the users to access specific parts of the UI. There is a set of so-called user interface roles, each of them providing access to a specific part of the administrative user interface. Those roles can be easily identified by their name prefix ROLE_UI . Important ROLE_ADMIN implicitly provides full access to the user interface. When working with role-based visibility, users (and the groups they belong to) may not have ROLE_ADMIN therefore. User Interface Roles This section describes which roles permit access to what parts of the user interface. Note that role-based visibility is not just hiding graphical elements from users, it does also protect server-side resources from unauthorized access if necessary. It is important to understand that the UI roles are not coupled, i.e. having a particular role does not imply any other permission than the one exactly provided by the role. Example: Just having the role ROLE_UI_NAV_CAPTURE_VIEW won't display the navigation menu. This requires the role ROLE_UI_NAV , too. The advantage of having independent roles is that it makes role-based visibility even more flexible, For example, it is possible to not use the navigation menu at all. The drawback of this approach is that it makes configuration more advanced. But configuring role-based visibility is not a daily tasks. General Access Important: ROLE_ADMIN_UI is required for accessing the admin ui in general in means of providing access to some often used resources Role User Interface ROLE_ADMIN_UI Allow user to access login page as well as commonly used resources Navigation Menu The navigation menu is the menu on the top-left that allows the user to navigate between subsections of the administrative user interface. Role User Interface ROLE_UI_NAV Display navigation menu ROLE_UI_NAV_RECORDINGS_VIEW Display navigation menu entry Recordings ROLE_UI_NAV_CAPTURE_VIEW Display navigation menu entry Capture ROLE_UI_NAV_SYSTEMS_VIEW Display navigation menu entry Systems ROLE_UI_NAV_ORGANIZATION_VIEW Display navigation menu entry Organization ROLE_UI_NAV_CONFIGURATION_VIEW Display navigation menu entry Configuration ROLE_UI_NAV_STATISTICS_VIEW Display navigation menu entry Statistics If you want to provide access to the navigation menu, ROLE_UI_NAV is needed. Then, for each of the navigation menu entries, include the respective role if the menu entry should be accessible by the user. Note that this really just controls the navigation menu and its menu entries. Not less, not more. Statistics: Organization Role User Interface ROLE_UI_STATISTICS_ORGANIZATION_VIEW Display Organization page Recordings: Events Role User Interface ROLE_UI_EVENTS_VIEW Display Events page ROLE_UI_EVENTS_COUNTERS_VIEW Display the Counters on the Events page ROLE_UI_EVENTS_CREATE Display Add Event button on Events page ROLE_UI_EVENTS_DELETE Display Delete action in Events table ROLE_UI_EVENTS_EDITOR_VIEW Display Playback/Editor action in Events table ROLE_UI_EVENTS_DETAILS_VIEW Display Event Details action in Events table ROLE_UI_TASKS_CREATE Display Actions on Events page For the Playback/Editor tool, further access can be provided: Role User Interface ROLE_UI_EVENTS_EDITOR_EDIT Allow the user to actually edit videos There are quite a number of roles to provide selective access to the tabs offered by the Event Details modal: Role User Interface ROLE_UI_EVENTS_DETAILS_METADATA_VIEW Display tab Metadata ROLE_UI_EVENTS_DETAILS_ASSETS_VIEW Display tab Assets ROLE_UI_EVENTS_DETAILS_PUBLICATIONS_VIEW Display tab Publications ROLE_UI_EVENTS_DETAILS_WORKFLOWS_VIEW Display tab Workflows ROLE_UI_EVENTS_DETAILS_SCHEDULING_VIEW Display tab Scheduling ROLE_UI_EVENTS_DETAILS_ACL_VIEW Display tab Access Policy ROLE_UI_EVENTS_DETAILS_COMMENTS_VIEW Display tab Comments ROLE_UI_EVENTS_DETAILS_STATISTICS_VIEW Display tab Statistics For the individual tabs, it is possible to further provide access: Role User Interface ROLE_UI_EVENTS_DETAILS_METADATA_EDIT Allow the user to edit Metadata ROLE_UI_EVENTS_DETAILS_ACL_EDIT Allow the user to edit Access Policy ROLE_UI_EVENTS_DETAILS_WORKFLOWS_EDIT Allow the user to edit Workflows ROLE_UI_EVENTS_DETAILS_WORKFLOWS_DELETE Allow the user to delete Workflows ROLE_UI_EVENTS_DETAILS_SCHEDULING_EDIT Allow the user to edit Scheduling ROLE_UI_EVENTS_DETAILS_COMMENTS_CREATE Allow the user to create comments ROLE_UI_EVENTS_DETAILS_COMMENTS_DELETE Allow the user to delete comments ROLE_UI_EVENTS_DETAILS_COMMENTS_EDIT Allow the user to edit comments ROLE_UI_EVENTS_DETAILS_COMMENTS_REPLY Allow the user to reply to comments ROLE_UI_EVENTS_DETAILS_COMMENTS_RESOLVE Allow the user to resolve comments Recordings: Series Role User Interface ROLE_UI_SERIES_VIEW Display Series page ROLE_UI_SERIES_CREATE Display Add Series on Series page ROLE_UI_SERIES_DELETE Display Delete action in Series table ROLE_UI_SERIES_DETAILS_VIEW Display Series Details action in Series table There are quite a number of roles to provide selective access to the tabs offered by the Series Details modal: Role User Interface ROLE_UI_SERIES_DETAILS_METADATA_VIEW Display tab Metadata ROLE_UI_SERIES_DETAILS_ACL_VIEW Display tab Access Policy ROLE_UI_SERIES_DETAILS_THEMES_VIEW Display tab Theme ROLE_UI_SERIES_DETAILS_STATISTICS_VIEW Display tab Statistics For the individual tabs, it is possible to further provide access: Role User Interface ROLE_UI_SERIES_DETAILS_METADATA_EDIT Allow the user to edit Metadata ROLE_UI_SERIES_DETAILS_ACL_EDIT Allow the user to edit Access Policy ROLE_UI_SERIES_DETAILS_THEMES_EDIT Allow the user to edit Theme Capture: Locations Role User Interface ROLE_UI_LOCATIONS_VIEW Display Locations page ROLE_UI_LOCATIONS_DELETE Display Delete action in Locations table ROLE_UI_LOCATIONS_DETAILS_VIEW Display Location Details action in Locations table There are quite a number of roles to provide selective access to the tabs offered by the Locations Details modal: Role User Interface ROLE_UI_LOCATIONS_DETAILS_CAPABILITIES_VIEW Display tab Capabilities ROLE_UI_LOCATIONS_DETAILS_CONFIGURATION_VIEW Display tab Configuration ROLE_UI_LOCATIONS_DETAILS_GENERAL_VIEW Display tab General Systems: Jobs, Servers and Services Role User Interface ROLE_UI_JOBS_VIEW Display Jobs page ROLE_UI_SERVERS_VIEW Display Servers page ROLE_UI_SERVICES_VIEW Display Services page On those pages, it is possible to further provide access: Role User Interface ROLE_UI_SERVERS_MAINTENANCE_EDIT Allow the user turn on/off server maintenance ROLE_UI_SERVICES_STATUS_EDIT Allow the user to sanitize services Organization: Users Role User Interface ROLE_UI_USERS_VIEW Display Users page ROLE_UI_USERS_CREATE Display Add user on Users page ROLE_UI_USERS_DELETE Display Delete action in Users table ROLE_UI_USERS_EDIT Display User Details action in Users table Organization: Groups Role User Interface ROLE_UI_GROUPS_VIEW Display Groups page ROLE_UI_GROUPS_CREATE Display Add groups on Groups page ROLE_UI_GROUPS_DELETE Display Delete action in Groups table ROLE_UI_GROUPS_EDIT Display Group Details action in Groups table Organization: Access Policies Role User Interface ROLE_UI_ACLS_VIEW Display Access Policies page ROLE_UI_ACLS_CREATE Display Add access policy on Access Policies page ROLE_UI_ACLS_DELETE Display Delete action in Access Policies table ROLE_UI_ACLS_EDIT Display Group Details action in Access Policies table Configuration: Themes Role User Interface ROLE_UI_THEMES_VIEW Display Themes page ROLE_UI_THEMES_CREATE Display Add theme on Themes page ROLE_UI_THEMES_DELETE Display Delete action in Themes table ROLE_UI_THEMES_EDIT Display Theme Details action in Themes table","title":"Role-based Visibility"},{"location":"configuration/admin-ui/role-based-visibility/#role-based-visibility","text":"Opencast supports a powerful mechanism that allows to provide users selective access to the administrative user interface. Using that mechanism, it is possible to configure what parts of the UI (and therefore functionality) are visible to a given user based on the user's roles. Hence, we call that mechanism role-based visibility. This is no security feature and does not guarantee that users cannot access any of the functionality.","title":"Role-Based Visibility"},{"location":"configuration/admin-ui/role-based-visibility/#how-to-use","text":"The best practice to assign a larger set of roles to a user is to use Opencast's support for user groups. This way, you can define a group whose roles provide access to the parts of the UI you want to provide access to. Given such a group, you can just add users to that group and they will get all the roles of the group which includes roles that allow the users to access specific parts of the UI. There is a set of so-called user interface roles, each of them providing access to a specific part of the administrative user interface. Those roles can be easily identified by their name prefix ROLE_UI . Important ROLE_ADMIN implicitly provides full access to the user interface. When working with role-based visibility, users (and the groups they belong to) may not have ROLE_ADMIN therefore.","title":"How To Use"},{"location":"configuration/admin-ui/role-based-visibility/#user-interface-roles","text":"This section describes which roles permit access to what parts of the user interface. Note that role-based visibility is not just hiding graphical elements from users, it does also protect server-side resources from unauthorized access if necessary. It is important to understand that the UI roles are not coupled, i.e. having a particular role does not imply any other permission than the one exactly provided by the role. Example: Just having the role ROLE_UI_NAV_CAPTURE_VIEW won't display the navigation menu. This requires the role ROLE_UI_NAV , too. The advantage of having independent roles is that it makes role-based visibility even more flexible, For example, it is possible to not use the navigation menu at all. The drawback of this approach is that it makes configuration more advanced. But configuring role-based visibility is not a daily tasks.","title":"User Interface Roles"},{"location":"configuration/admin-ui/role-based-visibility/#general-access","text":"Important: ROLE_ADMIN_UI is required for accessing the admin ui in general in means of providing access to some often used resources Role User Interface ROLE_ADMIN_UI Allow user to access login page as well as commonly used resources","title":"General Access"},{"location":"configuration/admin-ui/role-based-visibility/#navigation-menu","text":"The navigation menu is the menu on the top-left that allows the user to navigate between subsections of the administrative user interface. Role User Interface ROLE_UI_NAV Display navigation menu ROLE_UI_NAV_RECORDINGS_VIEW Display navigation menu entry Recordings ROLE_UI_NAV_CAPTURE_VIEW Display navigation menu entry Capture ROLE_UI_NAV_SYSTEMS_VIEW Display navigation menu entry Systems ROLE_UI_NAV_ORGANIZATION_VIEW Display navigation menu entry Organization ROLE_UI_NAV_CONFIGURATION_VIEW Display navigation menu entry Configuration ROLE_UI_NAV_STATISTICS_VIEW Display navigation menu entry Statistics If you want to provide access to the navigation menu, ROLE_UI_NAV is needed. Then, for each of the navigation menu entries, include the respective role if the menu entry should be accessible by the user. Note that this really just controls the navigation menu and its menu entries. Not less, not more.","title":"Navigation Menu"},{"location":"configuration/admin-ui/role-based-visibility/#statistics-organization","text":"Role User Interface ROLE_UI_STATISTICS_ORGANIZATION_VIEW Display Organization page","title":"Statistics: Organization"},{"location":"configuration/admin-ui/role-based-visibility/#recordings-events","text":"Role User Interface ROLE_UI_EVENTS_VIEW Display Events page ROLE_UI_EVENTS_COUNTERS_VIEW Display the Counters on the Events page ROLE_UI_EVENTS_CREATE Display Add Event button on Events page ROLE_UI_EVENTS_DELETE Display Delete action in Events table ROLE_UI_EVENTS_EDITOR_VIEW Display Playback/Editor action in Events table ROLE_UI_EVENTS_DETAILS_VIEW Display Event Details action in Events table ROLE_UI_TASKS_CREATE Display Actions on Events page For the Playback/Editor tool, further access can be provided: Role User Interface ROLE_UI_EVENTS_EDITOR_EDIT Allow the user to actually edit videos There are quite a number of roles to provide selective access to the tabs offered by the Event Details modal: Role User Interface ROLE_UI_EVENTS_DETAILS_METADATA_VIEW Display tab Metadata ROLE_UI_EVENTS_DETAILS_ASSETS_VIEW Display tab Assets ROLE_UI_EVENTS_DETAILS_PUBLICATIONS_VIEW Display tab Publications ROLE_UI_EVENTS_DETAILS_WORKFLOWS_VIEW Display tab Workflows ROLE_UI_EVENTS_DETAILS_SCHEDULING_VIEW Display tab Scheduling ROLE_UI_EVENTS_DETAILS_ACL_VIEW Display tab Access Policy ROLE_UI_EVENTS_DETAILS_COMMENTS_VIEW Display tab Comments ROLE_UI_EVENTS_DETAILS_STATISTICS_VIEW Display tab Statistics For the individual tabs, it is possible to further provide access: Role User Interface ROLE_UI_EVENTS_DETAILS_METADATA_EDIT Allow the user to edit Metadata ROLE_UI_EVENTS_DETAILS_ACL_EDIT Allow the user to edit Access Policy ROLE_UI_EVENTS_DETAILS_WORKFLOWS_EDIT Allow the user to edit Workflows ROLE_UI_EVENTS_DETAILS_WORKFLOWS_DELETE Allow the user to delete Workflows ROLE_UI_EVENTS_DETAILS_SCHEDULING_EDIT Allow the user to edit Scheduling ROLE_UI_EVENTS_DETAILS_COMMENTS_CREATE Allow the user to create comments ROLE_UI_EVENTS_DETAILS_COMMENTS_DELETE Allow the user to delete comments ROLE_UI_EVENTS_DETAILS_COMMENTS_EDIT Allow the user to edit comments ROLE_UI_EVENTS_DETAILS_COMMENTS_REPLY Allow the user to reply to comments ROLE_UI_EVENTS_DETAILS_COMMENTS_RESOLVE Allow the user to resolve comments","title":"Recordings: Events"},{"location":"configuration/admin-ui/role-based-visibility/#recordings-series","text":"Role User Interface ROLE_UI_SERIES_VIEW Display Series page ROLE_UI_SERIES_CREATE Display Add Series on Series page ROLE_UI_SERIES_DELETE Display Delete action in Series table ROLE_UI_SERIES_DETAILS_VIEW Display Series Details action in Series table There are quite a number of roles to provide selective access to the tabs offered by the Series Details modal: Role User Interface ROLE_UI_SERIES_DETAILS_METADATA_VIEW Display tab Metadata ROLE_UI_SERIES_DETAILS_ACL_VIEW Display tab Access Policy ROLE_UI_SERIES_DETAILS_THEMES_VIEW Display tab Theme ROLE_UI_SERIES_DETAILS_STATISTICS_VIEW Display tab Statistics For the individual tabs, it is possible to further provide access: Role User Interface ROLE_UI_SERIES_DETAILS_METADATA_EDIT Allow the user to edit Metadata ROLE_UI_SERIES_DETAILS_ACL_EDIT Allow the user to edit Access Policy ROLE_UI_SERIES_DETAILS_THEMES_EDIT Allow the user to edit Theme","title":"Recordings: Series"},{"location":"configuration/admin-ui/role-based-visibility/#capture-locations","text":"Role User Interface ROLE_UI_LOCATIONS_VIEW Display Locations page ROLE_UI_LOCATIONS_DELETE Display Delete action in Locations table ROLE_UI_LOCATIONS_DETAILS_VIEW Display Location Details action in Locations table There are quite a number of roles to provide selective access to the tabs offered by the Locations Details modal: Role User Interface ROLE_UI_LOCATIONS_DETAILS_CAPABILITIES_VIEW Display tab Capabilities ROLE_UI_LOCATIONS_DETAILS_CONFIGURATION_VIEW Display tab Configuration ROLE_UI_LOCATIONS_DETAILS_GENERAL_VIEW Display tab General","title":"Capture: Locations"},{"location":"configuration/admin-ui/role-based-visibility/#systems-jobs-servers-and-services","text":"Role User Interface ROLE_UI_JOBS_VIEW Display Jobs page ROLE_UI_SERVERS_VIEW Display Servers page ROLE_UI_SERVICES_VIEW Display Services page On those pages, it is possible to further provide access: Role User Interface ROLE_UI_SERVERS_MAINTENANCE_EDIT Allow the user turn on/off server maintenance ROLE_UI_SERVICES_STATUS_EDIT Allow the user to sanitize services","title":"Systems: Jobs, Servers and Services"},{"location":"configuration/admin-ui/role-based-visibility/#organization-users","text":"Role User Interface ROLE_UI_USERS_VIEW Display Users page ROLE_UI_USERS_CREATE Display Add user on Users page ROLE_UI_USERS_DELETE Display Delete action in Users table ROLE_UI_USERS_EDIT Display User Details action in Users table","title":"Organization: Users"},{"location":"configuration/admin-ui/role-based-visibility/#organization-groups","text":"Role User Interface ROLE_UI_GROUPS_VIEW Display Groups page ROLE_UI_GROUPS_CREATE Display Add groups on Groups page ROLE_UI_GROUPS_DELETE Display Delete action in Groups table ROLE_UI_GROUPS_EDIT Display Group Details action in Groups table","title":"Organization: Groups"},{"location":"configuration/admin-ui/role-based-visibility/#organization-access-policies","text":"Role User Interface ROLE_UI_ACLS_VIEW Display Access Policies page ROLE_UI_ACLS_CREATE Display Add access policy on Access Policies page ROLE_UI_ACLS_DELETE Display Delete action in Access Policies table ROLE_UI_ACLS_EDIT Display Group Details action in Access Policies table","title":"Organization: Access Policies"},{"location":"configuration/admin-ui/role-based-visibility/#configuration-themes","text":"Role User Interface ROLE_UI_THEMES_VIEW Display Themes page ROLE_UI_THEMES_CREATE Display Add theme on Themes page ROLE_UI_THEMES_DELETE Display Delete action in Themes table ROLE_UI_THEMES_EDIT Display Theme Details action in Themes table","title":"Configuration: Themes"},{"location":"configuration/admin-ui/statistics/","text":"Overview In Opencast, the \"Statistics\" feature can be seen as a set of charts which can be displayed in the Admin UI. Currently, statistics for three so-called \"resource types\" are available: Statistics for the resource type EPISODE are displayed in a tab in the event details dialog. Statistics for the resource type SERIES are displayed in a tab in the series details dialog. Statistics for the resource type ORGANIZATION are displayed in the \"Statistics\" menu of Opencast. These tabs/menus are only visible if the statistics feature is configured. For the statistics to work, you need a data source from which Opencast can retrieve the data to display. Currently, InfluxDB is the only supported data source. Architecture A complete setup consists of the following components: InfluxDB A source which actually generates your data A tool which ingests your data into InfluxDB Opencast For example, using Opencast's opencast-influxdb-adapter , your architecture would look like this: Precisely, the Opencast bundle opencast-statistics-provider-influx is the one that needs to be able to connect to InfluxDB using http(s). So the node hosting this bundle needs network access to InfluxDB. Configuration Before configuring Opencast, you should have a running InfluxDB instance and should think about how you want your data to be written to InfluxDB and what your InfluxDB database schema should look like. Specifically, you should think about retention policies, measurement names, field/tag names and how much you want to downsample your data . If you don't have any data in your InfluxDB, but want to verify your setup is working, there is some test data provided in the section Verifying Your Setup . InfluxDB Access Opencast needs to know how to talk to your InfluxDB instance. Therefore, you should edit the configuration file etc/org.opencastproject.statistics.provider.influx.StatisticsProviderInfluxService.cfg and fill in your influx URI, username, password, and database name. Statistics Providers To support the detailed configuration of the charts to be shown in the Admin UI, Opencast has a concept called Statistics Providers . Each statistics provider can be configured separately and for each provider, there is one chart displayed in the Admin UI. The configuration files of the providers have to be stored at etc/statistics and they have to follow a certain naming convention. Configuration files of providers using InfluxDB have to be named starting with influx. . All provider configurations have to be in json format. So e.g. influx.views.episode.sum.json would be a valid name. For each provider, the following properties have to be configured: id has to be a unique identifier and can be chosen freely. title is the title to be displayed with the chart. This can be a translation key. description is the description to be displayed with the chart. This can be a translation key. resourceType tells Opencast to which type of entity the chart refers to. Valid values are EPISODE , SERIES , and ORGANIZATION . This is used by Opencast to decide where to display the chart. sources is list of JSON objects, each containing the following fields: measurement , e.g. infinite.impressions_daily tells Opencast that your InfluxDB data retention policy is named infinite and your InfluxDB measurement name is impressions_daily . aggregation , e.g. SUM tells Opencast that InfluxDB's SUM() function should be used to calculate the values to display in the chart. aggregationVariable , e.g. value tells Opencast that the InfluxDB field which should be summed is named value . resourceIdName , e.g. episodeId tells Opencast that the InfluxDB tag identifying the resource type this provider refers to is named episodeId . resolutions is a list of resolutions supported by this provider. Opencast allows the user to select a resolution with which the data is displayed. Valid values are HOURLY , DAILY , WEEKLY , MONTHLY and YEARLY . E.g. when a chart shows data of two years, a DAILY resolution will lead to 2x365=730 values to be plotted while a MONTHLY resolution would leave us with 24 values being plotted in the chart. type defines the structure of the data provided by this provider. Currently, timeseries and runningtotal are supported. Here is an example json configuration for a provider which generates charts for episodes showing the number of views: etc/statistics/influx.views.episode.sum.json { \"id\": \"episode.views.sum.influx\", \"title\": \"STATISTICS.TITLE.VIEWS_SUM\", \"description\": \"STATISTICS.DESCRIPTION.VIEWS_SUM\", \"resourceType\": \"EPISODE\", \"sources\": [{ \"measurement\": \"infinite.impressions_daily\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"value\", \"resourceIdName\": \"episodeId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"timeseries\" } CSV Exports Statistics can be exported to CSV files by clicking the \"download\" button in the top right corner of a graph. Per default, the export will contain the data which the graph currently displays. For series statistics, it is possible to change this behavior in the way that exported series statistics contain the data of all events of a series instead of just the top level series data. To enable this, it is necessary to specify which Statistics Provider should be used to get the episode data. See the configuration file org.opencastproject.statistics.export.impl.StatisticsExportServiceImpl.cfg for details. Using the runningtotal provider The runningtotal statistics provider is a special type of time series statistics provider. To illustrate what it can be used for, let\u2019s assume we want to track the number of hours of videos per organization (this is actually what the provider was initially designed for). We create a JSON file for the provider as such: { \"id\": \"organization.publishedhours.influx\", \"title\": \"STATISTICS.TITLE.PUBLISHEDHOURS\", \"description\": \"STATISTICS.DESCRIPTION.PUBLISHEDHOURS\", \"resourceType\": \"ORGANIZATION\", \"sources\": [{ \"measurement\": \"infinite.publishedhours\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"hours\", \"resourceIdName\": \"organizationId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"runningtotal\" } Note that the published hours entries can be negative, in case we retract a video. When the runningtotal provider is asked to report on, for example, the monthly hours of video for a specific year, it will first take the sum of all video lengths up until that year. Then, for each month, it will take the sum of all the entries in that month, and add it to the previous value. And so on for the next months. To actually write these hours to the statistics data base, you have to add the statistics-writer workflow operation handler to your workflows. Specifically, somewhere in your publishing workflow, you have to add an entry such as this: <operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation> To decrement the running total of hours in the case of retractions, set the retract property to true . In the default case, or when the retract property is false the running total is not decremented when a retraction occurs. Verifying Your Setup If you want to test your setup, you can put the following test data into InfluxDB and check if Opencast displays all charts correctly. First, create a series and an event as part of that series using the Opencast Admin UI. Second, copy the test data to a file called testdata.txt and edit it to match your InfluxDB database schema. Make sure you replace the episodeId , seriesId , and organizazionId tag value with the correct identifiers of the test event/series you just created. Also make sure, that the tag names (e.g.) episodeId and the field name ( value ) match the ones you have specified in the source strings of your providers. Also, the database name, retention policy name and measurement name have to match your configuration. The InfluxDB test data could look like this: # DDL CREATE DATABASE opencast # DML # CONTEXT-DATABASE: opencast impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554468810 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554555210 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554641610 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554728010 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554814410 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554900810 The file format of the InfluxDB test data is described here . You can import the test data into InfluxDB using the following command: influx -import -path=testdata.txt -precision=s -database=opencast Once you have imported your test data, you should be able to view the charts you have configured when accessing the event/series details of your test event or Opencast's statistics section.","title":"Statistics"},{"location":"configuration/admin-ui/statistics/#overview","text":"In Opencast, the \"Statistics\" feature can be seen as a set of charts which can be displayed in the Admin UI. Currently, statistics for three so-called \"resource types\" are available: Statistics for the resource type EPISODE are displayed in a tab in the event details dialog. Statistics for the resource type SERIES are displayed in a tab in the series details dialog. Statistics for the resource type ORGANIZATION are displayed in the \"Statistics\" menu of Opencast. These tabs/menus are only visible if the statistics feature is configured. For the statistics to work, you need a data source from which Opencast can retrieve the data to display. Currently, InfluxDB is the only supported data source.","title":"Overview"},{"location":"configuration/admin-ui/statistics/#architecture","text":"A complete setup consists of the following components: InfluxDB A source which actually generates your data A tool which ingests your data into InfluxDB Opencast For example, using Opencast's opencast-influxdb-adapter , your architecture would look like this: Precisely, the Opencast bundle opencast-statistics-provider-influx is the one that needs to be able to connect to InfluxDB using http(s). So the node hosting this bundle needs network access to InfluxDB.","title":"Architecture"},{"location":"configuration/admin-ui/statistics/#configuration","text":"Before configuring Opencast, you should have a running InfluxDB instance and should think about how you want your data to be written to InfluxDB and what your InfluxDB database schema should look like. Specifically, you should think about retention policies, measurement names, field/tag names and how much you want to downsample your data . If you don't have any data in your InfluxDB, but want to verify your setup is working, there is some test data provided in the section Verifying Your Setup .","title":"Configuration"},{"location":"configuration/admin-ui/statistics/#influxdb-access","text":"Opencast needs to know how to talk to your InfluxDB instance. Therefore, you should edit the configuration file etc/org.opencastproject.statistics.provider.influx.StatisticsProviderInfluxService.cfg and fill in your influx URI, username, password, and database name.","title":"InfluxDB Access"},{"location":"configuration/admin-ui/statistics/#statistics-providers","text":"To support the detailed configuration of the charts to be shown in the Admin UI, Opencast has a concept called Statistics Providers . Each statistics provider can be configured separately and for each provider, there is one chart displayed in the Admin UI. The configuration files of the providers have to be stored at etc/statistics and they have to follow a certain naming convention. Configuration files of providers using InfluxDB have to be named starting with influx. . All provider configurations have to be in json format. So e.g. influx.views.episode.sum.json would be a valid name. For each provider, the following properties have to be configured: id has to be a unique identifier and can be chosen freely. title is the title to be displayed with the chart. This can be a translation key. description is the description to be displayed with the chart. This can be a translation key. resourceType tells Opencast to which type of entity the chart refers to. Valid values are EPISODE , SERIES , and ORGANIZATION . This is used by Opencast to decide where to display the chart. sources is list of JSON objects, each containing the following fields: measurement , e.g. infinite.impressions_daily tells Opencast that your InfluxDB data retention policy is named infinite and your InfluxDB measurement name is impressions_daily . aggregation , e.g. SUM tells Opencast that InfluxDB's SUM() function should be used to calculate the values to display in the chart. aggregationVariable , e.g. value tells Opencast that the InfluxDB field which should be summed is named value . resourceIdName , e.g. episodeId tells Opencast that the InfluxDB tag identifying the resource type this provider refers to is named episodeId . resolutions is a list of resolutions supported by this provider. Opencast allows the user to select a resolution with which the data is displayed. Valid values are HOURLY , DAILY , WEEKLY , MONTHLY and YEARLY . E.g. when a chart shows data of two years, a DAILY resolution will lead to 2x365=730 values to be plotted while a MONTHLY resolution would leave us with 24 values being plotted in the chart. type defines the structure of the data provided by this provider. Currently, timeseries and runningtotal are supported. Here is an example json configuration for a provider which generates charts for episodes showing the number of views: etc/statistics/influx.views.episode.sum.json { \"id\": \"episode.views.sum.influx\", \"title\": \"STATISTICS.TITLE.VIEWS_SUM\", \"description\": \"STATISTICS.DESCRIPTION.VIEWS_SUM\", \"resourceType\": \"EPISODE\", \"sources\": [{ \"measurement\": \"infinite.impressions_daily\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"value\", \"resourceIdName\": \"episodeId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"timeseries\" }","title":"Statistics Providers"},{"location":"configuration/admin-ui/statistics/#csv-exports","text":"Statistics can be exported to CSV files by clicking the \"download\" button in the top right corner of a graph. Per default, the export will contain the data which the graph currently displays. For series statistics, it is possible to change this behavior in the way that exported series statistics contain the data of all events of a series instead of just the top level series data. To enable this, it is necessary to specify which Statistics Provider should be used to get the episode data. See the configuration file org.opencastproject.statistics.export.impl.StatisticsExportServiceImpl.cfg for details.","title":"CSV Exports"},{"location":"configuration/admin-ui/statistics/#using-the-runningtotal-provider","text":"The runningtotal statistics provider is a special type of time series statistics provider. To illustrate what it can be used for, let\u2019s assume we want to track the number of hours of videos per organization (this is actually what the provider was initially designed for). We create a JSON file for the provider as such: { \"id\": \"organization.publishedhours.influx\", \"title\": \"STATISTICS.TITLE.PUBLISHEDHOURS\", \"description\": \"STATISTICS.DESCRIPTION.PUBLISHEDHOURS\", \"resourceType\": \"ORGANIZATION\", \"sources\": [{ \"measurement\": \"infinite.publishedhours\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"hours\", \"resourceIdName\": \"organizationId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"runningtotal\" } Note that the published hours entries can be negative, in case we retract a video. When the runningtotal provider is asked to report on, for example, the monthly hours of video for a specific year, it will first take the sum of all video lengths up until that year. Then, for each month, it will take the sum of all the entries in that month, and add it to the previous value. And so on for the next months. To actually write these hours to the statistics data base, you have to add the statistics-writer workflow operation handler to your workflows. Specifically, somewhere in your publishing workflow, you have to add an entry such as this: <operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation> To decrement the running total of hours in the case of retractions, set the retract property to true . In the default case, or when the retract property is false the running total is not decremented when a retraction occurs.","title":"Using the runningtotal provider"},{"location":"configuration/admin-ui/statistics/#verifying-your-setup","text":"If you want to test your setup, you can put the following test data into InfluxDB and check if Opencast displays all charts correctly. First, create a series and an event as part of that series using the Opencast Admin UI. Second, copy the test data to a file called testdata.txt and edit it to match your InfluxDB database schema. Make sure you replace the episodeId , seriesId , and organizazionId tag value with the correct identifiers of the test event/series you just created. Also make sure, that the tag names (e.g.) episodeId and the field name ( value ) match the ones you have specified in the source strings of your providers. Also, the database name, retention policy name and measurement name have to match your configuration. The InfluxDB test data could look like this: # DDL CREATE DATABASE opencast # DML # CONTEXT-DATABASE: opencast impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554468810 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554555210 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554641610 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554728010 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554814410 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554900810 The file format of the InfluxDB test data is described here . You can import the test data into InfluxDB using the following command: influx -import -path=testdata.txt -precision=s -database=opencast Once you have imported your test data, you should be able to view the charts you have configured when accessing the event/series details of your test event or Opencast's statistics section.","title":"Verifying Your Setup"},{"location":"configuration/admin-ui/thumbnails/","text":"Overview Video content is often represented visually by using thumbnail images and metadata. Think of, for example, of list of videos displayed as a thumbnail image together with the title and description for each video. On this page, this is the image that we refer to as thumbnail. Since having high quality thumbnails is important, the Opencast video editor comes with built-in support for thumbnails. We distinguish between three kinds of thumbnails: The Thumbnail Preview is a preview of the thumbnail shown in the video editor only The Default Thumbnail is automatically generated A Snapshot Thumbnail can be extracted from the video by the user An Uploaded Thumbnail is uploaded by the user As both the video editor and your workflows need to work together to enable full support of this feature, the Admin UI comes with a number of configuration options that allows this feature to be integrated into your workflow configuration. This page describes the configuration options of the Admin UI relevant for the thumbnail support of the video editor. These options can be adjusted in the configuration file etc/org.opencastproject.adminui.cfg . Thumbnail Preview The video editor displays a preview of the actual thumbnail at any time. This preview image is expected to be published in the publication channel internal as attachment with the flavor as specified in the Admin UI configuration: # Default: thumbnail/preview #thumbnail.preview.flavor=thumbnail/preview The initial thumbnail preview image is generated by the workflow that creates and publishes the distribution artefacts required by the video editor (e.g. etc/workflows/partial-preview.xml ). If the user uploads a thumbnail in the video editor, the thumbnail preview is created by converting the uploaded thumbnail using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale If the user selects the default thumbnail or a snapshot thumbnail in the video editor, the update of the thumbnail preview is done differently depending on whether automatic distribution is enabled or not. In case that automatic distribution is disabled, the thumbnail preview is extracted from the source track using the following encoding profile: # Default: editor.thumbnail.preview #thumbnail.preview.profile=editor.thumbnail.preview In case that automatic distribution is enabled, a master thumbnail image is extracted. The thumbnail preview image is then created by downscaling this master thumbnail image using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale Note that the thumbnail preview image is supposed to be used by the Admin UI only. Default Thumbnail This thumbnail is supposed to be automatically generated without user interaction. When the user chooses the default thumbnail in the video editor, Opencast will automatically generate and publish an updated thumbnail preview image. The default thumbnail image is extracted from a track identified by the following configuration: # Default: presenter #thumbnail.source.flavor.type.primary=presenter # Default: presentation #thumbnail.source.flavor.type.secondary=presentation # Default: source #thumbnail.source.flavor.subtype=source In this example, the default thumbnail would be extracted from the track with the flavor presenter/source or, if no such track is available, a track with the flavor presentation/source . The relative position within the edited video where the default thumbnail is extracted can be configured: # Default: 1.0 #thumbnail.default.position=1.0 Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `0` to indicate that the default thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the default thumbnail should be extracted Snapshot Thumbnail In case the user is not happy with the automatically generated default thumbnail, the user can extract a thumbnail at an arbitrary position within the video. The snapshot thumbnail will be extracted from tracks identified by the following configuration properties: # Default: presenter/source #sourcetrack.left.flavor=presenter/source # Default: presentation/source #sourcetrack.right.flavor=presentation/source Note that the user can choose between \"Extract from video\", \"Extract from left video\" and \"Extract from right video\". In any case, the video editor ensures that the correct source track flavor is used. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `1` to indicate that a snapshot thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the snapshot thumbnail should be extracted - `thumbnailTrack` is set to the type of the flavor of the source track which is `presenter` or `presentation` Uploaded Thumbnail The most flexible option is to upload an image to be used as thumbnail. When the user uploads an image in the video editor, Opencast will automatically generate and publish the thumbnail preview and creates a new media package snapshot after adding the uploaded image as attachment to the media package. This attachment will have the following flavor: # Default: thumbnail/source #thumbnail.uploaded.flavor=thumbnail/source Additionally, the following tags are added to the attachment: # Default: archive #thumbnail.uploaded.tags=archive IMPORTANT: Please ensure that all workflows in your setup will always include this attachment when taking snapshots using the workflow operation snapshot by setting its configuration key source-tags and/or source-flavor appropriately. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `2` to indicate that an uploaded thumbnail is used Automatic Distribution To avoid the situation that a user needs to start a workflow just to update the thumbnail on the publication channels, Opencast supports automatic distribution of thumbnail images for publication channels that support incremental publication. This is currently supported by the following kinds of publication channels: Configurable publication channels (used by the External API) OAI-PMH publication channels Note that this mechanism is currently limited to at most one publication channel per kind. The automatic distribution of thumbnail images can be enabled in the configuration: # Default: false #thumbnail.distribution.auto=false If automatic distribution is enabled, Opencast will automatically create and publish the thumbnail. Note that the generation of multiple thumbnails is based on a master image that will be extracted using the following encoding profile: # Default: editor.thumbnail.master #thumbnail.master.profile=editor.thumbnail.master This master image will be converted into all the different formats required. For the automatic distribution to the OAI-PMH publication channel, the following settings are available: # The ID of the OAI-PMH publication channel # Default: oaipmh-default #thumbnail.distribution.oaipmh.channel=oaipmh-default # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.oaipmh.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.oaipmh.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.oaipmh.profiles=search-cover.http.downscale To enable automatic distribution to the OAI-PMH channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.oaipmh.channel must be set to a non-empty string. For the automatic distribution to the configurable publication channel, the following settings are available: # The ID of the configurable publication channel # Default: api #thumbnail.distribution.configurable.channel=api # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.configurable.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.configurable.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.configurable.profiles=search-cover.http.downscale To enable automatic distribution to the configurable publication channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.configurable.channel must be set to a non-empty string.","title":"Thumbnails"},{"location":"configuration/admin-ui/thumbnails/#overview","text":"Video content is often represented visually by using thumbnail images and metadata. Think of, for example, of list of videos displayed as a thumbnail image together with the title and description for each video. On this page, this is the image that we refer to as thumbnail. Since having high quality thumbnails is important, the Opencast video editor comes with built-in support for thumbnails. We distinguish between three kinds of thumbnails: The Thumbnail Preview is a preview of the thumbnail shown in the video editor only The Default Thumbnail is automatically generated A Snapshot Thumbnail can be extracted from the video by the user An Uploaded Thumbnail is uploaded by the user As both the video editor and your workflows need to work together to enable full support of this feature, the Admin UI comes with a number of configuration options that allows this feature to be integrated into your workflow configuration. This page describes the configuration options of the Admin UI relevant for the thumbnail support of the video editor. These options can be adjusted in the configuration file etc/org.opencastproject.adminui.cfg .","title":"Overview"},{"location":"configuration/admin-ui/thumbnails/#thumbnail-preview","text":"The video editor displays a preview of the actual thumbnail at any time. This preview image is expected to be published in the publication channel internal as attachment with the flavor as specified in the Admin UI configuration: # Default: thumbnail/preview #thumbnail.preview.flavor=thumbnail/preview The initial thumbnail preview image is generated by the workflow that creates and publishes the distribution artefacts required by the video editor (e.g. etc/workflows/partial-preview.xml ). If the user uploads a thumbnail in the video editor, the thumbnail preview is created by converting the uploaded thumbnail using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale If the user selects the default thumbnail or a snapshot thumbnail in the video editor, the update of the thumbnail preview is done differently depending on whether automatic distribution is enabled or not. In case that automatic distribution is disabled, the thumbnail preview is extracted from the source track using the following encoding profile: # Default: editor.thumbnail.preview #thumbnail.preview.profile=editor.thumbnail.preview In case that automatic distribution is enabled, a master thumbnail image is extracted. The thumbnail preview image is then created by downscaling this master thumbnail image using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale Note that the thumbnail preview image is supposed to be used by the Admin UI only.","title":"Thumbnail Preview"},{"location":"configuration/admin-ui/thumbnails/#default-thumbnail","text":"This thumbnail is supposed to be automatically generated without user interaction. When the user chooses the default thumbnail in the video editor, Opencast will automatically generate and publish an updated thumbnail preview image. The default thumbnail image is extracted from a track identified by the following configuration: # Default: presenter #thumbnail.source.flavor.type.primary=presenter # Default: presentation #thumbnail.source.flavor.type.secondary=presentation # Default: source #thumbnail.source.flavor.subtype=source In this example, the default thumbnail would be extracted from the track with the flavor presenter/source or, if no such track is available, a track with the flavor presentation/source . The relative position within the edited video where the default thumbnail is extracted can be configured: # Default: 1.0 #thumbnail.default.position=1.0 Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `0` to indicate that the default thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the default thumbnail should be extracted","title":"Default Thumbnail"},{"location":"configuration/admin-ui/thumbnails/#snapshot-thumbnail","text":"In case the user is not happy with the automatically generated default thumbnail, the user can extract a thumbnail at an arbitrary position within the video. The snapshot thumbnail will be extracted from tracks identified by the following configuration properties: # Default: presenter/source #sourcetrack.left.flavor=presenter/source # Default: presentation/source #sourcetrack.right.flavor=presentation/source Note that the user can choose between \"Extract from video\", \"Extract from left video\" and \"Extract from right video\". In any case, the video editor ensures that the correct source track flavor is used. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `1` to indicate that a snapshot thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the snapshot thumbnail should be extracted - `thumbnailTrack` is set to the type of the flavor of the source track which is `presenter` or `presentation`","title":"Snapshot Thumbnail"},{"location":"configuration/admin-ui/thumbnails/#uploaded-thumbnail","text":"The most flexible option is to upload an image to be used as thumbnail. When the user uploads an image in the video editor, Opencast will automatically generate and publish the thumbnail preview and creates a new media package snapshot after adding the uploaded image as attachment to the media package. This attachment will have the following flavor: # Default: thumbnail/source #thumbnail.uploaded.flavor=thumbnail/source Additionally, the following tags are added to the attachment: # Default: archive #thumbnail.uploaded.tags=archive IMPORTANT: Please ensure that all workflows in your setup will always include this attachment when taking snapshots using the workflow operation snapshot by setting its configuration key source-tags and/or source-flavor appropriately. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `2` to indicate that an uploaded thumbnail is used","title":"Uploaded Thumbnail"},{"location":"configuration/admin-ui/thumbnails/#automatic-distribution","text":"To avoid the situation that a user needs to start a workflow just to update the thumbnail on the publication channels, Opencast supports automatic distribution of thumbnail images for publication channels that support incremental publication. This is currently supported by the following kinds of publication channels: Configurable publication channels (used by the External API) OAI-PMH publication channels Note that this mechanism is currently limited to at most one publication channel per kind. The automatic distribution of thumbnail images can be enabled in the configuration: # Default: false #thumbnail.distribution.auto=false If automatic distribution is enabled, Opencast will automatically create and publish the thumbnail. Note that the generation of multiple thumbnails is based on a master image that will be extracted using the following encoding profile: # Default: editor.thumbnail.master #thumbnail.master.profile=editor.thumbnail.master This master image will be converted into all the different formats required. For the automatic distribution to the OAI-PMH publication channel, the following settings are available: # The ID of the OAI-PMH publication channel # Default: oaipmh-default #thumbnail.distribution.oaipmh.channel=oaipmh-default # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.oaipmh.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.oaipmh.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.oaipmh.profiles=search-cover.http.downscale To enable automatic distribution to the OAI-PMH channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.oaipmh.channel must be set to a non-empty string. For the automatic distribution to the configurable publication channel, the following settings are available: # The ID of the configurable publication channel # Default: api #thumbnail.distribution.configurable.channel=api # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.configurable.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.configurable.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.configurable.profiles=search-cover.http.downscale To enable automatic distribution to the configurable publication channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.configurable.channel must be set to a non-empty string.","title":"Automatic Distribution"},{"location":"configuration/https/","text":"Serve Content Via HTTPS To make your installation available from the outside worls, you want to allow non-local traffic and want to secure connections from and to Opencast. To archieve that, you can either use an HTTP(S) proxy like Apache httpd or Nginx (recommended) or enable HTTPS directly in Opencast. Using Nginx to enable HTTPS (recommended) Using Apache httpd to enable HTTPS Enable HTTPS directly in Opencast Note that introducing HTTPS will not automatically migrate old content. It may still use the previously configured HTTP protocol. For a semi-automatic migration, please take a look at the following guide: Migrating old content to HTTPS General Recommendations It's hard to keep up with security (e.g. proper TLS configuration). That is why we recommend using a proxy like Nginx or Apache as, due to their general popularity, it is usually much easier to find good configuration recommendations. There are also a couple of great sites to test your final setup: Observatory by Mozilla Qualys SSL Labs If you have no easy way of obtaining proper TLS certificates for your organization, please consider using Let\u2019s Encrypt . For testing and developer servers, properly configured self-signed certificates can be an option.","title":"Overview"},{"location":"configuration/https/#serve-content-via-https","text":"To make your installation available from the outside worls, you want to allow non-local traffic and want to secure connections from and to Opencast. To archieve that, you can either use an HTTP(S) proxy like Apache httpd or Nginx (recommended) or enable HTTPS directly in Opencast. Using Nginx to enable HTTPS (recommended) Using Apache httpd to enable HTTPS Enable HTTPS directly in Opencast Note that introducing HTTPS will not automatically migrate old content. It may still use the previously configured HTTP protocol. For a semi-automatic migration, please take a look at the following guide: Migrating old content to HTTPS","title":"Serve Content Via HTTPS"},{"location":"configuration/https/#general-recommendations","text":"It's hard to keep up with security (e.g. proper TLS configuration). That is why we recommend using a proxy like Nginx or Apache as, due to their general popularity, it is usually much easier to find good configuration recommendations. There are also a couple of great sites to test your final setup: Observatory by Mozilla Qualys SSL Labs If you have no easy way of obtaining proper TLS certificates for your organization, please consider using Let\u2019s Encrypt . For testing and developer servers, properly configured self-signed certificates can be an option.","title":"General Recommendations"},{"location":"configuration/https/apache-httpd/","text":"Enable HTTPS using Apache httpd Using Nginx as reverse proxy for Opencast is the preferred way of running Opencast. Refer to the Nginx guide for configuration instructions for that type of setup. This guide will help you to configure httpd to act as HTTP(S) proxy for Opencast. Opencast Configuration Make sure to use https as protocol for org.opencastproject.server.url in etc/custom.properties . org.opencastproject.server.url=https://example.opencast.org No other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the default settings. Minimal Set-up Note that this guide does not give any security advice but is meant to provide a minimal working example which works well with Opencast. The following configuration is an example for /etc/httpd/conf.d/opencast.conf . Note that depending on your distributions packaging, often conf.d or sites-enabled directories are used. Adjust the file path accordingly. Explanations for the configuration directives are provided inline. Please make sure to replace example.opencast.org with your node's domain name. The main goals of this set-up are: Always redirect to HTTPS Proxy to Opencast and take care of TLS Avoid caching <VirtualHost *:80> ServerName example.opencast.org RewriteEngine on RewriteRule ^/(.*)$ https://example.opencast.org/$1 [NC] </VirtualHost> <VirtualHost *:443> ServerName example.opencast.org # Enable TLS SSLEngine on SSLProxyEngine on SSLCertificateFile /etc/ssl/certs/oc-cert.crt SSLCertificateKeyFile /etc/ssl/private/oc-key.key SSLCertificateChainFile /etc/ssl/certs/oc-chain.crt # Make sure Opencast knows about HTTPS being used RequestHeader set X-Forwarded-SSL \"on\" RequestHeader set X-Forwarded-Proto \"https\" # Make sure to serve cookies only via secure connections. Header edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure # Depending on your integration, you may also want to allow cookies # to be used on other sites. In that case, use this instead: #Header edit Set-Cookie ^(.*)$ $1; HttpOnly; Secure; SameSite=None # Proxy requests to Opencast ProxyPreserveHost On ProxyPass / http://127.0.0.1:8080/ ProxyPassReverse / http://example.opencast.org </VirtualHost>","title":"Using Apache httpd"},{"location":"configuration/https/apache-httpd/#enable-https-using-apache-httpd","text":"Using Nginx as reverse proxy for Opencast is the preferred way of running Opencast. Refer to the Nginx guide for configuration instructions for that type of setup. This guide will help you to configure httpd to act as HTTP(S) proxy for Opencast.","title":"Enable HTTPS using Apache httpd"},{"location":"configuration/https/apache-httpd/#opencast-configuration","text":"Make sure to use https as protocol for org.opencastproject.server.url in etc/custom.properties . org.opencastproject.server.url=https://example.opencast.org No other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the default settings.","title":"Opencast Configuration"},{"location":"configuration/https/apache-httpd/#minimal-set-up","text":"Note that this guide does not give any security advice but is meant to provide a minimal working example which works well with Opencast. The following configuration is an example for /etc/httpd/conf.d/opencast.conf . Note that depending on your distributions packaging, often conf.d or sites-enabled directories are used. Adjust the file path accordingly. Explanations for the configuration directives are provided inline. Please make sure to replace example.opencast.org with your node's domain name. The main goals of this set-up are: Always redirect to HTTPS Proxy to Opencast and take care of TLS Avoid caching <VirtualHost *:80> ServerName example.opencast.org RewriteEngine on RewriteRule ^/(.*)$ https://example.opencast.org/$1 [NC] </VirtualHost> <VirtualHost *:443> ServerName example.opencast.org # Enable TLS SSLEngine on SSLProxyEngine on SSLCertificateFile /etc/ssl/certs/oc-cert.crt SSLCertificateKeyFile /etc/ssl/private/oc-key.key SSLCertificateChainFile /etc/ssl/certs/oc-chain.crt # Make sure Opencast knows about HTTPS being used RequestHeader set X-Forwarded-SSL \"on\" RequestHeader set X-Forwarded-Proto \"https\" # Make sure to serve cookies only via secure connections. Header edit Set-Cookie ^(.*)$ $1;HttpOnly;Secure # Depending on your integration, you may also want to allow cookies # to be used on other sites. In that case, use this instead: #Header edit Set-Cookie ^(.*)$ $1; HttpOnly; Secure; SameSite=None # Proxy requests to Opencast ProxyPreserveHost On ProxyPass / http://127.0.0.1:8080/ ProxyPassReverse / http://example.opencast.org </VirtualHost>","title":"Minimal Set-up"},{"location":"configuration/https/migration/","text":"Migrating old content to HTTPS Opencast will not modify already published events. This means that old publications might still use HTTP as protocol if it was used before. Re-processing or re-publishing will update the links but this may not be an option for larger migrations. For that, the following steps might help. Note that you modify stored data directly without any safety nets usually provided by Opencast. You should understand what you are doing! Backup your database, and the Solr and Elasticsearch indexes. Elasticsearch: {data}/index Solr: {data}/solr-indexes Configure Opencast to use HTTPS and test your set-up with a new publication. Put all your nodes into maintenance mode or, at least, do not process any videos. Update the media packages: find . -type f -name \"*.xml\" -exec \\ sed -i 's/http\\:\\/\\/oc-presentation\\.example\\.com\\:80/https:\\/\\/oc-presentation.example.com/g' {} + Update database tables. Note that Opencast 5 did change the database table name prefix from mh to oc : UPDATE opencast.oc_assets_snapshot SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; UPDATE opencast.oc_search SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; Remove the search service's Solr index. It usually is located at solr-indexes/search but its location really depends on org.opencastproject.solr.dir and org.opencastproject.search.solr.dir Rebuild the Solr indices by re-starting your Opencast node running the search service (usually presentation). Rebuild the Elasticsearch indices using the REST endpoint listed in the docs: https://admin.opencast.example.com/docs.html?path=/admin-ng/index Note: If the solr index does not repopulate by itself please check if your nodes are still in maintenance mode and reactivate them.","title":"Migrating old content to HTTPS"},{"location":"configuration/https/migration/#migrating-old-content-to-https","text":"Opencast will not modify already published events. This means that old publications might still use HTTP as protocol if it was used before. Re-processing or re-publishing will update the links but this may not be an option for larger migrations. For that, the following steps might help. Note that you modify stored data directly without any safety nets usually provided by Opencast. You should understand what you are doing! Backup your database, and the Solr and Elasticsearch indexes. Elasticsearch: {data}/index Solr: {data}/solr-indexes Configure Opencast to use HTTPS and test your set-up with a new publication. Put all your nodes into maintenance mode or, at least, do not process any videos. Update the media packages: find . -type f -name \"*.xml\" -exec \\ sed -i 's/http\\:\\/\\/oc-presentation\\.example\\.com\\:80/https:\\/\\/oc-presentation.example.com/g' {} + Update database tables. Note that Opencast 5 did change the database table name prefix from mh to oc : UPDATE opencast.oc_assets_snapshot SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; UPDATE opencast.oc_search SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; Remove the search service's Solr index. It usually is located at solr-indexes/search but its location really depends on org.opencastproject.solr.dir and org.opencastproject.search.solr.dir Rebuild the Solr indices by re-starting your Opencast node running the search service (usually presentation). Rebuild the Elasticsearch indices using the REST endpoint listed in the docs: https://admin.opencast.example.com/docs.html?path=/admin-ng/index Note: If the solr index does not repopulate by itself please check if your nodes are still in maintenance mode and reactivate them.","title":"Migrating old content to HTTPS"},{"location":"configuration/https/nginx/","text":"Enable HTTPS using Nginx This guide will help you to configure Nginx to act as HTTP(S) proxy for Opencast. Opencast Configuration Make sure to use https as protocol for org.opencastproject.server.url in etc/custom.properties . org.opencastproject.server.url=https://example.opencast.org No other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the default settings. Minimal Set-up Note that this guide does not give any security advice but is meant to provide a minimal working example which works well with Opencast. The following configuration is an example for /etc/nginx/nginx.conf . Note that depending on your distributions packaging, often conf.d or sites-enabled directories are used. But since this is an Opencast only set-up (we do not use the web server for anything else), we are just using the main configuration file. Explanations for the configuration directives are provided inline. Please make sure to replace example.opencast.org with your node's domain name. The main goals of this set-up are: Always redirect to HTTPS Proxy to Opencast and take care of TLS Avoid caching # Check your distribution's default nginx.conf to make sure the first # configuration keys (up until the http section) make sense within your # distribution's set-up. # Defines user and group credentials used by worker processes. If group is # omitted, a group whose name equals that of user is used. user nginx; # Configures logging to `/var/log/\u2026`. Log level `error` is used by default. error_log /var/log/nginx/error.log; # Defines a file that will store the process ID of the main process. This needs # to match the Systemd unit file. pid /run/nginx.pid; events { # Sets the maximum number of simultaneous connections that can be opened by # a worker process. worker_connections 1024; } ### # What follows is the specific http(s) set-up for Opencast. ## http { # HTTP set-up server { listen 80; listen [::]:80; server_name _; # Enforce HTTPS by redirecting requests location / { return 301 https://example.opencast.org$request_uri; } } # HTTPS set-up server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name example.opencast.org; # Path to the TLS certificate and private key. In almost all cases, you # need to provide intermediate certificates as well to ensure browsers # get the whole certificate chain. ssl_certificate_key /path/to/example.opencast.org.key; ssl_certificate /path/to/example.opencast.org.crt; # Accept large ingests. There should be no limit since Opencast may get # really large ingests. client_max_body_size 0; # Proxy configuration for Opencast location / { # Make sure to pass the real addresses as well as the fact that # outwards we are using HTTPS to Opencast. proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # Pass requests to this location. This expects Opencast to be # running locally on port 8080 which should be the default set-up. proxy_pass http://127.0.0.1:8080; # Make sure to redirect location headers to HTTPS. This is just a # precaution and shouldn't strictly be necessary but it did prevent # some issues in the past and it does not cost much performance. proxy_redirect http://$host https://$host; # Make sure to serve cookies only via secure connections. proxy_cookie_path / \"/; HTTPOnly; Secure\"; # Depending on your integration, you may also want to allow cookies # to be used on other sites. In that case, use this instead: #proxy_cookie_path / \"/; HTTPOnly; Secure; SameSite=None\"; # Do not buffer responses proxy_buffering off; # Do not buffer requests proxy_request_buffering off; } } }","title":"Using Nginx"},{"location":"configuration/https/nginx/#enable-https-using-nginx","text":"This guide will help you to configure Nginx to act as HTTP(S) proxy for Opencast.","title":"Enable HTTPS using Nginx"},{"location":"configuration/https/nginx/#opencast-configuration","text":"Make sure to use https as protocol for org.opencastproject.server.url in etc/custom.properties . org.opencastproject.server.url=https://example.opencast.org No other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the default settings.","title":"Opencast Configuration"},{"location":"configuration/https/nginx/#minimal-set-up","text":"Note that this guide does not give any security advice but is meant to provide a minimal working example which works well with Opencast. The following configuration is an example for /etc/nginx/nginx.conf . Note that depending on your distributions packaging, often conf.d or sites-enabled directories are used. But since this is an Opencast only set-up (we do not use the web server for anything else), we are just using the main configuration file. Explanations for the configuration directives are provided inline. Please make sure to replace example.opencast.org with your node's domain name. The main goals of this set-up are: Always redirect to HTTPS Proxy to Opencast and take care of TLS Avoid caching # Check your distribution's default nginx.conf to make sure the first # configuration keys (up until the http section) make sense within your # distribution's set-up. # Defines user and group credentials used by worker processes. If group is # omitted, a group whose name equals that of user is used. user nginx; # Configures logging to `/var/log/\u2026`. Log level `error` is used by default. error_log /var/log/nginx/error.log; # Defines a file that will store the process ID of the main process. This needs # to match the Systemd unit file. pid /run/nginx.pid; events { # Sets the maximum number of simultaneous connections that can be opened by # a worker process. worker_connections 1024; } ### # What follows is the specific http(s) set-up for Opencast. ## http { # HTTP set-up server { listen 80; listen [::]:80; server_name _; # Enforce HTTPS by redirecting requests location / { return 301 https://example.opencast.org$request_uri; } } # HTTPS set-up server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name example.opencast.org; # Path to the TLS certificate and private key. In almost all cases, you # need to provide intermediate certificates as well to ensure browsers # get the whole certificate chain. ssl_certificate_key /path/to/example.opencast.org.key; ssl_certificate /path/to/example.opencast.org.crt; # Accept large ingests. There should be no limit since Opencast may get # really large ingests. client_max_body_size 0; # Proxy configuration for Opencast location / { # Make sure to pass the real addresses as well as the fact that # outwards we are using HTTPS to Opencast. proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # Pass requests to this location. This expects Opencast to be # running locally on port 8080 which should be the default set-up. proxy_pass http://127.0.0.1:8080; # Make sure to redirect location headers to HTTPS. This is just a # precaution and shouldn't strictly be necessary but it did prevent # some issues in the past and it does not cost much performance. proxy_redirect http://$host https://$host; # Make sure to serve cookies only via secure connections. proxy_cookie_path / \"/; HTTPOnly; Secure\"; # Depending on your integration, you may also want to allow cookies # to be used on other sites. In that case, use this instead: #proxy_cookie_path / \"/; HTTPOnly; Secure; SameSite=None\"; # Do not buffer responses proxy_buffering off; # Do not buffer requests proxy_request_buffering off; } } }","title":"Minimal Set-up"},{"location":"configuration/https/opencast.only/","text":"Enable HTTPS directly in Opencast Edit etc/org.ops4j.pax.web.cfg and set: # This property specifies the comma separated list of addresses used by Opencast to listen to (e.g. localhost or # localhost,10.0.0.1). Host names or IP addresses can be used. Pax Web default value is \"0.0.0.0\". org.ops4j.pax.web.listening.addresses=0.0.0.0 # Whether Opencast itself should handle HTTPS traffic. # Even if you set this to 'false',you can still use an HTTP proxy to handle SSL. org.osgi.service.http.secure.enabled=true # The secure server port to use if running Opencast with HTTPS (as opposed to # a proxy handling HTTPS). # Note that we use the docker proxy for the port-mapping from 8843 from within # the container to 443 at the host # Don't run Opencast with root privileges, which is a security issue org.osgi.service.http.port.secure=8443 # Path to the keystore file. # Use the Java `keytool` to generate this file. # Example: # keytool -genkey -keyalg RSA -validity 365 -alias serverkey \\ # -keypass password -storepass password -keystore keystore.jks org.ops4j.pax.web.ssl.keystore=<path_to_keystore> # Password used for keystore integrity check. org.ops4j.pax.web.ssl.password=<the_keystore_password> # Password used for keystore. org.ops4j.pax.web.ssl.keypassword=<the_key_password> Port-Forwarding required Note that Opencast most likely can't bind to port 443. That's why you still need to reverse-proxy or port-forward if you want to avoid URLs with port specified like https://host:8443/ which is technically perfectly okay but may confuse users or may be perceived as \"ugly\". Here is a non-comprehensive lists of tools and methods which can be used for port forwarding: Port-Forwarding with iptables A rule like iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443 # Allow also localhost traffic to use :443 # iptables -A OUTPUT -t nat -o lo -p tcp --dport 443 -j REDIRECT --to-port 8443 should do the job after replacing eth0 with the network interface your Opencast consumers will connect on. Note that you usually want to persist the rule. Port-Forwarding with docker(-proxy) When starting a container from an Opencast image, either insert a command line argument to docker run: -p 443:8443 or add a ports: in docker-compose.yaml . Port-Forwarding with sniproxy Sniproxy can be used as well, especially if you have multiple servers running on the same machine that handle HTTPS individually (no termination proxy). user, pidfile, error_log ... listen 443 { proto tls table https_hosts fallback 127.0.0.1:8443 access_log { filename /var/log/sniproxy/https_access.log priority notice } } table https_hosts { .*\\.opencast\\.example\\.org 127.0.0.1:8443 } Creating the keystore What you need is the TLS private key and the certificate including the whole chain between the root certificate, all intermediates and the certificate itself. Step 1: Obtaining the certificate chain If you only have the key and the certificate, I recommend certificatechain.io or cert-chain-resolver . The latter can be used as follows: # Obtain the chain for cert.pem and save it at opencast.chain.pem.tmp # The -s command switch includes the root certificate; this is not # mandatory and might add some overhead cert-chain-resolver -s -o \"opencast.chain.pem.tmp\" \"cert.pem\" # Verify the certificate using the chain openssl verify -crl_download -crl_check -untrusted \"opencast.chain.pem.tmp\" \"cert.pem\" Step 2: Create the p12 keystore If the private key (assumed to be key.pem ) is encrypted (password protected), issue the following command. Note that there are safer ways supplying the key's password to OpenSSL. openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -passin \"pass:<the_keys_password>\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\" In case the private key is not protected by password: openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\" Step 3: Import the p12 keystore into a Java keystore: keytool \\ -importkeystore \\ -srckeystore \"opencast.p12\" \\ -srcstoretype \"pkcs12\" \\ -srcstorepass \"<the_keystore_password>\" \\ -destkeystore \"keystore.jks\" \\ -storepass \"<the_keystore_password>\" # print out details about the JKS built keytool \\ -keystore \"keystore.jks\" \\ -list \\ -destalias serverkey \\ -storepass \"<the_keystore_password>\" There exists a shell script automating that task . Default to HTTPS When finished, restarted and verified that HTTPS works as expected, you can change Opencast's default URL to the HTTPS one. Set org.opencastproject.server.url to the HTTPS-URL in etc/custom.properties . org.opencastproject.server.url=https://opencast.example.com","title":"Internal HTTPS"},{"location":"configuration/https/opencast.only/#enable-https-directly-in-opencast","text":"Edit etc/org.ops4j.pax.web.cfg and set: # This property specifies the comma separated list of addresses used by Opencast to listen to (e.g. localhost or # localhost,10.0.0.1). Host names or IP addresses can be used. Pax Web default value is \"0.0.0.0\". org.ops4j.pax.web.listening.addresses=0.0.0.0 # Whether Opencast itself should handle HTTPS traffic. # Even if you set this to 'false',you can still use an HTTP proxy to handle SSL. org.osgi.service.http.secure.enabled=true # The secure server port to use if running Opencast with HTTPS (as opposed to # a proxy handling HTTPS). # Note that we use the docker proxy for the port-mapping from 8843 from within # the container to 443 at the host # Don't run Opencast with root privileges, which is a security issue org.osgi.service.http.port.secure=8443 # Path to the keystore file. # Use the Java `keytool` to generate this file. # Example: # keytool -genkey -keyalg RSA -validity 365 -alias serverkey \\ # -keypass password -storepass password -keystore keystore.jks org.ops4j.pax.web.ssl.keystore=<path_to_keystore> # Password used for keystore integrity check. org.ops4j.pax.web.ssl.password=<the_keystore_password> # Password used for keystore. org.ops4j.pax.web.ssl.keypassword=<the_key_password>","title":"Enable HTTPS directly in Opencast"},{"location":"configuration/https/opencast.only/#port-forwarding-required","text":"Note that Opencast most likely can't bind to port 443. That's why you still need to reverse-proxy or port-forward if you want to avoid URLs with port specified like https://host:8443/ which is technically perfectly okay but may confuse users or may be perceived as \"ugly\". Here is a non-comprehensive lists of tools and methods which can be used for port forwarding:","title":"Port-Forwarding required"},{"location":"configuration/https/opencast.only/#port-forwarding-with-iptables","text":"A rule like iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443 # Allow also localhost traffic to use :443 # iptables -A OUTPUT -t nat -o lo -p tcp --dport 443 -j REDIRECT --to-port 8443 should do the job after replacing eth0 with the network interface your Opencast consumers will connect on. Note that you usually want to persist the rule.","title":"Port-Forwarding with iptables"},{"location":"configuration/https/opencast.only/#port-forwarding-with-docker-proxy","text":"When starting a container from an Opencast image, either insert a command line argument to docker run: -p 443:8443 or add a ports: in docker-compose.yaml .","title":"Port-Forwarding with docker(-proxy)"},{"location":"configuration/https/opencast.only/#port-forwarding-with-sniproxy","text":"Sniproxy can be used as well, especially if you have multiple servers running on the same machine that handle HTTPS individually (no termination proxy). user, pidfile, error_log ... listen 443 { proto tls table https_hosts fallback 127.0.0.1:8443 access_log { filename /var/log/sniproxy/https_access.log priority notice } } table https_hosts { .*\\.opencast\\.example\\.org 127.0.0.1:8443 }","title":"Port-Forwarding with sniproxy"},{"location":"configuration/https/opencast.only/#creating-the-keystore","text":"What you need is the TLS private key and the certificate including the whole chain between the root certificate, all intermediates and the certificate itself.","title":"Creating the keystore"},{"location":"configuration/https/opencast.only/#step-1-obtaining-the-certificate-chain","text":"If you only have the key and the certificate, I recommend certificatechain.io or cert-chain-resolver . The latter can be used as follows: # Obtain the chain for cert.pem and save it at opencast.chain.pem.tmp # The -s command switch includes the root certificate; this is not # mandatory and might add some overhead cert-chain-resolver -s -o \"opencast.chain.pem.tmp\" \"cert.pem\" # Verify the certificate using the chain openssl verify -crl_download -crl_check -untrusted \"opencast.chain.pem.tmp\" \"cert.pem\"","title":"Step 1: Obtaining the certificate chain"},{"location":"configuration/https/opencast.only/#step-2-create-the-p12-keystore","text":"If the private key (assumed to be key.pem ) is encrypted (password protected), issue the following command. Note that there are safer ways supplying the key's password to OpenSSL. openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -passin \"pass:<the_keys_password>\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\" In case the private key is not protected by password: openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\"","title":"Step 2: Create the p12 keystore"},{"location":"configuration/https/opencast.only/#step-3-import-the-p12-keystore-into-a-java-keystore","text":"keytool \\ -importkeystore \\ -srckeystore \"opencast.p12\" \\ -srcstoretype \"pkcs12\" \\ -srcstorepass \"<the_keystore_password>\" \\ -destkeystore \"keystore.jks\" \\ -storepass \"<the_keystore_password>\" # print out details about the JKS built keytool \\ -keystore \"keystore.jks\" \\ -list \\ -destalias serverkey \\ -storepass \"<the_keystore_password>\" There exists a shell script automating that task .","title":"Step 3: Import the p12 keystore into a Java keystore:"},{"location":"configuration/https/opencast.only/#default-to-https","text":"When finished, restarted and verified that HTTPS works as expected, you can change Opencast's default URL to the HTTPS one. Set org.opencastproject.server.url to the HTTPS-URL in etc/custom.properties . org.opencastproject.server.url=https://opencast.example.com","title":"Default to HTTPS"},{"location":"configuration/https/self-signed-certificates/","text":"Self-Signed Certificates Since commit 4225bf ( security advisory GHSA-44cw-p2hm-gpf6 ) Opencast services check the validity of the certificates presented by third parties and when connecting to each other remotely. The validity check by Opencast's HTTPS client is basically performed the same way as any other HTTPS client would, for instance: validate the host name look up if the certificate is signed by a trusted Certificate Authority (CA) In case of self-signed certificates, a check whether the certificate is signed by a trusted CA, would fail. You are advised to obtain a valid certificate, issued by a trusted CA like Let's Encrypt . However, valid certificates are not always an option for testing or developer instances of Opencast, especially with Enterprise Firewalls or CAA records in place. Generating Self-Signed Certificates A self-signed certificate for multiple host names can be created with openSSL as follows: testing-cert.req.conf : [req] distinguished_name = req_distinguished_name x509_extensions = v3_req prompt = no [req_distinguished_name] C = CH ST = Wallis L = Matterhorn O = Apereo OU = Opencast CN = opencast [v3_req] keyUsage = nonRepudiation, digitalSignature, keyEncipherment extendedKeyUsage = serverAuth subjectAltName = @alt_names [alt_names] DNS.1 = opencast DNS.2 = presentation.local DNS.3 = admin.local DNS.4 = admin DNS.5 = presentation DNS.6 = worker DNS.7 = worker.local openssl req \\ -x509 \\ -nodes \\ -days 365 \\ -newkey rsa:2048 \\ -keyout key.pem \\ -out testing.pem \\ -config testing-cert.req.conf \\ -extensions 'v3_req' In order to view the just generated cert: openssl x509 -in testing.pem -text -noout Trusting Self-Signed Certificates In order to use self-signed certificates for testing or developer instances of Opencast, import your self-signed certificate(s) into the Java Trust Store (bundle of trusted CA certs) and restart Opencast. Store your certificate in a format compatible with keytool somewhere: cat >/tmp/testing.crt <<EOL -----BEGIN CERTIFICATE----- MIIGJzCCBA+gAw... ...O6g== -----END CERTIFICATE----- EOL Import the certificate with alias testing_root into the javax.net.ssl.trustStrore whose password defaults to changeit without asking questions: keytool \\ -import \\ -noprompt \\ -trustcacerts \\ -storepass changeit \\ -alias testing_root \\ -file /tmp/testing.crt \\ -keystore $JAVA_HOME/jre/lib/security/cacerts Delete the temporary file: rm /tmp/testing.crt Restart Opencast.","title":"Self-Signed Certificates"},{"location":"configuration/https/self-signed-certificates/#self-signed-certificates","text":"Since commit 4225bf ( security advisory GHSA-44cw-p2hm-gpf6 ) Opencast services check the validity of the certificates presented by third parties and when connecting to each other remotely. The validity check by Opencast's HTTPS client is basically performed the same way as any other HTTPS client would, for instance: validate the host name look up if the certificate is signed by a trusted Certificate Authority (CA) In case of self-signed certificates, a check whether the certificate is signed by a trusted CA, would fail. You are advised to obtain a valid certificate, issued by a trusted CA like Let's Encrypt . However, valid certificates are not always an option for testing or developer instances of Opencast, especially with Enterprise Firewalls or CAA records in place.","title":"Self-Signed Certificates"},{"location":"configuration/https/self-signed-certificates/#generating-self-signed-certificates","text":"A self-signed certificate for multiple host names can be created with openSSL as follows: testing-cert.req.conf : [req] distinguished_name = req_distinguished_name x509_extensions = v3_req prompt = no [req_distinguished_name] C = CH ST = Wallis L = Matterhorn O = Apereo OU = Opencast CN = opencast [v3_req] keyUsage = nonRepudiation, digitalSignature, keyEncipherment extendedKeyUsage = serverAuth subjectAltName = @alt_names [alt_names] DNS.1 = opencast DNS.2 = presentation.local DNS.3 = admin.local DNS.4 = admin DNS.5 = presentation DNS.6 = worker DNS.7 = worker.local openssl req \\ -x509 \\ -nodes \\ -days 365 \\ -newkey rsa:2048 \\ -keyout key.pem \\ -out testing.pem \\ -config testing-cert.req.conf \\ -extensions 'v3_req' In order to view the just generated cert: openssl x509 -in testing.pem -text -noout","title":"Generating Self-Signed Certificates"},{"location":"configuration/https/self-signed-certificates/#trusting-self-signed-certificates","text":"In order to use self-signed certificates for testing or developer instances of Opencast, import your self-signed certificate(s) into the Java Trust Store (bundle of trusted CA certs) and restart Opencast. Store your certificate in a format compatible with keytool somewhere: cat >/tmp/testing.crt <<EOL -----BEGIN CERTIFICATE----- MIIGJzCCBA+gAw... ...O6g== -----END CERTIFICATE----- EOL Import the certificate with alias testing_root into the javax.net.ssl.trustStrore whose password defaults to changeit without asking questions: keytool \\ -import \\ -noprompt \\ -trustcacerts \\ -storepass changeit \\ -alias testing_root \\ -file /tmp/testing.crt \\ -keystore $JAVA_HOME/jre/lib/security/cacerts Delete the temporary file: rm /tmp/testing.crt Restart Opencast.","title":"Trusting Self-Signed Certificates"},{"location":"installation/","text":"Install Opencast Server requirements higly depend on on processed material. There are a few hints about a sensible machine setup to run Opencast on: Hardware requirements Installation from Repository There are package repositories available for multiple operating systems. It provides packages containing pre-configured and pre-built Opencast installations. RedHat 8 based RedHat Enterprise Linux 8 CentOS 8 RedHat 7 based RedHat Enterprise Linux 7 CentOS 7 Scientific Linux 7 Fedora Debian based Debian Ubuntu Installation with Docker You can also use Docker to quickly install or test Opencast. There are multiple Docker images available for installing Opencast on either a single or multiple server. Testing Locally with Docker Installation from Source These guides will help you to build Opencast, including all necessary third party tools. This method will most likely work on all Unix-like systems and should be very similar on undocumented systems. Linux macOS (no official support) Installation Across Multiple Servers For production systems, it is recommended to install Opencast across multiple servers to separate the processing, management and presentation layer, so that, for example, even if the processing layer is under full load, users can still watch recordings unaffected since the presentation layer is running on a separate machine. Installation Across Multiple Servers Installation via Script We provide configuration scripts to install and configure Opencast automatically. These scripts rely on the packages from the repository above. Ansible","title":"Overview"},{"location":"installation/#install-opencast","text":"Server requirements higly depend on on processed material. There are a few hints about a sensible machine setup to run Opencast on: Hardware requirements","title":"Install Opencast"},{"location":"installation/#installation-from-repository","text":"There are package repositories available for multiple operating systems. It provides packages containing pre-configured and pre-built Opencast installations. RedHat 8 based RedHat Enterprise Linux 8 CentOS 8 RedHat 7 based RedHat Enterprise Linux 7 CentOS 7 Scientific Linux 7 Fedora Debian based Debian Ubuntu","title":"Installation from Repository"},{"location":"installation/#installation-with-docker","text":"You can also use Docker to quickly install or test Opencast. There are multiple Docker images available for installing Opencast on either a single or multiple server. Testing Locally with Docker","title":"Installation with Docker"},{"location":"installation/#installation-from-source","text":"These guides will help you to build Opencast, including all necessary third party tools. This method will most likely work on all Unix-like systems and should be very similar on undocumented systems. Linux macOS (no official support)","title":"Installation from Source"},{"location":"installation/#installation-across-multiple-servers","text":"For production systems, it is recommended to install Opencast across multiple servers to separate the processing, management and presentation layer, so that, for example, even if the processing layer is under full load, users can still watch recordings unaffected since the presentation layer is running on a separate machine. Installation Across Multiple Servers","title":"Installation Across Multiple Servers"},{"location":"installation/#installation-via-script","text":"We provide configuration scripts to install and configure Opencast automatically. These scripts rely on the packages from the repository above. Ansible","title":"Installation via Script"},{"location":"installation/ansible/","text":"Install from Repository via Ansible (Debian, and RedHat based distros) We provide Ansible installation and configuration scripts which drastically reduce the time required to set up an Opencast installation, and help you manage the configuration across your entire cluster. Whether you are installing a single machine, or dozens, these scripts should do the basic setup of your Opencast install. Note that these scripts are meant as a basis to get you started and you will likely need to adjust and extend them to fit your local environment for which you need to have some basic knowledge of Ansible. Please review the scripts before using them to make sure they fit your needs. Examples in this document refer to 7.x and r/7.x . You should replace those with the version you want to install! Install Ansible Ansible may be available from your distribution's packaging manager, or you may need to install it manually. See the Ansible installation documentation for more details. Script Setup The next step is getting the scripts themselves. Go to the list of branches and then click on the branch version you want. This must match the desired Opencast version, so if you want the latest Opencast 7 release click on r/7.x . Then click on Clone or download , then Download Zip . You will need to decompress this file someplace handy, and then run terminal commands from inside that directory. Alternatively, if you familiar with git you can just clone the repository like this git clone -b r/7.x https://github.com/opencast/oc-config-management Install Opencast To complete your install, please follow the instructions in the README.md documentation included in the scripts.","title":"Ansible"},{"location":"installation/ansible/#install-from-repository-via-ansible-debian-and-redhat-based-distros","text":"We provide Ansible installation and configuration scripts which drastically reduce the time required to set up an Opencast installation, and help you manage the configuration across your entire cluster. Whether you are installing a single machine, or dozens, these scripts should do the basic setup of your Opencast install. Note that these scripts are meant as a basis to get you started and you will likely need to adjust and extend them to fit your local environment for which you need to have some basic knowledge of Ansible. Please review the scripts before using them to make sure they fit your needs. Examples in this document refer to 7.x and r/7.x . You should replace those with the version you want to install!","title":"Install from Repository via Ansible (Debian, and RedHat based distros)"},{"location":"installation/ansible/#install-ansible","text":"Ansible may be available from your distribution's packaging manager, or you may need to install it manually. See the Ansible installation documentation for more details.","title":"Install Ansible"},{"location":"installation/ansible/#script-setup","text":"The next step is getting the scripts themselves. Go to the list of branches and then click on the branch version you want. This must match the desired Opencast version, so if you want the latest Opencast 7 release click on r/7.x . Then click on Clone or download , then Download Zip . You will need to decompress this file someplace handy, and then run terminal commands from inside that directory. Alternatively, if you familiar with git you can just clone the repository like this git clone -b r/7.x https://github.com/opencast/oc-config-management","title":"Script Setup"},{"location":"installation/ansible/#install-opencast","text":"To complete your install, please follow the instructions in the README.md documentation included in the scripts.","title":"Install Opencast"},{"location":"installation/debs/","text":"Install from Repository (Debian, Ubuntu) There is a Debian software repository (DEB) available for Debian-based Linux distributions provided by Greg Logan, and hosted at University of Osnabr\u00fcck. This repository provides prebuilt Opencast installations, including all 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself, but you still need to configure it. It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided by the Debian repository. Availability Note that it may take some time (usually about a week after a new release is out) before the Debian packages are available. Watch for announcements on list or just check which versions are available in the repository. Currently Supported Debian 9 and newer amd64 Ubuntu 18.04 amd64 Supported JDKs For Opencast 9 we support JDK 8 and JDK 11, however Opencast 10 will drop support for JDK 8. We strongly encourage you to use JDK 11 for Opencast 9. Activate Repository First you have to install the necessary repositories so that your package manager can access them: Ensure https repositories are supported: apt-get install apt-transport-https ca-certificates sudo wget gnupg2 Add Opencast repository: echo \"deb https://pkg.opencast.org/debian 9.x stable\" | sudo tee /etc/apt/sources.list.d/opencast.list It might take some time after the release of a new Opencast version before the Debs are moved to the stable repository. If you need the new release prior to its promotion to stable you can use the testing repository. Note that the testing repository is an additional repository and still requires the stable repository to be active. echo \"deb https://pkg.opencast.org/debian 9.x stable testing\" | sudo tee /etc/apt/sources.list.d/opencast.list Add the repository key to your apt keyring: wget -qO - https://pkg.opencast.org/gpgkeys/opencast-deb.key | sudo apt-key add - Update your package listing apt-get update Install Apache ActiveMQ The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be installed on the same machine as Opencast, however many adopters commonly install it on their admin nodes. Install ActiveMQ with: apt-get install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ must be started prior to Opencast startup. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation . Note that most Debian based distributions also have ActiveMQ packaged by upstream package maintainers. These packages will work, however the ActiveMQ configuration file will require modification to function correctly. Install Elasticsearch Starting with Opencast 9, Elasticsearch is now a dependency. Our packages do not explicitly depend on Elasticsearch because it runs externally to Opencast. By default we expect Elasticsearch to be running on the admin node, however you can configure the URL in Opencast's configuration files. In our repository we provide validated Elasticsearch packages copied from the upstream repository. Installation can be accomplished by running the following: apt-get install elasticsearch-oss If you wish to use the upstream Elasticsearch repository directly be aware that Opencast only formally supports Elasticsearch versions with the same major and minor version values. That is, if our 9.x repository has Elasticsearch 7.9.2 then Opencast only formally supports Elasticsearch versions starting with 7.9. Install Opencast For this guide we will be installing the latest released version of Opencast 9.x, however if you wish to install another version please change the name accordingly. Basic Installation For a basic installation (All-In-One) just run: apt-get install opencast-9-allinone elasticsearch-oss activemq-dist This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools. Note that while the repository provides a packaged version of FFmpeg, your distribution may have a version which is pre-installed or otherwise takes precedence. This version may work, however Opencast only formally supports the version(s) in the repository. To install the Opencast version of ffmpeg add ffmpeg-dist to the end of the command above. At this point Opencast is installed and will work locally, but it is not completely configured. Because additional configuration is required, neither Opencast nor ActiveMQ are configured to start automatically. Please follow the Basic Configuration guide . Once you are ready, enable Opencast and ActiveMQ to start on boot with: systemctl enable activemq.service systemctl enable elasticsearch.service systemctl enable opencast.service then start them with: systemctl start activemq.service systemctl start elasticsearch.service systemctl start opencast.service Advanced Installation While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might want to have more control over your system and deploy it over several machines by choosing which parts of Opencast you want to install. You can list all Opencast packages with: apt-cache search opencast This will list all available Opencast distributions in the form opencast-<version>-<dist-type> Some available distributions are: opencast-X-allinone opencast-X-admin opencast-X-presentation opencast-X-worker \u2026where X stands for a specific Opencast version. These packages will install the latest release for a given version, so opencast-8-admin will install the admin profile for Opencast 8.x (currently 8.9). Once Opencast 8.10 has been packaged and made available your system will automatically update to Opencast 8.10 using the standard apt-get tools. To list all available packages and versions, use: apt list 'opencast*' Point Revisions (Experts only) If for some reason you wish to install a specific point revision of Opencast, and the repository still hosts that point revision, you can select it by adding it, and the packaging build, to your apt-get install line. For example: apt-get install opencast-8-admin=8.9-2 Installs an Opencast 8.9 admin node, using the second build of that series. Not all series have more than a single build, and older point revisions may be removed once superceded, so please explore the repository prior to attempting this. Install 3rd-party-tools This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast from the repository, all necessary dependencies will be installed automatically. You can install all necessary 3rd-Party-Tools for Opencast like this: apt-get install ffmpeg-dist tesseract-ocr sox hunspell netcat Upgrading Major Versions While these packages will automatically upgrade you to the latest point version in a release series, they do not automatically upgrade you to the latest major version. In other words, if you install opencast-9-admin you get the latest 9.x release, not the latest 10.x release. To upgrade from one version to another you first stop Opencast: systemctl stop opencast.service As a reminder, these instructions will change your Opencast installation, and files to a new version which is likely incompatible with older versions. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast packaging (using Opencast 8 as an example): apt-get remove opencast-8-* Then install the new version (using Opencast 9 as an example): apt-get install opencast-9-allinone At this point you must follow the relevant upgrade instructions, prior to starting Opencast again. Uninstall Opencast To uninstall Opencast, you can run: apt-get remove 'opencast*' This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast Troubleshooting Missing Dependencies This repository expects that the stable section is always available, regardless of which version of Opencast you have installed. The 3rd party tools (ActiveMQ, FFmpeg) may or may not be in the other sections, but if they are there it is only during a testing period for a new version. For day-to-day use, please install them from stable !","title":"Debian/Ubuntu"},{"location":"installation/debs/#install-from-repository-debian-ubuntu","text":"There is a Debian software repository (DEB) available for Debian-based Linux distributions provided by Greg Logan, and hosted at University of Osnabr\u00fcck. This repository provides prebuilt Opencast installations, including all 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself, but you still need to configure it. It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided by the Debian repository.","title":"Install from Repository (Debian, Ubuntu)"},{"location":"installation/debs/#availability","text":"Note that it may take some time (usually about a week after a new release is out) before the Debian packages are available. Watch for announcements on list or just check which versions are available in the repository.","title":"Availability"},{"location":"installation/debs/#currently-supported","text":"Debian 9 and newer amd64 Ubuntu 18.04 amd64","title":"Currently Supported"},{"location":"installation/debs/#supported-jdks","text":"For Opencast 9 we support JDK 8 and JDK 11, however Opencast 10 will drop support for JDK 8. We strongly encourage you to use JDK 11 for Opencast 9.","title":"Supported JDKs"},{"location":"installation/debs/#activate-repository","text":"First you have to install the necessary repositories so that your package manager can access them: Ensure https repositories are supported: apt-get install apt-transport-https ca-certificates sudo wget gnupg2 Add Opencast repository: echo \"deb https://pkg.opencast.org/debian 9.x stable\" | sudo tee /etc/apt/sources.list.d/opencast.list It might take some time after the release of a new Opencast version before the Debs are moved to the stable repository. If you need the new release prior to its promotion to stable you can use the testing repository. Note that the testing repository is an additional repository and still requires the stable repository to be active. echo \"deb https://pkg.opencast.org/debian 9.x stable testing\" | sudo tee /etc/apt/sources.list.d/opencast.list Add the repository key to your apt keyring: wget -qO - https://pkg.opencast.org/gpgkeys/opencast-deb.key | sudo apt-key add - Update your package listing apt-get update","title":"Activate Repository"},{"location":"installation/debs/#install-apache-activemq","text":"The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be installed on the same machine as Opencast, however many adopters commonly install it on their admin nodes. Install ActiveMQ with: apt-get install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ must be started prior to Opencast startup. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation . Note that most Debian based distributions also have ActiveMQ packaged by upstream package maintainers. These packages will work, however the ActiveMQ configuration file will require modification to function correctly.","title":"Install Apache ActiveMQ"},{"location":"installation/debs/#install-elasticsearch","text":"Starting with Opencast 9, Elasticsearch is now a dependency. Our packages do not explicitly depend on Elasticsearch because it runs externally to Opencast. By default we expect Elasticsearch to be running on the admin node, however you can configure the URL in Opencast's configuration files. In our repository we provide validated Elasticsearch packages copied from the upstream repository. Installation can be accomplished by running the following: apt-get install elasticsearch-oss If you wish to use the upstream Elasticsearch repository directly be aware that Opencast only formally supports Elasticsearch versions with the same major and minor version values. That is, if our 9.x repository has Elasticsearch 7.9.2 then Opencast only formally supports Elasticsearch versions starting with 7.9.","title":"Install Elasticsearch"},{"location":"installation/debs/#install-opencast","text":"For this guide we will be installing the latest released version of Opencast 9.x, however if you wish to install another version please change the name accordingly.","title":"Install Opencast"},{"location":"installation/debs/#basic-installation","text":"For a basic installation (All-In-One) just run: apt-get install opencast-9-allinone elasticsearch-oss activemq-dist This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools. Note that while the repository provides a packaged version of FFmpeg, your distribution may have a version which is pre-installed or otherwise takes precedence. This version may work, however Opencast only formally supports the version(s) in the repository. To install the Opencast version of ffmpeg add ffmpeg-dist to the end of the command above. At this point Opencast is installed and will work locally, but it is not completely configured. Because additional configuration is required, neither Opencast nor ActiveMQ are configured to start automatically. Please follow the Basic Configuration guide . Once you are ready, enable Opencast and ActiveMQ to start on boot with: systemctl enable activemq.service systemctl enable elasticsearch.service systemctl enable opencast.service then start them with: systemctl start activemq.service systemctl start elasticsearch.service systemctl start opencast.service","title":"Basic Installation"},{"location":"installation/debs/#advanced-installation","text":"While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might want to have more control over your system and deploy it over several machines by choosing which parts of Opencast you want to install. You can list all Opencast packages with: apt-cache search opencast This will list all available Opencast distributions in the form opencast-<version>-<dist-type> Some available distributions are: opencast-X-allinone opencast-X-admin opencast-X-presentation opencast-X-worker \u2026where X stands for a specific Opencast version. These packages will install the latest release for a given version, so opencast-8-admin will install the admin profile for Opencast 8.x (currently 8.9). Once Opencast 8.10 has been packaged and made available your system will automatically update to Opencast 8.10 using the standard apt-get tools. To list all available packages and versions, use: apt list 'opencast*'","title":"Advanced Installation"},{"location":"installation/debs/#point-revisions-experts-only","text":"If for some reason you wish to install a specific point revision of Opencast, and the repository still hosts that point revision, you can select it by adding it, and the packaging build, to your apt-get install line. For example: apt-get install opencast-8-admin=8.9-2 Installs an Opencast 8.9 admin node, using the second build of that series. Not all series have more than a single build, and older point revisions may be removed once superceded, so please explore the repository prior to attempting this.","title":"Point Revisions (Experts only)"},{"location":"installation/debs/#install-3rd-party-tools","text":"This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast from the repository, all necessary dependencies will be installed automatically. You can install all necessary 3rd-Party-Tools for Opencast like this: apt-get install ffmpeg-dist tesseract-ocr sox hunspell netcat","title":"Install 3rd-party-tools"},{"location":"installation/debs/#upgrading-major-versions","text":"While these packages will automatically upgrade you to the latest point version in a release series, they do not automatically upgrade you to the latest major version. In other words, if you install opencast-9-admin you get the latest 9.x release, not the latest 10.x release. To upgrade from one version to another you first stop Opencast: systemctl stop opencast.service As a reminder, these instructions will change your Opencast installation, and files to a new version which is likely incompatible with older versions. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast packaging (using Opencast 8 as an example): apt-get remove opencast-8-* Then install the new version (using Opencast 9 as an example): apt-get install opencast-9-allinone At this point you must follow the relevant upgrade instructions, prior to starting Opencast again.","title":"Upgrading Major Versions"},{"location":"installation/debs/#uninstall-opencast","text":"To uninstall Opencast, you can run: apt-get remove 'opencast*' This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast","title":"Uninstall Opencast"},{"location":"installation/debs/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"installation/debs/#missing-dependencies","text":"This repository expects that the stable section is always available, regardless of which version of Opencast you have installed. The 3rd party tools (ActiveMQ, FFmpeg) may or may not be in the other sections, but if they are there it is only during a testing period for a new version. For day-to-day use, please install them from stable !","title":"Missing Dependencies"},{"location":"installation/docker-local/","text":"Testing Locally with Docker Opencast is a complex system that requires multiple steps to install and configure properly, which may be too complicated for quick, local testing. Therefore, the University of M\u00fcnster provides various Docker images for Opencast that can simplify this process. The only requirement is an x86_64 Linux system with a running Docker Engine. This method is ideal for new adopters who just want to try out Opencast. It can also be used to test workflows. Because of the isolation that Docker provides, multiple instances of Opencast can run in parallel on a single system. This might be helpful for developers. Install Docker Docker is available for multiple Linux distributions. Please have a look at the official documentation for the latest installation instructions. Note that it might be necessary to install docker-compose separately. Start with docker-compose Opencast is packaged into multiple distributions. There is a separate Docker image for each distribution. Simple installations can use the all-in-one distribution. Opencast requires a database and a message broker (Apache ActiveMQ). We currently support H2 or MySQL/MariaDB databases. The Docker Hub repository has official Docker images for MySQL and MariaDB. H2 is already integrated into Opencast so that no database container is needed. There are multiple 3rd-party Docker images for ActiveMQ; this guide uses webcenter/activemq . docker-compose can be used to configure, start and connect all services automatically. The opencast-docker repository contains multiple configuration examples: Configuration Compose file all-in-one + H2 https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2.yml all-in-one + H2 + pyCA https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2+pyca.yml all-in-one + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.mariadb.yml all-in-one + PostgreSQL https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.postgresql.yml admin, presentation, worker + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.mariadb.yml admin, presentation, worker + PostgreSQL https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.postgresql.yml Choose and download a configuration: $ curl -o docker-compose.yml <URL> You might want to edit the compose file and add extra volumes to include custom configurations or workflows (see compose file reference ). The compose files assume that the ActiveMQ configuration is located at ./assets/activemq.xml . You can download the file from the repository: $ mkdir assets $ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml Alternatively, you can use the Docker images to generate the file. This has the advantage that the correct version is always used: $ mkdir assets $ docker run -it --rm \\ quay.io/opencast/allinone:<version> \\ app:print:activemq.xml > assets/activemq.xml At this point you are ready to start Opencast with the up command: $ docker-compose up After downloading the necessary Docker images, docker-compose should start all relevant services and you should see the logging output. Alternatively, adding the -d flag will start Opencast in the background and hide the log messages. The admin UI is available at http://localhost:8080 . The down command will stop Opencast and remove the created Docker containers. All relevant Opencast files are still preserved in Docker volumes. To remove them as well, run down -v instead.","title":"Testing Locally"},{"location":"installation/docker-local/#testing-locally-with-docker","text":"Opencast is a complex system that requires multiple steps to install and configure properly, which may be too complicated for quick, local testing. Therefore, the University of M\u00fcnster provides various Docker images for Opencast that can simplify this process. The only requirement is an x86_64 Linux system with a running Docker Engine. This method is ideal for new adopters who just want to try out Opencast. It can also be used to test workflows. Because of the isolation that Docker provides, multiple instances of Opencast can run in parallel on a single system. This might be helpful for developers.","title":"Testing Locally with Docker"},{"location":"installation/docker-local/#install-docker","text":"Docker is available for multiple Linux distributions. Please have a look at the official documentation for the latest installation instructions. Note that it might be necessary to install docker-compose separately.","title":"Install Docker"},{"location":"installation/docker-local/#start-with-docker-compose","text":"Opencast is packaged into multiple distributions. There is a separate Docker image for each distribution. Simple installations can use the all-in-one distribution. Opencast requires a database and a message broker (Apache ActiveMQ). We currently support H2 or MySQL/MariaDB databases. The Docker Hub repository has official Docker images for MySQL and MariaDB. H2 is already integrated into Opencast so that no database container is needed. There are multiple 3rd-party Docker images for ActiveMQ; this guide uses webcenter/activemq . docker-compose can be used to configure, start and connect all services automatically. The opencast-docker repository contains multiple configuration examples: Configuration Compose file all-in-one + H2 https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2.yml all-in-one + H2 + pyCA https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2+pyca.yml all-in-one + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.mariadb.yml all-in-one + PostgreSQL https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.postgresql.yml admin, presentation, worker + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.mariadb.yml admin, presentation, worker + PostgreSQL https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.postgresql.yml Choose and download a configuration: $ curl -o docker-compose.yml <URL> You might want to edit the compose file and add extra volumes to include custom configurations or workflows (see compose file reference ). The compose files assume that the ActiveMQ configuration is located at ./assets/activemq.xml . You can download the file from the repository: $ mkdir assets $ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml Alternatively, you can use the Docker images to generate the file. This has the advantage that the correct version is always used: $ mkdir assets $ docker run -it --rm \\ quay.io/opencast/allinone:<version> \\ app:print:activemq.xml > assets/activemq.xml At this point you are ready to start Opencast with the up command: $ docker-compose up After downloading the necessary Docker images, docker-compose should start all relevant services and you should see the logging output. Alternatively, adding the -d flag will start Opencast in the background and hide the log messages. The admin UI is available at http://localhost:8080 . The down command will stop Opencast and remove the created Docker containers. All relevant Opencast files are still preserved in Docker volumes. To remove them as well, run down -v instead.","title":"Start with docker-compose"},{"location":"installation/multiple-servers/","text":"Install Across Multiple Servers Note that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good practices and presents what a lot of people are running. Step 1: Install Opencast Opencast consists of a large set of modules which together build the whole system. In a distributed set-up, different kinds of nodes are basically only defined by the existence or absence of specific modules. While it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution which can directly be built and installed. To build these distributions, you would compile Opencast just like it is outlined in the basic installation guides and will then find a set of different distributions, both as archive and in a separate directory. To list all distributions, run the following command after Opencast is built: % ls -1 build/*.tar.gz build/opencast-dist-admin-${version}.tar.gz build/opencast-dist-allinone-${version}.tar.gz build/opencast-dist-presentation-${version}.tar.gz build/opencast-dist-worker-${version}.tar.g ... The same distributions can be found in the packages provided in the Opencast RPM repository. These packages will automatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would install the package opencast21-distribution-worker . The following list describes possible set-ups: All-In-One This is the default set-up described in the basic installation guides. It works fine for testing purposes. It should usually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined distributions. Two-Server Set-up This set-up is the minimum set-up recommended for productive use. It will separate the video processing from the rest of the system, making the user-facing parts of your system much less affected by heavier loads. Three (or more) Server Set-up While in the last example we have created one combined node for both the administrative tools and the workers, in this example we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems performance simply by adding further worker nodes to the system. Step 2: Set-Up NFS Server Though it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can be used to link files instead of copying them and not everything has to be tunneled over HTTP. Thus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For smaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node. To do this, you first have to install and enable the NFS server: yum install nfs-utils nfs-utils-lib chkconfig --level 345 nfs on service nfs start You want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation for this it makes sense to manually create an opencast user and group with a common UID and GID: groupadd -g 1234 opencast useradd -g 1234 -u 1234 opencast If the user and group id 1234 is already used, just pick another one but make sure to pick the same one on all your Opencast nodes. Then create the directory to be shared and set its ownership to the newly created users: mkdir -p /srv/opencast chown opencast:opencast /srv/opencast Next we actually share the storage dir. For this we need to edit the file /etc/exports and set: /srv/opencast 131.173.172.190(rw,sync,no_subtree_check) with 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with: exportfs -a Of cause you have to open the necessary ports in your firewall configuration. For iptables, appropriate rules could be for example: -A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT -A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT You can set them by editing /etc/sysconfig/iptables and restarting the service afterwards. Now you have set-up your storage server. What is still left to do is to mount the network storage on all other servers of the Opencast clusters except the capture agents. To do that you need to edit the /etc/fstab on each server and add the command to mount the network storage on startup: storageserver.example.com:/srv/opencast /srv/opencast nfs rw,hard,intr,rsize=32768,wsize=32768 0 0 Important: Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if hard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible between certain parts of the storage. This may lead to failures. Important: Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage directory only. Step 3: Set-Up the Database First make sure to follow the regular database set-up . Do not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to configure your firewall: -A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT Step 4: Set-Up ActiveMQ Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node). ActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested. Installation If you use the Opencast RPM repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository You can download binary distributions from the Apache ActiveMQ website Configuration What you basically need to do is to point all your Opencast nodes to your message broker. For more information about the configuration, have a look at the Message Broker Set-Up Guide . Do not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow in your firewall. Step 5: Configure Opencast You did already set-up and configured your database and message broker in the last steps, but there is some more configuration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to set the login credentials etc. After that continue with the following steps: custom.properties Set the server URL to the public URL of each server (admin URL on admin, worker URL on worker, presentation URL on presentation, \u2026). This may either be this nodes IP address or preferable its domain name: org.opencastproject.server.url=http://<URL>:8080 Set the location of the shared storage directory: org.opencastproject.storage.dir=/srv/opencast org.opencastproject.organization-mh_default_org.cfg Set the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if possible: prop.org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080 Set the base URL of the server hosting the engage tools (usually the presentation node): prop.org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080 Set the base URL of the file server. When using a shared filesystem between servers, set all servers to use the same URL (e.g. URL of the admin node). prop.org.opencastproject.file.repo.url=http://<ADMIN-URL>:8080 org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg To ensure that jobs are not dispatched by non-admin nodes, on these you should also set: dispatch.interval=0","title":"Multiple Servers"},{"location":"installation/multiple-servers/#install-across-multiple-servers","text":"Note that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good practices and presents what a lot of people are running.","title":"Install Across Multiple Servers"},{"location":"installation/multiple-servers/#step-1-install-opencast","text":"Opencast consists of a large set of modules which together build the whole system. In a distributed set-up, different kinds of nodes are basically only defined by the existence or absence of specific modules. While it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution which can directly be built and installed. To build these distributions, you would compile Opencast just like it is outlined in the basic installation guides and will then find a set of different distributions, both as archive and in a separate directory. To list all distributions, run the following command after Opencast is built: % ls -1 build/*.tar.gz build/opencast-dist-admin-${version}.tar.gz build/opencast-dist-allinone-${version}.tar.gz build/opencast-dist-presentation-${version}.tar.gz build/opencast-dist-worker-${version}.tar.g ... The same distributions can be found in the packages provided in the Opencast RPM repository. These packages will automatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would install the package opencast21-distribution-worker . The following list describes possible set-ups:","title":"Step 1: Install Opencast"},{"location":"installation/multiple-servers/#all-in-one","text":"This is the default set-up described in the basic installation guides. It works fine for testing purposes. It should usually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined distributions.","title":"All-In-One"},{"location":"installation/multiple-servers/#two-server-set-up","text":"This set-up is the minimum set-up recommended for productive use. It will separate the video processing from the rest of the system, making the user-facing parts of your system much less affected by heavier loads.","title":"Two-Server Set-up"},{"location":"installation/multiple-servers/#three-or-more-server-set-up","text":"While in the last example we have created one combined node for both the administrative tools and the workers, in this example we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems performance simply by adding further worker nodes to the system.","title":"Three (or more) Server Set-up"},{"location":"installation/multiple-servers/#step-2-set-up-nfs-server","text":"Though it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can be used to link files instead of copying them and not everything has to be tunneled over HTTP. Thus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For smaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node. To do this, you first have to install and enable the NFS server: yum install nfs-utils nfs-utils-lib chkconfig --level 345 nfs on service nfs start You want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation for this it makes sense to manually create an opencast user and group with a common UID and GID: groupadd -g 1234 opencast useradd -g 1234 -u 1234 opencast If the user and group id 1234 is already used, just pick another one but make sure to pick the same one on all your Opencast nodes. Then create the directory to be shared and set its ownership to the newly created users: mkdir -p /srv/opencast chown opencast:opencast /srv/opencast Next we actually share the storage dir. For this we need to edit the file /etc/exports and set: /srv/opencast 131.173.172.190(rw,sync,no_subtree_check) with 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with: exportfs -a Of cause you have to open the necessary ports in your firewall configuration. For iptables, appropriate rules could be for example: -A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT -A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT You can set them by editing /etc/sysconfig/iptables and restarting the service afterwards. Now you have set-up your storage server. What is still left to do is to mount the network storage on all other servers of the Opencast clusters except the capture agents. To do that you need to edit the /etc/fstab on each server and add the command to mount the network storage on startup: storageserver.example.com:/srv/opencast /srv/opencast nfs rw,hard,intr,rsize=32768,wsize=32768 0 0 Important: Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if hard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible between certain parts of the storage. This may lead to failures. Important: Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage directory only.","title":"Step 2: Set-Up NFS Server"},{"location":"installation/multiple-servers/#step-3-set-up-the-database","text":"First make sure to follow the regular database set-up . Do not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to configure your firewall: -A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT","title":"Step 3: Set-Up the Database"},{"location":"installation/multiple-servers/#step-4-set-up-activemq","text":"Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node). ActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.","title":"Step 4: Set-Up ActiveMQ"},{"location":"installation/multiple-servers/#installation","text":"If you use the Opencast RPM repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository You can download binary distributions from the Apache ActiveMQ website","title":"Installation"},{"location":"installation/multiple-servers/#configuration","text":"What you basically need to do is to point all your Opencast nodes to your message broker. For more information about the configuration, have a look at the Message Broker Set-Up Guide . Do not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow in your firewall.","title":"Configuration"},{"location":"installation/multiple-servers/#step-5-configure-opencast","text":"You did already set-up and configured your database and message broker in the last steps, but there is some more configuration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to set the login credentials etc. After that continue with the following steps:","title":"Step 5: Configure Opencast"},{"location":"installation/multiple-servers/#customproperties","text":"Set the server URL to the public URL of each server (admin URL on admin, worker URL on worker, presentation URL on presentation, \u2026). This may either be this nodes IP address or preferable its domain name: org.opencastproject.server.url=http://<URL>:8080 Set the location of the shared storage directory: org.opencastproject.storage.dir=/srv/opencast","title":"custom.properties"},{"location":"installation/multiple-servers/#orgopencastprojectorganization-mh_default_orgcfg","text":"Set the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if possible: prop.org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080 Set the base URL of the server hosting the engage tools (usually the presentation node): prop.org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080 Set the base URL of the file server. When using a shared filesystem between servers, set all servers to use the same URL (e.g. URL of the admin node). prop.org.opencastproject.file.repo.url=http://<ADMIN-URL>:8080","title":"org.opencastproject.organization-mh_default_org.cfg"},{"location":"installation/multiple-servers/#orgopencastprojectserviceregistryimplserviceregistryjpaimplcfg","text":"To ensure that jobs are not dispatched by non-admin nodes, on these you should also set: dispatch.interval=0","title":"org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg"},{"location":"installation/rpm-el7/","text":"Install from Repository (Red Hat Enterprise Linux 7.x, CentOS 7.x, Scientific Linux 7.x) This guide is for EL7 only. There is a separate CentOS 8 and Red Hat Enterprise Linux 8 guide . This guide is based on an RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University . This repository provides preconfigured Opencast installations and all necessary 3rd-party-tools. Currently Supported CentOS 7.x (x86_64) Red Hat Enterprise Linux 7.x (x86_64) Scientific Linux 7.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported. Activate Repository First you have to install the necessary repositories: yum install -y https://pkg.opencast.org/rpms/release/el/7/oc-10/noarch/opencast-repository-10-1.el7.noarch.rpm It might take some time after the release of a new Opencast version before the RPMs are moved to the stable repository. Until then, you can use /etc/yum.repos.d/opencast-testing.repo instead to get the latest version. Note that the testing repository is an additional repository and still requires the stable repository to be active. You can check if the repositories were successfully enabled using: yum repolist enabled Install Opencast For a basic all-in-one installation just run: yum install opencast-allinone This will install the default distribution of Opencast and all its dependencies. For more options, see the advanced installation section below . Install Apache ActiveMQ The Apache ActiveMQ message broker is required by Opencast. It can be run on the same machine as Opencast. Install ActiveMQ by running: yum install activemq-dist A prepared configuration file for ActiveMQ comes with Opencast. It should suffice for an all-in-one installation and can be copied to replace the default configuration: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml Then start and enable ActiveMQ by running: systemctl start activemq systemctl enable activemq More information about how to properly set up ActiveMQ for Opencast, cluster installations in particular, can be found in the message broker configuration documentation . Install Elasticsearch Opencast uses Elasticsearch as a search index and a cache for quick access to some data from user interfaces. Make sure to install it on the node which also serves the admin interface. yum install elasticsearch-oss Opencast automatically configures the search index once it is connected. The default configuration will work for a local Elasticsearch with no modifications. Just make sure to start and enable the service: systemctl start elasticsearch systemctl enable elasticsearch Configuration Make sure to set your hostname, login information and other configuration details by following the Basic Configuration guide Start Opencast Finally, start and enable Opencast by running: systemctl start opencast.service systemctl enable opencast.service Advanced Installation The basic installation will give you an all-in-one Opencast distribution on a single server. For production, most users prefer deploying Opencast as a cluster, which allows for a better workload distribution. You can list all available Opencast packages/distributions with: yum search opencast This will list all available Opencast distributions in the form opencast-<dist-type> . Some commonly used distributions are: opencast-allinone opencast-admin opencast-presentation opencast-worker Upgrading Packages will automatically upgrade to the latest minor version in a release series when running dnf update . They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be required. For example, if you install Opencast 9.1, you get the latest 9.x release, but no 10 release. These instructions will upgrade Opencast to a new version which may be incompatible with older versions. Thus, a rollback might not be possible. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. For an RPM-based upgrade, first, stop Opencast: systemctl stop opencast.service Then, update the repository: yum install -y https://pkg.opencast.org/rpms/release/el/7/oc-10/noarch/opencast-repository-10-1.el7.noarch.rpm Upgrade to the new Opencast package by running: yum update Finally, since Opencast 10 switched to using Java 11, make sure that Java 8 is no longer installed. Alternative, you can also set Java 11 as default. yum remove 'java-1.8*' At this point you must follow the relevant upgrade instructions , prior to starting Opencast again. Uninstall Opencast To uninstall Opencast, you can run: yum remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) rm -rf /srv/opencast # Remove local db, search indexes and working files rm -rf /var/lib/opencast # Remove configuration files rm -rf /etc/opencast # Remove logs rm -rf /var/log/opencast Troubleshooting Missing Dependencies If you try to install Opencast but yum is complaining about missing dependencies, please check if the epel repository is really activated on your system. Some distributions come with epel preinstalled but disabled. The installation of the epel-release package will not fix this. You can check what repositories are installed and enabled by executing yum repolist enabled which should give you a list with epel, opencast and opencast-noarch in it. To enable a repository, edit the configuration file in /etc/yum.repos.d/ .","title":"RHEL/CentOS 7"},{"location":"installation/rpm-el7/#install-from-repository-red-hat-enterprise-linux-7x-centos-7x-scientific-linux-7x","text":"This guide is for EL7 only. There is a separate CentOS 8 and Red Hat Enterprise Linux 8 guide . This guide is based on an RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University . This repository provides preconfigured Opencast installations and all necessary 3rd-party-tools.","title":"Install from Repository (Red Hat Enterprise Linux 7.x, CentOS 7.x, Scientific Linux 7.x)"},{"location":"installation/rpm-el7/#currently-supported","text":"CentOS 7.x (x86_64) Red Hat Enterprise Linux 7.x (x86_64) Scientific Linux 7.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported.","title":"Currently Supported"},{"location":"installation/rpm-el7/#activate-repository","text":"First you have to install the necessary repositories: yum install -y https://pkg.opencast.org/rpms/release/el/7/oc-10/noarch/opencast-repository-10-1.el7.noarch.rpm It might take some time after the release of a new Opencast version before the RPMs are moved to the stable repository. Until then, you can use /etc/yum.repos.d/opencast-testing.repo instead to get the latest version. Note that the testing repository is an additional repository and still requires the stable repository to be active. You can check if the repositories were successfully enabled using: yum repolist enabled","title":"Activate Repository"},{"location":"installation/rpm-el7/#install-opencast","text":"For a basic all-in-one installation just run: yum install opencast-allinone This will install the default distribution of Opencast and all its dependencies. For more options, see the advanced installation section below .","title":"Install Opencast"},{"location":"installation/rpm-el7/#install-apache-activemq","text":"The Apache ActiveMQ message broker is required by Opencast. It can be run on the same machine as Opencast. Install ActiveMQ by running: yum install activemq-dist A prepared configuration file for ActiveMQ comes with Opencast. It should suffice for an all-in-one installation and can be copied to replace the default configuration: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml Then start and enable ActiveMQ by running: systemctl start activemq systemctl enable activemq More information about how to properly set up ActiveMQ for Opencast, cluster installations in particular, can be found in the message broker configuration documentation .","title":"Install Apache ActiveMQ"},{"location":"installation/rpm-el7/#install-elasticsearch","text":"Opencast uses Elasticsearch as a search index and a cache for quick access to some data from user interfaces. Make sure to install it on the node which also serves the admin interface. yum install elasticsearch-oss Opencast automatically configures the search index once it is connected. The default configuration will work for a local Elasticsearch with no modifications. Just make sure to start and enable the service: systemctl start elasticsearch systemctl enable elasticsearch","title":"Install Elasticsearch"},{"location":"installation/rpm-el7/#configuration","text":"Make sure to set your hostname, login information and other configuration details by following the Basic Configuration guide","title":"Configuration"},{"location":"installation/rpm-el7/#start-opencast","text":"Finally, start and enable Opencast by running: systemctl start opencast.service systemctl enable opencast.service","title":"Start Opencast"},{"location":"installation/rpm-el7/#advanced-installation","text":"The basic installation will give you an all-in-one Opencast distribution on a single server. For production, most users prefer deploying Opencast as a cluster, which allows for a better workload distribution. You can list all available Opencast packages/distributions with: yum search opencast This will list all available Opencast distributions in the form opencast-<dist-type> . Some commonly used distributions are: opencast-allinone opencast-admin opencast-presentation opencast-worker","title":"Advanced Installation"},{"location":"installation/rpm-el7/#upgrading","text":"Packages will automatically upgrade to the latest minor version in a release series when running dnf update . They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be required. For example, if you install Opencast 9.1, you get the latest 9.x release, but no 10 release. These instructions will upgrade Opencast to a new version which may be incompatible with older versions. Thus, a rollback might not be possible. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. For an RPM-based upgrade, first, stop Opencast: systemctl stop opencast.service Then, update the repository: yum install -y https://pkg.opencast.org/rpms/release/el/7/oc-10/noarch/opencast-repository-10-1.el7.noarch.rpm Upgrade to the new Opencast package by running: yum update Finally, since Opencast 10 switched to using Java 11, make sure that Java 8 is no longer installed. Alternative, you can also set Java 11 as default. yum remove 'java-1.8*' At this point you must follow the relevant upgrade instructions , prior to starting Opencast again.","title":"Upgrading"},{"location":"installation/rpm-el7/#uninstall-opencast","text":"To uninstall Opencast, you can run: yum remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) rm -rf /srv/opencast # Remove local db, search indexes and working files rm -rf /var/lib/opencast # Remove configuration files rm -rf /etc/opencast # Remove logs rm -rf /var/log/opencast","title":"Uninstall Opencast"},{"location":"installation/rpm-el7/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"installation/rpm-el7/#missing-dependencies","text":"If you try to install Opencast but yum is complaining about missing dependencies, please check if the epel repository is really activated on your system. Some distributions come with epel preinstalled but disabled. The installation of the epel-release package will not fix this. You can check what repositories are installed and enabled by executing yum repolist enabled which should give you a list with epel, opencast and opencast-noarch in it. To enable a repository, edit the configuration file in /etc/yum.repos.d/ .","title":"Missing Dependencies"},{"location":"installation/rpm-el8/","text":"Install from Repository (Red Hat Enterprise Linux 8.x, CentOS 8.x) This guide is for EL8 only. There is a separate CentOS 7 and Red Hat Enterprise Linux 7 guide . This guide is based on an RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University . This repository provides preconfigured Opencast installations and all necessary 3rd-party-tools. In addition to this guide, we have also recorded a full installation done in 30 minutes if you like to see how this works before you try it yourself. Currently Supported CentOS 8.x (x86_64) Red Hat Enterprise Linux 8.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported. Activate Repository First you have to install the necessary repositories: dnf install -y https://pkg.opencast.org/rpms/release/el/8/oc-10/noarch/opencast-repository-10-1.el8.noarch.rpm It might take some time after the release of a new Opencast version before the RPMs are moved to the stable repository. Until then, you can use /etc/yum.repos.d/opencast-testing.repo instead to get the latest version. Note that the testing repository is an additional repository and still requires the stable repository to be active. You can check if the repositories were successfully enabled using: dnf repolist enabled epel epel-modular opencast opencast-noarch opencast-testing opencast-testing-noarch Install Opencast For a basic all-in-one installation just run: dnf install opencast-allinone This will install the default distribution of Opencast and all its dependencies. For more options, see the advanced installation section below . Install Apache ActiveMQ The Apache ActiveMQ message broker is required by Opencast. It can be run on the same machine as Opencast. Install ActiveMQ by running: dnf install activemq-dist A prepared configuration file for ActiveMQ comes with Opencast. It should suffice for an all-in-one installation and can be copied to replace the default configuration: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml Then start and enable ActiveMQ by running: systemctl start activemq systemctl enable activemq More information about how to properly set up ActiveMQ for Opencast, cluster installations in particular, can be found in the message broker configuration documentation . Install Elasticsearch Opencast uses Elasticsearch as a search index and a cache for quick access to some data from user interfaces. Make sure to install it on the node which also serves the admin interface. dnf install elasticsearch-oss Opencast automatically configures the search index once it is connected. The default configuration will work for a local Elasticsearch with no modifications. Just make sure to start and enable the service: systemctl start elasticsearch systemctl enable elasticsearch Configuration Make sure to set your hostname, login information and other configuration details by following the Basic Configuration guide Start Opencast Finally, start and enable Opencast by running: systemctl start opencast.service systemctl enable opencast.service Advanced Installation The basic installation will give you an all-in-one Opencast distribution on a single server. For production, most users prefer deploying Opencast as a cluster, which allows for a better workload distribution. You can list all available Opencast packages/distributions with: dnf search opencast This will list all available Opencast distributions in the form opencast-<dist-type> . Some commonly used distributions are: opencast-allinone opencast-admin opencast-presentation opencast-worker Upgrading Packages will automatically upgrade to the latest minor version in a release series when running dnf update . They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be required. For example, if you install Opencast 10.1, you get the latest 10.x release, but no 11.x release. These instructions will upgrade Opencast to a new version which may be incompatible with older versions. Thus, a rollback might not be possible. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. For an RPM-based upgrade, first, stop Opencast: systemctl stop opencast.service Then, update the repository: dnf install -y https://pkg.opencast.org/rpms/release/el/8/oc-10/noarch/opencast-repository-10-1.el8.noarch.rpm Upgrade to the new Opencast package by running: dnf update Finally, since Opencast 10 switched to using Java 11, make sure that Java 8 is no longer installed. Alternative, you can also set Java 11 as default. dnf remove 'java-1.8*' At this point you must follow the relevant upgrade instructions , prior to starting Opencast again. Uninstall Opencast To uninstall Opencast, you can run: dnf remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) rm -rf /srv/opencast # Remove local db, search indexes and working files rm -rf /var/lib/opencast # Remove configuration files rm -rf /etc/opencast # Remove logs rm -rf /var/log/opencast","title":"RHEL/CentOS 8"},{"location":"installation/rpm-el8/#install-from-repository-red-hat-enterprise-linux-8x-centos-8x","text":"This guide is for EL8 only. There is a separate CentOS 7 and Red Hat Enterprise Linux 7 guide . This guide is based on an RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University . This repository provides preconfigured Opencast installations and all necessary 3rd-party-tools. In addition to this guide, we have also recorded a full installation done in 30 minutes if you like to see how this works before you try it yourself.","title":"Install from Repository (Red Hat Enterprise Linux 8.x, CentOS 8.x)"},{"location":"installation/rpm-el8/#currently-supported","text":"CentOS 8.x (x86_64) Red Hat Enterprise Linux 8.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported.","title":"Currently Supported"},{"location":"installation/rpm-el8/#activate-repository","text":"First you have to install the necessary repositories: dnf install -y https://pkg.opencast.org/rpms/release/el/8/oc-10/noarch/opencast-repository-10-1.el8.noarch.rpm It might take some time after the release of a new Opencast version before the RPMs are moved to the stable repository. Until then, you can use /etc/yum.repos.d/opencast-testing.repo instead to get the latest version. Note that the testing repository is an additional repository and still requires the stable repository to be active. You can check if the repositories were successfully enabled using: dnf repolist enabled epel epel-modular opencast opencast-noarch opencast-testing opencast-testing-noarch","title":"Activate Repository"},{"location":"installation/rpm-el8/#install-opencast","text":"For a basic all-in-one installation just run: dnf install opencast-allinone This will install the default distribution of Opencast and all its dependencies. For more options, see the advanced installation section below .","title":"Install Opencast"},{"location":"installation/rpm-el8/#install-apache-activemq","text":"The Apache ActiveMQ message broker is required by Opencast. It can be run on the same machine as Opencast. Install ActiveMQ by running: dnf install activemq-dist A prepared configuration file for ActiveMQ comes with Opencast. It should suffice for an all-in-one installation and can be copied to replace the default configuration: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml Then start and enable ActiveMQ by running: systemctl start activemq systemctl enable activemq More information about how to properly set up ActiveMQ for Opencast, cluster installations in particular, can be found in the message broker configuration documentation .","title":"Install Apache ActiveMQ"},{"location":"installation/rpm-el8/#install-elasticsearch","text":"Opencast uses Elasticsearch as a search index and a cache for quick access to some data from user interfaces. Make sure to install it on the node which also serves the admin interface. dnf install elasticsearch-oss Opencast automatically configures the search index once it is connected. The default configuration will work for a local Elasticsearch with no modifications. Just make sure to start and enable the service: systemctl start elasticsearch systemctl enable elasticsearch","title":"Install Elasticsearch"},{"location":"installation/rpm-el8/#configuration","text":"Make sure to set your hostname, login information and other configuration details by following the Basic Configuration guide","title":"Configuration"},{"location":"installation/rpm-el8/#start-opencast","text":"Finally, start and enable Opencast by running: systemctl start opencast.service systemctl enable opencast.service","title":"Start Opencast"},{"location":"installation/rpm-el8/#advanced-installation","text":"The basic installation will give you an all-in-one Opencast distribution on a single server. For production, most users prefer deploying Opencast as a cluster, which allows for a better workload distribution. You can list all available Opencast packages/distributions with: dnf search opencast This will list all available Opencast distributions in the form opencast-<dist-type> . Some commonly used distributions are: opencast-allinone opencast-admin opencast-presentation opencast-worker","title":"Advanced Installation"},{"location":"installation/rpm-el8/#upgrading","text":"Packages will automatically upgrade to the latest minor version in a release series when running dnf update . They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be required. For example, if you install Opencast 10.1, you get the latest 10.x release, but no 11.x release. These instructions will upgrade Opencast to a new version which may be incompatible with older versions. Thus, a rollback might not be possible. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. For an RPM-based upgrade, first, stop Opencast: systemctl stop opencast.service Then, update the repository: dnf install -y https://pkg.opencast.org/rpms/release/el/8/oc-10/noarch/opencast-repository-10-1.el8.noarch.rpm Upgrade to the new Opencast package by running: dnf update Finally, since Opencast 10 switched to using Java 11, make sure that Java 8 is no longer installed. Alternative, you can also set Java 11 as default. dnf remove 'java-1.8*' At this point you must follow the relevant upgrade instructions , prior to starting Opencast again.","title":"Upgrading"},{"location":"installation/rpm-el8/#uninstall-opencast","text":"To uninstall Opencast, you can run: dnf remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) rm -rf /srv/opencast # Remove local db, search indexes and working files rm -rf /var/lib/opencast # Remove configuration files rm -rf /etc/opencast # Remove logs rm -rf /var/log/opencast","title":"Uninstall Opencast"},{"location":"installation/rpm-fedora/","text":"Install from Repository (Fedora) The Opencast RPM repository for Fedora has been discontinued since Fedora with RPMfusion now provides nearly all necessary dependencies for Opencast. Use the following steps to install them, then continue with the installation from source . This guide is to be merged into the guide for the installation from source. Add RPMfusion repository RPMFusion is a community-driven RPM repository for Fedora. It provides tools like FFmpeg. You can activate it using: dnf install --nogpgcheck \\ http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\ http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm Install 3rd-party-tools You can install all necessary 3rd-Party-Tools for Opencast like this: dnf install maven ffmpeg tesseract hunspell sox synfig nmap-ncat For additional Unicode tests run during the build process, you can also install: dnf install hunspell-de tesseract-langpack-deu Install Apache ActiveMQ The Apache ActiveMQ message broker is commonly installed on the same machine as Opencast for an all-in-one system. The version of ActiveMQ shipped with Fedora is too old but you can use the ActiveMQ-dist Copr RPM repository Make sure it is properly configured for Opencast. For more information about the setup, have a look at the message broker configuration documentation . Install Opencast For the installation of Opencast, please have a look at the installation from source documentation .","title":"Fedora"},{"location":"installation/rpm-fedora/#install-from-repository-fedora","text":"The Opencast RPM repository for Fedora has been discontinued since Fedora with RPMfusion now provides nearly all necessary dependencies for Opencast. Use the following steps to install them, then continue with the installation from source . This guide is to be merged into the guide for the installation from source.","title":"Install from Repository (Fedora)"},{"location":"installation/rpm-fedora/#add-rpmfusion-repository","text":"RPMFusion is a community-driven RPM repository for Fedora. It provides tools like FFmpeg. You can activate it using: dnf install --nogpgcheck \\ http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\ http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm","title":"Add RPMfusion repository"},{"location":"installation/rpm-fedora/#install-3rd-party-tools","text":"You can install all necessary 3rd-Party-Tools for Opencast like this: dnf install maven ffmpeg tesseract hunspell sox synfig nmap-ncat For additional Unicode tests run during the build process, you can also install: dnf install hunspell-de tesseract-langpack-deu","title":"Install 3rd-party-tools"},{"location":"installation/rpm-fedora/#install-apache-activemq","text":"The Apache ActiveMQ message broker is commonly installed on the same machine as Opencast for an all-in-one system. The version of ActiveMQ shipped with Fedora is too old but you can use the ActiveMQ-dist Copr RPM repository Make sure it is properly configured for Opencast. For more information about the setup, have a look at the message broker configuration documentation .","title":"Install Apache ActiveMQ"},{"location":"installation/rpm-fedora/#install-opencast","text":"For the installation of Opencast, please have a look at the installation from source documentation .","title":"Install Opencast"},{"location":"installation/server-requirements/","text":"Hardware Requirements The resources Opencast needs highly depend on what and how much material you process on your cluster and how you configured your Opencast. Thus, treat this as a sensible starting point for testing out Opencast, nothing more. Sensible requirements for an Opencast server: Virtual machine Four cores 8GB of memory Additional notes about resources: Video processing is hard work and mostly profits from more CPU power More memory is only necessary for very large installations or with some special use-cases","title":"Hardware Requirements"},{"location":"installation/server-requirements/#hardware-requirements","text":"The resources Opencast needs highly depend on what and how much material you process on your cluster and how you configured your Opencast. Thus, treat this as a sensible starting point for testing out Opencast, nothing more. Sensible requirements for an Opencast server: Virtual machine Four cores 8GB of memory Additional notes about resources: Video processing is hard work and mostly profits from more CPU power More memory is only necessary for very large installations or with some special use-cases","title":"Hardware Requirements"},{"location":"installation/source-linux/","text":"Install from Source (Linux) These instructions outline how to install and build an all-in-one Opencast system on Linux. Preparation Create a dedicated Opencast system user: useradd -r -d /opt/opencast opencast Get Opencast source: You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git. Using the tarball: Select the tarball for the version you want to install from the GitHub releases section . # Download desired tarball curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz cd opencast--[...] Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version Install Dependencies Please make sure to install the following dependencies. Required: java-1.11.0-openjdk-devel.x86_64 / openjdk-11-jdk ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6 unzip gcc-c++ tar bzip2 nc Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Elasticsearch 7.9.x Required for text extraction (recommended): tesseract >= 3 Required for hunspell based text filtering (optional): hunspell >= 1.2.8 Required for audio normalization (optional): sox >= 14.4 Required for animate service (optional): synfig Dependency Download Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project website: Get FFmpeg Get Apache Maven Get Apache ActiveMQ Get Elasticsearch Building Opencast Automatically build all Opencast modules and assemble distributions for different server types: cd opencast-dir mvn clean install Deploy all-in-one distribution: cd build/ mv opencast-dist-allinone-*/ /opt/opencast Make sure everything belongs to the user opencast : sudo chown -R opencast:opencast /opt/opencast Configure Please follow the steps of the Basic Configuration guide . It will help you to set your hostname, login information, etc. Running Opencast To start Opencast, run .../bin/start-opencast as user opencast : sudo -u opencast /opt/opencast/bin/start-opencast As soon as Opencast is completely started, browse to http://localhost:8080 to get to the administration interface. Run Opencast as a service Usually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running once on a system and is started automatically. You will find service files for Opencast in docs/scripts/service/{opt,system}/ . Using Systemd Make sure the path to Opencast is set correctly: vim docs/scripts/service/opencast.service Install the unit file: cp docs/scripts/service/opencast.service /etc/systemd/system/ systemctl daemon-reload Start Opencast and make it run automatically: systemctl start opencast.service systemctl enable opencast.service Using SysV-Init Note that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit file or the Init script, it is recommended to use the Systemd unit file. Make sure the path to Opencast is set correctly: vim docs/scripts/service/etc-init.d-opencast Install init script: cp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast Enable service using chkconfig or update-rc.d Start Opencast using service opencast start","title":"Linux"},{"location":"installation/source-linux/#install-from-source-linux","text":"These instructions outline how to install and build an all-in-one Opencast system on Linux.","title":"Install from Source (Linux)"},{"location":"installation/source-linux/#preparation","text":"Create a dedicated Opencast system user: useradd -r -d /opt/opencast opencast Get Opencast source: You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git. Using the tarball: Select the tarball for the version you want to install from the GitHub releases section . # Download desired tarball curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz cd opencast--[...] Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version","title":"Preparation"},{"location":"installation/source-linux/#install-dependencies","text":"Please make sure to install the following dependencies. Required: java-1.11.0-openjdk-devel.x86_64 / openjdk-11-jdk ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6 unzip gcc-c++ tar bzip2 nc Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Elasticsearch 7.9.x Required for text extraction (recommended): tesseract >= 3 Required for hunspell based text filtering (optional): hunspell >= 1.2.8 Required for audio normalization (optional): sox >= 14.4 Required for animate service (optional): synfig","title":"Install Dependencies"},{"location":"installation/source-linux/#dependency-download","text":"Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project website: Get FFmpeg Get Apache Maven Get Apache ActiveMQ Get Elasticsearch","title":"Dependency Download"},{"location":"installation/source-linux/#building-opencast","text":"Automatically build all Opencast modules and assemble distributions for different server types: cd opencast-dir mvn clean install Deploy all-in-one distribution: cd build/ mv opencast-dist-allinone-*/ /opt/opencast Make sure everything belongs to the user opencast : sudo chown -R opencast:opencast /opt/opencast","title":"Building Opencast"},{"location":"installation/source-linux/#configure","text":"Please follow the steps of the Basic Configuration guide . It will help you to set your hostname, login information, etc.","title":"Configure"},{"location":"installation/source-linux/#running-opencast","text":"To start Opencast, run .../bin/start-opencast as user opencast : sudo -u opencast /opt/opencast/bin/start-opencast As soon as Opencast is completely started, browse to http://localhost:8080 to get to the administration interface.","title":"Running Opencast"},{"location":"installation/source-linux/#run-opencast-as-a-service","text":"Usually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running once on a system and is started automatically. You will find service files for Opencast in docs/scripts/service/{opt,system}/ .","title":"Run Opencast as a service"},{"location":"installation/source-linux/#using-systemd","text":"Make sure the path to Opencast is set correctly: vim docs/scripts/service/opencast.service Install the unit file: cp docs/scripts/service/opencast.service /etc/systemd/system/ systemctl daemon-reload Start Opencast and make it run automatically: systemctl start opencast.service systemctl enable opencast.service","title":"Using Systemd"},{"location":"installation/source-linux/#using-sysv-init","text":"Note that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit file or the Init script, it is recommended to use the Systemd unit file. Make sure the path to Opencast is set correctly: vim docs/scripts/service/etc-init.d-opencast Install init script: cp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast Enable service using chkconfig or update-rc.d Start Opencast using service opencast start","title":"Using SysV-Init"},{"location":"installation/source-macosx/","text":"Install from Source (macOS) These instructions outline how to install an all in one Opencast system on the macOS operating system. Tested on OS X 10.14.1 Mojave. The installation on macOS is not officially supported. Use this at your own risk. Preparation Open a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g. /opt/ , ~/develop/ or whatever you prefer. Get Opencast source You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git. Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version Using the tarball: Select the tarball for the version you want to install from the GitHub releases section under the \"Tags\" tab and download it directly from there or with the curl command specified below. # Download desired tarball, replace [...] with the desired version curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz Install Dependencies Please make sure to install the following dependencies. Required: Xcode jdk 11 ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6 (If you are using jEnv to set up your environment, make sure to enable the maven plugin .) Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Elasticsearch 7.9.x Required for text extraction: tesseract >= 3 Required for hunspell based text filtering: hunspell >= 1.2.8 Required for audio normalization: sox >= 14.4 (with MP3, FLAC and OGG support) Required for animate service: synfig Dependency Download You can download Xcode in the Mac App Store. JDK 8 for OS X is available from Oracle . Using Homebrew Homebrew is a package manager for OS X. For installation instruction see their website . brew install maven brew install ffmpeg brew install apache-activemq brew install tesseract brew install hunspell brew install sox brew install synfig Elasticsearch on macOS If you want to install Elasticsearch in the same machine run Elasticsearch as a Docker container docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e 'discovery.type=single-node' elasticsearch:7.9.3 Using pre-built binaries Pre-built versions of most dependencies can be downloaded from the respective project website: Get Apache Maven Get FFmpeg Get Apache ActiveMQ Building Opencast Switch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something like opencast-community-opencast-[\u2026] ). If you chose to download via git, use cd opencast . You can proceed by building opencast (depending on the folder permissions, you might need to start the command with sudo ): mvn clean install -Pdev Please be patient, as building Opencast for the first time will take quite long. Configure Please follow the steps of the Basic Configuration guide . It will help you to set your host name, login information, etc. Be aware that the config files now reside in the build folders for the desired distribution. For the all-in-one distribution, this would be /your/path/to/opencast/build/opencast-dist-allinone-[\u2026]/etc/ , again with [\u2026] representing the selected version. As specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in docs/scripts/activemq/activemq.xml . If you installed ActiveMQ using homebrew, you can find the installation path with brew info activemq . The configuration is probably located in /usr/local/Cellar/activemq/<version>/libexec/conf/ . ffprobe is used to analyze new videos. It is installed with FFmpeg but usually not on the path to be automatically executed. You have to link the ffprobe to /usr/local/bin/ . You can find the FFmpeg install directory with brew info ffmpeg . Usually you would link the file with ln -s /usr/local/Cellar/ffmpeg/<version>/bin/ffprobe /usr/local/bin/ffprobe . Running Opencast Make sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-opencast script: activemq start cd /your/path/to/opencast/ cd build/opencast-dist-allinone-[\u2026] ./bin/start-opencast As soon as Opencast is completely started, browse to localhost:8080 to get to the administration interface.","title":"MacOS X"},{"location":"installation/source-macosx/#install-from-source-macos","text":"These instructions outline how to install an all in one Opencast system on the macOS operating system. Tested on OS X 10.14.1 Mojave. The installation on macOS is not officially supported. Use this at your own risk.","title":"Install from Source (macOS)"},{"location":"installation/source-macosx/#preparation","text":"Open a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g. /opt/ , ~/develop/ or whatever you prefer.","title":"Preparation"},{"location":"installation/source-macosx/#get-opencast-source","text":"You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git. Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version Using the tarball: Select the tarball for the version you want to install from the GitHub releases section under the \"Tags\" tab and download it directly from there or with the curl command specified below. # Download desired tarball, replace [...] with the desired version curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz","title":"Get Opencast source"},{"location":"installation/source-macosx/#install-dependencies","text":"Please make sure to install the following dependencies. Required: Xcode jdk 11 ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6 (If you are using jEnv to set up your environment, make sure to enable the maven plugin .) Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Elasticsearch 7.9.x Required for text extraction: tesseract >= 3 Required for hunspell based text filtering: hunspell >= 1.2.8 Required for audio normalization: sox >= 14.4 (with MP3, FLAC and OGG support) Required for animate service: synfig","title":"Install Dependencies"},{"location":"installation/source-macosx/#dependency-download","text":"You can download Xcode in the Mac App Store. JDK 8 for OS X is available from Oracle .","title":"Dependency Download"},{"location":"installation/source-macosx/#using-homebrew","text":"Homebrew is a package manager for OS X. For installation instruction see their website . brew install maven brew install ffmpeg brew install apache-activemq brew install tesseract brew install hunspell brew install sox brew install synfig","title":"Using Homebrew"},{"location":"installation/source-macosx/#elasticsearch-on-macos","text":"If you want to install Elasticsearch in the same machine run Elasticsearch as a Docker container docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e 'discovery.type=single-node' elasticsearch:7.9.3","title":"Elasticsearch on macOS"},{"location":"installation/source-macosx/#using-pre-built-binaries","text":"Pre-built versions of most dependencies can be downloaded from the respective project website: Get Apache Maven Get FFmpeg Get Apache ActiveMQ","title":"Using pre-built binaries"},{"location":"installation/source-macosx/#building-opencast","text":"Switch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something like opencast-community-opencast-[\u2026] ). If you chose to download via git, use cd opencast . You can proceed by building opencast (depending on the folder permissions, you might need to start the command with sudo ): mvn clean install -Pdev Please be patient, as building Opencast for the first time will take quite long.","title":"Building Opencast"},{"location":"installation/source-macosx/#configure","text":"Please follow the steps of the Basic Configuration guide . It will help you to set your host name, login information, etc. Be aware that the config files now reside in the build folders for the desired distribution. For the all-in-one distribution, this would be /your/path/to/opencast/build/opencast-dist-allinone-[\u2026]/etc/ , again with [\u2026] representing the selected version. As specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in docs/scripts/activemq/activemq.xml . If you installed ActiveMQ using homebrew, you can find the installation path with brew info activemq . The configuration is probably located in /usr/local/Cellar/activemq/<version>/libexec/conf/ . ffprobe is used to analyze new videos. It is installed with FFmpeg but usually not on the path to be automatically executed. You have to link the ffprobe to /usr/local/bin/ . You can find the FFmpeg install directory with brew info ffmpeg . Usually you would link the file with ln -s /usr/local/Cellar/ffmpeg/<version>/bin/ffprobe /usr/local/bin/ffprobe .","title":"Configure"},{"location":"installation/source-macosx/#running-opencast","text":"Make sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-opencast script: activemq start cd /your/path/to/opencast/ cd build/opencast-dist-allinone-[\u2026] ./bin/start-opencast As soon as Opencast is completely started, browse to localhost:8080 to get to the administration interface.","title":"Running Opencast"},{"location":"modules/","text":"Module Documentation Documentation for modules included in Opencast. Atom and RSS Feed Amazon Services Amazon S3 Archive Storage Amazon S3 Distribution Execute Service Live Schedule LTI Module Media Module Metrics (OpenMetrics, Prometheus) Player Configuration URL Parameter Search Indexes Solr Stream Security Studio Text Extraction Internal Video Editor Setup Architecture Stand-alone Video Editor Video Segmentation Termination State Basic AWS AutoScaling Transcripts (Google Speech) Transcripts (IBM Watson) YouTube Publication","title":"Overview"},{"location":"modules/#module-documentation","text":"Documentation for modules included in Opencast. Atom and RSS Feed Amazon Services Amazon S3 Archive Storage Amazon S3 Distribution Execute Service Live Schedule LTI Module Media Module Metrics (OpenMetrics, Prometheus) Player Configuration URL Parameter Search Indexes Solr Stream Security Studio Text Extraction Internal Video Editor Setup Architecture Stand-alone Video Editor Video Segmentation Termination State Basic AWS AutoScaling Transcripts (Google Speech) Transcripts (IBM Watson) YouTube Publication","title":"Module Documentation"},{"location":"modules/amberscripttranscripts/","text":"AmberScript Transcription Service Overview The AmberScriptTranscriptionService uses the AmberScript Transcription API to transcribe audio files. Audio will get extracted from an opencast recording video file and sent to the AmberScript server to be processed. AmberScriptTranscriptionService will periodically check for a transcription result. Depending on your audio length and job type chosen, transcribing will take some time. When the transcription result is ready the service will transform it to VTT format and attach it to the recording. The recording will be available prior when its workflow finishes. As soon as the transcription gets attached, the Video will be able to be played back using transcriptions. Configuration Step 1: Get AmberScript API key Contact AmberScript via https://www.amberscript.com/en/opencast-integration Step 2: Configure AmberscriptTranscriptionService Edit opencast/etc/org.opencastproject.transcription.amberscript.AmberscriptTranscriptionService.cfg : Set enabled=true to enable the service. Set API key client.key=__YOU-API-KEY__ . This is mandatory. Change options to your liking. Step 3: Include workflow operations into your workflow Integrate AmberScript workflow operations by including the provided workflow file amberscript-start-transcription.xml into your existing workflow: <operation id=\"include\" description=\"Start AmberScript Transcription\"> <configurations> <configuration key=\"workflow-id\">amberscript-start-transcription</configuration> </configurations> </operation> Workflow Operations amberscript-start-transcription amberscript-attach-transcription","title":"Transcripts (AmberScript)"},{"location":"modules/amberscripttranscripts/#amberscript-transcription-service","text":"","title":"AmberScript Transcription Service"},{"location":"modules/amberscripttranscripts/#overview","text":"The AmberScriptTranscriptionService uses the AmberScript Transcription API to transcribe audio files. Audio will get extracted from an opencast recording video file and sent to the AmberScript server to be processed. AmberScriptTranscriptionService will periodically check for a transcription result. Depending on your audio length and job type chosen, transcribing will take some time. When the transcription result is ready the service will transform it to VTT format and attach it to the recording. The recording will be available prior when its workflow finishes. As soon as the transcription gets attached, the Video will be able to be played back using transcriptions.","title":"Overview"},{"location":"modules/amberscripttranscripts/#configuration","text":"","title":"Configuration"},{"location":"modules/amberscripttranscripts/#step-1-get-amberscript-api-key","text":"Contact AmberScript via https://www.amberscript.com/en/opencast-integration","title":"Step 1: Get AmberScript API key"},{"location":"modules/amberscripttranscripts/#step-2-configure-amberscripttranscriptionservice","text":"Edit opencast/etc/org.opencastproject.transcription.amberscript.AmberscriptTranscriptionService.cfg : Set enabled=true to enable the service. Set API key client.key=__YOU-API-KEY__ . This is mandatory. Change options to your liking.","title":"Step 2: Configure AmberscriptTranscriptionService"},{"location":"modules/amberscripttranscripts/#step-3-include-workflow-operations-into-your-workflow","text":"Integrate AmberScript workflow operations by including the provided workflow file amberscript-start-transcription.xml into your existing workflow: <operation id=\"include\" description=\"Start AmberScript Transcription\"> <configurations> <configuration key=\"workflow-id\">amberscript-start-transcription</configuration> </configurations> </operation>","title":"Step 3: Include workflow operations into your workflow"},{"location":"modules/amberscripttranscripts/#workflow-operations","text":"amberscript-start-transcription amberscript-attach-transcription","title":"Workflow Operations"},{"location":"modules/atomrss/","text":"Configure Atom and RSS Feeds This document will help you understand and configure the Opencast RSS and Atom feed catalog. The catalog supports multiple versions of each syndication format. Feed Catalog The catalog is located at: http://opencast.example.edu:8080/feeds Individual feeds are located at: http://opencast.example.edu:8080/feeds/<feed_selector> Defaults The catalog contains the following default feeds: Latest http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest Need an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest Series http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id> Aggregation (of a set of series) http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation> Custom http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query> Aggregation The feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration, http://opencast.example.edu:8080/feeds/aggregated/myseries would return the latest episodes from series series_1 and series_2 . The Opencast feed specifications are located in: .../etc/feeds Update aggregation.properties, the specification for an example feed aggregation: feed.selector=myseries feed.series=series_1,series_2 Custom The Opencast feed specifications are located in: .../etc/feeds Below is custom.properties, the default specification for an example custom feed of published episodes: feed.class=org.opencastproject.feed.impl.CustomFeedService feed.uri=custom feed.size=20 feed.query=dc_title-sum:{0} feed.name=Special episodes feed.description=Special collection of episodes feed.copyright=All rights reserved by The Opencast Project feed.home=/engage/ui feed.entry=/engage/ui/embed.html?id={0} feed.cover=/engage/feed-cover.png feed.rssflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.rsstags=rss feed.rssmediatype=video,audio feed.atomflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.atomtags=atom Properties The following properties are common to all feed specifications: Name Description feed.class Java implementation, e.g. LatestFeedService. feed.uri Feed location/identifier feed.size Maximum number of entries in the feed (default: 100). Set to 0 to include all available entries. feed.selector Feed route pattern, e.g. latest. feed.name Feed title feed.description Feed description feed.copyright Feed copyright notice feed.home Feed catalog homepage, e.g. http://www.opencastproject.org. feed.entry The route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}. feed.cover Feed image feed.rssflavors The RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance. feed.rsstags A comma, semi-colon or space-separated list of tags used to filter available enclosures feed.rssmediatype A comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures feed.atomflavors The Atom enclosures route pattern, e.g. presenter/delivery. feed.atomtags A comma, semi-colon or space-separated list of tags used to filter available enclosures The following properties are specific to custom feeds: Name Description feed.query A custom Lucene query, matched again Java's MessageFormat using solr. The query http://opencast.example.edu:8080/feeds/alphabetical/a would return all episodes starting with the letter a. feed.selector=alphabetical feed.query=dc_title:{0}*","title":"Atom/RSS Feed"},{"location":"modules/atomrss/#configure-atom-and-rss-feeds","text":"This document will help you understand and configure the Opencast RSS and Atom feed catalog. The catalog supports multiple versions of each syndication format.","title":"Configure Atom and RSS Feeds"},{"location":"modules/atomrss/#feed-catalog","text":"The catalog is located at: http://opencast.example.edu:8080/feeds Individual feeds are located at: http://opencast.example.edu:8080/feeds/<feed_selector>","title":"Feed Catalog"},{"location":"modules/atomrss/#defaults","text":"The catalog contains the following default feeds:","title":"Defaults"},{"location":"modules/atomrss/#latest","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest Need an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest","title":"Latest"},{"location":"modules/atomrss/#series","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id>","title":"Series"},{"location":"modules/atomrss/#aggregation-of-a-set-of-series","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation>","title":"Aggregation (of a set of series)"},{"location":"modules/atomrss/#custom","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query>","title":"Custom"},{"location":"modules/atomrss/#aggregation","text":"The feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration, http://opencast.example.edu:8080/feeds/aggregated/myseries would return the latest episodes from series series_1 and series_2 . The Opencast feed specifications are located in: .../etc/feeds Update aggregation.properties, the specification for an example feed aggregation: feed.selector=myseries feed.series=series_1,series_2","title":"Aggregation"},{"location":"modules/atomrss/#custom_1","text":"The Opencast feed specifications are located in: .../etc/feeds Below is custom.properties, the default specification for an example custom feed of published episodes: feed.class=org.opencastproject.feed.impl.CustomFeedService feed.uri=custom feed.size=20 feed.query=dc_title-sum:{0} feed.name=Special episodes feed.description=Special collection of episodes feed.copyright=All rights reserved by The Opencast Project feed.home=/engage/ui feed.entry=/engage/ui/embed.html?id={0} feed.cover=/engage/feed-cover.png feed.rssflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.rsstags=rss feed.rssmediatype=video,audio feed.atomflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.atomtags=atom","title":"Custom"},{"location":"modules/atomrss/#properties","text":"The following properties are common to all feed specifications: Name Description feed.class Java implementation, e.g. LatestFeedService. feed.uri Feed location/identifier feed.size Maximum number of entries in the feed (default: 100). Set to 0 to include all available entries. feed.selector Feed route pattern, e.g. latest. feed.name Feed title feed.description Feed description feed.copyright Feed copyright notice feed.home Feed catalog homepage, e.g. http://www.opencastproject.org. feed.entry The route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}. feed.cover Feed image feed.rssflavors The RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance. feed.rsstags A comma, semi-colon or space-separated list of tags used to filter available enclosures feed.rssmediatype A comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures feed.atomflavors The Atom enclosures route pattern, e.g. presenter/delivery. feed.atomtags A comma, semi-colon or space-separated list of tags used to filter available enclosures The following properties are specific to custom feeds: Name Description feed.query A custom Lucene query, matched again Java's MessageFormat using solr. The query http://opencast.example.edu:8080/feeds/alphabetical/a would return all episodes starting with the letter a. feed.selector=alphabetical feed.query=dc_title:{0}*","title":"Properties"},{"location":"modules/awss3archive/","text":"AWS S3 Archive Configuration This page documents the configuration for the AWS S3 components in the Opencast module asset-manager-storage-aws . This configuration is only required on the admin node, and only if you are using Amazon S3 as an archive repository. Amazon User Configuration Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require an Access Key ID and Secret Access Key . The user to which this key belongs requires the AmazonS3FullAccess permission, which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 archiving can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns. Amazon Service Configuration For development and testing it is generally safe to allow the Opencast AWS S3 Archive service to create the S3 bucket for you. It will create the bucket per its configuration, with private-only access to the files, and no versioning. Opencast Service Configuration The Opencast AWS S3 Archive service configuration can be found in the org.opencastproject.assetmanager.aws.s3.AwsS3AssetStore.cfg configuration file. Key Description Default Example org.opencastproject.assetmanager.aws.s3.enabled Whether to enable this service false org.opencastproject.assetmanager.aws.s3.region The AWS region to set us-east-1 org.opencastproject.assetmanager.aws.s3.bucket The S3 bucket name example-org-archive org.opencastproject.assetmanager.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.assetmanager.aws.s3.secret.key Your secret key 40 characters org.opencastproject.assetmanager.aws.s3.endpoint The endpoint to use Default AWS S3 endpoint https://s3.service.com org.opencastproject.assetmanager.aws.s3.path.style Whether to use path style false / Default AWS S3 style org.opencastproject.assetmanager.aws.s3.max.connections Number of max connections 50 org.opencastproject.assetmanager.aws.s3.connection.timeout Connection timeout in ms 10000 org.opencastproject.assetmanager.aws.s3.max.retries Number of max retries 100 Using S3 Archiving There are two major methods to access S3 archiving features: manually, and via a workflow. Amazon S3 archiving is not part of the default workflows and manual S3 offload is disabled by default. To enable manual S3 offload you must edit the offload.xml workflow configuration file and change var s3Enabled = false; to var s3Enabled = true; . To manually offload a media package follow the directions in the user documentation. To automatically offload a media package to S3 you must add the move-storage workflow operation to your workflow. The operation documentation can be found here . Migrating to S3 Archiving with Pre-Existing Data Archiving to S3 is a non-destructive operation in that it is safe to move archive files back and forth between local storage and S3. To offload your local archive, select the workflow(s) and follow the manual offload steps described in the user documentation.","title":"Amazon S3 Archive Storage"},{"location":"modules/awss3archive/#aws-s3-archive-configuration","text":"This page documents the configuration for the AWS S3 components in the Opencast module asset-manager-storage-aws . This configuration is only required on the admin node, and only if you are using Amazon S3 as an archive repository.","title":"AWS S3 Archive Configuration"},{"location":"modules/awss3archive/#amazon-user-configuration","text":"Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require an Access Key ID and Secret Access Key . The user to which this key belongs requires the AmazonS3FullAccess permission, which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 archiving can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns.","title":"Amazon User Configuration"},{"location":"modules/awss3archive/#amazon-service-configuration","text":"For development and testing it is generally safe to allow the Opencast AWS S3 Archive service to create the S3 bucket for you. It will create the bucket per its configuration, with private-only access to the files, and no versioning.","title":"Amazon Service Configuration"},{"location":"modules/awss3archive/#opencast-service-configuration","text":"The Opencast AWS S3 Archive service configuration can be found in the org.opencastproject.assetmanager.aws.s3.AwsS3AssetStore.cfg configuration file. Key Description Default Example org.opencastproject.assetmanager.aws.s3.enabled Whether to enable this service false org.opencastproject.assetmanager.aws.s3.region The AWS region to set us-east-1 org.opencastproject.assetmanager.aws.s3.bucket The S3 bucket name example-org-archive org.opencastproject.assetmanager.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.assetmanager.aws.s3.secret.key Your secret key 40 characters org.opencastproject.assetmanager.aws.s3.endpoint The endpoint to use Default AWS S3 endpoint https://s3.service.com org.opencastproject.assetmanager.aws.s3.path.style Whether to use path style false / Default AWS S3 style org.opencastproject.assetmanager.aws.s3.max.connections Number of max connections 50 org.opencastproject.assetmanager.aws.s3.connection.timeout Connection timeout in ms 10000 org.opencastproject.assetmanager.aws.s3.max.retries Number of max retries 100","title":"Opencast Service Configuration"},{"location":"modules/awss3archive/#using-s3-archiving","text":"There are two major methods to access S3 archiving features: manually, and via a workflow. Amazon S3 archiving is not part of the default workflows and manual S3 offload is disabled by default. To enable manual S3 offload you must edit the offload.xml workflow configuration file and change var s3Enabled = false; to var s3Enabled = true; . To manually offload a media package follow the directions in the user documentation. To automatically offload a media package to S3 you must add the move-storage workflow operation to your workflow. The operation documentation can be found here .","title":"Using S3 Archiving"},{"location":"modules/awss3archive/#migrating-to-s3-archiving-with-pre-existing-data","text":"Archiving to S3 is a non-destructive operation in that it is safe to move archive files back and forth between local storage and S3. To offload your local archive, select the workflow(s) and follow the manual offload steps described in the user documentation.","title":"Migrating to S3 Archiving with Pre-Existing Data"},{"location":"modules/awss3distribution/","text":"AWS S3 Distribution Configuration This page documents the configuration for Opencast module distribution-service-aws-s3 . This configuration is only required on the presentation node, and only if you are using Amazon S3 and/or Cloudfront for distributing media to end users. Amazon User Configuration Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) AmazonS3FullAccess permission is required , which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 distribution can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns. Amazon Service Configuration The development and testing it is generally safe to allow the Opencast AWS S3 Distribution service to create the S3 bucket for you. It will create the bucket per its configuration, with public read-only access to the files, and no versioning. For production use we suggest using Amazon CloudFront, which requires additional configuration. Amazon CloudFront Amazon CloudFront provides an optional way to better handle distributing your media to end users. While fully configuring CloudFront is outside the scope of this documentation, we wish to note that this does affect one of the keys described below. Please ensure you use the correct distribution base format depending on which service you are using! Presigned URL S3 and Cloudfront work together to speed delivery of your content, but if your media URLs leak then anyone can download your recordings. S3 allows you to create Presigned URL s, which are only valid for a limited time. This means that even if your media URLs leak, they will only be valid for a configurable duration. Set org.opencastproject.distribution.aws.s3.presigned.url to true to enable this feature. Note: CloudFront and Presigned URL can be used together. Note: Opencast's distribution files can be quite large depending on your settings, and some of your users may not be able to complete the download within the time limit. While AWS should not stop a download currently in progress, some players may not completely download the media if playback is stopped. If you are experiencing complaints about playback breaking and have presigned URLs enabled, try lengthening the timeout. Service Default Security Note On startup, Opencast checks to see if the S3 bucket exists, and if it does not it creates it. This bucket has default permissions allowing anyone to read the full contents of the bucket. This may not be what you want, depending on your institutional priorites. If you wish to protect the files with presigned URLs, then please create the bucket in advance, with the appropriate security settings. S3 Compatible Service The S3 API has become the de facto standard interface for almost all storage providers. This module also supports S3 compatible service. In this case, org.opencastproject.distribution.aws.s3.endpoint should be set to the endpoint of the S3 service. Meanwhile, org.opencastproject.distribution.aws.s3.region should not be set. Note: only one of these two configuration keys may be set. There are two access style for bucket, virtual hosted style (default) and path style. - Virtual hosted style sample: https://bucketname.s3.service.com/ - Path style sample: https://s3.service.com/bucketname AWS use virtual hosted style by default, and will deprecate path style. Yet, for self hosted s3 compatible service, path style URL is useful. Set org.opencastproject.distribution.aws.s3.path.style to true to enable this feature. Opencast Service Configuration The Opencast AWS S3 Distribution service has five configuration keys, which can be found in the org.opencastproject.distribution.aws.s3.AwsS3DistributionServiceImpl.cfg configuration file. Key Description Default Example org.opencastproject.distribution.aws.s3.distribution.enable Whether to enable distribution to S3 false org.opencastproject.distribution.aws.s3.region The AWS region to set us-east-1 org.opencastproject.distribution.aws.s3.bucket The S3 bucket name example-org-dist org.opencastproject.distribution.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.distribution.aws.s3.secret.key Your secret key 40 characters org.opencastproject.distribution.aws.s3.endpoint The endpoint to use Default AWS S3 endpoint https://s3.service.com org.opencastproject.distribution.aws.s3.path.style Whether to use path style access URL false / Default AWS S3 style org.opencastproject.distribution.aws.s3.distribution.base Where the S3 files are available (derived from bucket & region or set by CloudFront) http://s3-us-west-2.amazonaws.com/example-org-dist or DOMAIN_NAME.cloudfront.net org.opencastproject.distribution.aws.s3.presigned.url Whether to enable presigned URL false org.opencastproject.distribution.aws.s3.presigned.url.valid.duration Valid duration for presigned URL in ms 21600000 (6 hours) org.opencastproject.distribution.aws.s3.max.connections Number of max connections 50 org.opencastproject.distribution.aws.s3.connection.timeout Connection timeout in ms 10000 org.opencastproject.distribution.aws.s3.max.retries Number of max retries 100 job.load.aws.s3.distribute Distribute job load 0.1 job.load.aws.s3.retract Retract job load 0.1 job.load.aws.s3.restore Restore job load 0.1 If org.opencastproject.distribution.aws.s3.access.id and org.opencastproject.distribution.aws.s3.secret.key are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain . Using S3 Distribution Amazon S3 distribution is already included in the default Opencast workflows, however it must first be enabled. The schedule-and-upload.xml and publish.xml workflow configuration files both contain lines containing the string \"Remove this line if you wish to publish to AWS S3\". Both of these lines must be removed before publishing to AWS S3 will function correctly. If you wish to use AWS S3 publishing with your own custom workflow, you must add the publish-aws workflow operation to your workflow. The operation documentation can be found here . Publishing to multiple distribution services Currently we do not support publication to multiple distribution services simultaneously. This means that whichever workflow operation is last in the workflow will be the final publication. Using this handler in custom workflows If your workflow contains both publish-engage and publish-aws , in that order, and without a conditional you would have publication files stored both locally and in AWS. This is likely not what you want, so protect your workflow operations appropriately. If you really do need these files stored in both places (for example, in cases where you need to make the files available immediately, and only push to AWS in some cases) then remember to add a retract-engage in between the publication operations. Note that if this step is omitted the files will remain available locally, but will not be used. Of further note, if you retract after publication to AWS then your workflow will not be available to users. To summarize, this table presents a subset of the various situations that are possible Workflow Operations Files present in the Media Module Files present in AWS Files served from publish-engage Yes No Opencast Media Module publish-aws No Yes AWS publish-engage, publish-aws Yes Yes AWS publish-aws, publish-engage Yes Yes Opencast Media Module publish-engage, retract-engage, publish-aws Temporary Yes AWS publish-engage, publish-aws, retract-engage No Yes Not available Migrating to S3 Distribution with Pre-Existing Data If you already have data published to your local Opencast install, you should be able to republish the media selecting AWS S3 as the distribution service to use.","title":"Amazon S3 Distribution"},{"location":"modules/awss3distribution/#aws-s3-distribution-configuration","text":"This page documents the configuration for Opencast module distribution-service-aws-s3 . This configuration is only required on the presentation node, and only if you are using Amazon S3 and/or Cloudfront for distributing media to end users.","title":"AWS S3 Distribution Configuration"},{"location":"modules/awss3distribution/#amazon-user-configuration","text":"Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) AmazonS3FullAccess permission is required , which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 distribution can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns.","title":"Amazon User Configuration"},{"location":"modules/awss3distribution/#amazon-service-configuration","text":"The development and testing it is generally safe to allow the Opencast AWS S3 Distribution service to create the S3 bucket for you. It will create the bucket per its configuration, with public read-only access to the files, and no versioning. For production use we suggest using Amazon CloudFront, which requires additional configuration.","title":"Amazon Service Configuration"},{"location":"modules/awss3distribution/#amazon-cloudfront","text":"Amazon CloudFront provides an optional way to better handle distributing your media to end users. While fully configuring CloudFront is outside the scope of this documentation, we wish to note that this does affect one of the keys described below. Please ensure you use the correct distribution base format depending on which service you are using!","title":"Amazon CloudFront"},{"location":"modules/awss3distribution/#presigned-url","text":"S3 and Cloudfront work together to speed delivery of your content, but if your media URLs leak then anyone can download your recordings. S3 allows you to create Presigned URL s, which are only valid for a limited time. This means that even if your media URLs leak, they will only be valid for a configurable duration. Set org.opencastproject.distribution.aws.s3.presigned.url to true to enable this feature. Note: CloudFront and Presigned URL can be used together. Note: Opencast's distribution files can be quite large depending on your settings, and some of your users may not be able to complete the download within the time limit. While AWS should not stop a download currently in progress, some players may not completely download the media if playback is stopped. If you are experiencing complaints about playback breaking and have presigned URLs enabled, try lengthening the timeout.","title":"Presigned URL"},{"location":"modules/awss3distribution/#service-default-security-note","text":"On startup, Opencast checks to see if the S3 bucket exists, and if it does not it creates it. This bucket has default permissions allowing anyone to read the full contents of the bucket. This may not be what you want, depending on your institutional priorites. If you wish to protect the files with presigned URLs, then please create the bucket in advance, with the appropriate security settings.","title":"Service Default Security Note"},{"location":"modules/awss3distribution/#s3-compatible-service","text":"The S3 API has become the de facto standard interface for almost all storage providers. This module also supports S3 compatible service. In this case, org.opencastproject.distribution.aws.s3.endpoint should be set to the endpoint of the S3 service. Meanwhile, org.opencastproject.distribution.aws.s3.region should not be set. Note: only one of these two configuration keys may be set. There are two access style for bucket, virtual hosted style (default) and path style. - Virtual hosted style sample: https://bucketname.s3.service.com/ - Path style sample: https://s3.service.com/bucketname AWS use virtual hosted style by default, and will deprecate path style. Yet, for self hosted s3 compatible service, path style URL is useful. Set org.opencastproject.distribution.aws.s3.path.style to true to enable this feature.","title":"S3 Compatible Service"},{"location":"modules/awss3distribution/#opencast-service-configuration","text":"The Opencast AWS S3 Distribution service has five configuration keys, which can be found in the org.opencastproject.distribution.aws.s3.AwsS3DistributionServiceImpl.cfg configuration file. Key Description Default Example org.opencastproject.distribution.aws.s3.distribution.enable Whether to enable distribution to S3 false org.opencastproject.distribution.aws.s3.region The AWS region to set us-east-1 org.opencastproject.distribution.aws.s3.bucket The S3 bucket name example-org-dist org.opencastproject.distribution.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.distribution.aws.s3.secret.key Your secret key 40 characters org.opencastproject.distribution.aws.s3.endpoint The endpoint to use Default AWS S3 endpoint https://s3.service.com org.opencastproject.distribution.aws.s3.path.style Whether to use path style access URL false / Default AWS S3 style org.opencastproject.distribution.aws.s3.distribution.base Where the S3 files are available (derived from bucket & region or set by CloudFront) http://s3-us-west-2.amazonaws.com/example-org-dist or DOMAIN_NAME.cloudfront.net org.opencastproject.distribution.aws.s3.presigned.url Whether to enable presigned URL false org.opencastproject.distribution.aws.s3.presigned.url.valid.duration Valid duration for presigned URL in ms 21600000 (6 hours) org.opencastproject.distribution.aws.s3.max.connections Number of max connections 50 org.opencastproject.distribution.aws.s3.connection.timeout Connection timeout in ms 10000 org.opencastproject.distribution.aws.s3.max.retries Number of max retries 100 job.load.aws.s3.distribute Distribute job load 0.1 job.load.aws.s3.retract Retract job load 0.1 job.load.aws.s3.restore Restore job load 0.1 If org.opencastproject.distribution.aws.s3.access.id and org.opencastproject.distribution.aws.s3.secret.key are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain .","title":"Opencast Service Configuration"},{"location":"modules/awss3distribution/#using-s3-distribution","text":"Amazon S3 distribution is already included in the default Opencast workflows, however it must first be enabled. The schedule-and-upload.xml and publish.xml workflow configuration files both contain lines containing the string \"Remove this line if you wish to publish to AWS S3\". Both of these lines must be removed before publishing to AWS S3 will function correctly. If you wish to use AWS S3 publishing with your own custom workflow, you must add the publish-aws workflow operation to your workflow. The operation documentation can be found here .","title":"Using S3 Distribution"},{"location":"modules/awss3distribution/#publishing-to-multiple-distribution-services","text":"Currently we do not support publication to multiple distribution services simultaneously. This means that whichever workflow operation is last in the workflow will be the final publication.","title":"Publishing to multiple distribution services"},{"location":"modules/awss3distribution/#using-this-handler-in-custom-workflows","text":"If your workflow contains both publish-engage and publish-aws , in that order, and without a conditional you would have publication files stored both locally and in AWS. This is likely not what you want, so protect your workflow operations appropriately. If you really do need these files stored in both places (for example, in cases where you need to make the files available immediately, and only push to AWS in some cases) then remember to add a retract-engage in between the publication operations. Note that if this step is omitted the files will remain available locally, but will not be used. Of further note, if you retract after publication to AWS then your workflow will not be available to users. To summarize, this table presents a subset of the various situations that are possible Workflow Operations Files present in the Media Module Files present in AWS Files served from publish-engage Yes No Opencast Media Module publish-aws No Yes AWS publish-engage, publish-aws Yes Yes AWS publish-aws, publish-engage Yes Yes Opencast Media Module publish-engage, retract-engage, publish-aws Temporary Yes AWS publish-engage, publish-aws, retract-engage No Yes Not available","title":"Using this handler in custom workflows"},{"location":"modules/awss3distribution/#migrating-to-s3-distribution-with-pre-existing-data","text":"If you already have data published to your local Opencast install, you should be able to republish the media selecting AWS S3 as the distribution service to use.","title":"Migrating to S3 Distribution with Pre-Existing Data"},{"location":"modules/editor/","text":"Stand-Alone Video Editor The editor is still beta . Opencast's stand-alone video editor provides a tool for users to cut videos without full access to the admin interface. It strives to be simple and easy to use while providing enough features for most common use-cases. Accessing The Editor You can access the editor by providing an event identifier to the web interface like this: /editor-ui/index.html?mediaPackageId=<ID> Preview Tracks Preview tracks for the editor are retrieved from the internal publication, similar to the editor in the admin interface. But unlike the admin interface, tracks are selected in the following way, falling back to the next rule if the previous yielded no results: select tracks tagged with preview.tag select tracks with sub-flavor preview.subtype select all available tracks More details about the preview track selection can be found and configured in etc/org.opencastproject.editor.EditorServiceImpl.cfg . Workflow Selection The editor offers a workflow selection, allowing users to choose how an event is being processed. Workflows need to be tagged editor to show up in the user interface. The interface honors title, description and display order of workflows. If only a single workflow exists, the selection will be skipped. Replacing the Admin Interface Editor It is possible to have the admin interface link to the stand-alone editor instead of the internal editor. For this, configure the prop.admin.editor.url in etc/org.opencastproject.organization-mh_default_org.cfg . Configuration The following configuration files allow customization of the editor: Backend (track selection, \u2026) etc/org.opencastproject.editor.EditorServiceImpl.cfg User interface (which tools to show, \u2026)) etc/ui-config/mh_default_org/editor/editor-settings.toml Admin interface integration etc/org.opencastproject.organization-mh_default_org.cfg","title":"Stand-alone Video Editor"},{"location":"modules/editor/#stand-alone-video-editor","text":"The editor is still beta . Opencast's stand-alone video editor provides a tool for users to cut videos without full access to the admin interface. It strives to be simple and easy to use while providing enough features for most common use-cases.","title":"Stand-Alone Video Editor"},{"location":"modules/editor/#accessing-the-editor","text":"You can access the editor by providing an event identifier to the web interface like this: /editor-ui/index.html?mediaPackageId=<ID>","title":"Accessing The Editor"},{"location":"modules/editor/#preview-tracks","text":"Preview tracks for the editor are retrieved from the internal publication, similar to the editor in the admin interface. But unlike the admin interface, tracks are selected in the following way, falling back to the next rule if the previous yielded no results: select tracks tagged with preview.tag select tracks with sub-flavor preview.subtype select all available tracks More details about the preview track selection can be found and configured in etc/org.opencastproject.editor.EditorServiceImpl.cfg .","title":"Preview Tracks"},{"location":"modules/editor/#workflow-selection","text":"The editor offers a workflow selection, allowing users to choose how an event is being processed. Workflows need to be tagged editor to show up in the user interface. The interface honors title, description and display order of workflows. If only a single workflow exists, the selection will be skipped.","title":"Workflow Selection"},{"location":"modules/editor/#replacing-the-admin-interface-editor","text":"It is possible to have the admin interface link to the stand-alone editor instead of the internal editor. For this, configure the prop.admin.editor.url in etc/org.opencastproject.organization-mh_default_org.cfg .","title":"Replacing the Admin Interface Editor"},{"location":"modules/editor/#configuration","text":"The following configuration files allow customization of the editor: Backend (track selection, \u2026) etc/org.opencastproject.editor.EditorServiceImpl.cfg User interface (which tools to show, \u2026)) etc/ui-config/mh_default_org/editor/editor-settings.toml Admin interface integration etc/org.opencastproject.organization-mh_default_org.cfg","title":"Configuration"},{"location":"modules/execute/","text":"Execute Service The Execute Service allows a workflow to run external scripts or applications with any MediaPackage element as arguments. This provides a flexible way to operate with MediaPackage resources without the need to write Java code or build Opencast from source. Commands are executed on worker nodes. There are two execute workflow operations: Execute Once : for running a single command that may operate on multiple elements of a mediapackage Execute Many : for running a command for each element in a mediapackage that matches the given criteria Service Configuration The Execute Service configuration in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg must be updated to define which commands may be run: # Load factor job.load.execute = 1.0 # The list of commands, separated by spaces, which may be run by the Execute Service. # A value of * means any command is allowed. # Default: empty (no commands allowed) #commands.allowed = If commands.allowed is empty or undefined (the default), the service won't be able to run any commands. Use the special key * to permit any command to be executed (not recommended for production systems). To adjust the job load factor for a command, use the load parameter in the workflow operation rather than adjusting the job.load.execute parameter above. Parameter substitution The command arguments may contain placeholders, which are substituted by their corresponding values before the command runs. The complete list of available placeholders is detailed in the table below. Placeholder Used in Meaning #{id} Execute Once The Mediapackage ID #{flavor(some/flavor)} Execute Once The absolute path of the element matching the specified flavor. If several elements have the same flavor, the first element returned by MediaPackage#getElementsByFlavor is used. #{in} Execute Many The absolute path of the input element #{out} Execute Once, Execute Many The absolute path of the output element, formed from the output-filename parameter Using custom properties in the argument list Custom properties can be included in the command line by using the syntax #{name} , where name is the variable name, as defined in the Execute Service's configuration file or in the global configuration file custom.properties . The substitution will be done in the following order of precedence: Placeholders defined in the table above. Configuration keys defined in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg . Configuration keys defined in custom.properties . For instance, suppose you use the Execute Service with the following arguments: \"John Doe\" xyz #{my.property} the command run will receive that argument list as-is, because my.property is not a valid placeholder, nor is it defined in the Execute Service's configuration file or custom.properties . However, if you define my.property in custom.properties : my.property = foo then the command will get the following argument list: \"John Doe\" xyz foo If you define the same variable in the Execute Service's configuration file (regardless of whether the variable is defined in custom.properties or not): my.property = bar then the actual argument list will be: \"John Doe\" xyz bar Executing commands in workflows For more information on how to execute a command in a workflow, see: Execute Once Workflow Operation Execute Many Workflow Operation","title":"Execute Service"},{"location":"modules/execute/#execute-service","text":"The Execute Service allows a workflow to run external scripts or applications with any MediaPackage element as arguments. This provides a flexible way to operate with MediaPackage resources without the need to write Java code or build Opencast from source. Commands are executed on worker nodes. There are two execute workflow operations: Execute Once : for running a single command that may operate on multiple elements of a mediapackage Execute Many : for running a command for each element in a mediapackage that matches the given criteria","title":"Execute Service"},{"location":"modules/execute/#service-configuration","text":"The Execute Service configuration in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg must be updated to define which commands may be run: # Load factor job.load.execute = 1.0 # The list of commands, separated by spaces, which may be run by the Execute Service. # A value of * means any command is allowed. # Default: empty (no commands allowed) #commands.allowed = If commands.allowed is empty or undefined (the default), the service won't be able to run any commands. Use the special key * to permit any command to be executed (not recommended for production systems). To adjust the job load factor for a command, use the load parameter in the workflow operation rather than adjusting the job.load.execute parameter above.","title":"Service Configuration"},{"location":"modules/execute/#parameter-substitution","text":"The command arguments may contain placeholders, which are substituted by their corresponding values before the command runs. The complete list of available placeholders is detailed in the table below. Placeholder Used in Meaning #{id} Execute Once The Mediapackage ID #{flavor(some/flavor)} Execute Once The absolute path of the element matching the specified flavor. If several elements have the same flavor, the first element returned by MediaPackage#getElementsByFlavor is used. #{in} Execute Many The absolute path of the input element #{out} Execute Once, Execute Many The absolute path of the output element, formed from the output-filename parameter","title":"Parameter substitution"},{"location":"modules/execute/#using-custom-properties-in-the-argument-list","text":"Custom properties can be included in the command line by using the syntax #{name} , where name is the variable name, as defined in the Execute Service's configuration file or in the global configuration file custom.properties . The substitution will be done in the following order of precedence: Placeholders defined in the table above. Configuration keys defined in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg . Configuration keys defined in custom.properties . For instance, suppose you use the Execute Service with the following arguments: \"John Doe\" xyz #{my.property} the command run will receive that argument list as-is, because my.property is not a valid placeholder, nor is it defined in the Execute Service's configuration file or custom.properties . However, if you define my.property in custom.properties : my.property = foo then the command will get the following argument list: \"John Doe\" xyz foo If you define the same variable in the Execute Service's configuration file (regardless of whether the variable is defined in custom.properties or not): my.property = bar then the actual argument list will be: \"John Doe\" xyz bar","title":"Using custom properties in the argument list"},{"location":"modules/execute/#executing-commands-in-workflows","text":"For more information on how to execute a command in a workflow, see: Execute Once Workflow Operation Execute Many Workflow Operation","title":"Executing commands in workflows"},{"location":"modules/googlespeechtranscripts/","text":"Transcripts (Automated by Google Speech) Overview The GoogleSpeechTranscriptionService invokes the Google Speech-to-Text service via REST API to transcribe audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the Google Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Note that because Google's Speech-to-Text service can take a while to process a recording, we do not wait for it to finish before proceeding with the rest of Opencast's normal processing, the transcription process is asynchronous. Workflow 1 runs: Audio file is created Google Speech-to-Text job is started Workflow finishes Translation finishes, workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts Google Speech-to-Text service documentation, including which languages are currently supported, can be found here . Configuration Notes : Instructions and screenshots provided in this section are based on Google Speech-to-Text documentation at the time of writing this document. For up to date instructions please search for 'google speech to text configuration' or visit Google Cloud service page . Step 1: Activate Google Speech and Google Cloud Storage APIs Log in to your Google account and Activate a 12 months free trial Google Cloud Platform services Create a Project to store your credentials and billing information Click Select a project to create new project or use existing project Enable Google Speech API Expand the menu on the left Go to APIs & Service > Libraries Find the Cloud Speech API and click Enable to enable the Google Cloud Speech API Enable Google Cloud Storage and Google Cloud Storage JSON API Go to APIs & Service > Libraries Find Google Cloud Storage and Google Cloud Storage JSON API and enable them if there are not. Create a cloud storage bucket. This is where you will temporary host the files you want to transcribe Go to your Google Cloud Dashboard Expand the menu on the left Go to Storage > Browser Click CREATE BUCKET to create a bucket for the selected project Step 2: Get Google Cloud credentials Go to your Google Cloud Dashboard Expand the menu on the left Go to APIs & Service > Credentials Click on the tab OAuth Consent Screen Fill in a Project name and Save it. Don't worry about the other fields. Go back to Credentials Click the button that says Create Credentials select OAuth Client ID Choose Web Application and give it a name. Add https://developers.google.com/oauthplayground in Authorized redirect URIs . You will need to use this in the next step to get your refresh token Click Create and take note of your Client ID and Client Secret Getting your Refresh Token and Authorization endpoint Go to https://developers.google.com/oauthplayground (Make sure you added this URL to your Authorized redirect URIs in the previous step.) In the top right corner, click the settings icon Take note of your Token endpoint . It is the token endpoint URL needed for the configuration. Make sure the Access token location is set to Authorization header w/ Bearer prefix Make sure Access type is set to Offline Make sure Force prompt is set to 'Consent Screen' Check Use your own OAuth credentials Paste your Client ID and Client Secret created previously. Close the settings. Select the scope of your APIs Click Step 1 Select & authorize APIs tab on the left Find Cloud Speech API v1 and click on https://www.googleapis.com/auth/cloud-platform to select it. Find Cloud Storage API v1 from the list, expand it and click on https://www.googleapis.com/auth/devstorage.full_control to select it Find Cloud Storage JSON API v1 expand it and select https://www.googleapis.com/auth/devstorage.full_control Click Authorize APIs , allow access to your account when prompted. There will be a few warning prompts, just proceed. (On some browser you may need to click the advanced option before you can proceed to next page) When you get to step 2 Exchange authorization code for tokens tab, click Exchange authorization code for tokens . You will need the OAuth Client ID, OAuth Client secret ,the Refresh token and Token endpoint for the configuration file Step 3: Configure GoogleSpeechTranscriptionService Edit etc/org.opencastproject.transcription.googlespeech.GoogleSpeechTranscriptionService.cfg : Set enabled =true Use OAuth Client ID , OAuth Client secret , Refresh token , Token endpoint and storage bucket created above to respectively set google.cloud.client.id , google.cloud.client.secret , google.cloud.refresh.token , google.cloud.token.endpoint.url and google.cloud.storage.bucket Enter the appropriate language in google.speech.language , default is ( en-US ). List of supported language: https://cloud.google.com/speech-to-text/docs/languages Remove profanity (bad language) from transcription by using google.speech.profanity.filter , default is ( false ), not removed by default In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. Example of configuration file: # Change enabled to true to enable this service. enabled=false # Google Cloud Service details google.cloud.client.id=<OAUTH_CLIENT_ID> google.cloud.client.secret=<OAUTH_CLIENT_SECRET> google.cloud.refresh.token=1<REFRESH_TOKEN> google.cloud.token.endpoint.url=<TOKEN_ENDPOINT> # google cloud storage bucket google.cloud.storage.bucket=<BUCKET_NAME> # Language of the supplied audio. See the Google Speech-to-Text service documentation # for available languages. If empty, the default will be used (\"en-US\"). google.speech.language= # Filter out profanities from result. Default is false google.speech.profanity.filter=false # Workflow to be executed when results are ready to be attached to media package. workflow=google-speech-attach-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. # (in seconds) Default is 1 minute. workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # The default is 5 minutes. # (in seconds) completion.check.buffer=300 # How long to wait after a transcription is supposed to finish before marking the job as # cancelled in the database. Default is 5 hours. # (in seconds) max.processing.time=18000 # How long to keep result files in the working file repository in days. # The default is 7 days. cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. notification.email=localadmin@domain Step 4: Add encoding profile for extracting audio The Google Speech-to-Text service has limitations on audio types. Supported audio type are here . By default Opencast will use the encoding settings in etc/encoding/googlespeech-audio.properties. Step 5: Add workflow operations and create new workflow Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the archive to attach the caption/transcripts. <!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mediapackage already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Step 6: Create a workflow that will add the generated caption/transcript to the media package and republish it A sample one can be found in etc/workflows/google-speech-attach-transcripts.xml <!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">80</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation> Transcription delay before cancellation If an event is deleted before the end of Google transcription process, or the Google Speech to Text API has some issues, or something unexpected happens, the transcription process for the event will not be immediately cancelled. Instead, transcription will be attempted several times based on the video duration and configuration properties: completion.check.buffer and max.processing.time . Video duration + completion.check.buffer + max.processing.time set the duration before a Google transcription job is cancelled. completion.check.buffer 5 minutes by default completion.check.buffer 5 hours by default. All these values can be changed in Google Transcription properties file: etc/org.opencastproject.transcription.googlespeech.GoogleSpeechTranscriptionService.cfg For example, if you have a 30 min video, using the default values, it will take 5 hours and 35 min before the transcription is cancelled (when something goes wrong). Workflow Operations google-speech-attach-transcription google-speech-start-transcription","title":"Transcripts (Google Speech)"},{"location":"modules/googlespeechtranscripts/#transcripts-automated-by-google-speech","text":"","title":"Transcripts (Automated by Google Speech)"},{"location":"modules/googlespeechtranscripts/#overview","text":"The GoogleSpeechTranscriptionService invokes the Google Speech-to-Text service via REST API to transcribe audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the Google Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Note that because Google's Speech-to-Text service can take a while to process a recording, we do not wait for it to finish before proceeding with the rest of Opencast's normal processing, the transcription process is asynchronous. Workflow 1 runs: Audio file is created Google Speech-to-Text job is started Workflow finishes Translation finishes, workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts Google Speech-to-Text service documentation, including which languages are currently supported, can be found here .","title":"Overview"},{"location":"modules/googlespeechtranscripts/#configuration","text":"Notes : Instructions and screenshots provided in this section are based on Google Speech-to-Text documentation at the time of writing this document. For up to date instructions please search for 'google speech to text configuration' or visit Google Cloud service page .","title":"Configuration"},{"location":"modules/googlespeechtranscripts/#step-1-activate-google-speech-and-google-cloud-storage-apis","text":"Log in to your Google account and Activate a 12 months free trial Google Cloud Platform services Create a Project to store your credentials and billing information Click Select a project to create new project or use existing project Enable Google Speech API Expand the menu on the left Go to APIs & Service > Libraries Find the Cloud Speech API and click Enable to enable the Google Cloud Speech API Enable Google Cloud Storage and Google Cloud Storage JSON API Go to APIs & Service > Libraries Find Google Cloud Storage and Google Cloud Storage JSON API and enable them if there are not. Create a cloud storage bucket. This is where you will temporary host the files you want to transcribe Go to your Google Cloud Dashboard Expand the menu on the left Go to Storage > Browser Click CREATE BUCKET to create a bucket for the selected project","title":"Step 1: Activate Google Speech and Google Cloud Storage APIs"},{"location":"modules/googlespeechtranscripts/#step-2-get-google-cloud-credentials","text":"Go to your Google Cloud Dashboard Expand the menu on the left Go to APIs & Service > Credentials Click on the tab OAuth Consent Screen Fill in a Project name and Save it. Don't worry about the other fields. Go back to Credentials Click the button that says Create Credentials select OAuth Client ID Choose Web Application and give it a name. Add https://developers.google.com/oauthplayground in Authorized redirect URIs . You will need to use this in the next step to get your refresh token Click Create and take note of your Client ID and Client Secret","title":"Step 2: Get Google Cloud credentials"},{"location":"modules/googlespeechtranscripts/#getting-your-refresh-token-and-authorization-endpoint","text":"Go to https://developers.google.com/oauthplayground (Make sure you added this URL to your Authorized redirect URIs in the previous step.) In the top right corner, click the settings icon Take note of your Token endpoint . It is the token endpoint URL needed for the configuration. Make sure the Access token location is set to Authorization header w/ Bearer prefix Make sure Access type is set to Offline Make sure Force prompt is set to 'Consent Screen' Check Use your own OAuth credentials Paste your Client ID and Client Secret created previously. Close the settings. Select the scope of your APIs Click Step 1 Select & authorize APIs tab on the left Find Cloud Speech API v1 and click on https://www.googleapis.com/auth/cloud-platform to select it. Find Cloud Storage API v1 from the list, expand it and click on https://www.googleapis.com/auth/devstorage.full_control to select it Find Cloud Storage JSON API v1 expand it and select https://www.googleapis.com/auth/devstorage.full_control Click Authorize APIs , allow access to your account when prompted. There will be a few warning prompts, just proceed. (On some browser you may need to click the advanced option before you can proceed to next page) When you get to step 2 Exchange authorization code for tokens tab, click Exchange authorization code for tokens . You will need the OAuth Client ID, OAuth Client secret ,the Refresh token and Token endpoint for the configuration file","title":"Getting your Refresh Token and Authorization endpoint"},{"location":"modules/googlespeechtranscripts/#step-3-configure-googlespeechtranscriptionservice","text":"Edit etc/org.opencastproject.transcription.googlespeech.GoogleSpeechTranscriptionService.cfg : Set enabled =true Use OAuth Client ID , OAuth Client secret , Refresh token , Token endpoint and storage bucket created above to respectively set google.cloud.client.id , google.cloud.client.secret , google.cloud.refresh.token , google.cloud.token.endpoint.url and google.cloud.storage.bucket Enter the appropriate language in google.speech.language , default is ( en-US ). List of supported language: https://cloud.google.com/speech-to-text/docs/languages Remove profanity (bad language) from transcription by using google.speech.profanity.filter , default is ( false ), not removed by default In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. Example of configuration file: # Change enabled to true to enable this service. enabled=false # Google Cloud Service details google.cloud.client.id=<OAUTH_CLIENT_ID> google.cloud.client.secret=<OAUTH_CLIENT_SECRET> google.cloud.refresh.token=1<REFRESH_TOKEN> google.cloud.token.endpoint.url=<TOKEN_ENDPOINT> # google cloud storage bucket google.cloud.storage.bucket=<BUCKET_NAME> # Language of the supplied audio. See the Google Speech-to-Text service documentation # for available languages. If empty, the default will be used (\"en-US\"). google.speech.language= # Filter out profanities from result. Default is false google.speech.profanity.filter=false # Workflow to be executed when results are ready to be attached to media package. workflow=google-speech-attach-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. # (in seconds) Default is 1 minute. workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # The default is 5 minutes. # (in seconds) completion.check.buffer=300 # How long to wait after a transcription is supposed to finish before marking the job as # cancelled in the database. Default is 5 hours. # (in seconds) max.processing.time=18000 # How long to keep result files in the working file repository in days. # The default is 7 days. cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. notification.email=localadmin@domain","title":"Step 3: Configure GoogleSpeechTranscriptionService"},{"location":"modules/googlespeechtranscripts/#step-4-add-encoding-profile-for-extracting-audio","text":"The Google Speech-to-Text service has limitations on audio types. Supported audio type are here . By default Opencast will use the encoding settings in etc/encoding/googlespeech-audio.properties.","title":"Step 4: Add encoding profile for extracting audio"},{"location":"modules/googlespeechtranscripts/#step-5-add-workflow-operations-and-create-new-workflow","text":"Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the archive to attach the caption/transcripts. <!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mediapackage already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation>","title":"Step 5: Add workflow operations and create new workflow"},{"location":"modules/googlespeechtranscripts/#step-6-create-a-workflow-that-will-add-the-generated-captiontranscript-to-the-media-package-and-republish-it","text":"A sample one can be found in etc/workflows/google-speech-attach-transcripts.xml <!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">80</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Step 6: Create a workflow that will add the generated caption/transcript to the media package and republish it"},{"location":"modules/googlespeechtranscripts/#transcription-delay-before-cancellation","text":"If an event is deleted before the end of Google transcription process, or the Google Speech to Text API has some issues, or something unexpected happens, the transcription process for the event will not be immediately cancelled. Instead, transcription will be attempted several times based on the video duration and configuration properties: completion.check.buffer and max.processing.time . Video duration + completion.check.buffer + max.processing.time set the duration before a Google transcription job is cancelled. completion.check.buffer 5 minutes by default completion.check.buffer 5 hours by default. All these values can be changed in Google Transcription properties file: etc/org.opencastproject.transcription.googlespeech.GoogleSpeechTranscriptionService.cfg For example, if you have a 30 min video, using the default values, it will take 5 hours and 35 min before the transcription is cancelled (when something goes wrong).","title":"Transcription delay before cancellation"},{"location":"modules/googlespeechtranscripts/#workflow-operations","text":"google-speech-attach-transcription google-speech-start-transcription","title":"Workflow Operations"},{"location":"modules/liveschedule/","text":"Live Schedule Service Overview The Live Schedule Service manages a live event in the Search index on the engage server. When an event is scheduled and the publishLive configuration is set, a live media package is published to the Search index. The live media package contains track(s) with live streaming URLs. The live media package is retracted from the Search index when the capture finishes or if it fails. If event metadata, such as title or duration, are updated, the live media package in the Search index is updated accordingly. Pre-requisites To use this service, you need to have: A streaming server (Wowza, nginx-rtmp) or CDN already set up to stream live content A capture agent capable of streaming to it A player capable of playing live streams. The Paella player supports the HLS protocol. Other players/protocols have not been tested. Configuration Step 1: Configure the service Edit etc/org.opencastproject.liveschedule.impl.LiveScheduleServiceImpl.cfg . If your capture agent does not register a capture.device.live.resolution.WIDTHxHEIGHT property, it's mandatory to configure the live.streamingUrl . The live.streamingUrl should be set to your streaming server's output URL (or the subscriber URL specified by your CDN) and is indexed by the engage server. This is the URL that the player will use to play the live stream. For instance, if using rtmp, set it to something like: rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ For HLS, see below: # Configuration for the Live Schedule Service # # If the capture agent doesn't register the capture.device.live.resolution.WIDTHxHEIGHT property, # specify live.streamingUrl, live.resolution, and live.streamName below: # # ----------------------------- # The base URL that the player will use to play the live stream live.streamingUrl=http://streaming.server/hls/ # If a comma-separated list is provided, several resolutions will be generated for each flavor live.resolution=1920x540,960x270 # Possible variable substitutions: # #{id} = media package id # #{flavor} = type-subtype of flavor # #{caName} = capture agent name # #{resolution} = video resolution e.g. 1920x1080 #live.streamName=#{caName}-#{flavor}.stream-#{resolution} live.streamName=#{caName}/playlist.m3u8 # ----------------------------- # The same mime-type applies to all flavors and resolutions live.mimeType=application/x-mpegURL # If a comma-separated list is provided, several streams links will be generated, one for each # resolution-targetFlavor combination. # Default is presenter/delivery #live.targetFlavors=presenter/delivery # The distribution service to use: download or aws.s3 live.distributionService=download # A list of combinations with target flavor and resolution for which streaming URIs should be published. # For example: live.publishStreaming=presenter/delivery:1920x540 # Default is not to publish streaming URIs # live.publishStreaming= Step 2: Configure the capture agent Capture agent does not register the capture.device.live.resolution.WIDTHxHEIGHT property Configure the capture agent to stream to your streaming server (or the publisher URL specified by your CDN), using the same stream name specified in live.streamName. Capture agent registers the capture.device.live.resolution.WIDTHxHEIGHT property If your capture agent supports configuring custom capture agent properties, instead of configuring the live.streamingUrl, live.resolution, live.streamName, you can update the capture agent firmware to pass the following when registering to Opencast: capture.device.names: add 'live' to the current list of devices capture.device.live.resolution.WIDTHxHEIGHT=STREAMING_URL_USED_BY_PLAYER: one for each desired stream Then, the LiveScheduleService will generate as many live tracks as the resolutions registered, with their streaming URLs, using 'presenter/delivery' (or the flavor configured, but only one flavor can be used). If a property capture.device.live.resolution.WIDTHxHEIGHT was registered, it will take precedence over the LiveScheduleService configuration. Example 1: Capture agent does not register with capture.device.live.resolution.WIDTHxHEIGHT If: live.streamingUrl=rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION live.streamName=#{caName}-#{flavor}.stream live.targetFlavors=presenter/delivery capture agent name: ca01 Then, the capture agent should stream to ('/' is replaced by '-'): rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ca01-presenter-delivery.stream Note: Please refer to your streaming server or CDN documentation for the correct syntax of the streaming URL. The live.streamingUrl may be very different from the URL the capture agent streams to. For instance, with Akamai, the URL used by the player will be something like live.streamingUrl=rtmp://xyz.live.edgefcs.net/live/ and the capture agent's publish URL something like rtmp://a.bcd.e.akamaientrypoint.net/EntryPoint. The stream name should always match. Example 2: Capture agent registers with capture.device.live.resolution.WIDTHxHEIGHT If the capture agent registers itself with: property key value capture.device.names presentation,presenter,live capture.device.presentation.flavor presentation/source capture.device.presenter.flavor presenter/source capture.device.live.resolution.1920x540 rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 capture.device.live.resolution.960x270 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345 The LiveScheduleService will generate a media package with two live tracks having the following urls: rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345 Step 3: Configure the Workflow When scheduling a live event via the admin UI, the workflow needs to have the publishLive configuration set to true (this is already included in the sample workflows). If not using the sample Opencast workflows, add to the <configuration_panel> : <fieldset> <legend>Publish live stream:</legend> <ul> <li> <input id=\"publishLive\" name=\"publishLive\" type=\"checkbox\" class=\"configField\" value=\"false\" /> <label for=\"publishLive\">Add live event to Opencast Media Module</label> </li> </ul> </fieldset> And to the defaults operation: <operation id=\"defaults\" description=\"Applying default configuration values\"> <configurations> <configuration key=\"comment\">false</configuration> <configuration key=\"publishToMediaModule\">true</configuration> <configuration key=\"publishToOaiPmh\">true</configuration> <configuration key=\"uploadedSearchPreview\">false</configuration> <configuration key=\"publishLive\">false</configuration> </configurations> </operation>","title":"Live Schedule"},{"location":"modules/liveschedule/#live-schedule-service","text":"","title":"Live Schedule Service"},{"location":"modules/liveschedule/#overview","text":"The Live Schedule Service manages a live event in the Search index on the engage server. When an event is scheduled and the publishLive configuration is set, a live media package is published to the Search index. The live media package contains track(s) with live streaming URLs. The live media package is retracted from the Search index when the capture finishes or if it fails. If event metadata, such as title or duration, are updated, the live media package in the Search index is updated accordingly.","title":"Overview"},{"location":"modules/liveschedule/#pre-requisites","text":"To use this service, you need to have: A streaming server (Wowza, nginx-rtmp) or CDN already set up to stream live content A capture agent capable of streaming to it A player capable of playing live streams. The Paella player supports the HLS protocol. Other players/protocols have not been tested.","title":"Pre-requisites"},{"location":"modules/liveschedule/#configuration","text":"","title":"Configuration"},{"location":"modules/liveschedule/#step-1-configure-the-service","text":"Edit etc/org.opencastproject.liveschedule.impl.LiveScheduleServiceImpl.cfg . If your capture agent does not register a capture.device.live.resolution.WIDTHxHEIGHT property, it's mandatory to configure the live.streamingUrl . The live.streamingUrl should be set to your streaming server's output URL (or the subscriber URL specified by your CDN) and is indexed by the engage server. This is the URL that the player will use to play the live stream. For instance, if using rtmp, set it to something like: rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ For HLS, see below: # Configuration for the Live Schedule Service # # If the capture agent doesn't register the capture.device.live.resolution.WIDTHxHEIGHT property, # specify live.streamingUrl, live.resolution, and live.streamName below: # # ----------------------------- # The base URL that the player will use to play the live stream live.streamingUrl=http://streaming.server/hls/ # If a comma-separated list is provided, several resolutions will be generated for each flavor live.resolution=1920x540,960x270 # Possible variable substitutions: # #{id} = media package id # #{flavor} = type-subtype of flavor # #{caName} = capture agent name # #{resolution} = video resolution e.g. 1920x1080 #live.streamName=#{caName}-#{flavor}.stream-#{resolution} live.streamName=#{caName}/playlist.m3u8 # ----------------------------- # The same mime-type applies to all flavors and resolutions live.mimeType=application/x-mpegURL # If a comma-separated list is provided, several streams links will be generated, one for each # resolution-targetFlavor combination. # Default is presenter/delivery #live.targetFlavors=presenter/delivery # The distribution service to use: download or aws.s3 live.distributionService=download # A list of combinations with target flavor and resolution for which streaming URIs should be published. # For example: live.publishStreaming=presenter/delivery:1920x540 # Default is not to publish streaming URIs # live.publishStreaming=","title":"Step 1: Configure the service"},{"location":"modules/liveschedule/#step-2-configure-the-capture-agent","text":"","title":"Step 2: Configure the capture agent"},{"location":"modules/liveschedule/#capture-agent-does-not-register-the-capturedeviceliveresolutionwidthxheight-property","text":"Configure the capture agent to stream to your streaming server (or the publisher URL specified by your CDN), using the same stream name specified in live.streamName.","title":"Capture agent does not register the capture.device.live.resolution.WIDTHxHEIGHT property"},{"location":"modules/liveschedule/#capture-agent-registers-the-capturedeviceliveresolutionwidthxheight-property","text":"If your capture agent supports configuring custom capture agent properties, instead of configuring the live.streamingUrl, live.resolution, live.streamName, you can update the capture agent firmware to pass the following when registering to Opencast: capture.device.names: add 'live' to the current list of devices capture.device.live.resolution.WIDTHxHEIGHT=STREAMING_URL_USED_BY_PLAYER: one for each desired stream Then, the LiveScheduleService will generate as many live tracks as the resolutions registered, with their streaming URLs, using 'presenter/delivery' (or the flavor configured, but only one flavor can be used). If a property capture.device.live.resolution.WIDTHxHEIGHT was registered, it will take precedence over the LiveScheduleService configuration.","title":"Capture agent registers the capture.device.live.resolution.WIDTHxHEIGHT property"},{"location":"modules/liveschedule/#example-1","text":"","title":"Example 1:"},{"location":"modules/liveschedule/#capture-agent-does-not-register-with-capturedeviceliveresolutionwidthxheight","text":"If: live.streamingUrl=rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION live.streamName=#{caName}-#{flavor}.stream live.targetFlavors=presenter/delivery capture agent name: ca01 Then, the capture agent should stream to ('/' is replaced by '-'): rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ca01-presenter-delivery.stream Note: Please refer to your streaming server or CDN documentation for the correct syntax of the streaming URL. The live.streamingUrl may be very different from the URL the capture agent streams to. For instance, with Akamai, the URL used by the player will be something like live.streamingUrl=rtmp://xyz.live.edgefcs.net/live/ and the capture agent's publish URL something like rtmp://a.bcd.e.akamaientrypoint.net/EntryPoint. The stream name should always match.","title":"Capture agent does not register with capture.device.live.resolution.WIDTHxHEIGHT"},{"location":"modules/liveschedule/#example-2","text":"","title":"Example 2:"},{"location":"modules/liveschedule/#capture-agent-registers-with-capturedeviceliveresolutionwidthxheight","text":"If the capture agent registers itself with: property key value capture.device.names presentation,presenter,live capture.device.presentation.flavor presentation/source capture.device.presenter.flavor presenter/source capture.device.live.resolution.1920x540 rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 capture.device.live.resolution.960x270 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345 The LiveScheduleService will generate a media package with two live tracks having the following urls: rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345","title":"Capture agent registers with capture.device.live.resolution.WIDTHxHEIGHT"},{"location":"modules/liveschedule/#step-3-configure-the-workflow","text":"When scheduling a live event via the admin UI, the workflow needs to have the publishLive configuration set to true (this is already included in the sample workflows). If not using the sample Opencast workflows, add to the <configuration_panel> : <fieldset> <legend>Publish live stream:</legend> <ul> <li> <input id=\"publishLive\" name=\"publishLive\" type=\"checkbox\" class=\"configField\" value=\"false\" /> <label for=\"publishLive\">Add live event to Opencast Media Module</label> </li> </ul> </fieldset> And to the defaults operation: <operation id=\"defaults\" description=\"Applying default configuration values\"> <configurations> <configuration key=\"comment\">false</configuration> <configuration key=\"publishToMediaModule\">true</configuration> <configuration key=\"publishToOaiPmh\">true</configuration> <configuration key=\"uploadedSearchPreview\">false</configuration> <configuration key=\"publishLive\">false</configuration> </configurations> </operation>","title":"Step 3: Configure the Workflow"},{"location":"modules/ltimodule/","text":"Integrating Opencast using LTI About LTI LTI provides an easy way to integrate Opencast into any system which can act as an LTI tool consumer such as many learning management systems (LMS). Popular examples for LTI consumers include Sakai , Moodle or ILIAS . Using the LTI integration, students can access Opencast through an LTI tool in the LMS course site, and can play back Opencast videos without ever leaving their course. More information about the LTI specification is available at IMS Learning Tools Interoperability . Configuration Configure OAuth LTI uses OAuth to authenticate users. To enable OAuth in Opencast, edit etc/security/mh_default_org.xml and uncomment the oauthProtectedResourceFilter in the authentication filters section: <ref bean=\"oauthProtectedResourceFilter\" /> Next, configure the OAuth consumer by setting custom credentials in etc/org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg : oauth.consumer.name.1=CONSUMERNAME oauth.consumer.key.1=CONSUMERKEY oauth.consumer.secret.1=CONSUMERSECRET Configure LTI Opencast's LTI module allows additional configuration like making a OAuth consumer key a highly trusted key, preventing Opencast from generating a temporary username, or to block some specific usernames like the system administrator. For more details, take a look at the options in etc/org.opencastproject.security.lti.LtiLaunchAuthenticationHandler.cfg . The \u201cdelete\u201d key in the series overview tool can be configured by specifying the retraction workflow in etc/org.opencastproject.lti.service.impl.LtiServiceImpl.cfg . The property is called retract-workflow-id , and it defaults to retract . Configure and test an LTI tool in the LMS Configure an LTI tool in the LMS with these values: LTI launch URL: <presentation-node-url>/lti LTI key: the value of oauth.consumer.key LTI secret: the value of oauth.consumer.secret Access the LTI tool configured for Opencast in the LMS. The Opencast LTI welcome page should appear. Use the links provided there to verify the LTI connection. LTI Roles LTI users will only see Opencast series and videos which are public, or those to which they have access because of the Opencast roles which they have. The Opencast LTI module grants an LTI user the role(s) formed from the LTI parameters context_id and roles . The LTI context is typically the LMS course ID, and the default LTI role for a student in a course is Learner . The Opencast role granted would therefore be <context-id>_Learner . To make a series or video visible to students who access Opencast through LTI in an LMS course, add the role <context-id>_Learner to the series or event access control list (ACL). An additional prefix for these generated roles may be defined in Opencast's LTI configuration file based on the used OAuth consumer. That way, you can distinguish between users from multiple different consumers. LTI users may also have additional roles if the LTI user is created as an Opencast user in the Admin UI and given additional roles, or if one or more Opencast User Providers or Role Providers are configured. Specifying LTI Tools Opencast will redirect an LTI user to the URL specified by the LTI custom tool parameter. Some LMS systems allow custom parameters to be defined separately in each place where an LTI tool is used, whereas other systems only allow custom parameters to be defined globally. To show the media module, use engage/ui/ as LTI custom_tool launch parameter To show all videos for a single series, use ltitools/index.html as LTI custom_tool launch parameter and specify the following query parameters: subtool=series series=SERIESID if you have the series ID series_name=SERIESNAME if you just have the series name (has to be unique) deletion=true to show a delete button next to each episode edit=true if you want to display an edit button next to each episode download=true to show a button next to each episode that allows for downloading individual video files lng=LANG to force a language (the browser language is used otherwise) To show an upload dialog, use ltitools/index.html as LTI custom_tool launch parameter and specify the following query parameters: subtool=upload series=SERIESID if you have the series ID series_name=SERIESNAME if you just have the series name (has to be unique) lng=LANG to force a language (the browser language is used otherwise) To show a single video, use /play/<id> as LTI custom_tool launch parameter To show a debug page before proceeding to the tool, append the parameter test=true For more information about how to set custom LTI parameters, please check the documentation of your LMS. Customizing LTI\u2019s look The LTI module provides the option to provide custom style sheets for configuring the look and feel of the tools which may be important to match the design of the LTI consumer in which it is included. The CSS file can be found in the user interface configuration directory usually located at: etc/ui-config/mh_default_org/ltitools/lti.css","title":"LTI Module"},{"location":"modules/ltimodule/#integrating-opencast-using-lti","text":"","title":"Integrating Opencast using LTI"},{"location":"modules/ltimodule/#about-lti","text":"LTI provides an easy way to integrate Opencast into any system which can act as an LTI tool consumer such as many learning management systems (LMS). Popular examples for LTI consumers include Sakai , Moodle or ILIAS . Using the LTI integration, students can access Opencast through an LTI tool in the LMS course site, and can play back Opencast videos without ever leaving their course. More information about the LTI specification is available at IMS Learning Tools Interoperability .","title":"About LTI"},{"location":"modules/ltimodule/#configuration","text":"","title":"Configuration"},{"location":"modules/ltimodule/#configure-oauth","text":"LTI uses OAuth to authenticate users. To enable OAuth in Opencast, edit etc/security/mh_default_org.xml and uncomment the oauthProtectedResourceFilter in the authentication filters section: <ref bean=\"oauthProtectedResourceFilter\" /> Next, configure the OAuth consumer by setting custom credentials in etc/org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg : oauth.consumer.name.1=CONSUMERNAME oauth.consumer.key.1=CONSUMERKEY oauth.consumer.secret.1=CONSUMERSECRET","title":"Configure OAuth"},{"location":"modules/ltimodule/#configure-lti","text":"Opencast's LTI module allows additional configuration like making a OAuth consumer key a highly trusted key, preventing Opencast from generating a temporary username, or to block some specific usernames like the system administrator. For more details, take a look at the options in etc/org.opencastproject.security.lti.LtiLaunchAuthenticationHandler.cfg . The \u201cdelete\u201d key in the series overview tool can be configured by specifying the retraction workflow in etc/org.opencastproject.lti.service.impl.LtiServiceImpl.cfg . The property is called retract-workflow-id , and it defaults to retract .","title":"Configure LTI"},{"location":"modules/ltimodule/#configure-and-test-an-lti-tool-in-the-lms","text":"Configure an LTI tool in the LMS with these values: LTI launch URL: <presentation-node-url>/lti LTI key: the value of oauth.consumer.key LTI secret: the value of oauth.consumer.secret Access the LTI tool configured for Opencast in the LMS. The Opencast LTI welcome page should appear. Use the links provided there to verify the LTI connection.","title":"Configure and test an LTI tool in the LMS"},{"location":"modules/ltimodule/#lti-roles","text":"LTI users will only see Opencast series and videos which are public, or those to which they have access because of the Opencast roles which they have. The Opencast LTI module grants an LTI user the role(s) formed from the LTI parameters context_id and roles . The LTI context is typically the LMS course ID, and the default LTI role for a student in a course is Learner . The Opencast role granted would therefore be <context-id>_Learner . To make a series or video visible to students who access Opencast through LTI in an LMS course, add the role <context-id>_Learner to the series or event access control list (ACL). An additional prefix for these generated roles may be defined in Opencast's LTI configuration file based on the used OAuth consumer. That way, you can distinguish between users from multiple different consumers. LTI users may also have additional roles if the LTI user is created as an Opencast user in the Admin UI and given additional roles, or if one or more Opencast User Providers or Role Providers are configured.","title":"LTI Roles"},{"location":"modules/ltimodule/#specifying-lti-tools","text":"Opencast will redirect an LTI user to the URL specified by the LTI custom tool parameter. Some LMS systems allow custom parameters to be defined separately in each place where an LTI tool is used, whereas other systems only allow custom parameters to be defined globally. To show the media module, use engage/ui/ as LTI custom_tool launch parameter To show all videos for a single series, use ltitools/index.html as LTI custom_tool launch parameter and specify the following query parameters: subtool=series series=SERIESID if you have the series ID series_name=SERIESNAME if you just have the series name (has to be unique) deletion=true to show a delete button next to each episode edit=true if you want to display an edit button next to each episode download=true to show a button next to each episode that allows for downloading individual video files lng=LANG to force a language (the browser language is used otherwise) To show an upload dialog, use ltitools/index.html as LTI custom_tool launch parameter and specify the following query parameters: subtool=upload series=SERIESID if you have the series ID series_name=SERIESNAME if you just have the series name (has to be unique) lng=LANG to force a language (the browser language is used otherwise) To show a single video, use /play/<id> as LTI custom_tool launch parameter To show a debug page before proceeding to the tool, append the parameter test=true For more information about how to set custom LTI parameters, please check the documentation of your LMS.","title":"Specifying LTI Tools"},{"location":"modules/ltimodule/#customizing-ltis-look","text":"The LTI module provides the option to provide custom style sheets for configuring the look and feel of the tools which may be important to match the design of the LTI consumer in which it is included. The CSS file can be found in the user interface configuration directory usually located at: etc/ui-config/mh_default_org/ltitools/lti.css","title":"Customizing LTI\u2019s look"},{"location":"modules/mediamodule.configuration/","text":"Media Module Configuration The media module is the default overview of the distributed media files. The configurations for the media module are done for each tenant. So the configuration keys are located in etc/org.opencastproject.organization-mh_default_org.cfg : prop.logo_mediamodule This logo file will be displayed in the upper left of the media module page Default: Opencast logo prop.player The player that should be use to play the videos. Default: Paella player","title":"Media Module"},{"location":"modules/mediamodule.configuration/#media-module-configuration","text":"The media module is the default overview of the distributed media files. The configurations for the media module are done for each tenant. So the configuration keys are located in etc/org.opencastproject.organization-mh_default_org.cfg : prop.logo_mediamodule This logo file will be displayed in the upper left of the media module page Default: Opencast logo prop.player The player that should be use to play the videos. Default: Paella player","title":"Media Module Configuration"},{"location":"modules/metrics/","text":"Metrics (OpenMetrics, Prometheus) Opencast comes with a metrics endpoint that supports the OpenMetrics format and can be used by tools like Prometheus . The endpoint is available at /metrics . Available Metrics Opencast related metrics describe the whole cluster and will be identical on all nodes while JVM metrics are specific to each node. These available metrics allow monitoring the current cluster state when it comes to processing and should allow for good alerting rules: How many workflows are being processed How many jobs are being processed Are there any services in a warning or error state How many events are in the asset manager Here is a complete list of the available Opencast related metrics: # HELP opencast_services_total Number of services in a cluster # TYPE opencast_services_total gauge opencast_services_total{state=\"ERROR\",} 0.0 opencast_services_total{state=\"WARNING\",} 4.0 opencast_services_total{state=\"NORMAL\",} 83.0 # HELP opencast_job_load_current Maximum job load # TYPE opencast_job_load_current gauge opencast_job_load_current{host=\"https://example.opencast.org\",} 3.0 # HELP opencast_workflow_active Active workflows # TYPE opencast_workflow_active gauge opencast_workflow_active{organization=\"mh_default_org\",} 1.0 # HELP opencast_job_load_max Maximum job load # TYPE opencast_job_load_max gauge opencast_job_load_max{host=\"https://example.opencast.org\",} 4.0 # HELP opencast_job_active Active jobs # TYPE opencast_job_active gauge opencast_job_active{host=\"https://example.opencast.org\",organization=\"mh_default_org\",} 4.0 # HELP opencast_version Version of Opencast (based on metrics module) # TYPE opencast_version gauge opencast_version{part=\"major\",} 10.0 opencast_version{part=\"minor\",} 0.0 # HELP requests_total Total requests. # TYPE requests_total counter requests_total 1.0 # HELP opencast_asset_manager_events Events in Asset Manager # TYPE opencast_asset_manager_events gauge opencast_asset_manager_events{organization=\"mh_default_org\",} 1.0 Additionally, standard JVM metrics are exported providing information about e.g. memory and CPU usage, threads, classloading, etc. Here is a complete list of the available JVM metrics with exemplary values: # HELP process_cpu_seconds_total Total user and system CPU time spent in seconds. # TYPE process_cpu_seconds_total counter process_cpu_seconds_total 117.251697 # HELP process_start_time_seconds Start time of the process since unix epoch in seconds. # TYPE process_start_time_seconds gauge process_start_time_seconds 1.623394602475E9 # HELP process_open_fds Number of open file descriptors. # TYPE process_open_fds gauge process_open_fds 627.0 # HELP process_max_fds Maximum number of open file descriptors. # TYPE process_max_fds gauge process_max_fds 10240.0 # HELP jvm_memory_objects_pending_finalization The number of objects waiting in the finalizer queue. # TYPE jvm_memory_objects_pending_finalization gauge jvm_memory_objects_pending_finalization 0.0 # HELP jvm_memory_bytes_used Used bytes of a given JVM memory area. # TYPE jvm_memory_bytes_used gauge jvm_memory_bytes_used{area=\"heap\",} 2.74153448E8 jvm_memory_bytes_used{area=\"nonheap\",} 2.04918736E8 # HELP jvm_memory_bytes_committed Committed (bytes) of a given JVM memory area. # TYPE jvm_memory_bytes_committed gauge jvm_memory_bytes_committed{area=\"heap\",} 4.37256192E8 jvm_memory_bytes_committed{area=\"nonheap\",} 2.25353728E8 # HELP jvm_memory_bytes_max Max (bytes) of a given JVM memory area. # TYPE jvm_memory_bytes_max gauge jvm_memory_bytes_max{area=\"heap\",} 1.073741824E9 jvm_memory_bytes_max{area=\"nonheap\",} -1.0 # HELP jvm_memory_bytes_init Initial bytes of a given JVM memory area. # TYPE jvm_memory_bytes_init gauge jvm_memory_bytes_init{area=\"heap\",} 1.34217728E8 jvm_memory_bytes_init{area=\"nonheap\",} 7667712.0 # HELP jvm_memory_pool_bytes_used Used bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_used gauge jvm_memory_pool_bytes_used{pool=\"CodeHeap 'non-nmethods'\",} 1361536.0 jvm_memory_pool_bytes_used{pool=\"Metaspace\",} 1.36619544E8 jvm_memory_pool_bytes_used{pool=\"CodeHeap 'profiled nmethods'\",} 3.937024E7 jvm_memory_pool_bytes_used{pool=\"Compressed Class Space\",} 1.5748792E7 jvm_memory_pool_bytes_used{pool=\"G1 Eden Space\",} 1.24780544E8 jvm_memory_pool_bytes_used{pool=\"G1 Old Gen\",} 1.31547112E8 jvm_memory_pool_bytes_used{pool=\"G1 Survivor Space\",} 1.7825792E7 jvm_memory_pool_bytes_used{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.1818624E7 # HELP jvm_memory_pool_bytes_committed Committed bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_committed gauge jvm_memory_pool_bytes_committed{pool=\"CodeHeap 'non-nmethods'\",} 2555904.0 jvm_memory_pool_bytes_committed{pool=\"Metaspace\",} 1.51691264E8 jvm_memory_pool_bytes_committed{pool=\"CodeHeap 'profiled nmethods'\",} 3.9452672E7 jvm_memory_pool_bytes_committed{pool=\"Compressed Class Space\",} 1.9791872E7 jvm_memory_pool_bytes_committed{pool=\"G1 Eden Space\",} 2.33832448E8 jvm_memory_pool_bytes_committed{pool=\"G1 Old Gen\",} 1.85597952E8 jvm_memory_pool_bytes_committed{pool=\"G1 Survivor Space\",} 1.7825792E7 jvm_memory_pool_bytes_committed{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.1862016E7 # HELP jvm_memory_pool_bytes_max Max bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_max gauge jvm_memory_pool_bytes_max{pool=\"CodeHeap 'non-nmethods'\",} 5836800.0 jvm_memory_pool_bytes_max{pool=\"Metaspace\",} -1.0 jvm_memory_pool_bytes_max{pool=\"CodeHeap 'profiled nmethods'\",} 1.22908672E8 jvm_memory_pool_bytes_max{pool=\"Compressed Class Space\",} 1.073741824E9 jvm_memory_pool_bytes_max{pool=\"G1 Eden Space\",} -1.0 jvm_memory_pool_bytes_max{pool=\"G1 Old Gen\",} 1.073741824E9 jvm_memory_pool_bytes_max{pool=\"G1 Survivor Space\",} -1.0 jvm_memory_pool_bytes_max{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.22912768E8 # HELP jvm_memory_pool_bytes_init Initial bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_init gauge jvm_memory_pool_bytes_init{pool=\"CodeHeap 'non-nmethods'\",} 2555904.0 jvm_memory_pool_bytes_init{pool=\"Metaspace\",} 0.0 jvm_memory_pool_bytes_init{pool=\"CodeHeap 'profiled nmethods'\",} 2555904.0 jvm_memory_pool_bytes_init{pool=\"Compressed Class Space\",} 0.0 jvm_memory_pool_bytes_init{pool=\"G1 Eden Space\",} 2.7262976E7 jvm_memory_pool_bytes_init{pool=\"G1 Old Gen\",} 1.06954752E8 jvm_memory_pool_bytes_init{pool=\"G1 Survivor Space\",} 0.0 jvm_memory_pool_bytes_init{pool=\"CodeHeap 'non-profiled nmethods'\",} 2555904.0 # HELP jvm_memory_pool_collection_used_bytes Used bytes after last collection of a given JVM memory pool. # TYPE jvm_memory_pool_collection_used_bytes gauge jvm_memory_pool_collection_used_bytes{pool=\"G1 Eden Space\",} 0.0 jvm_memory_pool_collection_used_bytes{pool=\"G1 Old Gen\",} 1.29009136E8 jvm_memory_pool_collection_used_bytes{pool=\"G1 Survivor Space\",} 1.7825792E7 # HELP jvm_memory_pool_collection_committed_bytes Committed after last collection bytes of a given JVM memory pool. # TYPE jvm_memory_pool_collection_committed_bytes gauge jvm_memory_pool_collection_committed_bytes{pool=\"G1 Eden Space\",} 2.33832448E8 jvm_memory_pool_collection_committed_bytes{pool=\"G1 Old Gen\",} 2.21249536E8 jvm_memory_pool_collection_committed_bytes{pool=\"G1 Survivor Space\",} 1.7825792E7 # HELP jvm_memory_pool_collection_max_bytes Max bytes after last collection of a given JVM memory pool. # TYPE jvm_memory_pool_collection_max_bytes gauge jvm_memory_pool_collection_max_bytes{pool=\"G1 Eden Space\",} -1.0 jvm_memory_pool_collection_max_bytes{pool=\"G1 Old Gen\",} 1.073741824E9 jvm_memory_pool_collection_max_bytes{pool=\"G1 Survivor Space\",} -1.0 # HELP jvm_memory_pool_collection_init_bytes Initial after last collection bytes of a given JVM memory pool. # TYPE jvm_memory_pool_collection_init_bytes gauge jvm_memory_pool_collection_init_bytes{pool=\"G1 Eden Space\",} 2.7262976E7 jvm_memory_pool_collection_init_bytes{pool=\"G1 Old Gen\",} 1.06954752E8 jvm_memory_pool_collection_init_bytes{pool=\"G1 Survivor Space\",} 0.0 # HELP jvm_memory_pool_allocated_bytes_created Total bytes allocated in a given JVM memory pool. Only updated after GC, not continuously. # TYPE jvm_memory_pool_allocated_bytes_created gauge jvm_memory_pool_allocated_bytes_created{pool=\"CodeHeap 'profiled nmethods'\",} 1.623394629741E9 jvm_memory_pool_allocated_bytes_created{pool=\"G1 Old Gen\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"G1 Eden Space\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"G1 Survivor Space\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"Compressed Class Space\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"Metaspace\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"CodeHeap 'non-nmethods'\",} 1.623394629746E9 # HELP jvm_memory_pool_allocated_bytes_total Total bytes allocated in a given JVM memory pool. Only updated after GC, not continuously. # TYPE jvm_memory_pool_allocated_bytes_total counter jvm_memory_pool_allocated_bytes_total{pool=\"CodeHeap 'profiled nmethods'\",} 3.7028864E7 jvm_memory_pool_allocated_bytes_total{pool=\"G1 Old Gen\",} 1.3262048E8 jvm_memory_pool_allocated_bytes_total{pool=\"G1 Eden Space\",} 8.74512384E8 jvm_memory_pool_allocated_bytes_total{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.145216E7 jvm_memory_pool_allocated_bytes_total{pool=\"G1 Survivor Space\",} 1.8874368E7 jvm_memory_pool_allocated_bytes_total{pool=\"Compressed Class Space\",} 1.4760208E7 jvm_memory_pool_allocated_bytes_total{pool=\"Metaspace\",} 1.28033584E8 jvm_memory_pool_allocated_bytes_total{pool=\"CodeHeap 'non-nmethods'\",} 1340416.0 # HELP jvm_buffer_pool_used_bytes Used bytes of a given JVM buffer pool. # TYPE jvm_buffer_pool_used_bytes gauge jvm_buffer_pool_used_bytes{pool=\"mapped\",} 0.0 jvm_buffer_pool_used_bytes{pool=\"direct\",} 290150.0 # HELP jvm_buffer_pool_capacity_bytes Bytes capacity of a given JVM buffer pool. # TYPE jvm_buffer_pool_capacity_bytes gauge jvm_buffer_pool_capacity_bytes{pool=\"mapped\",} 0.0 jvm_buffer_pool_capacity_bytes{pool=\"direct\",} 290150.0 # HELP jvm_buffer_pool_used_buffers Used buffers of a given JVM buffer pool. # TYPE jvm_buffer_pool_used_buffers gauge jvm_buffer_pool_used_buffers{pool=\"mapped\",} 0.0 jvm_buffer_pool_used_buffers{pool=\"direct\",} 32.0 # HELP jvm_gc_collection_seconds Time spent in a given JVM garbage collector in seconds. # TYPE jvm_gc_collection_seconds summary jvm_gc_collection_seconds_count{gc=\"G1 Young Generation\",} 41.0 jvm_gc_collection_seconds_sum{gc=\"G1 Young Generation\",} 0.447 jvm_gc_collection_seconds_count{gc=\"G1 Old Generation\",} 0.0 jvm_gc_collection_seconds_sum{gc=\"G1 Old Generation\",} 0.0 # HELP jvm_threads_current Current thread count of a JVM # TYPE jvm_threads_current gauge jvm_threads_current 188.0 # HELP jvm_threads_daemon Daemon thread count of a JVM # TYPE jvm_threads_daemon gauge jvm_threads_daemon 73.0 # HELP jvm_threads_peak Peak thread count of a JVM # TYPE jvm_threads_peak gauge jvm_threads_peak 188.0 # HELP jvm_threads_started_total Started thread count of a JVM # TYPE jvm_threads_started_total counter jvm_threads_started_total 211.0 # HELP jvm_threads_deadlocked Cycles of JVM-threads that are in deadlock waiting to acquire object monitors or ownable synchronizers # TYPE jvm_threads_deadlocked gauge jvm_threads_deadlocked 0.0 # HELP jvm_threads_deadlocked_monitor Cycles of JVM-threads that are in deadlock waiting to acquire object monitors # TYPE jvm_threads_deadlocked_monitor gauge jvm_threads_deadlocked_monitor 0.0 # HELP jvm_threads_state Current count of threads by state # TYPE jvm_threads_state gauge jvm_threads_state{state=\"BLOCKED\",} 0.0 jvm_threads_state{state=\"TERMINATED\",} 0.0 jvm_threads_state{state=\"WAITING\",} 54.0 jvm_threads_state{state=\"TIMED_WAITING\",} 78.0 jvm_threads_state{state=\"NEW\",} 0.0 jvm_threads_state{state=\"RUNNABLE\",} 56.0 # HELP jvm_classes_loaded The number of classes that are currently loaded in the JVM # TYPE jvm_classes_loaded gauge jvm_classes_loaded 21570.0 # HELP jvm_classes_loaded_total The total number of classes that have been loaded since the JVM has started execution # TYPE jvm_classes_loaded_total counter jvm_classes_loaded_total 21570.0 # HELP jvm_classes_unloaded_total The total number of classes that have been unloaded since the JVM has started execution # TYPE jvm_classes_unloaded_total counter jvm_classes_unloaded_total 0.0 # HELP jvm_info VM version info # TYPE jvm_info gauge jvm_info{runtime=\"OpenJDK Runtime Environment\",vendor=\"Oracle Corporation\",version=\"11.0.10+9\",} 1.0 A corresponding monitoring mixin for JVM metrics with dashboards and alerting rules can be found at github.com/grafana/jsonnet-libs . Access By default, you need to be authenticated and have ROLE_ADMIN or ROLE_METRICS to access the endpoint. You can configure this in the security configuration (e.g. etc/security/mh_default.org.xml ). For example, to allow anonymous access set: <sec:intercept-url pattern=\"/metrics\" access=\"ROLE_ANONYMOUS\" /> Prometheus Configuration There is nothing special when it comes to the Prometheus configuration: - job_name: opencast scheme: https basic_auth: username: <oc-user> password: <oc-password> static_configs: - targets: - example.opencast.org","title":"Metrics (OpenMetrics, Prometheus)"},{"location":"modules/metrics/#metrics-openmetrics-prometheus","text":"Opencast comes with a metrics endpoint that supports the OpenMetrics format and can be used by tools like Prometheus . The endpoint is available at /metrics .","title":"Metrics (OpenMetrics, Prometheus)"},{"location":"modules/metrics/#available-metrics","text":"Opencast related metrics describe the whole cluster and will be identical on all nodes while JVM metrics are specific to each node. These available metrics allow monitoring the current cluster state when it comes to processing and should allow for good alerting rules: How many workflows are being processed How many jobs are being processed Are there any services in a warning or error state How many events are in the asset manager Here is a complete list of the available Opencast related metrics: # HELP opencast_services_total Number of services in a cluster # TYPE opencast_services_total gauge opencast_services_total{state=\"ERROR\",} 0.0 opencast_services_total{state=\"WARNING\",} 4.0 opencast_services_total{state=\"NORMAL\",} 83.0 # HELP opencast_job_load_current Maximum job load # TYPE opencast_job_load_current gauge opencast_job_load_current{host=\"https://example.opencast.org\",} 3.0 # HELP opencast_workflow_active Active workflows # TYPE opencast_workflow_active gauge opencast_workflow_active{organization=\"mh_default_org\",} 1.0 # HELP opencast_job_load_max Maximum job load # TYPE opencast_job_load_max gauge opencast_job_load_max{host=\"https://example.opencast.org\",} 4.0 # HELP opencast_job_active Active jobs # TYPE opencast_job_active gauge opencast_job_active{host=\"https://example.opencast.org\",organization=\"mh_default_org\",} 4.0 # HELP opencast_version Version of Opencast (based on metrics module) # TYPE opencast_version gauge opencast_version{part=\"major\",} 10.0 opencast_version{part=\"minor\",} 0.0 # HELP requests_total Total requests. # TYPE requests_total counter requests_total 1.0 # HELP opencast_asset_manager_events Events in Asset Manager # TYPE opencast_asset_manager_events gauge opencast_asset_manager_events{organization=\"mh_default_org\",} 1.0 Additionally, standard JVM metrics are exported providing information about e.g. memory and CPU usage, threads, classloading, etc. Here is a complete list of the available JVM metrics with exemplary values: # HELP process_cpu_seconds_total Total user and system CPU time spent in seconds. # TYPE process_cpu_seconds_total counter process_cpu_seconds_total 117.251697 # HELP process_start_time_seconds Start time of the process since unix epoch in seconds. # TYPE process_start_time_seconds gauge process_start_time_seconds 1.623394602475E9 # HELP process_open_fds Number of open file descriptors. # TYPE process_open_fds gauge process_open_fds 627.0 # HELP process_max_fds Maximum number of open file descriptors. # TYPE process_max_fds gauge process_max_fds 10240.0 # HELP jvm_memory_objects_pending_finalization The number of objects waiting in the finalizer queue. # TYPE jvm_memory_objects_pending_finalization gauge jvm_memory_objects_pending_finalization 0.0 # HELP jvm_memory_bytes_used Used bytes of a given JVM memory area. # TYPE jvm_memory_bytes_used gauge jvm_memory_bytes_used{area=\"heap\",} 2.74153448E8 jvm_memory_bytes_used{area=\"nonheap\",} 2.04918736E8 # HELP jvm_memory_bytes_committed Committed (bytes) of a given JVM memory area. # TYPE jvm_memory_bytes_committed gauge jvm_memory_bytes_committed{area=\"heap\",} 4.37256192E8 jvm_memory_bytes_committed{area=\"nonheap\",} 2.25353728E8 # HELP jvm_memory_bytes_max Max (bytes) of a given JVM memory area. # TYPE jvm_memory_bytes_max gauge jvm_memory_bytes_max{area=\"heap\",} 1.073741824E9 jvm_memory_bytes_max{area=\"nonheap\",} -1.0 # HELP jvm_memory_bytes_init Initial bytes of a given JVM memory area. # TYPE jvm_memory_bytes_init gauge jvm_memory_bytes_init{area=\"heap\",} 1.34217728E8 jvm_memory_bytes_init{area=\"nonheap\",} 7667712.0 # HELP jvm_memory_pool_bytes_used Used bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_used gauge jvm_memory_pool_bytes_used{pool=\"CodeHeap 'non-nmethods'\",} 1361536.0 jvm_memory_pool_bytes_used{pool=\"Metaspace\",} 1.36619544E8 jvm_memory_pool_bytes_used{pool=\"CodeHeap 'profiled nmethods'\",} 3.937024E7 jvm_memory_pool_bytes_used{pool=\"Compressed Class Space\",} 1.5748792E7 jvm_memory_pool_bytes_used{pool=\"G1 Eden Space\",} 1.24780544E8 jvm_memory_pool_bytes_used{pool=\"G1 Old Gen\",} 1.31547112E8 jvm_memory_pool_bytes_used{pool=\"G1 Survivor Space\",} 1.7825792E7 jvm_memory_pool_bytes_used{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.1818624E7 # HELP jvm_memory_pool_bytes_committed Committed bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_committed gauge jvm_memory_pool_bytes_committed{pool=\"CodeHeap 'non-nmethods'\",} 2555904.0 jvm_memory_pool_bytes_committed{pool=\"Metaspace\",} 1.51691264E8 jvm_memory_pool_bytes_committed{pool=\"CodeHeap 'profiled nmethods'\",} 3.9452672E7 jvm_memory_pool_bytes_committed{pool=\"Compressed Class Space\",} 1.9791872E7 jvm_memory_pool_bytes_committed{pool=\"G1 Eden Space\",} 2.33832448E8 jvm_memory_pool_bytes_committed{pool=\"G1 Old Gen\",} 1.85597952E8 jvm_memory_pool_bytes_committed{pool=\"G1 Survivor Space\",} 1.7825792E7 jvm_memory_pool_bytes_committed{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.1862016E7 # HELP jvm_memory_pool_bytes_max Max bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_max gauge jvm_memory_pool_bytes_max{pool=\"CodeHeap 'non-nmethods'\",} 5836800.0 jvm_memory_pool_bytes_max{pool=\"Metaspace\",} -1.0 jvm_memory_pool_bytes_max{pool=\"CodeHeap 'profiled nmethods'\",} 1.22908672E8 jvm_memory_pool_bytes_max{pool=\"Compressed Class Space\",} 1.073741824E9 jvm_memory_pool_bytes_max{pool=\"G1 Eden Space\",} -1.0 jvm_memory_pool_bytes_max{pool=\"G1 Old Gen\",} 1.073741824E9 jvm_memory_pool_bytes_max{pool=\"G1 Survivor Space\",} -1.0 jvm_memory_pool_bytes_max{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.22912768E8 # HELP jvm_memory_pool_bytes_init Initial bytes of a given JVM memory pool. # TYPE jvm_memory_pool_bytes_init gauge jvm_memory_pool_bytes_init{pool=\"CodeHeap 'non-nmethods'\",} 2555904.0 jvm_memory_pool_bytes_init{pool=\"Metaspace\",} 0.0 jvm_memory_pool_bytes_init{pool=\"CodeHeap 'profiled nmethods'\",} 2555904.0 jvm_memory_pool_bytes_init{pool=\"Compressed Class Space\",} 0.0 jvm_memory_pool_bytes_init{pool=\"G1 Eden Space\",} 2.7262976E7 jvm_memory_pool_bytes_init{pool=\"G1 Old Gen\",} 1.06954752E8 jvm_memory_pool_bytes_init{pool=\"G1 Survivor Space\",} 0.0 jvm_memory_pool_bytes_init{pool=\"CodeHeap 'non-profiled nmethods'\",} 2555904.0 # HELP jvm_memory_pool_collection_used_bytes Used bytes after last collection of a given JVM memory pool. # TYPE jvm_memory_pool_collection_used_bytes gauge jvm_memory_pool_collection_used_bytes{pool=\"G1 Eden Space\",} 0.0 jvm_memory_pool_collection_used_bytes{pool=\"G1 Old Gen\",} 1.29009136E8 jvm_memory_pool_collection_used_bytes{pool=\"G1 Survivor Space\",} 1.7825792E7 # HELP jvm_memory_pool_collection_committed_bytes Committed after last collection bytes of a given JVM memory pool. # TYPE jvm_memory_pool_collection_committed_bytes gauge jvm_memory_pool_collection_committed_bytes{pool=\"G1 Eden Space\",} 2.33832448E8 jvm_memory_pool_collection_committed_bytes{pool=\"G1 Old Gen\",} 2.21249536E8 jvm_memory_pool_collection_committed_bytes{pool=\"G1 Survivor Space\",} 1.7825792E7 # HELP jvm_memory_pool_collection_max_bytes Max bytes after last collection of a given JVM memory pool. # TYPE jvm_memory_pool_collection_max_bytes gauge jvm_memory_pool_collection_max_bytes{pool=\"G1 Eden Space\",} -1.0 jvm_memory_pool_collection_max_bytes{pool=\"G1 Old Gen\",} 1.073741824E9 jvm_memory_pool_collection_max_bytes{pool=\"G1 Survivor Space\",} -1.0 # HELP jvm_memory_pool_collection_init_bytes Initial after last collection bytes of a given JVM memory pool. # TYPE jvm_memory_pool_collection_init_bytes gauge jvm_memory_pool_collection_init_bytes{pool=\"G1 Eden Space\",} 2.7262976E7 jvm_memory_pool_collection_init_bytes{pool=\"G1 Old Gen\",} 1.06954752E8 jvm_memory_pool_collection_init_bytes{pool=\"G1 Survivor Space\",} 0.0 # HELP jvm_memory_pool_allocated_bytes_created Total bytes allocated in a given JVM memory pool. Only updated after GC, not continuously. # TYPE jvm_memory_pool_allocated_bytes_created gauge jvm_memory_pool_allocated_bytes_created{pool=\"CodeHeap 'profiled nmethods'\",} 1.623394629741E9 jvm_memory_pool_allocated_bytes_created{pool=\"G1 Old Gen\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"G1 Eden Space\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"G1 Survivor Space\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"Compressed Class Space\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"Metaspace\",} 1.623394629746E9 jvm_memory_pool_allocated_bytes_created{pool=\"CodeHeap 'non-nmethods'\",} 1.623394629746E9 # HELP jvm_memory_pool_allocated_bytes_total Total bytes allocated in a given JVM memory pool. Only updated after GC, not continuously. # TYPE jvm_memory_pool_allocated_bytes_total counter jvm_memory_pool_allocated_bytes_total{pool=\"CodeHeap 'profiled nmethods'\",} 3.7028864E7 jvm_memory_pool_allocated_bytes_total{pool=\"G1 Old Gen\",} 1.3262048E8 jvm_memory_pool_allocated_bytes_total{pool=\"G1 Eden Space\",} 8.74512384E8 jvm_memory_pool_allocated_bytes_total{pool=\"CodeHeap 'non-profiled nmethods'\",} 1.145216E7 jvm_memory_pool_allocated_bytes_total{pool=\"G1 Survivor Space\",} 1.8874368E7 jvm_memory_pool_allocated_bytes_total{pool=\"Compressed Class Space\",} 1.4760208E7 jvm_memory_pool_allocated_bytes_total{pool=\"Metaspace\",} 1.28033584E8 jvm_memory_pool_allocated_bytes_total{pool=\"CodeHeap 'non-nmethods'\",} 1340416.0 # HELP jvm_buffer_pool_used_bytes Used bytes of a given JVM buffer pool. # TYPE jvm_buffer_pool_used_bytes gauge jvm_buffer_pool_used_bytes{pool=\"mapped\",} 0.0 jvm_buffer_pool_used_bytes{pool=\"direct\",} 290150.0 # HELP jvm_buffer_pool_capacity_bytes Bytes capacity of a given JVM buffer pool. # TYPE jvm_buffer_pool_capacity_bytes gauge jvm_buffer_pool_capacity_bytes{pool=\"mapped\",} 0.0 jvm_buffer_pool_capacity_bytes{pool=\"direct\",} 290150.0 # HELP jvm_buffer_pool_used_buffers Used buffers of a given JVM buffer pool. # TYPE jvm_buffer_pool_used_buffers gauge jvm_buffer_pool_used_buffers{pool=\"mapped\",} 0.0 jvm_buffer_pool_used_buffers{pool=\"direct\",} 32.0 # HELP jvm_gc_collection_seconds Time spent in a given JVM garbage collector in seconds. # TYPE jvm_gc_collection_seconds summary jvm_gc_collection_seconds_count{gc=\"G1 Young Generation\",} 41.0 jvm_gc_collection_seconds_sum{gc=\"G1 Young Generation\",} 0.447 jvm_gc_collection_seconds_count{gc=\"G1 Old Generation\",} 0.0 jvm_gc_collection_seconds_sum{gc=\"G1 Old Generation\",} 0.0 # HELP jvm_threads_current Current thread count of a JVM # TYPE jvm_threads_current gauge jvm_threads_current 188.0 # HELP jvm_threads_daemon Daemon thread count of a JVM # TYPE jvm_threads_daemon gauge jvm_threads_daemon 73.0 # HELP jvm_threads_peak Peak thread count of a JVM # TYPE jvm_threads_peak gauge jvm_threads_peak 188.0 # HELP jvm_threads_started_total Started thread count of a JVM # TYPE jvm_threads_started_total counter jvm_threads_started_total 211.0 # HELP jvm_threads_deadlocked Cycles of JVM-threads that are in deadlock waiting to acquire object monitors or ownable synchronizers # TYPE jvm_threads_deadlocked gauge jvm_threads_deadlocked 0.0 # HELP jvm_threads_deadlocked_monitor Cycles of JVM-threads that are in deadlock waiting to acquire object monitors # TYPE jvm_threads_deadlocked_monitor gauge jvm_threads_deadlocked_monitor 0.0 # HELP jvm_threads_state Current count of threads by state # TYPE jvm_threads_state gauge jvm_threads_state{state=\"BLOCKED\",} 0.0 jvm_threads_state{state=\"TERMINATED\",} 0.0 jvm_threads_state{state=\"WAITING\",} 54.0 jvm_threads_state{state=\"TIMED_WAITING\",} 78.0 jvm_threads_state{state=\"NEW\",} 0.0 jvm_threads_state{state=\"RUNNABLE\",} 56.0 # HELP jvm_classes_loaded The number of classes that are currently loaded in the JVM # TYPE jvm_classes_loaded gauge jvm_classes_loaded 21570.0 # HELP jvm_classes_loaded_total The total number of classes that have been loaded since the JVM has started execution # TYPE jvm_classes_loaded_total counter jvm_classes_loaded_total 21570.0 # HELP jvm_classes_unloaded_total The total number of classes that have been unloaded since the JVM has started execution # TYPE jvm_classes_unloaded_total counter jvm_classes_unloaded_total 0.0 # HELP jvm_info VM version info # TYPE jvm_info gauge jvm_info{runtime=\"OpenJDK Runtime Environment\",vendor=\"Oracle Corporation\",version=\"11.0.10+9\",} 1.0 A corresponding monitoring mixin for JVM metrics with dashboards and alerting rules can be found at github.com/grafana/jsonnet-libs .","title":"Available Metrics"},{"location":"modules/metrics/#access","text":"By default, you need to be authenticated and have ROLE_ADMIN or ROLE_METRICS to access the endpoint. You can configure this in the security configuration (e.g. etc/security/mh_default.org.xml ). For example, to allow anonymous access set: <sec:intercept-url pattern=\"/metrics\" access=\"ROLE_ANONYMOUS\" />","title":"Access"},{"location":"modules/metrics/#prometheus-configuration","text":"There is nothing special when it comes to the Prometheus configuration: - job_name: opencast scheme: https basic_auth: username: <oc-user> password: <oc-password> static_configs: - targets: - example.opencast.org","title":"Prometheus Configuration"},{"location":"modules/player.configuration/","text":"Opencast Player - Configuration The configurations for the player are done for each tenant. So the configuration keys are located in .../etc/ui-config/<tenant>/theodul/config.yml The default tenant for opencast is mh_default_org Select the Opencast Player To activate the player set in each tenant this line in the file .../etc/org.opencastproject.organization-<tenant>.cfg . prop.player=/paella/ui/watch.html?id=#{id}","title":"Configuration"},{"location":"modules/player.configuration/#opencast-player-configuration","text":"The configurations for the player are done for each tenant. So the configuration keys are located in .../etc/ui-config/<tenant>/theodul/config.yml The default tenant for opencast is mh_default_org","title":"Opencast Player - Configuration"},{"location":"modules/player.configuration/#select-the-opencast-player","text":"To activate the player set in each tenant this line in the file .../etc/org.opencastproject.organization-<tenant>.cfg . prop.player=/paella/ui/watch.html?id=#{id}","title":"Select the Opencast Player"},{"location":"modules/player.matomo.tracking/","text":"Opencast Player - Matomo Tracking Plugin This plugin allows using Matomo to track usage data. To setup Matomo please follow the instructions on the Matomo website: The 5-minute Matomo Installation The plugin respects the Do-Not-Track settings of a browser. Please consider the legal requirements of your country when you set up Matomo. This plugin uses a Matomo JavaScript library that is loaded from the remote Matomo server! Tested Matomo version: 3.0.2+ ; Matomo Analytics Cloud The configurations for the Matomo player plugin are done for each tenant. The configuration keys are located in etc/ui-config/<organization>/theodul/config.yml . To activate the plugin set the Matomo server URL: server: https://matomo.example.com/matomo Configuration server: The Matomo server from which the Piwik JS library will be loaded and where the data will be reported. site_id: 1 The Matomo site ID has to be numeric value. If not set this will be 1. It is recommended to use different site IDs for each tenant that is configured in Opencast. heartbeat: 30 The heartbeat setting to track how long a user stayed on the player page. Set to 0 or comment this line to disable the heartbeat. notification: true The plugin shows a notification about the tracking to the user. This can be disabled with this option. (Default: true ) Before you disable the notification, make sure that you do not violate any local regulations. track_events: [\"play\", \"pause\", \"seek\", \"ended\"] This setting lets you track several player events. Add the events that you want to track to the list. Comment this property to prevent event tracking. Events that can be tracked: play: play has been pressed (will also be called if after seeking). pause: pause has been pressed (will also be called if before seeking). seek: user jumps to a different time. Time in seconds will be stored ended: video has reached the end playbackrate: user changes the playback speed (values 0.75 to 3.00) volume: Volume change by the user value 0.0 to 1.0 quality: manual change of video quality (quality tag is stored) fullscreen: user presses fullscreen button focus: user selects one video to be enlarged (flavor of selected video is stored) layout_reset: user switches back to default layout zoom: user changes the zoom of the video Tracked Data Additional to the event data that can be turned on for each event (see above), this Opencast specific data is tracked if tracking is allowed: Page name as <title of the event> - <lecturer name> Custom Matomo variables: \"event\" as <title of the event> (<event id>) \"series\" as <title of the series> (<series id>) \"presenter\" \"view_mode\" which can be desktop , mobile or embed Heartbeat data does not show how long a video has been played but how long a viewer remained on the page, while the page was in the foreground.","title":"Matomo Tracking"},{"location":"modules/player.matomo.tracking/#opencast-player-matomo-tracking-plugin","text":"This plugin allows using Matomo to track usage data. To setup Matomo please follow the instructions on the Matomo website: The 5-minute Matomo Installation The plugin respects the Do-Not-Track settings of a browser. Please consider the legal requirements of your country when you set up Matomo. This plugin uses a Matomo JavaScript library that is loaded from the remote Matomo server! Tested Matomo version: 3.0.2+ ; Matomo Analytics Cloud The configurations for the Matomo player plugin are done for each tenant. The configuration keys are located in etc/ui-config/<organization>/theodul/config.yml . To activate the plugin set the Matomo server URL: server: https://matomo.example.com/matomo","title":"Opencast Player - Matomo Tracking Plugin"},{"location":"modules/player.matomo.tracking/#configuration","text":"","title":"Configuration"},{"location":"modules/player.matomo.tracking/#server","text":"The Matomo server from which the Piwik JS library will be loaded and where the data will be reported.","title":"server:"},{"location":"modules/player.matomo.tracking/#site_id-1","text":"The Matomo site ID has to be numeric value. If not set this will be 1. It is recommended to use different site IDs for each tenant that is configured in Opencast.","title":"site_id: 1"},{"location":"modules/player.matomo.tracking/#heartbeat-30","text":"The heartbeat setting to track how long a user stayed on the player page. Set to 0 or comment this line to disable the heartbeat.","title":"heartbeat: 30"},{"location":"modules/player.matomo.tracking/#notification-true","text":"The plugin shows a notification about the tracking to the user. This can be disabled with this option. (Default: true ) Before you disable the notification, make sure that you do not violate any local regulations.","title":"notification: true"},{"location":"modules/player.matomo.tracking/#track_events-play-pause-seek-ended","text":"This setting lets you track several player events. Add the events that you want to track to the list. Comment this property to prevent event tracking. Events that can be tracked: play: play has been pressed (will also be called if after seeking). pause: pause has been pressed (will also be called if before seeking). seek: user jumps to a different time. Time in seconds will be stored ended: video has reached the end playbackrate: user changes the playback speed (values 0.75 to 3.00) volume: Volume change by the user value 0.0 to 1.0 quality: manual change of video quality (quality tag is stored) fullscreen: user presses fullscreen button focus: user selects one video to be enlarged (flavor of selected video is stored) layout_reset: user switches back to default layout zoom: user changes the zoom of the video","title":"track_events: [\"play\", \"pause\", \"seek\", \"ended\"]"},{"location":"modules/player.matomo.tracking/#tracked-data","text":"Additional to the event data that can be turned on for each event (see above), this Opencast specific data is tracked if tracking is allowed: Page name as <title of the event> - <lecturer name> Custom Matomo variables: \"event\" as <title of the event> (<event id>) \"series\" as <title of the series> (<series id>) \"presenter\" \"view_mode\" which can be desktop , mobile or embed Heartbeat data does not show how long a video has been played but how long a viewer remained on the page, while the page was in the foreground.","title":"Tracked Data"},{"location":"modules/player.url.parameter/","text":"Opencast Player * URL Parameters URL Parameters time Possible values Minutes (with value X ) and seconds (with value Y ) XmYs YsXm XmY Minutes (with value X ) only Xm Seconds (with value Y ) only Ys Y Default value - Description Seeks initially automatically to a specified time automatically plays the video from the specified time on autoplay Possible values true false Default value false Description Automatically starts playing the video after a short delay quality Possible values low medium high Default value medium Description Sets a video quality if the video has been encoded in multiple qualities mode Possible values desktop embed mobile Default value desktop Description Sets the player mode manually browser Possible values all default Default value default Description If your browser is not supported, try the new player with this flag activated overwrites filtering for supported browsers with parameter set to all Example http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s Developer URL Parameters debug Possible values true false Default value false Description prints debug output to the developer console debugEvents Possible values true false Default value false Description Prints debug output to the developer console when an event occurs format Possible Values hls : Apple HTTP Live Streaming dash : MPEG DASH rtmp : Adobe RTMP (Flash) mp4 : MP4 videos (no streaming) webm : WebM videos (no streaming) audio : audio only (no streaming) default : reset to defaults Default value default Description sets the preferred (streaming) format if not available, the defaults will be selected the value is permanently stored for the browser in the local storage Example http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true","title":"URL Parameters"},{"location":"modules/player.url.parameter/#opencast-player-url-parameters","text":"","title":"Opencast Player * URL Parameters"},{"location":"modules/player.url.parameter/#url-parameters","text":"time Possible values Minutes (with value X ) and seconds (with value Y ) XmYs YsXm XmY Minutes (with value X ) only Xm Seconds (with value Y ) only Ys Y Default value - Description Seeks initially automatically to a specified time automatically plays the video from the specified time on autoplay Possible values true false Default value false Description Automatically starts playing the video after a short delay quality Possible values low medium high Default value medium Description Sets a video quality if the video has been encoded in multiple qualities mode Possible values desktop embed mobile Default value desktop Description Sets the player mode manually browser Possible values all default Default value default Description If your browser is not supported, try the new player with this flag activated overwrites filtering for supported browsers with parameter set to all","title":"URL Parameters"},{"location":"modules/player.url.parameter/#example","text":"http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s","title":"Example"},{"location":"modules/player.url.parameter/#developer-url-parameters","text":"debug Possible values true false Default value false Description prints debug output to the developer console debugEvents Possible values true false Default value false Description Prints debug output to the developer console when an event occurs format Possible Values hls : Apple HTTP Live Streaming dash : MPEG DASH rtmp : Adobe RTMP (Flash) mp4 : MP4 videos (no streaming) webm : WebM videos (no streaming) audio : audio only (no streaming) default : reset to defaults Default value default Description sets the preferred (streaming) format if not available, the defaults will be selected the value is permanently stored for the browser in the local storage","title":"Developer URL Parameters"},{"location":"modules/player.url.parameter/#example_1","text":"http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true","title":"Example"},{"location":"modules/stream-security/","text":"Stream Security Introduction Security usually is a challenging, technically aspects of any software system. However, diving into technical details before understanding the principles of the solution can lead to false assumptions about the level of security in place. Therefore, this section provides a high-level overview of Opencast's stream security functionality. Content Security in Opencast In many settings, some or even all content published by an Opencast installation must not be accessible by everyone. Instead, access should be restricted to those users with corresponding permissions. So, if access control already ensures that each user only has access to the recordings he or she is allowed to see, what does stream security add to the mix? Looking more closely at what it means to serve recordings to a viewer reveals that a distinction needs to be made between: the presentation of the video player, the recording metadata the serving of the video streams, preview images etc. to that player. The former is protected by the engage part of Opencast. The latter may be served by download and streaming servers. Those distribution servers are independent of Opencast and have no knowledge about the current user and its permissions with regard to the requested video asset . To summarize: Opencast is capable of assessing a recording\u2019s access control list and the current user\u2019s permissions to decide if a user is allowed to access the recording\u2019s metadata and the player. External download and streaming servers, serving the actual video files are not aware of these permissions. As a result, nothing prevents an authorized user from passing on the actual video and image URLs to the public, thereby circumventing the restrictions implied on the presentation layer earlier on. Securing the Streams Since the download and streaming servers do not (and should not) have access to security related information about the user, its roles nor its permissions with regard to the media files, there is no way to perform authorization checks the same way Opencast is performing them while serving up recording metadata. The only way to decide if a given request should be served or not is to leave authorization to Opencast and agree on a secure protocol that defines whether a request is meant to be granted by Opencast or not. Stream security solves the problem exactly as described: Each request that is sent to any of the download or streaming servers must contain a validation policy, indicating for how long access should be granted and optionally even from which IP address. Signing of the policy ensures that potential changes to the policy will be detected. On the other end, the server must be enabled to verify the signature and extract the policy to verify whether it should comply with the request or not. What is secured and what is not? Even with Stream security enabled, some loopholes exist where unauthorized viewers might be able to get access to protected resources, even though for a limited time only. The following section describes in detail what is and what is not secured. URL hacking Executive summary: Accessing a resource with an unsigned or incorrectly signed URL is impossible. Resources distributed by Opencast are organized in a file structure that is built upon a resource\u2019s series identifier as well as the identifier of the recording itself. Since those identifiers usually are based on UUIDs , guessing the URL is hard but not impossible. In addition, a malicious user might be getting hold of a valid identifier through network sniffing, social hacking or by other means. With Stream Security enabled, a user cannot access that resource, since the URL for accessing the resource would either be lacking the policy and signature completely or would contain a broken signature due to an identifier mismatch in the policy. It is important to note that, if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible. Revoking access rights Executive summary: Access is revoked once the digital signature expires. If a user has the rights to access a resource, it does not automatically mean that permission has been granted for a lifetime. After a signed URL\u2019s policy has expired, the URL must receive an updated policy and be signed again in order to provide continuous access to the corresponding resource, so in the case of revoked access rights, the user in question will be able to keep access to the resource as long as the initially signed URL is valid. After that, Opencast will not provide a signed URL anymore due to the change in permissions. On the other hand, there is no way to revoke access to that resource for that particular user unless the URL expires. The only way would be to completely remove the resource from the distribution server. It is therefore important to choose reasonable expiration times for signed URLs. Unauthorized sharing of URLs Executive summary: Leaked signed URLs are only accessible for the duration of the validity of the signature. A signed URL shared by an authorized user with a non-authorized third party will expire (as explained above). The expiration time can be set as low as some seconds but will then require even authorized users to obtain newly signed URLs as they continue to access protected content (e.g. the user takes a quick break watching a recording by hitting \u201cpause\u201d, then hits \u201cplay\u201d again to resume). This risk can be lowered further by restricting a resource to a client\u2019s IP address so that it can only be played by someone with the same IP. Downloading or ripping content Executive summary: Content protected by stream security is not protected against unauthorized publication through authorized users. Since stream security does not implement digital rights management (DRM), authorized users may download content while in possession of correctly signed URLs. When that content is republished on systems that are not under the control of the original owner (i.e. are not protected by stream security or any other means), it is publicly available. Most institutions will have a policy in place that legally prevents circumventing protection and sharing of protected media, and as a result, the above scenario will be taxed as piracy. Technical Overview Stream security consists of several components, and each of these components must be installed and configured properly, otherwise the system may not behave as expected. This part of the documentation describes how each of the components need to be installed and holds information on which configuration options are available. Terms For the understanding of this document it is important to have the following terms clearly defined. Policy A policy defines the timeframe and (optionally) from which addresses a specified resource may be accessed. In order to exchange the policy between system components, the involved components must agree on a serialization specification. Signature The signature expresses the validity of a policy. As with the policy, the system\u2019s signature components, must follow a predefined signing algorithm. Only then is it possible to verify if the signature was issued for a specific policy, or if either the signature or the policy was modified. Key Using keys is a common way to protect information that is being shared between two or more systems. In stream security, keys are used to prevent signature forgery. A key consists of an identifier (ID) and a secret value. The keys need to be kept private, otherwise everyone can create signatures and thereby gain unlimited access to all resource protected by that key. Signing Protocol The combination of a policy specification and a signature algorithm forms the signing protocol, where the policy contains the rules to be applied and the signature ensures that the rules remain unaltered. Components that implement the same signing protocol are compatible and can be used in combination. Components A typical signing infrastructure consists of two main components: a signing service and a verification component. While the signing service is used to sign arbitrary URLs, the verification component is located on the distribution servers to protect the resources and only serve requests that have been properly signed. All signing providers and verification components developed by the Opencast community implement the Opencast signing protocol as documented in the developer guide and are therefore compatible. URL Signing Service The URL signing service is designed to support one or more signing implementations called signing providers. With this concept, different signing protocols, and by virtue, different verification components are supported. The resource is presented to each signing provider in turn, where it is either signed or passed on. This process continues until a signature is obtained. Out of the box, Opencast provides the following implementation: Generic Signing Provider : This provider may be used in combination with HTTP servers. It appends the necessary information (policy, signature and key id) to the URL. The URL signing service makes it straightforward to provide additional implementations to handle third party distribution servers URL signatures. This becomes important in situations where files are served by a server that is currently not supported or if files are served by a CDN that implements its own proprietary signing protocol. Verification components In order to take advantage of the signed URLs, a verification component needs to reside on the distribution servers to verify the validity of the signature (i.e. check that the URL has not been altered after it was signed) and then grant or deny access to the resource, based on the policy associated with the URL. In addition to these external verification components there is also an Opencast verification component called the UrlSigningFilter that is used to protect files that Opencast itself provides. Verification components have the option of strict or non-strict checking. Strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If using non-strict checking, only the path to the resource will be considered. So if the request is for a resource at http://httpdserver:8080/the/full/path/video.mp4 , only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. This is useful when using a load balancer so that the requested hostname does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number. Further Information For further technical information like installation instructions, configuration guides, server plugins and the signing specification, please have a look at these documents: Stream Security Configuration & Testing The Opencast Signing Protocol is defined in the subsection Stream Security in the modules section of the developer guide.","title":"Stream Security"},{"location":"modules/stream-security/#stream-security","text":"","title":"Stream Security"},{"location":"modules/stream-security/#introduction","text":"Security usually is a challenging, technically aspects of any software system. However, diving into technical details before understanding the principles of the solution can lead to false assumptions about the level of security in place. Therefore, this section provides a high-level overview of Opencast's stream security functionality.","title":"Introduction"},{"location":"modules/stream-security/#content-security-in-opencast","text":"In many settings, some or even all content published by an Opencast installation must not be accessible by everyone. Instead, access should be restricted to those users with corresponding permissions. So, if access control already ensures that each user only has access to the recordings he or she is allowed to see, what does stream security add to the mix? Looking more closely at what it means to serve recordings to a viewer reveals that a distinction needs to be made between: the presentation of the video player, the recording metadata the serving of the video streams, preview images etc. to that player. The former is protected by the engage part of Opencast. The latter may be served by download and streaming servers. Those distribution servers are independent of Opencast and have no knowledge about the current user and its permissions with regard to the requested video asset . To summarize: Opencast is capable of assessing a recording\u2019s access control list and the current user\u2019s permissions to decide if a user is allowed to access the recording\u2019s metadata and the player. External download and streaming servers, serving the actual video files are not aware of these permissions. As a result, nothing prevents an authorized user from passing on the actual video and image URLs to the public, thereby circumventing the restrictions implied on the presentation layer earlier on.","title":"Content Security in Opencast"},{"location":"modules/stream-security/#securing-the-streams","text":"Since the download and streaming servers do not (and should not) have access to security related information about the user, its roles nor its permissions with regard to the media files, there is no way to perform authorization checks the same way Opencast is performing them while serving up recording metadata. The only way to decide if a given request should be served or not is to leave authorization to Opencast and agree on a secure protocol that defines whether a request is meant to be granted by Opencast or not. Stream security solves the problem exactly as described: Each request that is sent to any of the download or streaming servers must contain a validation policy, indicating for how long access should be granted and optionally even from which IP address. Signing of the policy ensures that potential changes to the policy will be detected. On the other end, the server must be enabled to verify the signature and extract the policy to verify whether it should comply with the request or not.","title":"Securing the Streams"},{"location":"modules/stream-security/#what-is-secured-and-what-is-not","text":"Even with Stream security enabled, some loopholes exist where unauthorized viewers might be able to get access to protected resources, even though for a limited time only. The following section describes in detail what is and what is not secured.","title":"What is secured and what is not?"},{"location":"modules/stream-security/#url-hacking","text":"Executive summary: Accessing a resource with an unsigned or incorrectly signed URL is impossible. Resources distributed by Opencast are organized in a file structure that is built upon a resource\u2019s series identifier as well as the identifier of the recording itself. Since those identifiers usually are based on UUIDs , guessing the URL is hard but not impossible. In addition, a malicious user might be getting hold of a valid identifier through network sniffing, social hacking or by other means. With Stream Security enabled, a user cannot access that resource, since the URL for accessing the resource would either be lacking the policy and signature completely or would contain a broken signature due to an identifier mismatch in the policy. It is important to note that, if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible.","title":"URL hacking"},{"location":"modules/stream-security/#revoking-access-rights","text":"Executive summary: Access is revoked once the digital signature expires. If a user has the rights to access a resource, it does not automatically mean that permission has been granted for a lifetime. After a signed URL\u2019s policy has expired, the URL must receive an updated policy and be signed again in order to provide continuous access to the corresponding resource, so in the case of revoked access rights, the user in question will be able to keep access to the resource as long as the initially signed URL is valid. After that, Opencast will not provide a signed URL anymore due to the change in permissions. On the other hand, there is no way to revoke access to that resource for that particular user unless the URL expires. The only way would be to completely remove the resource from the distribution server. It is therefore important to choose reasonable expiration times for signed URLs.","title":"Revoking access rights"},{"location":"modules/stream-security/#unauthorized-sharing-of-urls","text":"Executive summary: Leaked signed URLs are only accessible for the duration of the validity of the signature. A signed URL shared by an authorized user with a non-authorized third party will expire (as explained above). The expiration time can be set as low as some seconds but will then require even authorized users to obtain newly signed URLs as they continue to access protected content (e.g. the user takes a quick break watching a recording by hitting \u201cpause\u201d, then hits \u201cplay\u201d again to resume). This risk can be lowered further by restricting a resource to a client\u2019s IP address so that it can only be played by someone with the same IP.","title":"Unauthorized sharing of URLs"},{"location":"modules/stream-security/#downloading-or-ripping-content","text":"Executive summary: Content protected by stream security is not protected against unauthorized publication through authorized users. Since stream security does not implement digital rights management (DRM), authorized users may download content while in possession of correctly signed URLs. When that content is republished on systems that are not under the control of the original owner (i.e. are not protected by stream security or any other means), it is publicly available. Most institutions will have a policy in place that legally prevents circumventing protection and sharing of protected media, and as a result, the above scenario will be taxed as piracy.","title":"Downloading or ripping content"},{"location":"modules/stream-security/#technical-overview","text":"Stream security consists of several components, and each of these components must be installed and configured properly, otherwise the system may not behave as expected. This part of the documentation describes how each of the components need to be installed and holds information on which configuration options are available.","title":"Technical Overview"},{"location":"modules/stream-security/#terms","text":"For the understanding of this document it is important to have the following terms clearly defined.","title":"Terms"},{"location":"modules/stream-security/#policy","text":"A policy defines the timeframe and (optionally) from which addresses a specified resource may be accessed. In order to exchange the policy between system components, the involved components must agree on a serialization specification.","title":"Policy"},{"location":"modules/stream-security/#signature","text":"The signature expresses the validity of a policy. As with the policy, the system\u2019s signature components, must follow a predefined signing algorithm. Only then is it possible to verify if the signature was issued for a specific policy, or if either the signature or the policy was modified.","title":"Signature"},{"location":"modules/stream-security/#key","text":"Using keys is a common way to protect information that is being shared between two or more systems. In stream security, keys are used to prevent signature forgery. A key consists of an identifier (ID) and a secret value. The keys need to be kept private, otherwise everyone can create signatures and thereby gain unlimited access to all resource protected by that key.","title":"Key"},{"location":"modules/stream-security/#signing-protocol","text":"The combination of a policy specification and a signature algorithm forms the signing protocol, where the policy contains the rules to be applied and the signature ensures that the rules remain unaltered. Components that implement the same signing protocol are compatible and can be used in combination.","title":"Signing Protocol"},{"location":"modules/stream-security/#components","text":"A typical signing infrastructure consists of two main components: a signing service and a verification component. While the signing service is used to sign arbitrary URLs, the verification component is located on the distribution servers to protect the resources and only serve requests that have been properly signed. All signing providers and verification components developed by the Opencast community implement the Opencast signing protocol as documented in the developer guide and are therefore compatible.","title":"Components"},{"location":"modules/stream-security/#url-signing-service","text":"The URL signing service is designed to support one or more signing implementations called signing providers. With this concept, different signing protocols, and by virtue, different verification components are supported. The resource is presented to each signing provider in turn, where it is either signed or passed on. This process continues until a signature is obtained. Out of the box, Opencast provides the following implementation: Generic Signing Provider : This provider may be used in combination with HTTP servers. It appends the necessary information (policy, signature and key id) to the URL. The URL signing service makes it straightforward to provide additional implementations to handle third party distribution servers URL signatures. This becomes important in situations where files are served by a server that is currently not supported or if files are served by a CDN that implements its own proprietary signing protocol.","title":"URL Signing Service"},{"location":"modules/stream-security/#verification-components","text":"In order to take advantage of the signed URLs, a verification component needs to reside on the distribution servers to verify the validity of the signature (i.e. check that the URL has not been altered after it was signed) and then grant or deny access to the resource, based on the policy associated with the URL. In addition to these external verification components there is also an Opencast verification component called the UrlSigningFilter that is used to protect files that Opencast itself provides. Verification components have the option of strict or non-strict checking. Strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If using non-strict checking, only the path to the resource will be considered. So if the request is for a resource at http://httpdserver:8080/the/full/path/video.mp4 , only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. This is useful when using a load balancer so that the requested hostname does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number.","title":"Verification components"},{"location":"modules/stream-security/#further-information","text":"For further technical information like installation instructions, configuration guides, server plugins and the signing specification, please have a look at these documents: Stream Security Configuration & Testing The Opencast Signing Protocol is defined in the subsection Stream Security in the modules section of the developer guide.","title":"Further Information"},{"location":"modules/streaming-wowza/","text":"Wowza Streaming Distribution Service The distribution-service-streaming-wowza module copies the media files to the Wowza application directory and generates a SMIL file containing the paths to those files, grouping those with the same flavor but different qualities. Then, for each configured streaming protocol, it generates the adequate entries in the MediaPackage and sets the necessary URLs and MIME-Types automatically. The protocols supported and the transport format they use are summarized below: HTTP(S)-based protocols, corresponding to the modern Streaming Formats HLS: (Live) Streaming from Apple HDS: Dynamic Streaming from Adobe DASH: MPEG-DASH Dynamic Adaptive Streaming SMOOTH: Microsoft's Smooth Streaming Please note : Only the protocols HLS and DASH (with and without SSL) have been thoroughly tested. Requirements A Wowza Streaming Engine version >= 4.0 is required. Please pay special attention to the instructions re. cross-domain access. Directory Structure The structure how this module stores the SMIL and media files is important to understand how the Wowza server must be configured to properly work with Opencast. This structure always follows the same pattern: ${org.opencastproject.streaming.directory}/<organization-id>/<channel-id>/<mediapackage-id>/<element-id>/<filename> , where: ${org.opencastproject.streaming.directory} is this module's root directory, as configured in Opencast's configuration (see below) <organization-id> is the identifier for the current organization (by default mh-default-org ) <channel-id> is the channel identifier. Normally, the Workflow Operation determines the value of this parameter; for instance, the operation publish-engage calls the Streaming Service with a hardcoded value for this property of engage-player <mediapackage-id> , <element-id> and <filename> are different for each MediaPackageElement that this module distributes. The organization ID is automatically assigned based on the server's DNS name ( more info ). Each organization (or tenant ) is independent from the others defined in the system. For the media distribution, that means that each organization's media content is stored in separate directories, so the streaming applications should also be different, as we will see below. Configuration Edit the file etc/org.opencastproject.distribution.streaming.wowza.WowzaStreamingDistributionService.cfg and adjust the values to match those of your scenario. Most important are: org.opencastproject.<tenant>.wowza.url=http(s)://<wowza-server>/<wowza-application> org.opencastproject.<tenant>.wowza.port=<port_number> The port numbers are only necessary when non-standard ports are used. In most cases, it is safe to comment them out or simply not include those properties in the file. Not defining the streaming url for a tenant will result in streams not being published for this tenant. Set the streaming directory in $KARAF/etc/custom.properties : org.opencastproject.streaming.directory=/mnt/opencast-drive/content/streams Restart your Opencast server. Installation on the Wowza side Pre-requirements Download/Purchase the Wowza Streaming Engine from the Wowza Homepage and install it according to their manuals. The shared drive indicated in the org.opencastproject.streaming.directory in the custom.properties file in Opencast must also be mounted in the Wowza server. Please note that mount points do not necessarily match! (e.g. the path /mnt/opencast-drive-content-streams in the Opencast server might be mounted as /media/opencast-streams in the Wowza server). Do not forget to open your firewall on ports 80 (HTTP) and, if you want to use SSL, 443. You will have set your login credentials during the setup of Wowza. You will need these for the web UI. Open http://<wowza-server>:8088/enginemanager and log in Select \"Application -> Add Application\" in the top menu Select \"VOD Single Server\" Enter a name for the new application. You must use the same application name you have configured in $KARAF/etc/custom.properties (for instance: opencast-engage ) Application Description : Feel free to add a description. Playback Types : Enable your desired streaming protocols Options : Disable the global CORS Content Directory : Mark the checkbox Use the following directory . The directory you should input is a subdirectory of the path indicated in the property org.opencastproject.streaming.directory defined in the file $KARAF/etc/custom.properties . That subdirectory's name is the organization's ID ( mh_default_org by default). For instance, if the org.opencastproject.streaming.directory is mounted in the Wowza Server as: /mnt/opencast-streams then the Content Directory for the default organization would be: /mnt/opencast-streams/mh_default_org In a multitenant Opencast setup, an organization with ID my_organization should have the Content Directory set to: /mnt/opencast-streams/my_organization Optional Settings Opencast HTML5 Player is able to play videos from Wowza using adaptive streaming protocols. However, some browsers may experiment problems due to cross-domain issues, which means that we need to instruct Wowza to include the right Allow-Origin headers in its HTTP requests. On the other hand, you may experiment problems with the MPEG-DASH protocol, depending on the encoding of the video sources. All this can be configured in the \"Options\" section of the Wowza application: Click on the tab \"Properties\" in your application If you can't see the \"Properties\" tab, go to \"Users\" > \"Edit\" > \"Preferences\" and select \"Allow access to advanced properties and features\" Scroll down the page to \"Custom\" Click the \"Edit\" button Add the following Properties Path Name Type Value /Root/Application/HTTPStreamer cupertinoUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashAdjustCTTSForFirstKeyFrameToZero Boolean true Due to some limitations in Bitbucket's Markdown parser, we can write this value within a table because it contains a \"pipe\" symbol (\"|\"). The correct value for this property is: Access-Control-Allow-Origin: *|Access-Control-Allow-Methods:GET, HEAD, OPTIONS Do not forget to restart the application! Players and Formats Theodul : HLS, DASH (over HTTP and HTTPS) Paella : HLS, DASH (over HTTP and HTTPS) Encoding Profiles Keep in mind that you have to adapt your encoding profiles when you want generate the videos to distribute via HLS or DASH. Specifically, if the videos with different qualities are not keyframe-aligned, they may not play smoothly or not play at all. You can find more information here . Limitations This module is able to correctly distribute new elements incrementally. That means that if some elements in a mediapackage are already distributed when another Distribute operation runs, the operation should run without errors. However, partial Retract operations are discouraged and cause the remaining elements to be no longer playable. The recommended procedure to retract only some elements in a mediapackage is therefore: Completely retract the mediapackage Distribute again only the desired elements The effects of this limitation are small, because the retract-engage workflow operation always retracts the whole Mediapackage and because partial retractions seem to have little to no practical application. These can however be performed by calling the corresponding REST endpoints. In such cases, users are encouraged to use the recommended method above.","title":"Wowza Streaming Distribution Service"},{"location":"modules/streaming-wowza/#wowza-streaming-distribution-service","text":"The distribution-service-streaming-wowza module copies the media files to the Wowza application directory and generates a SMIL file containing the paths to those files, grouping those with the same flavor but different qualities. Then, for each configured streaming protocol, it generates the adequate entries in the MediaPackage and sets the necessary URLs and MIME-Types automatically. The protocols supported and the transport format they use are summarized below: HTTP(S)-based protocols, corresponding to the modern Streaming Formats HLS: (Live) Streaming from Apple HDS: Dynamic Streaming from Adobe DASH: MPEG-DASH Dynamic Adaptive Streaming SMOOTH: Microsoft's Smooth Streaming Please note : Only the protocols HLS and DASH (with and without SSL) have been thoroughly tested.","title":"Wowza Streaming Distribution Service"},{"location":"modules/streaming-wowza/#requirements","text":"A Wowza Streaming Engine version >= 4.0 is required. Please pay special attention to the instructions re. cross-domain access.","title":"Requirements"},{"location":"modules/streaming-wowza/#directory-structure","text":"The structure how this module stores the SMIL and media files is important to understand how the Wowza server must be configured to properly work with Opencast. This structure always follows the same pattern: ${org.opencastproject.streaming.directory}/<organization-id>/<channel-id>/<mediapackage-id>/<element-id>/<filename> , where: ${org.opencastproject.streaming.directory} is this module's root directory, as configured in Opencast's configuration (see below) <organization-id> is the identifier for the current organization (by default mh-default-org ) <channel-id> is the channel identifier. Normally, the Workflow Operation determines the value of this parameter; for instance, the operation publish-engage calls the Streaming Service with a hardcoded value for this property of engage-player <mediapackage-id> , <element-id> and <filename> are different for each MediaPackageElement that this module distributes. The organization ID is automatically assigned based on the server's DNS name ( more info ). Each organization (or tenant ) is independent from the others defined in the system. For the media distribution, that means that each organization's media content is stored in separate directories, so the streaming applications should also be different, as we will see below.","title":"Directory Structure"},{"location":"modules/streaming-wowza/#configuration","text":"Edit the file etc/org.opencastproject.distribution.streaming.wowza.WowzaStreamingDistributionService.cfg and adjust the values to match those of your scenario. Most important are: org.opencastproject.<tenant>.wowza.url=http(s)://<wowza-server>/<wowza-application> org.opencastproject.<tenant>.wowza.port=<port_number> The port numbers are only necessary when non-standard ports are used. In most cases, it is safe to comment them out or simply not include those properties in the file. Not defining the streaming url for a tenant will result in streams not being published for this tenant. Set the streaming directory in $KARAF/etc/custom.properties : org.opencastproject.streaming.directory=/mnt/opencast-drive/content/streams Restart your Opencast server.","title":"Configuration"},{"location":"modules/streaming-wowza/#installation-on-the-wowza-side","text":"","title":"Installation on the Wowza side"},{"location":"modules/streaming-wowza/#pre-requirements","text":"Download/Purchase the Wowza Streaming Engine from the Wowza Homepage and install it according to their manuals. The shared drive indicated in the org.opencastproject.streaming.directory in the custom.properties file in Opencast must also be mounted in the Wowza server. Please note that mount points do not necessarily match! (e.g. the path /mnt/opencast-drive-content-streams in the Opencast server might be mounted as /media/opencast-streams in the Wowza server). Do not forget to open your firewall on ports 80 (HTTP) and, if you want to use SSL, 443. You will have set your login credentials during the setup of Wowza. You will need these for the web UI. Open http://<wowza-server>:8088/enginemanager and log in Select \"Application -> Add Application\" in the top menu Select \"VOD Single Server\" Enter a name for the new application. You must use the same application name you have configured in $KARAF/etc/custom.properties (for instance: opencast-engage ) Application Description : Feel free to add a description. Playback Types : Enable your desired streaming protocols Options : Disable the global CORS Content Directory : Mark the checkbox Use the following directory . The directory you should input is a subdirectory of the path indicated in the property org.opencastproject.streaming.directory defined in the file $KARAF/etc/custom.properties . That subdirectory's name is the organization's ID ( mh_default_org by default). For instance, if the org.opencastproject.streaming.directory is mounted in the Wowza Server as: /mnt/opencast-streams then the Content Directory for the default organization would be: /mnt/opencast-streams/mh_default_org In a multitenant Opencast setup, an organization with ID my_organization should have the Content Directory set to: /mnt/opencast-streams/my_organization","title":"Pre-requirements"},{"location":"modules/streaming-wowza/#optional-settings","text":"Opencast HTML5 Player is able to play videos from Wowza using adaptive streaming protocols. However, some browsers may experiment problems due to cross-domain issues, which means that we need to instruct Wowza to include the right Allow-Origin headers in its HTTP requests. On the other hand, you may experiment problems with the MPEG-DASH protocol, depending on the encoding of the video sources. All this can be configured in the \"Options\" section of the Wowza application: Click on the tab \"Properties\" in your application If you can't see the \"Properties\" tab, go to \"Users\" > \"Edit\" > \"Preferences\" and select \"Allow access to advanced properties and features\" Scroll down the page to \"Custom\" Click the \"Edit\" button Add the following Properties Path Name Type Value /Root/Application/HTTPStreamer cupertinoUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashAdjustCTTSForFirstKeyFrameToZero Boolean true Due to some limitations in Bitbucket's Markdown parser, we can write this value within a table because it contains a \"pipe\" symbol (\"|\"). The correct value for this property is: Access-Control-Allow-Origin: *|Access-Control-Allow-Methods:GET, HEAD, OPTIONS Do not forget to restart the application!","title":"Optional Settings"},{"location":"modules/streaming-wowza/#players-and-formats","text":"Theodul : HLS, DASH (over HTTP and HTTPS) Paella : HLS, DASH (over HTTP and HTTPS)","title":"Players and Formats"},{"location":"modules/streaming-wowza/#encoding-profiles","text":"Keep in mind that you have to adapt your encoding profiles when you want generate the videos to distribute via HLS or DASH. Specifically, if the videos with different qualities are not keyframe-aligned, they may not play smoothly or not play at all. You can find more information here .","title":"Encoding Profiles"},{"location":"modules/streaming-wowza/#limitations","text":"This module is able to correctly distribute new elements incrementally. That means that if some elements in a mediapackage are already distributed when another Distribute operation runs, the operation should run without errors. However, partial Retract operations are discouraged and cause the remaining elements to be no longer playable. The recommended procedure to retract only some elements in a mediapackage is therefore: Completely retract the mediapackage Distribute again only the desired elements The effects of this limitation are small, because the retract-engage workflow operation always retracts the whole Mediapackage and because partial retractions seem to have little to no practical application. These can however be performed by calling the corresponding REST endpoints. In such cases, users are encouraged to use the recommended method above.","title":"Limitations"},{"location":"modules/studio/","text":"Opencast Studio Studio is a small web application that runs in the browser and allows the user to record webcam video, the user's display and microphone audio. Afterwards, the user can easily upload their recording to an Opencast instance. Studio uses the recording capabilities built into modern browsers to record audio and video streams. The recording happens completely in the user's browser: no server is involved in that part. Network access is only needed to initially load the application and to (optionally) upload the videos to an Opencast instance. This module includes Studio directly into Opencast and pre-configures it accordingly. It is available at https://yourserver/studio . Note: Studio is developed outside of the main repository : you can find additional documentation in that repository. Please also report bugs and feature requests for Studio to that repository, unless it's a bug related to the integration in Opencast. Giving users access to Studio The path /studio is accessible by users with the role ROLE_ADMIN or ROLE_STUDIO . The APIs used by Studio ( /ingest/* and info/me.json ) are also accessible if the user has ROLE_STUDIO . The preferred way to let your users access Studio is via LTI. Remember to configure your LTI users to have the role ROLE_STUDIO so that they can access Studio and all APIs used by Studio. Configuring Studio Studio is pre-configured via etc/ui-config/mh_default_org/studio/settings.toml . You can modify that file to change the configuration, but note that you probably don't want to touch opencast.serverUrl and opencast.loginProvided . For information on possible configuration values, please see CONFIGURATION.md in the Studio repository . Workflow requirements The videos produced by the built-in recording capabilities of browsers are often quite exotic, to put it mildly. The Opencast workflow responsible for processing uploads from Studio needs to be able to handle the following things: Variable framerate . If your workflow produces 1000fps videos, it's probably because it can't handle variable framerate. The standard solution would be to re-encode at a fixed and common framerate. Missing duration and seeking data . Videos produced by Chrome and Edge do not store the video duration in the container. Furthermore, they don't contain any seeking cues, so that some operations can't be done quickly. Variable video dimensions . This can happen when someone records from a phone and rotates it by 90\u00b0, making width and height of the video swap. Another common case is browsers capturing a single window/application on the user's desktop. When that window is resized, the video dimensions change, too. Very long frames . If the user's device is very slow and can't keep up with encoding, the frame rate might be very low. A more extreme example is the \"capture tab\" feature of Chrome. In that case, Chrome records all the frames produced by its rendering engine \u2013 if the website displayed in the selected tab is static and the user does not scroll, no new frames are created, potentially for minutes! Additionally, for the video cutting in Studio to work, your workflow needs to respect the SMIL catalog Studio includes in the ingest. The default Studio workflow can handle all those things. Finally, here are some other oddities and details of videos produced by browsers: Most browsers will default to VP8 as video codec, OPUS as audio codec and WEBM (or the superset MKV) as container. Desktop capture seem to happen with 30fps in Chrome and Firefox (tested on a 60hz monitor). In some cases, Firefox encodes all frames as key-frames, which \u2013 given the fixed bitrate \u2013 often results in a fairly low quality video.","title":"Studio"},{"location":"modules/studio/#opencast-studio","text":"Studio is a small web application that runs in the browser and allows the user to record webcam video, the user's display and microphone audio. Afterwards, the user can easily upload their recording to an Opencast instance. Studio uses the recording capabilities built into modern browsers to record audio and video streams. The recording happens completely in the user's browser: no server is involved in that part. Network access is only needed to initially load the application and to (optionally) upload the videos to an Opencast instance. This module includes Studio directly into Opencast and pre-configures it accordingly. It is available at https://yourserver/studio . Note: Studio is developed outside of the main repository : you can find additional documentation in that repository. Please also report bugs and feature requests for Studio to that repository, unless it's a bug related to the integration in Opencast.","title":"Opencast Studio"},{"location":"modules/studio/#giving-users-access-to-studio","text":"The path /studio is accessible by users with the role ROLE_ADMIN or ROLE_STUDIO . The APIs used by Studio ( /ingest/* and info/me.json ) are also accessible if the user has ROLE_STUDIO . The preferred way to let your users access Studio is via LTI. Remember to configure your LTI users to have the role ROLE_STUDIO so that they can access Studio and all APIs used by Studio.","title":"Giving users access to Studio"},{"location":"modules/studio/#configuring-studio","text":"Studio is pre-configured via etc/ui-config/mh_default_org/studio/settings.toml . You can modify that file to change the configuration, but note that you probably don't want to touch opencast.serverUrl and opencast.loginProvided . For information on possible configuration values, please see CONFIGURATION.md in the Studio repository .","title":"Configuring Studio"},{"location":"modules/studio/#workflow-requirements","text":"The videos produced by the built-in recording capabilities of browsers are often quite exotic, to put it mildly. The Opencast workflow responsible for processing uploads from Studio needs to be able to handle the following things: Variable framerate . If your workflow produces 1000fps videos, it's probably because it can't handle variable framerate. The standard solution would be to re-encode at a fixed and common framerate. Missing duration and seeking data . Videos produced by Chrome and Edge do not store the video duration in the container. Furthermore, they don't contain any seeking cues, so that some operations can't be done quickly. Variable video dimensions . This can happen when someone records from a phone and rotates it by 90\u00b0, making width and height of the video swap. Another common case is browsers capturing a single window/application on the user's desktop. When that window is resized, the video dimensions change, too. Very long frames . If the user's device is very slow and can't keep up with encoding, the frame rate might be very low. A more extreme example is the \"capture tab\" feature of Chrome. In that case, Chrome records all the frames produced by its rendering engine \u2013 if the website displayed in the selected tab is static and the user does not scroll, no new frames are created, potentially for minutes! Additionally, for the video cutting in Studio to work, your workflow needs to respect the SMIL catalog Studio includes in the ingest. The default Studio workflow can handle all those things. Finally, here are some other oddities and details of videos produced by browsers: Most browsers will default to VP8 as video codec, OPUS as audio codec and WEBM (or the superset MKV) as container. Desktop capture seem to happen with 30fps in Chrome and Firefox (tested on a 60hz monitor). In some cases, Firefox encodes all frames as key-frames, which \u2013 given the fixed bitrate \u2013 often results in a fairly low quality video.","title":"Workflow requirements"},{"location":"modules/terminationstate.aws.autoscaling/","text":"AWS Auto-Scaling Termination State Service This page documents the configuration for Opencast module terminationstate-aws . This configuration is only required on nodes that are part of an AWS Auto Scaling group. The purpose of this module to manage the termination of an AWS EC2 instance, triggered when an Auto Scaling Group \"scales in\", as the Opencast process may still be processing jobs which we want to complete. This is special implementation of the basic Termination State Service It does not terminate the Opencast process or the instance itself . Auto Scaling Groups can trigger a Lifecycle Hook when an instance is created or terminated which allow events to occur before the creation or termination is completed. The service can poll if the termination hook has been triggered, at which point it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs and if so emit a heartbeat when no jobs are running it will tell the Auto Scaling group to complete the Terminate life-cycle action Alternatively you can disable the Lifecycle state polling and call the REST endpoint (termination/aws/autoscaling) to signal that the instance is now terminating. The details of how to achieve this are beyond the scope of this document, but using a CloudWatch Alarm to trigger a Lambda function is a suggested route. Amazon User Configuration Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) The termination state service requires a number of permissions to query and respond to changes in the instance's lifecycle. You should follow these instructions to create a new policy that is assigned to the IAM profile or user account. The following policy contains all the necessary permissions. You will need to change the region and account number in the Resource ARN with your own. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"ReadInstanceLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:DescribeAutoScalingInstances\", \"autoscaling:DescribeAutoScalingGroups\", \"autoscaling:DescribeLifecycleHooks\" ], \"Resource\": \"*\" }, { \"Sid\": \"UpdateLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:CompleteLifecycleAction\", \"autoscaling:RecordLifecycleActionHeartbeat\" ], \"Resource\": \"arn:aws:autoscaling:<region>:<account>:autoScalingGroup:*:autoScalingGroupName/*\" } ] } A free Amazon account will work for small scale testing, but be aware that AutoScaling can incur costs if not correctly setup. Amazon AutoScaling Configuration Please consult the AWS documentation to create an AutoScaling Group . You will need to explicitly add a Lifecycle Hook for the \"autoscaling:EC2_INSTANCE_TERMINATING\" Lifecycle transition. The 'Heartbeat Timeout' should be set to something appropriate. The default 3600 seconds is fine for production but quite long when developing your deployment. NOTE: the service will tell the AutoScaling Group to complete termination even if the timeout hasn't expired once there are no jobs running. Opencast Service Configuration The Opencast AWS Autoscaling Termination State Service configuration can be found in the file org.opencastproject.terminationstate.aws.AutoScalingTerminationStateService.cfg . Key name Value Example enable true to enable the service, false (default) otherwise true lifecycle.polling.enabled true to poll the Lifecycle for the termination state true lifecycle.polling.period frequency which to poll the Lifecycle in seconds 300 lifecycle.heartbeat.period frequency which to check if if jobs are running and emit Lifecycle heartbeat 300 access.id AWS user's access ID 20 alphanumeric characters access.secret AWS user's secret key 40 characters If access.id and access.secret are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain . NOTE : both the lifecycle.polling.period and lifecycle.heartbeat.period should be less than the 'Heartbeat Timeout' of the Lifecycle Hook or else the instance could be terminated before the service can respond.","title":"AWS AutoScaling"},{"location":"modules/terminationstate.aws.autoscaling/#aws-auto-scaling-termination-state-service","text":"This page documents the configuration for Opencast module terminationstate-aws . This configuration is only required on nodes that are part of an AWS Auto Scaling group. The purpose of this module to manage the termination of an AWS EC2 instance, triggered when an Auto Scaling Group \"scales in\", as the Opencast process may still be processing jobs which we want to complete. This is special implementation of the basic Termination State Service It does not terminate the Opencast process or the instance itself . Auto Scaling Groups can trigger a Lifecycle Hook when an instance is created or terminated which allow events to occur before the creation or termination is completed. The service can poll if the termination hook has been triggered, at which point it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs and if so emit a heartbeat when no jobs are running it will tell the Auto Scaling group to complete the Terminate life-cycle action Alternatively you can disable the Lifecycle state polling and call the REST endpoint (termination/aws/autoscaling) to signal that the instance is now terminating. The details of how to achieve this are beyond the scope of this document, but using a CloudWatch Alarm to trigger a Lambda function is a suggested route.","title":"AWS Auto-Scaling Termination State Service"},{"location":"modules/terminationstate.aws.autoscaling/#amazon-user-configuration","text":"Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) The termination state service requires a number of permissions to query and respond to changes in the instance's lifecycle. You should follow these instructions to create a new policy that is assigned to the IAM profile or user account. The following policy contains all the necessary permissions. You will need to change the region and account number in the Resource ARN with your own. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"ReadInstanceLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:DescribeAutoScalingInstances\", \"autoscaling:DescribeAutoScalingGroups\", \"autoscaling:DescribeLifecycleHooks\" ], \"Resource\": \"*\" }, { \"Sid\": \"UpdateLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:CompleteLifecycleAction\", \"autoscaling:RecordLifecycleActionHeartbeat\" ], \"Resource\": \"arn:aws:autoscaling:<region>:<account>:autoScalingGroup:*:autoScalingGroupName/*\" } ] } A free Amazon account will work for small scale testing, but be aware that AutoScaling can incur costs if not correctly setup.","title":"Amazon User Configuration"},{"location":"modules/terminationstate.aws.autoscaling/#amazon-autoscaling-configuration","text":"Please consult the AWS documentation to create an AutoScaling Group . You will need to explicitly add a Lifecycle Hook for the \"autoscaling:EC2_INSTANCE_TERMINATING\" Lifecycle transition. The 'Heartbeat Timeout' should be set to something appropriate. The default 3600 seconds is fine for production but quite long when developing your deployment. NOTE: the service will tell the AutoScaling Group to complete termination even if the timeout hasn't expired once there are no jobs running.","title":"Amazon AutoScaling Configuration"},{"location":"modules/terminationstate.aws.autoscaling/#opencast-service-configuration","text":"The Opencast AWS Autoscaling Termination State Service configuration can be found in the file org.opencastproject.terminationstate.aws.AutoScalingTerminationStateService.cfg . Key name Value Example enable true to enable the service, false (default) otherwise true lifecycle.polling.enabled true to poll the Lifecycle for the termination state true lifecycle.polling.period frequency which to poll the Lifecycle in seconds 300 lifecycle.heartbeat.period frequency which to check if if jobs are running and emit Lifecycle heartbeat 300 access.id AWS user's access ID 20 alphanumeric characters access.secret AWS user's secret key 40 characters If access.id and access.secret are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain . NOTE : both the lifecycle.polling.period and lifecycle.heartbeat.period should be less than the 'Heartbeat Timeout' of the Lifecycle Hook or else the instance could be terminated before the service can respond.","title":"Opencast Service Configuration"},{"location":"modules/terminationstate/","text":"Termination State Service This page documents the configuration for Opencast module terminationstate-impl . This module is provided as a convenience when you wish to terminate the Opencast process or the machine it is running on, when Opencast may still be processing jobs you want to complete. It also forms the basis for more sophisticated services that assist the dynamic scaling of nodes in cloud environments, see AWS AutoScaling: Termination State Service It does not terminate the Opencast process or the instance itself . The default termination state is \"none\". If the termination state is set to \"wait\" it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs when no jobs are running it will set the termination state to \"ready\" The termination state can then be monitored and the action completed when the state is changes from \"wait\" to \"ready\". Opencast Service Configuration The Opencast Termination State Service configuration can be found in the file org.opencastproject.terminationstate.impl.TerminationStateServiceImpl.cfg . Key name Value Example job.polling.period frequency which to check if jobs are running in seconds 300","title":"Basic"},{"location":"modules/terminationstate/#termination-state-service","text":"This page documents the configuration for Opencast module terminationstate-impl . This module is provided as a convenience when you wish to terminate the Opencast process or the machine it is running on, when Opencast may still be processing jobs you want to complete. It also forms the basis for more sophisticated services that assist the dynamic scaling of nodes in cloud environments, see AWS AutoScaling: Termination State Service It does not terminate the Opencast process or the instance itself . The default termination state is \"none\". If the termination state is set to \"wait\" it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs when no jobs are running it will set the termination state to \"ready\" The termination state can then be monitored and the action completed when the state is changes from \"wait\" to \"ready\".","title":"Termination State Service"},{"location":"modules/terminationstate/#opencast-service-configuration","text":"The Opencast Termination State Service configuration can be found in the file org.opencastproject.terminationstate.impl.TerminationStateServiceImpl.cfg . Key name Value Example job.polling.period frequency which to check if jobs are running in seconds 300","title":"Opencast Service Configuration"},{"location":"modules/textextraction/","text":"Text Extraction Configuration How the text extraction process works The sequence of the Opencast services used during slide detection and text extraction is the following: -----> Segmentation -----> TextAnalyzerService -----------------> / \\ / \\ TextExtractor DictionaryService (OCR with Tesseract) (Filter extracted texts) The segmentation will define the frames which are passed to the text analyzer. For extraction, a frame from the end of a segment is used to make sure that most of a slides text is visible. The frame is then exported as image and passed to the text extraction service which calls an OCR engine to get the text output. For this, the Tesseract OCR engine is used by default. After the text extraction is done, the analysis service will pass the recognized text to the dictionary service which may filter it to remove messed up words, unknown words, single characters or other things depending on the actual implementation and configuration. Finally, the extracted text is attached to the media package as MPEG 7 XML and the Opencast workflow continues. Configuration This section describes the configuration of all involved tools and services. In this guide, German is used as target language but the configuration for other languages should be similar. If necessary, important differences will be pointed out. OCR Engine: Tesseract Tesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an output file. The command line arguments for this will be handled by Opencast. But apart from these mandatory ones, it is possible to pass additional arguments to Tesseract, defining the internally used dictionary, box files and the layout analysis. For example, if you want OCR for German content, you want to run something like this: tesseract in.tif out.txt -l deu --psm 3 The arguments in.tif and out.txt are automatically set by Opencast. The argument -l specifies the language files used by Tesseract. deu specifies the German language. Multiple languages may be specified, separated by plus characters. Please make sure that you have installed the language packs you want to use on every worker (E.g. yum install tesseract-langpack-deu ). Finally --psm 3 specifies the layout analysis for Tesseract. The value 3 means Fully automatic page segmentation, but no orientation and script detection which is actually the default. Hence in this case, the argument could simply be omitted. If you know more about your input videos, you might want to use different options here (not likely). This option might be just -psm with only one dash in your system. In Opencast, you can modify this options in the custom.properties file by setting the following option: org.opencastproject.textanalyzer.tesseract.options=-l deu --psm 3 It is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and only this will enable the recognition of special characters specific to your local language. If you supply a reference to a list of additional words using --user-words , the path to that file must not be enclosed in quotation marks. Newer versions of Tesseract come with additional neural nets LSTM. Its performance might be significantly different from the previous Tesseract engine. Its usage might be specified using --oem N with N being a number documented in your Tesseract manual. Encoding (Image Preprocessing) The text extraction works best if there is a high contrast between text and background and additionally, the text is not too thin. Ideally, this means that you have black and white images with a clear, bold font. At this point, it is probably worth noting that despite what is often said and could also be found in the old documentation for Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted (white on black). Because of the way Tesseract works, that does not matter. A lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is why, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included directly into the image extraction step using FFmpeg. For this, edit the /etc/opencast/encoding/opencast-images.properties and modify the command for the image extraction: profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path} \\ -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1 \\ -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix} This profile will create a gray, high contrast image. The additional light blur will reduce or remove noise and thicken the normal letters. The kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your material are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel mixer. DictionaryService (Filtering) The filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for. For searching, you might want a higher degree of filtering, for users you might also want to present text with slight errors, for testing and debugging, you want no filtering at all. Starting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just swapped out at any time: dictionary-none dictionary-regexp (default) dictionary-hunspell No Filtering (dictionary-none) The dictionary-none module is the simplest one. It will just let the recognized texts pass through unmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one. Using a Regular Expression (dictionary-regexp) Starting with 1.6, this is the default implementation for the DictionaryService. It is limited in terms of filtering capabilities as it will not check if a recognized word actually makes sense. Here is how this service works: If configured with a valid pattern that compiles to a regular expression, then this pattern is used, otherwise a fall- back to the default expression \\w+ . The pattern is repeatedly applied to the extracted text, until the end is reached. Each match is returned, separated by a space character. The default expression for this module is \\w+ which will let upper- and lowercase characters as well as digits pass through, but will block all other characters. For the German language, for example, this would mean that all special characters would be blocked as well. So you want to configure Opencast to let them pass as well. Example: * pattern: \\w+ * text input: \"a\u00e4a bbb\" * text output: \"a a bbb\" If this is undesired, modify the pattern in etc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg : For German, a suitable pattern could be: pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]* This expression will let all words pass which contain upper- and lowercase [a-z], digits and German special characters as well as punctuation at the end of a word. Additionally, it requires that the words are at least two characters long which will filter out most of the common noise. Note the double-escaping of \\w . A similar pattern that could be used for Spanish would be: pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]* Using a Spell Checker (dictionary-hunspell) Last, the dictionary-hunspell will check words based on a spell checker and a dictionary. As spell checker, the tool hunspell is used which is one of the most common spell checkers on Linux and should be available from the system repositories for most common operating systems. For the Hunspell based DictionaryService, there are two configuration options: One specifies the location of the binary and one is for the arguments to use for filtering. By default, Opencast will just call hunspell without an absolute path. This will work as long as hunspell is in the systems path which should be the case unless you have built and installed it manually. In that case, the binary can be configured using the following option in the custom.properties file: org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell While most people will not need the binary path configuration, most people will need the filtering option which can be used for setting the languages. Configuration for this can be done using the following key in the custom.properties file: org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G Note that equivalent to the Tesseract configuration, again the necessary languages have to be installed in the system. On RedHat based systems, for German, you would install the hunspell-de package from the system repositories. For Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be interesting for technical terms.","title":"Text Extraction"},{"location":"modules/textextraction/#text-extraction-configuration","text":"","title":"Text Extraction Configuration"},{"location":"modules/textextraction/#how-the-text-extraction-process-works","text":"The sequence of the Opencast services used during slide detection and text extraction is the following: -----> Segmentation -----> TextAnalyzerService -----------------> / \\ / \\ TextExtractor DictionaryService (OCR with Tesseract) (Filter extracted texts) The segmentation will define the frames which are passed to the text analyzer. For extraction, a frame from the end of a segment is used to make sure that most of a slides text is visible. The frame is then exported as image and passed to the text extraction service which calls an OCR engine to get the text output. For this, the Tesseract OCR engine is used by default. After the text extraction is done, the analysis service will pass the recognized text to the dictionary service which may filter it to remove messed up words, unknown words, single characters or other things depending on the actual implementation and configuration. Finally, the extracted text is attached to the media package as MPEG 7 XML and the Opencast workflow continues.","title":"How the text extraction process works"},{"location":"modules/textextraction/#configuration","text":"This section describes the configuration of all involved tools and services. In this guide, German is used as target language but the configuration for other languages should be similar. If necessary, important differences will be pointed out.","title":"Configuration"},{"location":"modules/textextraction/#ocr-engine-tesseract","text":"Tesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an output file. The command line arguments for this will be handled by Opencast. But apart from these mandatory ones, it is possible to pass additional arguments to Tesseract, defining the internally used dictionary, box files and the layout analysis. For example, if you want OCR for German content, you want to run something like this: tesseract in.tif out.txt -l deu --psm 3 The arguments in.tif and out.txt are automatically set by Opencast. The argument -l specifies the language files used by Tesseract. deu specifies the German language. Multiple languages may be specified, separated by plus characters. Please make sure that you have installed the language packs you want to use on every worker (E.g. yum install tesseract-langpack-deu ). Finally --psm 3 specifies the layout analysis for Tesseract. The value 3 means Fully automatic page segmentation, but no orientation and script detection which is actually the default. Hence in this case, the argument could simply be omitted. If you know more about your input videos, you might want to use different options here (not likely). This option might be just -psm with only one dash in your system. In Opencast, you can modify this options in the custom.properties file by setting the following option: org.opencastproject.textanalyzer.tesseract.options=-l deu --psm 3 It is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and only this will enable the recognition of special characters specific to your local language. If you supply a reference to a list of additional words using --user-words , the path to that file must not be enclosed in quotation marks. Newer versions of Tesseract come with additional neural nets LSTM. Its performance might be significantly different from the previous Tesseract engine. Its usage might be specified using --oem N with N being a number documented in your Tesseract manual.","title":"OCR Engine: Tesseract"},{"location":"modules/textextraction/#encoding-image-preprocessing","text":"The text extraction works best if there is a high contrast between text and background and additionally, the text is not too thin. Ideally, this means that you have black and white images with a clear, bold font. At this point, it is probably worth noting that despite what is often said and could also be found in the old documentation for Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted (white on black). Because of the way Tesseract works, that does not matter. A lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is why, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included directly into the image extraction step using FFmpeg. For this, edit the /etc/opencast/encoding/opencast-images.properties and modify the command for the image extraction: profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path} \\ -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1 \\ -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix} This profile will create a gray, high contrast image. The additional light blur will reduce or remove noise and thicken the normal letters. The kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your material are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel mixer.","title":"Encoding (Image Preprocessing)"},{"location":"modules/textextraction/#dictionaryservice-filtering","text":"The filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for. For searching, you might want a higher degree of filtering, for users you might also want to present text with slight errors, for testing and debugging, you want no filtering at all. Starting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just swapped out at any time: dictionary-none dictionary-regexp (default) dictionary-hunspell","title":"DictionaryService (Filtering)"},{"location":"modules/textextraction/#no-filtering-dictionary-none","text":"The dictionary-none module is the simplest one. It will just let the recognized texts pass through unmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.","title":"No Filtering (dictionary-none)"},{"location":"modules/textextraction/#using-a-regular-expression-dictionary-regexp","text":"Starting with 1.6, this is the default implementation for the DictionaryService. It is limited in terms of filtering capabilities as it will not check if a recognized word actually makes sense. Here is how this service works: If configured with a valid pattern that compiles to a regular expression, then this pattern is used, otherwise a fall- back to the default expression \\w+ . The pattern is repeatedly applied to the extracted text, until the end is reached. Each match is returned, separated by a space character. The default expression for this module is \\w+ which will let upper- and lowercase characters as well as digits pass through, but will block all other characters. For the German language, for example, this would mean that all special characters would be blocked as well. So you want to configure Opencast to let them pass as well. Example: * pattern: \\w+ * text input: \"a\u00e4a bbb\" * text output: \"a a bbb\" If this is undesired, modify the pattern in etc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg : For German, a suitable pattern could be: pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]* This expression will let all words pass which contain upper- and lowercase [a-z], digits and German special characters as well as punctuation at the end of a word. Additionally, it requires that the words are at least two characters long which will filter out most of the common noise. Note the double-escaping of \\w . A similar pattern that could be used for Spanish would be: pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*","title":"Using a Regular Expression (dictionary-regexp)"},{"location":"modules/textextraction/#using-a-spell-checker-dictionary-hunspell","text":"Last, the dictionary-hunspell will check words based on a spell checker and a dictionary. As spell checker, the tool hunspell is used which is one of the most common spell checkers on Linux and should be available from the system repositories for most common operating systems. For the Hunspell based DictionaryService, there are two configuration options: One specifies the location of the binary and one is for the arguments to use for filtering. By default, Opencast will just call hunspell without an absolute path. This will work as long as hunspell is in the systems path which should be the case unless you have built and installed it manually. In that case, the binary can be configured using the following option in the custom.properties file: org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell While most people will not need the binary path configuration, most people will need the filtering option which can be used for setting the languages. Configuration for this can be done using the following key in the custom.properties file: org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G Note that equivalent to the Tesseract configuration, again the necessary languages have to be installed in the system. On RedHat based systems, for German, you would install the hunspell-de package from the system repositories. For Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be interesting for technical terms.","title":"Using a Spell Checker (dictionary-hunspell)"},{"location":"modules/timelinepreviews/","text":"Timeline Previews Configuration The Timeline previews service generates timeline preview images from a given video. These are shown above the timeline of the video in the engage player. The generation of these images is done using FFmpeg and all preview images are stored in one image file. To achieve this, several FFmpeg video filters are combined: - fps : to specify how many preview images should be generated. As the length of track is known and the desired number of preview images is configured in the workflow operation handler, it can be calculated how many seconds each preview image should represent. If 1 divided by that duration in seconds is set as fps value, FFmpeg will generate the desired amount of preview images. - scale : to achieve the desired output image resolution. This filter will scale the input video, so that the generated images will have that resolution. If one of the values is set to -1, the filter will use a value that maintains the aspect ratio of the input image. - tile : to tile all remaining frames together. This filter will put the preview images into one image file. The grid size can be set and is currently always quadratic, which means the number of lines and the number of columns are both the rounded up square root of the desired number of images. Configuration The resolution, the output format and the mimetype can be configured in etc/org.opencastproject.timelinepreviews.ffmpeg.TimelinePreviewsServiceImpl.cfg . Width of the resolution of a single preview image in pixels (defaults to 160). resolutionX = 160 Height of the resolution of a single preview image in pixels (defaults to -1). If not set or set to -1, it will be set automatically to preserve the original aspect ratio. resolutionY = -1 Output file format for the timeline previews image file (defaults to \".png\"). outputFormat = \".png\" Mimetype for the output image (defaults to \"image/png\"). mimetype = \"image/png\"","title":"Timeline Previews"},{"location":"modules/timelinepreviews/#timeline-previews-configuration","text":"The Timeline previews service generates timeline preview images from a given video. These are shown above the timeline of the video in the engage player. The generation of these images is done using FFmpeg and all preview images are stored in one image file. To achieve this, several FFmpeg video filters are combined: - fps : to specify how many preview images should be generated. As the length of track is known and the desired number of preview images is configured in the workflow operation handler, it can be calculated how many seconds each preview image should represent. If 1 divided by that duration in seconds is set as fps value, FFmpeg will generate the desired amount of preview images. - scale : to achieve the desired output image resolution. This filter will scale the input video, so that the generated images will have that resolution. If one of the values is set to -1, the filter will use a value that maintains the aspect ratio of the input image. - tile : to tile all remaining frames together. This filter will put the preview images into one image file. The grid size can be set and is currently always quadratic, which means the number of lines and the number of columns are both the rounded up square root of the desired number of images.","title":"Timeline Previews Configuration"},{"location":"modules/timelinepreviews/#configuration","text":"The resolution, the output format and the mimetype can be configured in etc/org.opencastproject.timelinepreviews.ffmpeg.TimelinePreviewsServiceImpl.cfg . Width of the resolution of a single preview image in pixels (defaults to 160). resolutionX = 160 Height of the resolution of a single preview image in pixels (defaults to -1). If not set or set to -1, it will be set automatically to preserve the original aspect ratio. resolutionY = -1 Output file format for the timeline previews image file (defaults to \".png\"). outputFormat = \".png\" Mimetype for the output image (defaults to \"image/png\"). mimetype = \"image/png\"","title":"Configuration"},{"location":"modules/videoeditor.architecture/","text":"Video Editor: Architecture Modules Of The Video Editor The Video Editor consists of the following modules. Additional to this there is a Workflow Operation Handler within the Conductor module that provides the UI elements for the Video Editor. silencedetection-api API for the silence detection silencedetection-impl Implementation of the silence detection service Provides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cut file. silencedetection-remote Remote implementation of the silence detection service to enable load balancing in a distributed setup. smil-api API for the SMIL service smil-impl The SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create consistent SMIL files. videoeditor-api The API for the Video Editor which takes a SMIL file as an input to create a cut version of the media files. videoeditor-ffmpeg-impl The Video Editor service creates new media files that will be cut based on the information provided in a SMIL file. In the current implementation GStreamer with the gnonlin module is used to process the files. videoeditor-remote Remote implementation of the video editor service to enable load balancing in a distributed setup. Several other changes have been made on other Opencast modules to provide a better user experience for the video editor (i.e. byte-range request on the working-file-repository). Edit List Format The video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions and namespace extensions have been made to make sure that Opencast is able to find the files. As we usually have two (or more) parallel media files, these files are grouped in a <par> -element which forms a segment that should be included in the resulting video. This means the included <video> -files will be played in parallel. The clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all <videos> within a <par> . For each segment a <par> is created. In the result of the silence detection segments with silence are omitted within the SMIL files, so only segments within the SMIL doc will be in the resulting video. The segments within the SMIL file will be in the order they are written down. If the sequence of the segments is changed, the sequence within the resulting video is changed too. Example SMIL file <smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\"> <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\"> <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/> <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\"> <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/> <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/> </paramGroup> <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\"> <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/> <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/> </paramGroup> </head> <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\"> <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\"> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/> </par> </body> </smil> Workflow Operations Waveform Operation The waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image). The operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image. Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example). The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too. Waveform Operation Template <operation id=\"waveform\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> </configurations> </operation> Silence Operation The silence operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request. The input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type, and reference-tracks-flavor where the subtype of the media files that should be included in the provided SMIL file will be set. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. The output of this operation is a SMIL file (see the example above). Silence Operation Template <operation id=\"silence\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> </configurations> </operation> Editor Operation The editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed. The input parameters are: source-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor. preview-flavors: the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors. smil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used. skipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped. The output parameters are: target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will be taken for processing the edited files afterwards. target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation. Editor Operation Template <operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"preview-flavors\">*/preview</configuration> <configuration key=\"skipped-flavors\">*/preview</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">episode/smil</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation> Including The Video Editor To The Workflow Definition File Including the Video Editor with the silence detection into the needs some changes in the default workflow. Several of the steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set ${trimHold} variable like in the current workflow definitions with trimming. The prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the workflow-definition XML-file rewriting the file should be forced: Changes in the workflow definition <configuration key=\"rewrite\">true</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> The preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This operation should be after the prepare-av operation. Workflow operation to create WebM preview videos <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video for videoeditor preview\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/preview</configuration> <configuration key=\"encoding-profile\">webm-preview.http</configuration> </configurations> </operation> An audio-only file has to be composed for the waveform and silence operation. This operation should be after the prepare-av operation. Workflow operation to compose the audio-only file(s) <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Extracting audio for waveform generation\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/audio</configuration> <configuration key=\"encoding-profile\">audio.wav</configuration> </configurations> </operation> The waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available. The silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available. After all previous operations have been done the editor can be included. See above for the XML-code for this operation. You may consider to tag the trimmed files for archiving. Then you should include this operation after the editor: Tagging trimmed files for the archive <operation id=\"tag\" description=\"Tagging media for archival\"> <configurations> <configuration key=\"source-flavors\">*/trimmed</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> You could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations. The rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other operations is \"/trimmed\" if you follow the naming in this example. The default compose-distribute-publish.xml workflow definition within the Video Editor branch has already been updated to include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but could still be used.","title":"Architecture"},{"location":"modules/videoeditor.architecture/#video-editor-architecture","text":"","title":"Video Editor: Architecture"},{"location":"modules/videoeditor.architecture/#modules-of-the-video-editor","text":"The Video Editor consists of the following modules. Additional to this there is a Workflow Operation Handler within the Conductor module that provides the UI elements for the Video Editor. silencedetection-api API for the silence detection silencedetection-impl Implementation of the silence detection service Provides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cut file. silencedetection-remote Remote implementation of the silence detection service to enable load balancing in a distributed setup. smil-api API for the SMIL service smil-impl The SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create consistent SMIL files. videoeditor-api The API for the Video Editor which takes a SMIL file as an input to create a cut version of the media files. videoeditor-ffmpeg-impl The Video Editor service creates new media files that will be cut based on the information provided in a SMIL file. In the current implementation GStreamer with the gnonlin module is used to process the files. videoeditor-remote Remote implementation of the video editor service to enable load balancing in a distributed setup. Several other changes have been made on other Opencast modules to provide a better user experience for the video editor (i.e. byte-range request on the working-file-repository).","title":"Modules Of The Video Editor"},{"location":"modules/videoeditor.architecture/#edit-list-format","text":"The video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions and namespace extensions have been made to make sure that Opencast is able to find the files. As we usually have two (or more) parallel media files, these files are grouped in a <par> -element which forms a segment that should be included in the resulting video. This means the included <video> -files will be played in parallel. The clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all <videos> within a <par> . For each segment a <par> is created. In the result of the silence detection segments with silence are omitted within the SMIL files, so only segments within the SMIL doc will be in the resulting video. The segments within the SMIL file will be in the order they are written down. If the sequence of the segments is changed, the sequence within the resulting video is changed too. Example SMIL file <smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\"> <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\"> <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/> <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\"> <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/> <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/> </paramGroup> <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\"> <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/> <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/> </paramGroup> </head> <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\"> <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\"> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/> </par> </body> </smil>","title":"Edit List Format"},{"location":"modules/videoeditor.architecture/#workflow-operations","text":"","title":"Workflow Operations"},{"location":"modules/videoeditor.architecture/#waveform-operation","text":"The waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image). The operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image. Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example). The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too. Waveform Operation Template <operation id=\"waveform\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> </configurations> </operation>","title":"Waveform Operation"},{"location":"modules/videoeditor.architecture/#silence-operation","text":"The silence operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request. The input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type, and reference-tracks-flavor where the subtype of the media files that should be included in the provided SMIL file will be set. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. The output of this operation is a SMIL file (see the example above). Silence Operation Template <operation id=\"silence\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> </configurations> </operation>","title":"Silence Operation"},{"location":"modules/videoeditor.architecture/#editor-operation","text":"The editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed. The input parameters are: source-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor. preview-flavors: the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors. smil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used. skipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped. The output parameters are: target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will be taken for processing the edited files afterwards. target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation. Editor Operation Template <operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"preview-flavors\">*/preview</configuration> <configuration key=\"skipped-flavors\">*/preview</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">episode/smil</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation>","title":"Editor Operation"},{"location":"modules/videoeditor.architecture/#including-the-video-editor-to-the-workflow-definition-file","text":"Including the Video Editor with the silence detection into the needs some changes in the default workflow. Several of the steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set ${trimHold} variable like in the current workflow definitions with trimming. The prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the workflow-definition XML-file rewriting the file should be forced: Changes in the workflow definition <configuration key=\"rewrite\">true</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> The preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This operation should be after the prepare-av operation. Workflow operation to create WebM preview videos <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video for videoeditor preview\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/preview</configuration> <configuration key=\"encoding-profile\">webm-preview.http</configuration> </configurations> </operation> An audio-only file has to be composed for the waveform and silence operation. This operation should be after the prepare-av operation. Workflow operation to compose the audio-only file(s) <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Extracting audio for waveform generation\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/audio</configuration> <configuration key=\"encoding-profile\">audio.wav</configuration> </configurations> </operation> The waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available. The silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available. After all previous operations have been done the editor can be included. See above for the XML-code for this operation. You may consider to tag the trimmed files for archiving. Then you should include this operation after the editor: Tagging trimmed files for the archive <operation id=\"tag\" description=\"Tagging media for archival\"> <configurations> <configuration key=\"source-flavors\">*/trimmed</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> You could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations. The rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other operations is \"/trimmed\" if you follow the naming in this example. The default compose-distribute-publish.xml workflow definition within the Video Editor branch has already been updated to include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but could still be used.","title":"Including The Video Editor To The Workflow Definition File"},{"location":"modules/videoeditor.setup/","text":"Video Editor: Setup Silence Detection Configuration The settings regarding the sensitivity of the silence detection can be changed in etc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg . silence.pre.length Duration of silence that should be included at the beginning of a new voice segment. This is to avoid that a cut seems to sudden. Default: 2000 (2s) silence.threshold.db Silence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location). Default: -40dB silence.min.length Minimum duration in milliseconds to detect a sequence as silence. Default: 10000 (10s) voice.min.length Minimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence. Default: 60000 (1min) Video Editor Configuration The FFmpeg properties for the Video Editor can be modified in etc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg . Usually there should be no reason to touch this file.","title":"Setup"},{"location":"modules/videoeditor.setup/#video-editor-setup","text":"","title":"Video Editor: Setup"},{"location":"modules/videoeditor.setup/#silence-detection-configuration","text":"The settings regarding the sensitivity of the silence detection can be changed in etc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg . silence.pre.length Duration of silence that should be included at the beginning of a new voice segment. This is to avoid that a cut seems to sudden. Default: 2000 (2s) silence.threshold.db Silence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location). Default: -40dB silence.min.length Minimum duration in milliseconds to detect a sequence as silence. Default: 10000 (10s) voice.min.length Minimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence. Default: 60000 (1min)","title":"Silence Detection Configuration"},{"location":"modules/videoeditor.setup/#video-editor-configuration","text":"The FFmpeg properties for the Video Editor can be modified in etc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg . Usually there should be no reason to touch this file.","title":"Video Editor Configuration"},{"location":"modules/videosegmentation/","text":"Video Segmentation Configuration What is Video Segmentation Video segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture, segmentation is best applied to captured screen presentation, that the presenter goes through slide after slide. As a result, the video segmentation returns the exact times of slide changes on the timeline, which allows for sophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player. How the video segmentation process works For detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind this filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the difference. What can be optimized The segmentation does not yield perfect results for all scenarios if always the same parameters for the FFmpeg filter are used. Especially for presentations that include live handwriting or small videos often way too many segments are created. In these special cases the difference between two consecutive frames is much higher than for normal presentation slides and these big differences happen very often, whereby many segments would be found. To improve the resulting number of segments, different FFmpeg parameters are tried out and to prevent having segments that are too short to be reasonably clickable, too short segments are filtered out. How the Optimization works In general the optimization repeats a cycle of calling the FFmpeg filter, merging too small segments and calculating a new changes threshold until the segmentation is good enough. Additional to calling the FFmpeg function there is a filter function that merges small segments to a bigger segment or splits it to the surrounding segments if the resulting segment would be too small. This can be beneficial for example if a video is shown in a lecture, so that the video will be only one segment and not many short segments. The stability threshold is used in the filter method to determine which segments are long enough and which should be merged. First the segmentation is run with a stability threshold of 1 second and the initial changes threshold, that can be changed in the options. If the segmentation or the filtered segmentation doesn't deviate more from the preferred number of segments than the maximum error allows, the optimization is done. If not, a new changes threshold, that should yield better results, is calculated and the segmentation is run again until the segmentation is good enough or until the maximum number of cycles is reached. Configuration The value for the frame difference as well as the minimum length for a segment, the preferred number of segments, the maximum error and the maximum number of cycles can be configured in etc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg . The options that can be set are the minimum length of a segment (defaults to 60 sec). stabilitythreshold = 60 The percentage of pixels that may change between two frames without considering them different (defaults to 0.025). changesthreshold = 0.025 The number of segments that the segmentation optimally should yield (defaults to 30). prefNumber = 30 The maximum error for the number of segments in percent. As soon as a segmentation with a lower error is achieved the optimization will be ended (defaults to 0.25). maxError = 0.25 The maximum number of times the optimization will call the FFmpeg select filter (defaults to 3). maxCycles = 3 The absolute maximum number of segments. If at the end of the optimization more segments than this are found, instead a uniform segmentation will be generated (defaults to 150). absoluteMax = 150 The absolute minimum number of segments. If at the end of the optimization less segments than this are found, instead a uniform segmentation will be generated (defaults to 3). absoluteMin = 3 This parameter controls whether the options prefNumber, absoluteMax and absoluteMin are interpreted as absolute segment numbers or relative to track duration. If this is set to true, prefNumber, absoluteMax and absoluteMin will be interpreted as number of segments per hour. (defaults to false) durationDependent = false","title":"Video Segmentation"},{"location":"modules/videosegmentation/#video-segmentation-configuration","text":"","title":"Video Segmentation Configuration"},{"location":"modules/videosegmentation/#what-is-video-segmentation","text":"Video segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture, segmentation is best applied to captured screen presentation, that the presenter goes through slide after slide. As a result, the video segmentation returns the exact times of slide changes on the timeline, which allows for sophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player.","title":"What is Video Segmentation"},{"location":"modules/videosegmentation/#how-the-video-segmentation-process-works","text":"For detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind this filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the difference.","title":"How the video segmentation process works"},{"location":"modules/videosegmentation/#what-can-be-optimized","text":"The segmentation does not yield perfect results for all scenarios if always the same parameters for the FFmpeg filter are used. Especially for presentations that include live handwriting or small videos often way too many segments are created. In these special cases the difference between two consecutive frames is much higher than for normal presentation slides and these big differences happen very often, whereby many segments would be found. To improve the resulting number of segments, different FFmpeg parameters are tried out and to prevent having segments that are too short to be reasonably clickable, too short segments are filtered out.","title":"What can be optimized"},{"location":"modules/videosegmentation/#how-the-optimization-works","text":"In general the optimization repeats a cycle of calling the FFmpeg filter, merging too small segments and calculating a new changes threshold until the segmentation is good enough. Additional to calling the FFmpeg function there is a filter function that merges small segments to a bigger segment or splits it to the surrounding segments if the resulting segment would be too small. This can be beneficial for example if a video is shown in a lecture, so that the video will be only one segment and not many short segments. The stability threshold is used in the filter method to determine which segments are long enough and which should be merged. First the segmentation is run with a stability threshold of 1 second and the initial changes threshold, that can be changed in the options. If the segmentation or the filtered segmentation doesn't deviate more from the preferred number of segments than the maximum error allows, the optimization is done. If not, a new changes threshold, that should yield better results, is calculated and the segmentation is run again until the segmentation is good enough or until the maximum number of cycles is reached.","title":"How the Optimization works"},{"location":"modules/videosegmentation/#configuration","text":"The value for the frame difference as well as the minimum length for a segment, the preferred number of segments, the maximum error and the maximum number of cycles can be configured in etc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg . The options that can be set are the minimum length of a segment (defaults to 60 sec). stabilitythreshold = 60 The percentage of pixels that may change between two frames without considering them different (defaults to 0.025). changesthreshold = 0.025 The number of segments that the segmentation optimally should yield (defaults to 30). prefNumber = 30 The maximum error for the number of segments in percent. As soon as a segmentation with a lower error is achieved the optimization will be ended (defaults to 0.25). maxError = 0.25 The maximum number of times the optimization will call the FFmpeg select filter (defaults to 3). maxCycles = 3 The absolute maximum number of segments. If at the end of the optimization more segments than this are found, instead a uniform segmentation will be generated (defaults to 150). absoluteMax = 150 The absolute minimum number of segments. If at the end of the optimization less segments than this are found, instead a uniform segmentation will be generated (defaults to 3). absoluteMin = 3 This parameter controls whether the options prefNumber, absoluteMax and absoluteMin are interpreted as absolute segment numbers or relative to track duration. If this is set to true, prefNumber, absoluteMax and absoluteMin will be interpreted as number of segments per hour. (defaults to false) durationDependent = false","title":"Configuration"},{"location":"modules/watsontranscripts/","text":"Transcripts (Automated by IBM Watson) Overview The IBMWatsonTranscriptionService invokes the IBM Watson Speech-to-Text service via REST API to translate audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the IBM Watson Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Workflow 1 runs: Audio file created Watson Speech-to-Text job started Workflow finishes Translation finishes, callback with results is received, and workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts IBM Watson Speech-to-Text service documentation, including which languages are currently supported, can be found here . Configuration Step 1: Get IBM Watson credentials Create a 30-day trial account in IBM Cloud Get service credentials As of 10/30/2018, the service has migrated to token-based Identity and Access Management (IAM) authentication so user and password are not generated anymore. Previously created instances can still use user name and password. Details can be found here . Step 2: Configure IBMWatsonTranscriptionService Edit etc/org.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg : Set enabled =true Use service credentials obtained above to set ibm_watson_api_key ( ibm.watson.user and ibm.watson.psw are still supported to be used with instances created previously) Enter the IBM Watson Speech-to-Text url in ibm.watson.service.url , if not using the default (https://stream.watsonplatform.net/speech-to-text/api) Enter the appropriate language model in ibm.watson.model , if not using the default ( en-US_BroadbandModel ) In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. Configure the SmtpService. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. If re-submitting requests is desired in case of failures, configure max-attempts and retry.workflow . If max.attempts > 1 and the service receives an error callback, it will start the workflow specified in retry_workflow to create a new job. When max.attempts is reached for a track, the service will stop retrying. # Change enabled to true to enable this service. enabled=false # IBM Watson Speech-to-Text service url # Default: https://stream.watsonplatform.net/speech-to-text/api # ibm.watson.service.url=https://stream.watsonplatform.net/speech-to-text/api # APi key obtained when registering with the IBM Watson Speech-to_text service. # If empty, user and password below will be used. ibm.watson.api.key=<API_KEY> # User obtained when registering with the IBM Watson Speech-to_text service. # Mandatory if ibm.watson.api.key not entered. #ibm.watson.user=<SERVICE_USER> # Password obtained when registering with the IBM Watson Speech-to_text service # Mandatory if ibm.watson.api.key not entered. #ibm.watson.password=<SERVICE_PSW> # Language model to be used. See the IBM Watson Speech-to-Text service documentation # for available models. # Default: en-US_BroadbandModel #ibm.watson.model=en-US_BroadbandModel # Workflow to be executed when results are ready to be attached to media package. # Default: attach-watson-transcripts #workflow=attach-watson-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. In seconds. # Default: 60 #workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # This is only used if we didn't get a callback from the ibm watson speech-to-text service. # In seconds. # Default: 600 #completion.check.buffer=600 # How long to wait after a transcription is supposed to finish before marking the job as # canceled in the database. In seconds. Default is 2 hours. # Default: 7200 #max.processing.time=7200 # How long to keep result files in the working file repository in days. # Default: 7 #cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. #notification.email= # Start transcription job load # Default: 0.1 #job.load.start.transcription=0.1 # Number of max attempts. If max attempts > 1 and the service returned an error after the recognitions job was # accepted or the job did not return any results, the transcription is re-submitted. Default is to not retry. # Default: 1 #max.attempts= # If max.attempts > 1, name of workflow to use for retries. #retry.workflow= Step 3: Add encoding profile for extracting audio The IBM Watson Speech-to-Text service has limitations on audio file size. Try using the encoding profile suggested in etc/encoding/watson-audio.properties. Step 4: Add workflow operations and create new workflow Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the Asset Manager to attach the caption/transcripts. <!-- Extract audio from one of the presenter videos --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <!-- The target tag 'transcript' will be used in the next 'start-watson-transcription' operation --> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Create a workflow that will add the generated caption/transcript to the media package and republish it. A sample one can be found in etc/workflows/attach-watson-transcripts.xml If re-submitting requests is desired in case of failures, create a workflow that will start a transcription job. A sample one can be found in etc/workflows/retry-watson-transcripts.xml Workflow Operations start-watson-transcription attach-watson-transcription","title":"Transcripts (IBM Watson)"},{"location":"modules/watsontranscripts/#transcripts-automated-by-ibm-watson","text":"","title":"Transcripts (Automated by IBM Watson)"},{"location":"modules/watsontranscripts/#overview","text":"The IBMWatsonTranscriptionService invokes the IBM Watson Speech-to-Text service via REST API to translate audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the IBM Watson Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Workflow 1 runs: Audio file created Watson Speech-to-Text job started Workflow finishes Translation finishes, callback with results is received, and workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts IBM Watson Speech-to-Text service documentation, including which languages are currently supported, can be found here .","title":"Overview"},{"location":"modules/watsontranscripts/#configuration","text":"","title":"Configuration"},{"location":"modules/watsontranscripts/#step-1-get-ibm-watson-credentials","text":"Create a 30-day trial account in IBM Cloud Get service credentials As of 10/30/2018, the service has migrated to token-based Identity and Access Management (IAM) authentication so user and password are not generated anymore. Previously created instances can still use user name and password. Details can be found here .","title":"Step 1: Get IBM Watson credentials"},{"location":"modules/watsontranscripts/#step-2-configure-ibmwatsontranscriptionservice","text":"Edit etc/org.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg : Set enabled =true Use service credentials obtained above to set ibm_watson_api_key ( ibm.watson.user and ibm.watson.psw are still supported to be used with instances created previously) Enter the IBM Watson Speech-to-Text url in ibm.watson.service.url , if not using the default (https://stream.watsonplatform.net/speech-to-text/api) Enter the appropriate language model in ibm.watson.model , if not using the default ( en-US_BroadbandModel ) In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. Configure the SmtpService. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. If re-submitting requests is desired in case of failures, configure max-attempts and retry.workflow . If max.attempts > 1 and the service receives an error callback, it will start the workflow specified in retry_workflow to create a new job. When max.attempts is reached for a track, the service will stop retrying. # Change enabled to true to enable this service. enabled=false # IBM Watson Speech-to-Text service url # Default: https://stream.watsonplatform.net/speech-to-text/api # ibm.watson.service.url=https://stream.watsonplatform.net/speech-to-text/api # APi key obtained when registering with the IBM Watson Speech-to_text service. # If empty, user and password below will be used. ibm.watson.api.key=<API_KEY> # User obtained when registering with the IBM Watson Speech-to_text service. # Mandatory if ibm.watson.api.key not entered. #ibm.watson.user=<SERVICE_USER> # Password obtained when registering with the IBM Watson Speech-to_text service # Mandatory if ibm.watson.api.key not entered. #ibm.watson.password=<SERVICE_PSW> # Language model to be used. See the IBM Watson Speech-to-Text service documentation # for available models. # Default: en-US_BroadbandModel #ibm.watson.model=en-US_BroadbandModel # Workflow to be executed when results are ready to be attached to media package. # Default: attach-watson-transcripts #workflow=attach-watson-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. In seconds. # Default: 60 #workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # This is only used if we didn't get a callback from the ibm watson speech-to-text service. # In seconds. # Default: 600 #completion.check.buffer=600 # How long to wait after a transcription is supposed to finish before marking the job as # canceled in the database. In seconds. Default is 2 hours. # Default: 7200 #max.processing.time=7200 # How long to keep result files in the working file repository in days. # Default: 7 #cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. #notification.email= # Start transcription job load # Default: 0.1 #job.load.start.transcription=0.1 # Number of max attempts. If max attempts > 1 and the service returned an error after the recognitions job was # accepted or the job did not return any results, the transcription is re-submitted. Default is to not retry. # Default: 1 #max.attempts= # If max.attempts > 1, name of workflow to use for retries. #retry.workflow=","title":"Step 2: Configure IBMWatsonTranscriptionService"},{"location":"modules/watsontranscripts/#step-3-add-encoding-profile-for-extracting-audio","text":"The IBM Watson Speech-to-Text service has limitations on audio file size. Try using the encoding profile suggested in etc/encoding/watson-audio.properties.","title":"Step 3: Add encoding profile for extracting audio"},{"location":"modules/watsontranscripts/#step-4-add-workflow-operations-and-create-new-workflow","text":"Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the Asset Manager to attach the caption/transcripts. <!-- Extract audio from one of the presenter videos --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <!-- The target tag 'transcript' will be used in the next 'start-watson-transcription' operation --> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Create a workflow that will add the generated caption/transcript to the media package and republish it. A sample one can be found in etc/workflows/attach-watson-transcripts.xml If re-submitting requests is desired in case of failures, create a workflow that will start a transcription job. A sample one can be found in etc/workflows/retry-watson-transcripts.xml","title":"Step 4: Add workflow operations and create new workflow"},{"location":"modules/watsontranscripts/#workflow-operations","text":"start-watson-transcription attach-watson-transcription","title":"Workflow Operations"},{"location":"modules/waveform/","text":"Waveform Service Configuration The Waveform service generates waveform images from a audio/video file. These waveform images are then shown in the Admin-UI video editor. Service Configuration The Waveform service configuration file etc/org.opencastproject.waveform.ffmpeg.WaveformServiceImpl.cfg provides the following options: job.load.waveform = 0.5 With this value you can define the load of waveform jobs, see job load waveform.image.width.min = 5000 This will define the minimum width of the waveform image in pixels. waveform.image.width.max = 20000 This will define the maximum width of the waveform image in pixels. waveform.image.width.ppm = 200 This value defines the width of the waveform image in relation to the length of the audio/video file (in pixels per minute). waveform.image.height = 500 This will define the height of the waveform image in pixels. waveform.color = black This value defines the color of the waveform. The value must be a RGB(A) hex code or one of the predefined values, see FFMPEG Colors . You can define one color per audio channel separated by a whitespace. waveform.split.channels = false This boolean value defines whether multiple audio channels should be mixed in one waveform (if false ) or separated one next to each other (if true ). waveform.scale = lin This value defines the scale of the waveform. You can chose between lin for linear or log for logarithmic scale.","title":"Waveform Service"},{"location":"modules/waveform/#waveform-service-configuration","text":"The Waveform service generates waveform images from a audio/video file. These waveform images are then shown in the Admin-UI video editor.","title":"Waveform Service Configuration"},{"location":"modules/waveform/#service-configuration","text":"The Waveform service configuration file etc/org.opencastproject.waveform.ffmpeg.WaveformServiceImpl.cfg provides the following options: job.load.waveform = 0.5 With this value you can define the load of waveform jobs, see job load waveform.image.width.min = 5000 This will define the minimum width of the waveform image in pixels. waveform.image.width.max = 20000 This will define the maximum width of the waveform image in pixels. waveform.image.width.ppm = 200 This value defines the width of the waveform image in relation to the length of the audio/video file (in pixels per minute). waveform.image.height = 500 This will define the height of the waveform image in pixels. waveform.color = black This value defines the color of the waveform. The value must be a RGB(A) hex code or one of the predefined values, see FFMPEG Colors . You can define one color per audio channel separated by a whitespace. waveform.split.channels = false This boolean value defines whether multiple audio channels should be mixed in one waveform (if false ) or separated one next to each other (if true ). waveform.scale = lin This value defines the scale of the waveform. You can chose between lin for linear or log for logarithmic scale.","title":"Service Configuration"},{"location":"modules/youtubepublication/","text":"YouTube Publication Configuration This page documents the configuration for Opencast module publication-service-youtube-v3 . Before you start You need to meet these requirements to make a YouTube Publication: Google Account YouTube Channel to make the publication Google Developers Configuration Below is a summarized version of Google's quickstart page . If these instructions do not work for you, or are unclear please let us know - Google has a habit of changing its configuration pages and we don't always notice! Create new Google Project Login to Google account Navigate to the Google Developers Console Click Create Project and follow the instructions Navigate to the Google Credentials Console Select OAuth consent screen Configure the API Consent Screen, you will need to set the Product name Select Credentials Select Create Credentials , specifically OAuth Client ID Select Other application type Save Client ID in JSON Format Download the client information in JSON format by clicking Download JSON This currently looks like an arrow pointing downwards on the rightmost portion of the client id row Save the JSON file to ${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json (Usually this is etc/youtube-v3/client-secrets-youtube-v3.json ) Enable API Navigate to the Google API Dashboard Click Enable APIs and Services in the navigation pane Use the filter to find and enable YouTube Data API v3 Enable the publication service In etc/org.opencastproject.publication.youtube.YouTubeV3PublicationServiceImpl.cfg set org.opencastproject.publication.youtube.enabled=true Update the category, keywords, default privacy, and default playlist variables as required YouTube configuration in Opencast With the JSON file created and saved previously, you have to proceed as described: Start Opencast server (Restart Opencast in case was running) Note: Until this service is fully configured, Opencast will not start completely. In case you want to abort the configuration, you only need to delete the JSON file and restart Opencast. In the command line, enter the command to view the extended status of the Opencast service: # systemctl status opencast -l This command will show parts of the Opencast logs in which you should see an URL that you have to copy to a browser. The web page will ask for your Google account (you have to use the account with which you created the developer project earlier) followed by access settings and settings for the channel you want to publish to. Once you have accepted the access, you will receive an answer like: Received verification code. Closing\u2026 Now verify that Opencast has received the access key and that it has been saved in data/opencast/youtube-v3/data-store/store. Restart Opencast Activate YouTube publication in Opencast Opencast can now publish to YouTube. The last step is to activate this feature. For this you have to create a new workflow or modify an existing one. Open the workflows etc/opencast/workflows/ng-schedule-and-upload.xml and etc/opencast/workflows/ng-publish.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"/> Open the workflows etc/opencast/workflows/ng-retract.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"retractFromYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"retractFromYouTube\" type=\"checkbox\" checked=\"checked\" class=\"configField\" value=\"true\" /> Opencast will detect the new workflow without restart, with that you can select the new workflow with the YouTube option enabled.","title":"YouTube Publication"},{"location":"modules/youtubepublication/#youtube-publication-configuration","text":"This page documents the configuration for Opencast module publication-service-youtube-v3 .","title":"YouTube Publication Configuration"},{"location":"modules/youtubepublication/#before-you-start","text":"You need to meet these requirements to make a YouTube Publication: Google Account YouTube Channel to make the publication","title":"Before you start"},{"location":"modules/youtubepublication/#google-developers-configuration","text":"Below is a summarized version of Google's quickstart page . If these instructions do not work for you, or are unclear please let us know - Google has a habit of changing its configuration pages and we don't always notice!","title":"Google Developers Configuration"},{"location":"modules/youtubepublication/#create-new-google-project","text":"Login to Google account Navigate to the Google Developers Console Click Create Project and follow the instructions Navigate to the Google Credentials Console Select OAuth consent screen Configure the API Consent Screen, you will need to set the Product name Select Credentials Select Create Credentials , specifically OAuth Client ID Select Other application type","title":"Create new Google Project"},{"location":"modules/youtubepublication/#save-client-id-in-json-format","text":"Download the client information in JSON format by clicking Download JSON This currently looks like an arrow pointing downwards on the rightmost portion of the client id row Save the JSON file to ${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json (Usually this is etc/youtube-v3/client-secrets-youtube-v3.json )","title":"Save Client ID in JSON Format"},{"location":"modules/youtubepublication/#enable-api","text":"Navigate to the Google API Dashboard Click Enable APIs and Services in the navigation pane Use the filter to find and enable YouTube Data API v3","title":"Enable API"},{"location":"modules/youtubepublication/#enable-the-publication-service","text":"In etc/org.opencastproject.publication.youtube.YouTubeV3PublicationServiceImpl.cfg set org.opencastproject.publication.youtube.enabled=true Update the category, keywords, default privacy, and default playlist variables as required","title":"Enable the publication service"},{"location":"modules/youtubepublication/#youtube-configuration-in-opencast","text":"With the JSON file created and saved previously, you have to proceed as described: Start Opencast server (Restart Opencast in case was running) Note: Until this service is fully configured, Opencast will not start completely. In case you want to abort the configuration, you only need to delete the JSON file and restart Opencast. In the command line, enter the command to view the extended status of the Opencast service: # systemctl status opencast -l This command will show parts of the Opencast logs in which you should see an URL that you have to copy to a browser. The web page will ask for your Google account (you have to use the account with which you created the developer project earlier) followed by access settings and settings for the channel you want to publish to. Once you have accepted the access, you will receive an answer like: Received verification code. Closing\u2026 Now verify that Opencast has received the access key and that it has been saved in data/opencast/youtube-v3/data-store/store. Restart Opencast","title":"YouTube configuration in Opencast"},{"location":"modules/youtubepublication/#activate-youtube-publication-in-opencast","text":"Opencast can now publish to YouTube. The last step is to activate this feature. For this you have to create a new workflow or modify an existing one. Open the workflows etc/opencast/workflows/ng-schedule-and-upload.xml and etc/opencast/workflows/ng-publish.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"/> Open the workflows etc/opencast/workflows/ng-retract.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"retractFromYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"retractFromYouTube\" type=\"checkbox\" checked=\"checked\" class=\"configField\" value=\"true\" /> Opencast will detect the new workflow without restart, with that you can select the new workflow with the YouTube option enabled.","title":"Activate YouTube publication in Opencast"},{"location":"modules/paella.player/configuration/","text":"Paella Player The Paella (pronounced 'paeja') Player is an Open Source JavaScript video player capable of playing an unlimited number of audio & video streams synchronously, Live Streaming, Zoom, Captions, contributed user plugins and a lot more. It is easy to install and customize for your own needs. Paella has been specially designed for lecture recordings. It works with all HTML5 browsers (Chrome, Firefox, Safari and Edge) and within iOS and Android. Have a look to the paella features list or see them live on paella demos page Paella is Opencast's default player. Configuration The configurations for the paella player are done for each tenant. The paella configuration files are located in etc/ui-config/<tenant_id>/paella/config.json . For the default mh_default_org tenant file is located at etc/ui-config/mh_default_org/paella/config.json . For more information about the configuration format options, see the paella documentation Tracks to be played An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure es.upv.paella.opencast.loader plugin. Multiple audio tracks An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. Read the es.upv.paella.opencast.loader documentation plugin for more information. This feature is useful when you have multiple audio languages, so the users can switch to the audio language they want. Selecting video canvas to use You can configure which canvas to use in order to render video files. This is useful to enable 360 videos for example. Read the es.upv.paella.opencast.loader documentation plugin for more information.","title":"Configuration"},{"location":"modules/paella.player/configuration/#paella-player","text":"The Paella (pronounced 'paeja') Player is an Open Source JavaScript video player capable of playing an unlimited number of audio & video streams synchronously, Live Streaming, Zoom, Captions, contributed user plugins and a lot more. It is easy to install and customize for your own needs. Paella has been specially designed for lecture recordings. It works with all HTML5 browsers (Chrome, Firefox, Safari and Edge) and within iOS and Android. Have a look to the paella features list or see them live on paella demos page Paella is Opencast's default player.","title":"Paella Player"},{"location":"modules/paella.player/configuration/#configuration","text":"The configurations for the paella player are done for each tenant. The paella configuration files are located in etc/ui-config/<tenant_id>/paella/config.json . For the default mh_default_org tenant file is located at etc/ui-config/mh_default_org/paella/config.json . For more information about the configuration format options, see the paella documentation","title":"Configuration"},{"location":"modules/paella.player/configuration/#tracks-to-be-played","text":"An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure es.upv.paella.opencast.loader plugin.","title":"Tracks to be played"},{"location":"modules/paella.player/configuration/#multiple-audio-tracks","text":"An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. Read the es.upv.paella.opencast.loader documentation plugin for more information. This feature is useful when you have multiple audio languages, so the users can switch to the audio language they want.","title":"Multiple audio tracks"},{"location":"modules/paella.player/configuration/#selecting-video-canvas-to-use","text":"You can configure which canvas to use in order to render video files. This is useful to enable 360 videos for example. Read the es.upv.paella.opencast.loader documentation plugin for more information.","title":"Selecting video canvas to use"},{"location":"modules/paella.player/plugins/","text":"Paella player plugins Almost every paella feature is a plugin that can be enabled/disabled by each organization. You need to modify the plugins section of the paella config file . To enable/disable a plugin you need to set the plugin enable property to false . Example: { ... \"plugins\": { \"list\": { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true }, ... } } } Plugins provided by Paella player To view a full list of plugins, see the the paella documentation page Plugins provided by Opencast The paella bundle for Opencast comes with a list of plugins to integrate with Opencast Plugin Description es.upv.paella.opencast.descriptionPlugin Adds a panel with the video description information. es.upv.paella.opencast.downloadsPlugin Adds a panel to download the videos. es.upv.paella.opencast.episodesFromSeries Show a list of videos in the same series. es.upv.paella.opencast.loader Configures how events are loaded into paella player. es.upv.paella.opencast.logIn Adds a button to be able to login. es.upv.paella.opencast.searchPlugin Enable searches using the OCR transcription. es.upv.paella.opencast.transcriptionTabBarPlugin Adds a panel to show the OCR transcriptions. es.upv.paella.opencast.userTrackingSaverPlugIn Allows to use Opencast Usertracking Service to track usage data.","title":"Overview"},{"location":"modules/paella.player/plugins/#paella-player-plugins","text":"Almost every paella feature is a plugin that can be enabled/disabled by each organization. You need to modify the plugins section of the paella config file . To enable/disable a plugin you need to set the plugin enable property to false . Example: { ... \"plugins\": { \"list\": { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true }, ... } } }","title":"Paella player plugins"},{"location":"modules/paella.player/plugins/#plugins-provided-by-paella-player","text":"To view a full list of plugins, see the the paella documentation page","title":"Plugins provided by Paella player"},{"location":"modules/paella.player/plugins/#plugins-provided-by-opencast","text":"The paella bundle for Opencast comes with a list of plugins to integrate with Opencast Plugin Description es.upv.paella.opencast.descriptionPlugin Adds a panel with the video description information. es.upv.paella.opencast.downloadsPlugin Adds a panel to download the videos. es.upv.paella.opencast.episodesFromSeries Show a list of videos in the same series. es.upv.paella.opencast.loader Configures how events are loaded into paella player. es.upv.paella.opencast.logIn Adds a button to be able to login. es.upv.paella.opencast.searchPlugin Enable searches using the OCR transcription. es.upv.paella.opencast.transcriptionTabBarPlugin Adds a panel to show the OCR transcriptions. es.upv.paella.opencast.userTrackingSaverPlugIn Allows to use Opencast Usertracking Service to track usage data.","title":"Plugins provided by Opencast"},{"location":"modules/paella.player/url.parameter/","text":"Paella Player - URL Parameters Parameter Example Description id SOME-ID Video Id to play time 10m20s Seeks initially automatically to a specified time autoplay true Automatically starts playing the video id Video Id to play time Seeks initially automatically to a specified time. automatically plays the video from the specified time on Possible values * Hours (with value X ), minutes (with value Y ) and seconds (with value Z ) * XhYmZs * Minutes (with value Y ) and seconds (with value Z ) * YmZs * Minutes (with value Y ) only * Ym * Seconds (with value Z ) only * Zs Default value: - autoplay Automatically starts playing the video after a short delay Possible values * true * false Default value: false Example http://YOUR.SERVER/paella/ui/watch.html?id=SOME-ID&time=3m30s","title":"URL Parameters"},{"location":"modules/paella.player/url.parameter/#paella-player-url-parameters","text":"Parameter Example Description id SOME-ID Video Id to play time 10m20s Seeks initially automatically to a specified time autoplay true Automatically starts playing the video","title":"Paella Player - URL Parameters"},{"location":"modules/paella.player/url.parameter/#id","text":"Video Id to play","title":"id"},{"location":"modules/paella.player/url.parameter/#time","text":"Seeks initially automatically to a specified time. automatically plays the video from the specified time on Possible values * Hours (with value X ), minutes (with value Y ) and seconds (with value Z ) * XhYmZs * Minutes (with value Y ) and seconds (with value Z ) * YmZs * Minutes (with value Y ) only * Ym * Seconds (with value Z ) only * Zs Default value: -","title":"time"},{"location":"modules/paella.player/url.parameter/#autoplay","text":"Automatically starts playing the video after a short delay Possible values * true * false Default value: false","title":"autoplay"},{"location":"modules/paella.player/url.parameter/#example","text":"http://YOUR.SERVER/paella/ui/watch.html?id=SOME-ID&time=3m30s","title":"Example"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.descriptionPlugin/","text":"Paella plugin: es.upv.paella.opencast.descriptionPlugin This plugin adds a panel with the video description information. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.descriptionPlugin plugin. { \"es.upv.paella.opencast.descriptionPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.descriptionPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.descriptionPlugin/#paella-plugin-esupvpaellaopencastdescriptionplugin","text":"This plugin adds a panel with the video description information. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.descriptionPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.descriptionPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.descriptionPlugin plugin. { \"es.upv.paella.opencast.descriptionPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.downloadsPlugin/","text":"Paella plugin: es.upv.paella.opencast.downloadsPlugin This plugin adds a panel to download the videos. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.downloadsPlugin plugin. { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.downloadsPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.downloadsPlugin/#paella-plugin-esupvpaellaopencastdownloadsplugin","text":"This plugin adds a panel to download the videos. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.downloadsPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.downloadsPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.downloadsPlugin plugin. { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.episodesFromSeries/","text":"Paella plugin: es.upv.paella.opencast.episodesFromSeries This plugin shows a list of videos in the same series. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.episodesFromSeries plugin. { \"es.upv.paella.opencast.episodesFromSeries\": { \"enabled\": true } }","title":"es.upv.paella.opencast.episodesFromSeries"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.episodesFromSeries/#paella-plugin-esupvpaellaopencastepisodesfromseries","text":"This plugin shows a list of videos in the same series. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.episodesFromSeries"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.episodesFromSeries/#configuration","text":"You need to enabled the es.upv.paella.opencast.episodesFromSeries plugin. { \"es.upv.paella.opencast.episodesFromSeries\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/","text":"Paella plugin: es.upv.paella.opencast.loader This plugin configures how events are loaded into paella player. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Control which flavors to play An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure the streams property. The streams property is an array of rules. The first that matches is the one that will be applied. Each element in the array have two properties: filter : select which devices the rule applies to. Valid devices: Android, Linux, MacOS, Windows, iOS, iPad, iPhone, iPodTouch tracks : select which tracks to import into paella. tracks can be selected by flavors or tags Example: { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/*\"], \"tags\": [] } } ] } Multiple audio tracks An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. These tracks need to be m4a files. You need to configure the audioTag property. It is an object where the key is the flavor to configure and the value is the label that will be shown in the player interface. Example: Your mediapackage has three audio tracks for english, spanish and german languages { \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\", \"audio_de/delivery\" : \"de\" } } Selecting which video canvas to use You can configure which canvas to use in order to render video files. This is useful to enable 360 videos for example. Nowadays, paella has three video canvas you can use: video : Default rectangular canvas (This is used by default if no other canvas defined) video360 : 360 videos video360theta : 360 videos for Ricoh 360 cameras You need to configure the videoCanvas property. It is an object where the key is the flavor to configure and the value is the canvas to use. Example: { \"videoCanvas\": { \"*/delivery+360\": \"video360\", \"*/delivery+360Theta\": \"video360Theta\" } } Examples An institution wants to play only */delivery media tracks and has two audio tracks for English and Spanish languages { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/delivery\"], \"tags\": [] } } ], \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\" }, \"videoCanvas\": { \"*/delivery+360\": \"video360\", \"*/delivery+360Theta\": \"video360Theta\" } } } An institution wants to play sidebyside/delivery track on Android and iOS devices, and presenter/delivery and presentation/delivery on the other devices { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"Android\", \"iOS\"] }, \"tracks\": { \"flavors\": [\"sidebyside/delivery\"], \"tags\": [] } }, { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"presenter/delivery\", \"presentation/delivery\"], \"tags\": [] } } ], \"audioTag\": { }, \"videoCanvas\": { \"*/delivery+360\": \"video360\", \"*/delivery+360Theta\": \"video360Theta\" } } }","title":"es.upv.paella.opencast.loader"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#paella-plugin-esupvpaellaopencastloader","text":"This plugin configures how events are loaded into paella player. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.loader"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#control-which-flavors-to-play","text":"An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure the streams property. The streams property is an array of rules. The first that matches is the one that will be applied. Each element in the array have two properties: filter : select which devices the rule applies to. Valid devices: Android, Linux, MacOS, Windows, iOS, iPad, iPhone, iPodTouch tracks : select which tracks to import into paella. tracks can be selected by flavors or tags Example: { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/*\"], \"tags\": [] } } ] }","title":"Control which flavors to play"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#multiple-audio-tracks","text":"An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. These tracks need to be m4a files. You need to configure the audioTag property. It is an object where the key is the flavor to configure and the value is the label that will be shown in the player interface. Example: Your mediapackage has three audio tracks for english, spanish and german languages { \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\", \"audio_de/delivery\" : \"de\" } }","title":"Multiple audio tracks"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#selecting-which-video-canvas-to-use","text":"You can configure which canvas to use in order to render video files. This is useful to enable 360 videos for example. Nowadays, paella has three video canvas you can use: video : Default rectangular canvas (This is used by default if no other canvas defined) video360 : 360 videos video360theta : 360 videos for Ricoh 360 cameras You need to configure the videoCanvas property. It is an object where the key is the flavor to configure and the value is the canvas to use. Example: { \"videoCanvas\": { \"*/delivery+360\": \"video360\", \"*/delivery+360Theta\": \"video360Theta\" } }","title":"Selecting which video canvas to use"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#examples","text":"An institution wants to play only */delivery media tracks and has two audio tracks for English and Spanish languages { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/delivery\"], \"tags\": [] } } ], \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\" }, \"videoCanvas\": { \"*/delivery+360\": \"video360\", \"*/delivery+360Theta\": \"video360Theta\" } } } An institution wants to play sidebyside/delivery track on Android and iOS devices, and presenter/delivery and presentation/delivery on the other devices { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"Android\", \"iOS\"] }, \"tracks\": { \"flavors\": [\"sidebyside/delivery\"], \"tags\": [] } }, { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"presenter/delivery\", \"presentation/delivery\"], \"tags\": [] } } ], \"audioTag\": { }, \"videoCanvas\": { \"*/delivery+360\": \"video360\", \"*/delivery+360Theta\": \"video360Theta\" } } }","title":"Examples"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.logIn/","text":"Paella plugin: es.upv.paella.opencast.logIn This plugin adds a button to be able to login. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.logIn plugin. { \"es.upv.paella.opencast.logIn\": { \"enabled\": true } }","title":"es.upv.paella.opencast.logIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.logIn/#paella-plugin-esupvpaellaopencastlogin","text":"This plugin adds a button to be able to login. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.logIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.logIn/#configuration","text":"You need to enabled the es.upv.paella.opencast.logIn plugin. { \"es.upv.paella.opencast.logIn\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.searchPlugin/","text":"Paella plugin: es.upv.paella.opencast.searchPlugin This plugin enable searches using the OCR transcription. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.searchPlugin plugin. { \"es.upv.paella.opencast.searchPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.searchPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.searchPlugin/#paella-plugin-esupvpaellaopencastsearchplugin","text":"This plugin enable searches using the OCR transcription. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.searchPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.searchPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.searchPlugin plugin. { \"es.upv.paella.opencast.searchPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.transcriptionTabBarPlugin/","text":"Paella plugin: es.upv.paella.opencast.transcriptionTabBarPlugin This plugin adds a panel to show the OCR transcriptions. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.transcriptionTabBarPlugin plugin. { \"es.upv.paella.opencast.transcriptionTabBarPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.transcriptionTabBarPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.transcriptionTabBarPlugin/#paella-plugin-esupvpaellaopencasttranscriptiontabbarplugin","text":"This plugin adds a panel to show the OCR transcriptions. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.transcriptionTabBarPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.transcriptionTabBarPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.transcriptionTabBarPlugin plugin. { \"es.upv.paella.opencast.transcriptionTabBarPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.userTrackingSaverPlugIn/","text":"Paella plugin: es.upv.paella.opencast.userTrackingSaverPlugIn This plugin allows to use Opencast Usertracking Service to track usage data. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.userTrackingSaverPlugIn plugin. { \"es.upv.paella.opencast.userTrackingSaverPlugIn\": { \"enabled\": true } }","title":"es.upv.paella.opencast.userTrackingSaverPlugIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.userTrackingSaverPlugIn/#paella-plugin-esupvpaellaopencastusertrackingsaverplugin","text":"This plugin allows to use Opencast Usertracking Service to track usage data. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.userTrackingSaverPlugIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.userTrackingSaverPlugIn/#configuration","text":"You need to enabled the es.upv.paella.opencast.userTrackingSaverPlugIn plugin. { \"es.upv.paella.opencast.userTrackingSaverPlugIn\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/searchindex/","text":"Search Indexes Opencast comes with multiple search indexes which act both as a cache and as a fast way to perform full text searches on metadata. By default, the Solr search indexes are created automatically and no additional external software is required. For Elasticsearch, a separate installation is required since Opencast version 9.0. While this works well, all indexes can be deployed separately. This comes with the obvious drawback of a harder deployment but has also a few advantages like a smaller core system or being able to have some service redundancies which would not be possible otherwise. Solr is mostly powering older services and replacing this index type is planned for the future. But for now it is still the back-end for the search service (LTI and engage tools), the workflow service and the series service. Solr Configuration Guide Elasticsearch powers the external API as well as the administrative user interface of Opencast. Elasticsearch Configuration Guide","title":"Overview"},{"location":"modules/searchindex/#search-indexes","text":"Opencast comes with multiple search indexes which act both as a cache and as a fast way to perform full text searches on metadata. By default, the Solr search indexes are created automatically and no additional external software is required. For Elasticsearch, a separate installation is required since Opencast version 9.0. While this works well, all indexes can be deployed separately. This comes with the obvious drawback of a harder deployment but has also a few advantages like a smaller core system or being able to have some service redundancies which would not be possible otherwise. Solr is mostly powering older services and replacing this index type is planned for the future. But for now it is still the back-end for the search service (LTI and engage tools), the workflow service and the series service. Solr Configuration Guide Elasticsearch powers the external API as well as the administrative user interface of Opencast. Elasticsearch Configuration Guide","title":"Search Indexes"},{"location":"modules/searchindex/solr/","text":"Solr Configuration Opencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server. The software versions in these instructions are not the only versions that will work, they are just the version tested when this document was written. Newer versions of both Tomcat and Solr are highly recommended. Introduction Opencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In order to cluster services across multiple servers, we must provide shared storage solutions for each of these technologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If you plan on clustering either the workflow service or the search service, you must configure Opencast to use remote solr servers as described below, otherwise no further action is required. Obtaining the software Solr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat. $ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip $ unzip apache-tomcat-7.0.5.zip Download solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file doesn't retain proper unix permissions) $ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip $ unzip apache-solr-1.4.1.zip $ chmod 755 apache-tomcat-7.0.5/bin/* Deploy solr to tomcat Copy the solr example war file to tomcat's webapps directory and expand the war file. $ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/ Configure solr Add the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config from the search module. $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/search-service-impl/src/main/resources/solr solr Alternatively, if this is the solr index supporting the workflow service, copy those files instead: $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/workflow-service-impl/src/main/resources/solr solr Edit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files. Dependency of the workflow index The index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar file with that class within a directory named lib in the solr folder (you may need to create it if it does not exist). The .jar file can be the compiled solr bundle. Placing the jar in the main Tomcat lib directory does not work. Start the server $ bin/startup.sh Using CATALINA_BASE: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_HOME: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp Using JRE_HOME: /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home You should see that the solr server is running on http://localhost:8080/solr You can use the admin screen to monitor the server or make ad-hoc queries: Secure the solr server Just like with a relational database server, it is critical that you limit access to the solr server. Opencast's communication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP requests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to Opencast data from outside Opencast itself. Configure Opencast Set the URL to this solr server in Opencast's custom.properties file: org.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/ If this solr server is supporting clustered workflow services: org.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/ It is important to understand that a solr server provides exactly one schema, and one schema only. If you want to cluster both the workflow service and the search service, you will need two separate solr servers. These solr servers can run on the same machine, but each will needs its own servlet container and port.","title":"Solr"},{"location":"modules/searchindex/solr/#solr-configuration","text":"Opencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server. The software versions in these instructions are not the only versions that will work, they are just the version tested when this document was written. Newer versions of both Tomcat and Solr are highly recommended.","title":"Solr Configuration"},{"location":"modules/searchindex/solr/#introduction","text":"Opencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In order to cluster services across multiple servers, we must provide shared storage solutions for each of these technologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If you plan on clustering either the workflow service or the search service, you must configure Opencast to use remote solr servers as described below, otherwise no further action is required.","title":"Introduction"},{"location":"modules/searchindex/solr/#obtaining-the-software","text":"Solr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat. $ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip $ unzip apache-tomcat-7.0.5.zip Download solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file doesn't retain proper unix permissions) $ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip $ unzip apache-solr-1.4.1.zip $ chmod 755 apache-tomcat-7.0.5/bin/*","title":"Obtaining the software"},{"location":"modules/searchindex/solr/#deploy-solr-to-tomcat","text":"Copy the solr example war file to tomcat's webapps directory and expand the war file. $ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/","title":"Deploy solr to tomcat"},{"location":"modules/searchindex/solr/#configure-solr","text":"Add the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config from the search module. $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/search-service-impl/src/main/resources/solr solr Alternatively, if this is the solr index supporting the workflow service, copy those files instead: $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/workflow-service-impl/src/main/resources/solr solr Edit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.","title":"Configure solr"},{"location":"modules/searchindex/solr/#dependency-of-the-workflow-index","text":"The index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar file with that class within a directory named lib in the solr folder (you may need to create it if it does not exist). The .jar file can be the compiled solr bundle. Placing the jar in the main Tomcat lib directory does not work.","title":"Dependency of the workflow index"},{"location":"modules/searchindex/solr/#start-the-server","text":"$ bin/startup.sh Using CATALINA_BASE: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_HOME: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp Using JRE_HOME: /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home You should see that the solr server is running on http://localhost:8080/solr You can use the admin screen to monitor the server or make ad-hoc queries:","title":"Start the server"},{"location":"modules/searchindex/solr/#secure-the-solr-server","text":"Just like with a relational database server, it is critical that you limit access to the solr server. Opencast's communication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP requests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to Opencast data from outside Opencast itself.","title":"Secure the solr server"},{"location":"modules/searchindex/solr/#configure-opencast","text":"Set the URL to this solr server in Opencast's custom.properties file: org.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/ If this solr server is supporting clustered workflow services: org.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/ It is important to understand that a solr server provides exactly one schema, and one schema only. If you want to cluster both the workflow service and the search service, you will need two separate solr servers. These solr servers can run on the same machine, but each will needs its own servlet container and port.","title":"Configure Opencast"},{"location":"workflowoperationhandlers/","text":"Workflow Operation Handler Introduction Workflows are the central element to define how a media package is being processed by the Opencast services. Their definitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code: <definition xmlns=\"http://workflow.opencastproject.org\"> .... <operation id=\"tag\" <configurations> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> </configurations> </operation> ... </definition> Default Workflow Operations The following table contains the workflow operations that are available in an out-of-the-box Opencast installation: Operation Handler Description Details add-catalog Add a catalog to the media package Documentation analyze-audio Analyze first audio stream Documentation analyze-tracks Analyze tracks in media package Documentation animate Create animated video sequence Documentation amberscript-start-transcription Start AmberScript Transcription Documentation amberscript-attach-transcription Attach AmberScript Transcription Documentation asset-delete Deletes the current mediapackage from the Archive Documentation attach-watson-transcription Attaches automated transcripts to mediapackage Documentation cleanup Cleanup the working file repository Documentation clone Clone media package elements to another flavor Documentation comment Add, resolve or delete a comment Documentation composite Compose two videos on one canvas. Documentation concat Concatenate multiple video tracks into one video track Documentation conditional-config Configure workflow configuration variable based on coditions Documentation configure-by-dcterm Set workflow parameter if dublincore term matches value Documentation copy Copy media package elements to target directory Documentation cover-image Generate a cover-image containing metadata Documentation crop-video Checks for black bars on the sides of the video Documentation cut-marks-to-smil Parses timestamps into a SMIL for the editor workflow Documentation defaults Applies default workflow configuration values Documentation demux Demuxes streams to multiple output files Documentation duplicate-event Create an event by cloning an existing one Documentation editor Waiting for user to review, then cut video based on edit-list Documentation encode Encode media files to differents formats in parallel Documentation error-resolution Internal operation to pause a workflow in error Documentation execute-many Execute a command for each matching element in a MediaPackage Documentation execute-once Execute a command for a MediaPackage Documentation export-wf-properties Export workflow properties Documentation extract-text Extracting text from presentation segments Documentation failing Operations that always fails Documentation google-speech-attach-transcription Attaches automated transcripts to mediapackage Documentation google-speech-start-transcription Starts automated transcription provided by Google Speech Documentation http-notify Notifies an HTTP endpoint about the process of the workflow Documentation image Extract images from a video using FFmpeg Documentation image-convert Convert images using FFmpeg Documentation image-to-video Create a video track from a source image Documentation import-wf-properties Import workflow properties Documentation incident Testing incidents on a dummy job Documentation include Include workflow definition in current workflow Documentation ingest-download Download files from external URL for ingest Documentation inspect Inspect the media (check if it is valid) Documentation log Log workflow status Documentation multiencode Encode to multiple profiles in one operation Documentation normalize-audio Normalize first audio stream Documentation partial-import Import partial tracks and process according to a SMIL document Documentation post-mediapackage Send mediapackage to remote service Documentation prepare-av Preparing audio and video work versions Documentation probe-resolution Set workflow instance variables based on video resolution Documentation process-smil Edit and Encode media defined by a SMIL file Documentation publish-aws Distribute and publish media to Amazon S3 and Cloudfront Documentation publish-configure Distribute and publish media to the configured publication Documentation publish-engage Distribute and publish media to the engage player Documentation publish-oaipmh Distribute and publish media to a OAI-PMH repository Documentation publish-youtube Distribute and publish media to YouTube Documentation republish-oaipmh Update media in a OAI-PMH repository Documentation retract-aws Retracts media from AWS S3 and Cloudfront publication Documentation retract-configure Retracts media from configured publication Documentation retract-engage Retracts media from Opencast Media Module publication Documentation retract-oaipmh Retracts media from a OAI-PMH repository Documentation retract-partial Retract a subset of the mediapackage from a publication Documentation retract-youtube Retracts media from YouTube Documentation segment-video Extracting segments from presentation Documentation segmentpreviews Extract segment images from a video using FFmpeg Documentation select-streams Select streams for further processing Documentation send-email Sends email notifications at any part of a workflow Documentation series Apply series to the mediapackage Documentation silence Silence detection on audio of the mediapackage Documentation snapshot Archive the current state of the mediapackage Documentation start-watson-transcription Starts automated transcription provided by IBM Watson Documentation start-workflow Start a new workflow for given media package ID Documentation statistics-writer Log statistical data about the video Documentation tag Modify the tag sets of media package elements Documentation tag-by-dcterm Modify the tags if dublincore term matches value Documentation theme Make settings of themes available to processing Documentation timelinepreviews Create a preview image stream from a given video track Documentation transfer-metadata Transfer metadata fields between catalogs Documentation waveform Create a waveform image of the audio of the mediapackage Documentation zip Create zipped archive of the current state of the mediapackage Documentation State Mappings Technically, a workflow can be in one of the following states: Technical State Description What the Admin UI displays in the events table instantiated The workflow is queued and will be started as soon as possible \"Pending\" running The workflow is running, no problems so far \"Running\" stopped The workflow was aborted by the user \"Processing canceled\" paused The workflow was paused and can be continued \"Paused\" succeeded The workflow has completed successfully \"Finished\" failed The workflow failed due to an error \"Processing failure\" failing The workflow is still running, but there were errors. It will fail. \"Running\" Using state mappings, it is possible to refine the labels displayed in the Admin UI events table for a particular workflow. Here is an example which displays \"Retracting\" instead of \"Running\" for the retract workflow: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definition xmlns=\"http://workflow.opencastproject.org\"> <id>retract</id> ... <state-mappings> <state-mapping state=\"running\">retracting</state-mapping> <state-mapping state=\"failing\">retracting</state-mapping> </state-mappings> When no state mappings are configured for a workflow, the generic default labels will be displayed. When a workflow includes other workflows, the event table only shows the state of the including workflow.","title":"Overview"},{"location":"workflowoperationhandlers/#workflow-operation-handler","text":"","title":"Workflow Operation Handler"},{"location":"workflowoperationhandlers/#introduction","text":"Workflows are the central element to define how a media package is being processed by the Opencast services. Their definitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code: <definition xmlns=\"http://workflow.opencastproject.org\"> .... <operation id=\"tag\" <configurations> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> </configurations> </operation> ... </definition>","title":"Introduction"},{"location":"workflowoperationhandlers/#default-workflow-operations","text":"The following table contains the workflow operations that are available in an out-of-the-box Opencast installation: Operation Handler Description Details add-catalog Add a catalog to the media package Documentation analyze-audio Analyze first audio stream Documentation analyze-tracks Analyze tracks in media package Documentation animate Create animated video sequence Documentation amberscript-start-transcription Start AmberScript Transcription Documentation amberscript-attach-transcription Attach AmberScript Transcription Documentation asset-delete Deletes the current mediapackage from the Archive Documentation attach-watson-transcription Attaches automated transcripts to mediapackage Documentation cleanup Cleanup the working file repository Documentation clone Clone media package elements to another flavor Documentation comment Add, resolve or delete a comment Documentation composite Compose two videos on one canvas. Documentation concat Concatenate multiple video tracks into one video track Documentation conditional-config Configure workflow configuration variable based on coditions Documentation configure-by-dcterm Set workflow parameter if dublincore term matches value Documentation copy Copy media package elements to target directory Documentation cover-image Generate a cover-image containing metadata Documentation crop-video Checks for black bars on the sides of the video Documentation cut-marks-to-smil Parses timestamps into a SMIL for the editor workflow Documentation defaults Applies default workflow configuration values Documentation demux Demuxes streams to multiple output files Documentation duplicate-event Create an event by cloning an existing one Documentation editor Waiting for user to review, then cut video based on edit-list Documentation encode Encode media files to differents formats in parallel Documentation error-resolution Internal operation to pause a workflow in error Documentation execute-many Execute a command for each matching element in a MediaPackage Documentation execute-once Execute a command for a MediaPackage Documentation export-wf-properties Export workflow properties Documentation extract-text Extracting text from presentation segments Documentation failing Operations that always fails Documentation google-speech-attach-transcription Attaches automated transcripts to mediapackage Documentation google-speech-start-transcription Starts automated transcription provided by Google Speech Documentation http-notify Notifies an HTTP endpoint about the process of the workflow Documentation image Extract images from a video using FFmpeg Documentation image-convert Convert images using FFmpeg Documentation image-to-video Create a video track from a source image Documentation import-wf-properties Import workflow properties Documentation incident Testing incidents on a dummy job Documentation include Include workflow definition in current workflow Documentation ingest-download Download files from external URL for ingest Documentation inspect Inspect the media (check if it is valid) Documentation log Log workflow status Documentation multiencode Encode to multiple profiles in one operation Documentation normalize-audio Normalize first audio stream Documentation partial-import Import partial tracks and process according to a SMIL document Documentation post-mediapackage Send mediapackage to remote service Documentation prepare-av Preparing audio and video work versions Documentation probe-resolution Set workflow instance variables based on video resolution Documentation process-smil Edit and Encode media defined by a SMIL file Documentation publish-aws Distribute and publish media to Amazon S3 and Cloudfront Documentation publish-configure Distribute and publish media to the configured publication Documentation publish-engage Distribute and publish media to the engage player Documentation publish-oaipmh Distribute and publish media to a OAI-PMH repository Documentation publish-youtube Distribute and publish media to YouTube Documentation republish-oaipmh Update media in a OAI-PMH repository Documentation retract-aws Retracts media from AWS S3 and Cloudfront publication Documentation retract-configure Retracts media from configured publication Documentation retract-engage Retracts media from Opencast Media Module publication Documentation retract-oaipmh Retracts media from a OAI-PMH repository Documentation retract-partial Retract a subset of the mediapackage from a publication Documentation retract-youtube Retracts media from YouTube Documentation segment-video Extracting segments from presentation Documentation segmentpreviews Extract segment images from a video using FFmpeg Documentation select-streams Select streams for further processing Documentation send-email Sends email notifications at any part of a workflow Documentation series Apply series to the mediapackage Documentation silence Silence detection on audio of the mediapackage Documentation snapshot Archive the current state of the mediapackage Documentation start-watson-transcription Starts automated transcription provided by IBM Watson Documentation start-workflow Start a new workflow for given media package ID Documentation statistics-writer Log statistical data about the video Documentation tag Modify the tag sets of media package elements Documentation tag-by-dcterm Modify the tags if dublincore term matches value Documentation theme Make settings of themes available to processing Documentation timelinepreviews Create a preview image stream from a given video track Documentation transfer-metadata Transfer metadata fields between catalogs Documentation waveform Create a waveform image of the audio of the mediapackage Documentation zip Create zipped archive of the current state of the mediapackage Documentation","title":"Default Workflow Operations"},{"location":"workflowoperationhandlers/#state-mappings","text":"Technically, a workflow can be in one of the following states: Technical State Description What the Admin UI displays in the events table instantiated The workflow is queued and will be started as soon as possible \"Pending\" running The workflow is running, no problems so far \"Running\" stopped The workflow was aborted by the user \"Processing canceled\" paused The workflow was paused and can be continued \"Paused\" succeeded The workflow has completed successfully \"Finished\" failed The workflow failed due to an error \"Processing failure\" failing The workflow is still running, but there were errors. It will fail. \"Running\" Using state mappings, it is possible to refine the labels displayed in the Admin UI events table for a particular workflow. Here is an example which displays \"Retracting\" instead of \"Running\" for the retract workflow: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definition xmlns=\"http://workflow.opencastproject.org\"> <id>retract</id> ... <state-mappings> <state-mapping state=\"running\">retracting</state-mapping> <state-mapping state=\"failing\">retracting</state-mapping> </state-mappings> When no state mappings are configured for a workflow, the generic default labels will be displayed. When a workflow includes other workflows, the event table only shows the state of the including workflow.","title":"State Mappings"},{"location":"workflowoperationhandlers/add-catalog-woh/","text":"AddCatalogWorkflowOperationHandler Description This operation adds a catalog to the media package of the running workflow. The catalog to add is specified by path. Additionally the name, flavor and tags of the catalog can be configured. If a catalog of the same flavor already exits in the media package, the parameter catalog-type-collision-behavior specifies how this case is handled. Parameter Table Configuration Key Example Description catalog-path ${karaf.etc}/catalogs/default_dublincore.xml Path to the catalog catalog-flavor dublincore/episode Flavor of the catalog catalog-name dublincore.xml Name of the catalog catalog-tags archive,dublincore List of tags, separated by commas catalog-type-collision-behavior keep How a collision is handled (more information below) All parameters are mandatory except catalog-tags . catalog-type-collision-behavior If the flavor of the new catalog and the flavor of an already existing catalog match, the catalog-type-collision-behavior specifies how this situation is handled. There are multiple supported options: - keep : The new catalog is added despite the collision. This results in two catalogs of the same type coexisting. - skip : The addition of the new catalog is skipped, the new catalog is not added. - fail : The workflow operation fails with an error, depending on the your configurations the complete workflow is aborted. Operation Example <operation id=\"add-catalog\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Add catalog to media package\"> <configurations> <configuration key=\"catalog-path\">${karaf.etc}/catalogs/default_dublincore.xml</configuration> <configuration key=\"catalog-flavor\">dublincore/episode</configuration> <configuration key=\"catalog-name\">dublincore.xml</configuration> <configuration key=\"catalog-tags\">archive,dublincore</configuration> <configuration key=\"catalog-type-collision-behavior\">keep</configuration> </configurations> </operation>","title":"Add Catalog"},{"location":"workflowoperationhandlers/add-catalog-woh/#addcatalogworkflowoperationhandler","text":"","title":"AddCatalogWorkflowOperationHandler"},{"location":"workflowoperationhandlers/add-catalog-woh/#description","text":"This operation adds a catalog to the media package of the running workflow. The catalog to add is specified by path. Additionally the name, flavor and tags of the catalog can be configured. If a catalog of the same flavor already exits in the media package, the parameter catalog-type-collision-behavior specifies how this case is handled.","title":"Description"},{"location":"workflowoperationhandlers/add-catalog-woh/#parameter-table","text":"Configuration Key Example Description catalog-path ${karaf.etc}/catalogs/default_dublincore.xml Path to the catalog catalog-flavor dublincore/episode Flavor of the catalog catalog-name dublincore.xml Name of the catalog catalog-tags archive,dublincore List of tags, separated by commas catalog-type-collision-behavior keep How a collision is handled (more information below) All parameters are mandatory except catalog-tags .","title":"Parameter Table"},{"location":"workflowoperationhandlers/add-catalog-woh/#catalog-type-collision-behavior","text":"If the flavor of the new catalog and the flavor of an already existing catalog match, the catalog-type-collision-behavior specifies how this situation is handled. There are multiple supported options: - keep : The new catalog is added despite the collision. This results in two catalogs of the same type coexisting. - skip : The addition of the new catalog is skipped, the new catalog is not added. - fail : The workflow operation fails with an error, depending on the your configurations the complete workflow is aborted.","title":"catalog-type-collision-behavior"},{"location":"workflowoperationhandlers/add-catalog-woh/#operation-example","text":"<operation id=\"add-catalog\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Add catalog to media package\"> <configurations> <configuration key=\"catalog-path\">${karaf.etc}/catalogs/default_dublincore.xml</configuration> <configuration key=\"catalog-flavor\">dublincore/episode</configuration> <configuration key=\"catalog-name\">dublincore.xml</configuration> <configuration key=\"catalog-tags\">archive,dublincore</configuration> <configuration key=\"catalog-type-collision-behavior\">keep</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/amberscript-attach-transcription-woh/","text":"AmberScript Attach Transcription Description AmberScript Attach Transcription workflow operation attaches the result file received from the Transcription Service to the media package. Parameter Table configuration keys description default example transcription-job-id This is filled out by the transcription service when starting the workflow. ${transcriptionJobId} Should always be \"${transcriptionJobId}\" target-flavor The flavor to apply to the captions/transcriptions file. Optional. captions/vtt captions/vtt+en target-tag The tag to apply to the caption/transcription file generated. Optional. - engage-download target-caption-format The caption format to be generated. vtt srt","title":"AmberScript Attach Transcription"},{"location":"workflowoperationhandlers/amberscript-attach-transcription-woh/#amberscript-attach-transcription","text":"","title":"AmberScript Attach Transcription"},{"location":"workflowoperationhandlers/amberscript-attach-transcription-woh/#description","text":"AmberScript Attach Transcription workflow operation attaches the result file received from the Transcription Service to the media package.","title":"Description"},{"location":"workflowoperationhandlers/amberscript-attach-transcription-woh/#parameter-table","text":"configuration keys description default example transcription-job-id This is filled out by the transcription service when starting the workflow. ${transcriptionJobId} Should always be \"${transcriptionJobId}\" target-flavor The flavor to apply to the captions/transcriptions file. Optional. captions/vtt captions/vtt+en target-tag The tag to apply to the caption/transcription file generated. Optional. - engage-download target-caption-format The caption format to be generated. vtt srt","title":"Parameter Table"},{"location":"workflowoperationhandlers/amberscript-start-transcription-woh/","text":"AmberScript Start Transcription Description AmberScript Start Transcription invokes the AmberScript Transcription Service by submitting an audio or video file to be transcribed and captioned. Parameter Table configuration keys description default example source-tag A tag selecting the audio or video file to be sent for translation/transcription. - engage-download source-flavor A flavor selecting the audio or video file to be sent for translation/transcription. - */themed jobtype direct (automated, fast) or perfect (additional manual improvements, slow) direct perfect language The target language for transcription. en nl skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. captions/vtt captions/timedtext Supported Languages At time of writing Amberscript supports the following language codes: da de en es fi fr nl no sv","title":"AmberScript Start Transcription"},{"location":"workflowoperationhandlers/amberscript-start-transcription-woh/#amberscript-start-transcription","text":"","title":"AmberScript Start Transcription"},{"location":"workflowoperationhandlers/amberscript-start-transcription-woh/#description","text":"AmberScript Start Transcription invokes the AmberScript Transcription Service by submitting an audio or video file to be transcribed and captioned.","title":"Description"},{"location":"workflowoperationhandlers/amberscript-start-transcription-woh/#parameter-table","text":"configuration keys description default example source-tag A tag selecting the audio or video file to be sent for translation/transcription. - engage-download source-flavor A flavor selecting the audio or video file to be sent for translation/transcription. - */themed jobtype direct (automated, fast) or perfect (additional manual improvements, slow) direct perfect language The target language for transcription. en nl skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. captions/vtt captions/timedtext","title":"Parameter Table"},{"location":"workflowoperationhandlers/amberscript-start-transcription-woh/#supported-languages","text":"At time of writing Amberscript supports the following language codes: da de en es fi fr nl no sv","title":"Supported Languages"},{"location":"workflowoperationhandlers/analyze-tracks-woh/","text":"AnalyzeTracksWorkflowOperationHandler Description The AnalyzeTracksWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the tracks audio and video properties. These variables can then be used to control if workflow operations should be executed. Note that this operation should be preceded by the inspect workflow operation handler. For all tracks matching the flavor specified by the mandatory configuration key source-flavor , the following workflow instance variables may be set: Name Example Description flavor _media presenter_source_media=true Track with specific favor exists flavor _audio presenter_source_audio=true Track contains at least one audio stream flavor _video presenter_source_video=true Track contains at least one video stream flavor _resolution_x presenter_source_resolution_x=1280 Horizontal resolution of the video stream flavor _resolution_y presenter_source_resolution_y=720 Vertical resolution of the video stream flavor _aspect presenter_source_aspect=4/3 Exact aspect ratio of the video stream flavor _aspect_snap presenter_source_aspect_snap=4/3 Nearest specified aspect ratio of the video flavor _framerate presenter_source_framerate=30.0 Framerate of the video stream Parameter Table Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input aspect-ratio 4/3,16/9 Snap to these aspect ratios if specified fail-no-tracks false Fail if flavor matches no tracks (Default: false) * mandatory configuration key Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken. Snap to Aspect Ratio Snap-to-aspect can be used to deal with slightly off resolutions. Given an SAR of 1, for example, a video with the resolution of 640x481 pixels has almost an aspect ration of 4/3, but is 1 pixel too wide. For special encoding options or cover generation, it would still be reasonable to use the 4/3 settings. If 4/3 is listed in the aspect-ratio option, \u2026_aspect_snap would be set to 4/3. Operation Example <operation id=\"analyze-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Analyze tracks in media package and set control variables\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"aspect-ratio\">4/3,16/9</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 and an included audio stream is passed to this operation as presentiation/source , the resulting variables would be: presentation_source_aspect=16/9 presentation_source_aspect_snap=16/9 presentation_source_audio=true presentation_source_media=true presentation_source_resolution_x=1280 presentation_source_resolution_y=720 presentation_source_video=true presentation_source_framerate=30.0","title":"Analyze Tracks"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#analyzetracksworkflowoperationhandler","text":"","title":"AnalyzeTracksWorkflowOperationHandler"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#description","text":"The AnalyzeTracksWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the tracks audio and video properties. These variables can then be used to control if workflow operations should be executed. Note that this operation should be preceded by the inspect workflow operation handler. For all tracks matching the flavor specified by the mandatory configuration key source-flavor , the following workflow instance variables may be set: Name Example Description flavor _media presenter_source_media=true Track with specific favor exists flavor _audio presenter_source_audio=true Track contains at least one audio stream flavor _video presenter_source_video=true Track contains at least one video stream flavor _resolution_x presenter_source_resolution_x=1280 Horizontal resolution of the video stream flavor _resolution_y presenter_source_resolution_y=720 Vertical resolution of the video stream flavor _aspect presenter_source_aspect=4/3 Exact aspect ratio of the video stream flavor _aspect_snap presenter_source_aspect_snap=4/3 Nearest specified aspect ratio of the video flavor _framerate presenter_source_framerate=30.0 Framerate of the video stream","title":"Description"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input aspect-ratio 4/3,16/9 Snap to these aspect ratios if specified fail-no-tracks false Fail if flavor matches no tracks (Default: false) * mandatory configuration key Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken.","title":"Parameter Table"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#snap-to-aspect-ratio","text":"Snap-to-aspect can be used to deal with slightly off resolutions. Given an SAR of 1, for example, a video with the resolution of 640x481 pixels has almost an aspect ration of 4/3, but is 1 pixel too wide. For special encoding options or cover generation, it would still be reasonable to use the 4/3 settings. If 4/3 is listed in the aspect-ratio option, \u2026_aspect_snap would be set to 4/3.","title":"Snap to Aspect Ratio"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#operation-example","text":"<operation id=\"analyze-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Analyze tracks in media package and set control variables\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"aspect-ratio\">4/3,16/9</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 and an included audio stream is passed to this operation as presentiation/source , the resulting variables would be: presentation_source_aspect=16/9 presentation_source_aspect_snap=16/9 presentation_source_audio=true presentation_source_media=true presentation_source_resolution_x=1280 presentation_source_resolution_y=720 presentation_source_video=true presentation_source_framerate=30.0","title":"Operation Example"},{"location":"workflowoperationhandlers/analyzeaudio-woh/","text":"AnalyzeAudioWorkflowOperationHandler Description The AnalyzeAudioWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track. This workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs: Used with Audio only file (forceTranscode is deactivated): Analyze the given audio file with SoX Write analyzed audio metadata back to the given track's mediapackage. Used with Video file or with Audio only file with forceTranscode activated: Extract audio file encoded as FLAC audio and save it temporary in a collection Analyze the previous encoded audio file with SoX Write analyzed audio metadata back to the given track's mediapackage. Delete the temporary encoded FLAC audio file Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track type=\"presentation/audio\" id=\"audio\"> <mimetype>video/x-flac</mimetype> <tags /> <url>fooVideo.flac</url> <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum> <duration>65680</duration> <audio id=\"audio-1\"> <device /> <encoder type=\"ADPCM\" /> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>62500.0</bitrate> <peakleveldb>-30</peakleveldb> <!-- NEW --> <rmsleveldb>-20</rmsleveldb> <!-- NEW --> <rmspeakdb>-10</rmspeakdb> <!-- NEW --> </audio> </track> Parameter Table configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE Operation Example <operation id=\"analyze-audio\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Analyze audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Analyze Audio"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#analyzeaudioworkflowoperationhandler","text":"","title":"AnalyzeAudioWorkflowOperationHandler"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#description","text":"The AnalyzeAudioWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track. This workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:","title":"Description"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated","text":"Analyze the given audio file with SoX Write analyzed audio metadata back to the given track's mediapackage.","title":"Used with Audio only file (forceTranscode is deactivated):"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#used-with-video-file-or-with-audio-only-file-with-forcetranscode-activated","text":"Extract audio file encoded as FLAC audio and save it temporary in a collection Analyze the previous encoded audio file with SoX Write analyzed audio metadata back to the given track's mediapackage. Delete the temporary encoded FLAC audio file Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track type=\"presentation/audio\" id=\"audio\"> <mimetype>video/x-flac</mimetype> <tags /> <url>fooVideo.flac</url> <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum> <duration>65680</duration> <audio id=\"audio-1\"> <device /> <encoder type=\"ADPCM\" /> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>62500.0</bitrate> <peakleveldb>-30</peakleveldb> <!-- NEW --> <rmsleveldb>-20</rmsleveldb> <!-- NEW --> <rmspeakdb>-10</rmspeakdb> <!-- NEW --> </audio> </track>","title":"Used with Video file or with Audio only file with forceTranscode activated:"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#parameter-table","text":"configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE","title":"Parameter Table"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#operation-example","text":"<operation id=\"analyze-audio\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Analyze audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/animate-woh/","text":"Animate Workflow Operation ID: animate Description The animate operation can be used to generate an animated video clip using Synfig . It can automatically including episode and series metadata (e.g. the title) into the animation. For example, this can be used to automatically generate custom intro videos. Parameter Table configuration keys required description animation-files yes The source animation file to use target-flavor yes Flavor of the generated video width no Width of the generated video height no Height of the generated video fps no FPS of the generated video cmd-args no Custom synfig arguments. Will override all arguments except input and output file target-tags no Tags for the generated video Synfig Files Synfig animation files used for input must be saved uncompressed or the metadata replacement will not work. Uncompressed files usually have the file extension .sif and not .sifz . Metadata Replacements You can use all metadata fields present in the episode and series DublinCore catalogs of an event. In SynfigStudio, just use placeholders of the following form: '{{' ['series' | 'episode'] '.' DC-FIELD '}}' Here are some common examples: {{episode.title}} {{episode.creator}} {{series.title}} Operation Examples <operation id=\"animate\" description=\"Create animated video clip\"> <configurations> <configuration key=\"animation-file\">/path/to/animation.sif</configuration> <configuration key=\"target-flavor\">presentation/intro</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Animate"},{"location":"workflowoperationhandlers/animate-woh/#animate-workflow-operation","text":"ID: animate","title":"Animate Workflow Operation"},{"location":"workflowoperationhandlers/animate-woh/#description","text":"The animate operation can be used to generate an animated video clip using Synfig . It can automatically including episode and series metadata (e.g. the title) into the animation. For example, this can be used to automatically generate custom intro videos.","title":"Description"},{"location":"workflowoperationhandlers/animate-woh/#parameter-table","text":"configuration keys required description animation-files yes The source animation file to use target-flavor yes Flavor of the generated video width no Width of the generated video height no Height of the generated video fps no FPS of the generated video cmd-args no Custom synfig arguments. Will override all arguments except input and output file target-tags no Tags for the generated video","title":"Parameter Table"},{"location":"workflowoperationhandlers/animate-woh/#synfig-files","text":"Synfig animation files used for input must be saved uncompressed or the metadata replacement will not work. Uncompressed files usually have the file extension .sif and not .sifz .","title":"Synfig Files"},{"location":"workflowoperationhandlers/animate-woh/#metadata-replacements","text":"You can use all metadata fields present in the episode and series DublinCore catalogs of an event. In SynfigStudio, just use placeholders of the following form: '{{' ['series' | 'episode'] '.' DC-FIELD '}}' Here are some common examples: {{episode.title}} {{episode.creator}} {{series.title}}","title":"Metadata Replacements"},{"location":"workflowoperationhandlers/animate-woh/#operation-examples","text":"<operation id=\"animate\" description=\"Create animated video clip\"> <configurations> <configuration key=\"animation-file\">/path/to/animation.sif</configuration> <configuration key=\"target-flavor\">presentation/intro</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/asset-delete-woh/","text":"AssetManagerDeleteWorkflowOperationHandler Description The delete handler is responsible for deleting an episode, identified by the workflow\u2019s current media package, from the asset manager. If no parameter is given, the whole episode and all of its snapshots are deleted. If the keep-last-snapshot parameter is used, it is advised to use the ingest-download workflow before asset-delete . Otherwise there will be logged a lot of errors for unreferenced snapshots and ACLs may vanish. Parameter Table Configuration Key Example Description keep-last-snapshot true Deletes every snapshot except the last one. Operation Example <operation id=\"asset-delete\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Delete from AssetManager\"> <configurations> <configuration key=\"keep-last-snapshot\">true</configuration> </configurations> </operation>","title":"Asset Delete"},{"location":"workflowoperationhandlers/asset-delete-woh/#assetmanagerdeleteworkflowoperationhandler","text":"","title":"AssetManagerDeleteWorkflowOperationHandler"},{"location":"workflowoperationhandlers/asset-delete-woh/#description","text":"The delete handler is responsible for deleting an episode, identified by the workflow\u2019s current media package, from the asset manager. If no parameter is given, the whole episode and all of its snapshots are deleted. If the keep-last-snapshot parameter is used, it is advised to use the ingest-download workflow before asset-delete . Otherwise there will be logged a lot of errors for unreferenced snapshots and ACLs may vanish.","title":"Description"},{"location":"workflowoperationhandlers/asset-delete-woh/#parameter-table","text":"Configuration Key Example Description keep-last-snapshot true Deletes every snapshot except the last one.","title":"Parameter Table"},{"location":"workflowoperationhandlers/asset-delete-woh/#operation-example","text":"<operation id=\"asset-delete\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Delete from AssetManager\"> <configurations> <configuration key=\"keep-last-snapshot\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/","text":"Attach Watson Transcription Description The Attach Watson Transcription converts the results file received from the IBM Watson Speech-to-Text service in json format, converts it to the desired caption format, and adds it to the media package. Parameter Table configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" target-flavor The flavor of the caption/transcription file generated. Mandatory only if target-caption-format not informed. captions/ target-caption-format + language captions/vtt+en target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package with the flavor target-flavor . EMPTY vtt Example <!-- Attach caption/transcript --> <operation id=\"attach-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow so just use this as is --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"target-tag\">archive</configuration> <!-- Caption generated will have the default flavor based on the target-caption-format and language e.g. captions/vtt+en --> <configuration key=\"target-caption-format\">vtt</configuration> <configuration key=\"target-tag\">engage-download</configuration> </configurations> </operation> <!-- Merge caption/transcript to existing publication and republish --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-tags\">engage-download</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Attach Watson Transcription"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#attach-watson-transcription","text":"","title":"Attach Watson Transcription"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#description","text":"The Attach Watson Transcription converts the results file received from the IBM Watson Speech-to-Text service in json format, converts it to the desired caption format, and adds it to the media package.","title":"Description"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#parameter-table","text":"configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" target-flavor The flavor of the caption/transcription file generated. Mandatory only if target-caption-format not informed. captions/ target-caption-format + language captions/vtt+en target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package with the flavor target-flavor . EMPTY vtt","title":"Parameter Table"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#example","text":"<!-- Attach caption/transcript --> <operation id=\"attach-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow so just use this as is --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"target-tag\">archive</configuration> <!-- Caption generated will have the default flavor based on the target-caption-format and language e.g. captions/vtt+en --> <configuration key=\"target-caption-format\">vtt</configuration> <configuration key=\"target-tag\">engage-download</configuration> </configurations> </operation> <!-- Merge caption/transcript to existing publication and republish --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-tags\">engage-download</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/cleanup-woh/","text":"CleanupWorkflowOperationHandler Description This operation removes all files from the workspace and the working file repository which belong to media package elements of the running workflow unless their flavor is matched by the value configured in preserve-flavors . It is usually used as last workflow operation in a workflow to ensure that temporary processing artefacts are removed. Parameter Table Configuration Key Example Description Default preserve-flavors security/* Comma-separated list of flavors to be preserved. delete-external true If files from external working file repositories should be deleted false delay 5 Seconds to wait before removing files 1 Notes If delete-external is set to true , the externally referenced media package elements will be removed from its source where the value of preserve-flavors does not match If you have an shared working file repository setting delete-external to false will speed up the cleanup process while still removing all files. Operation Example <operation id=\"cleanup\" fail-on-error=\"false\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"preserve-flavors\">security/*</configuration> <configuration key=\"delete-external\">true</configuration> <configuration key=\"delay\">5</configuration> </configurations> </operation>","title":"Cleanup"},{"location":"workflowoperationhandlers/cleanup-woh/#cleanupworkflowoperationhandler","text":"","title":"CleanupWorkflowOperationHandler"},{"location":"workflowoperationhandlers/cleanup-woh/#description","text":"This operation removes all files from the workspace and the working file repository which belong to media package elements of the running workflow unless their flavor is matched by the value configured in preserve-flavors . It is usually used as last workflow operation in a workflow to ensure that temporary processing artefacts are removed.","title":"Description"},{"location":"workflowoperationhandlers/cleanup-woh/#parameter-table","text":"Configuration Key Example Description Default preserve-flavors security/* Comma-separated list of flavors to be preserved. delete-external true If files from external working file repositories should be deleted false delay 5 Seconds to wait before removing files 1","title":"Parameter Table"},{"location":"workflowoperationhandlers/cleanup-woh/#notes","text":"If delete-external is set to true , the externally referenced media package elements will be removed from its source where the value of preserve-flavors does not match If you have an shared working file repository setting delete-external to false will speed up the cleanup process while still removing all files.","title":"Notes"},{"location":"workflowoperationhandlers/cleanup-woh/#operation-example","text":"<operation id=\"cleanup\" fail-on-error=\"false\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"preserve-flavors\">security/*</configuration> <configuration key=\"delete-external\">true</configuration> <configuration key=\"delay\">5</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/clone-woh/","text":"Clone Workflow Operation ID: clone Description The clone workflow operation can be used to clone media package elements. Parameter Table Configuration Key Example Description source-flavor presenter/source The source flavor(s) to clone source-tags archive Comma-separated list of source-tags target-flavor* presenter/target The target flavor * mandatory configuration key Notes: source-flavor and source-tags may be used both together to select media package elements based on both flavors and tags If source-flavor is not specified, all media package elements matching source-tags will be selected In case that neither source-flavor nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavor and source-tags , the operation will be skipped Source Flavor If source-flavor is specified as e.g. */source , all matching media package elements will be cloned and have the new flavor <original-flavor>/target . Target Flavor If target-flavor is specified as e.g. */target , the target flavors will have the subtype target and the type from the source If target-flavor is specified as e.g. target/* , the target flavors will have the type target and the subtype from the source. Operation Example <operation id=\"clone\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"target-flavor\">*/target</configuration> </configurations> </operation>","title":"Clone"},{"location":"workflowoperationhandlers/clone-woh/#clone-workflow-operation","text":"ID: clone","title":"Clone Workflow Operation"},{"location":"workflowoperationhandlers/clone-woh/#description","text":"The clone workflow operation can be used to clone media package elements.","title":"Description"},{"location":"workflowoperationhandlers/clone-woh/#parameter-table","text":"Configuration Key Example Description source-flavor presenter/source The source flavor(s) to clone source-tags archive Comma-separated list of source-tags target-flavor* presenter/target The target flavor * mandatory configuration key Notes: source-flavor and source-tags may be used both together to select media package elements based on both flavors and tags If source-flavor is not specified, all media package elements matching source-tags will be selected In case that neither source-flavor nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavor and source-tags , the operation will be skipped","title":"Parameter Table"},{"location":"workflowoperationhandlers/clone-woh/#source-flavor","text":"If source-flavor is specified as e.g. */source , all matching media package elements will be cloned and have the new flavor <original-flavor>/target .","title":"Source Flavor"},{"location":"workflowoperationhandlers/clone-woh/#target-flavor","text":"If target-flavor is specified as e.g. */target , the target flavors will have the subtype target and the type from the source If target-flavor is specified as e.g. target/* , the target flavors will have the type target and the subtype from the source.","title":"Target Flavor"},{"location":"workflowoperationhandlers/clone-woh/#operation-example","text":"<operation id=\"clone\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"target-flavor\">*/target</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/comment-woh/","text":"CommentWorkflowOperationHandler Description The CommentWorkflowOperationHandler can be used to create, resolve or delete comments for events within workflows. Parameter Table Configuration Key Example Description action create Action to be performed: create, resolve or delete. Default value is create. reason EVENTS.EVENTS.DETAILS. COMMENTS.REASONS.CUTTING The comment reason's i18n id. You can find the id in etc/listproviders/ event.comment.reasons.properties description Recording has not been cut yet. The description text to add to the comment. Notes: reason and description must be provided for the create action. create will not create duplicate comments: if there is already a comment with the same reason and description, a new comment will not be created. resolve and delete will perform no action if no comment matches the provided parameters (reason, description, or reason and description). If more than one comment matches the parameters, only the first matching comment will be resolved or deleted. Operation Examples Create a comment: <operation id=\"comment\" description=\"Mark the recording for cutting\"> <configurations> <configuration key=\"action\">create</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> <configuration key=\"description\">Recording has not been cut yet.</configuration> </configurations> </operation> Resolve a comment: <operation id=\"comment\" description=\"Resolve the cutting flag\"> <configurations> <configuration key=\"action\">resolve</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> </configurations> </operation>","title":"Comment"},{"location":"workflowoperationhandlers/comment-woh/#commentworkflowoperationhandler","text":"","title":"CommentWorkflowOperationHandler"},{"location":"workflowoperationhandlers/comment-woh/#description","text":"The CommentWorkflowOperationHandler can be used to create, resolve or delete comments for events within workflows.","title":"Description"},{"location":"workflowoperationhandlers/comment-woh/#parameter-table","text":"Configuration Key Example Description action create Action to be performed: create, resolve or delete. Default value is create. reason EVENTS.EVENTS.DETAILS. COMMENTS.REASONS.CUTTING The comment reason's i18n id. You can find the id in etc/listproviders/ event.comment.reasons.properties description Recording has not been cut yet. The description text to add to the comment. Notes: reason and description must be provided for the create action. create will not create duplicate comments: if there is already a comment with the same reason and description, a new comment will not be created. resolve and delete will perform no action if no comment matches the provided parameters (reason, description, or reason and description). If more than one comment matches the parameters, only the first matching comment will be resolved or deleted.","title":"Parameter Table"},{"location":"workflowoperationhandlers/comment-woh/#operation-examples","text":"Create a comment: <operation id=\"comment\" description=\"Mark the recording for cutting\"> <configurations> <configuration key=\"action\">create</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> <configuration key=\"description\">Recording has not been cut yet.</configuration> </configurations> </operation> Resolve a comment: <operation id=\"comment\" description=\"Resolve the cutting flag\"> <configurations> <configuration key=\"action\">resolve</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/composite-woh/","text":"Composite Workflow Operation Handler Description The CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optional watermark into one video, including encoding to different formats. The audio track is taken from both videos by default. Everything is done using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The layout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information about layouts see Opencast Composer Layout Module. The internal FFmpeg command is using the following filters: scale for scaling the videos, pad for defining the output dimension including the background color, movie for adding additional videos and images and overlay for aligning the videos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide If both upper and lower tracks have audio, \"source-audio-name\" can be set to \"upper\", \"lower\" or \"both\" to choose only the audio from one track or both tracks for the composite video. Sample complex composite filter command -filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4 Parameter Table Tags and flavors can be used in combination. configuration keys value type (EBNF) example description default value source-audio-name \"lower\", \"upper\" or \"both\" upper The \"name\" of track to use as a source audio. both source-tags-upper String , { \",\" , String } comp,rss The \"tag\" of the upper track to use as a source input. EMPTY source-flavor-upper MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the upper track to use as a source input. EMPTY source-tags-lower String , { \",\" , String } comp,rss The \"tag\" of the lower track to use as a source input. EMPTY source-flavor-lower MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the lower track to use as a source input. EMPTY source-tags-watermark String , { \",\" , String } branding The \"tag\" of the attachment image to use as a source input. EMPTY source-flavor-watermark MediaPackageElementFlavor image/work The \"flavor\" of the attachment image to use as a source input. EMPTY source-url-watermark URL file:///Users/me/logo.jpg The \"URL\" of the fallback image to use as a source input. EMPTY target-tags String , { \",\" , String } composite,rss,atom,archive The tags to apply to the compound video track. EMPTY * target-flavor MediaPackageElementFlavor composite/delivery The flavor to apply to the compound video track. EMPTY * encoding-profile String composite The encoding profile to use. EMPTY * output-resolution width , \"x\" , height | lower | higher 1920x1080 The resulting resolution of the compound video e.g. 1920x1080. EMPTY output-background String red The resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color. black layout name Json , \";\" , Json , [ \";\" , Json ] The layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined. EMPTY layout-single name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of one input video track (see layout ) EMPTY layout-dual name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of two input video tracks (see layout ). Defaults to value of layout if not set. EMPTY layout-{name} Json , \";\" , Json , [ \";\" , Json ] Define semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name. EMPTY * mandatory Notes: At least one of the configuration keys layout , layout-single , or layout-multiple must be set Output Resolution The output resolution must be specified using the configuration key output-resolution . The output resolution can be either explicitly specified (e.g. 1920x1080) or selected from the lower or upper input video (lower or higher). In case that only a single input track is available, both part-lower and part-higher will refer to that single input track. Layout Definition The layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and upper video and an optional specification for the watermark. The specifications have to be separated by comma. It is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately. A single layout is specified as follows: { // How much of the canvas shall be covered. [0.0 - 1.0] // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio. \"horizontalCoverage\": Double, // The offset between the anchor points of the media and the canvas \"anchorOffset\": { // The anchor point of the media. [0.0 - 1.0] // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner. // (0.5, 0.5) is the center. \"referring\": { \"left\": Double, \"top\": Double }, // The anchor point of the canvas. \"reference\": { \"left\": Double, \"top\": Double }, // The offset between the two anchor points. \"offset\": { \"y\": Integer, \"x\": Integer } } } // Example. // The media is scaled to cover the whole width of the canvas and is placed in the upper left corner. { \"horizontalCoverage\": 1.0, \"anchorOffset\": { \"referring\": { \"left\": 0.0, \"top\": 0.0 }, \"offset\": { \"y\": 0, \"x\": 0 }, \"reference\": { \"left\": 0.0, \"top\": 0.0 } } } // Example. // The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner // with an offset of -10px on both x and y axis so that it does not touch the canvas' border. { \"horizontalCoverage\": 0.2, \"anchorOffset\": { \"referring\": { \"left\": 1.0, \"top\": 1.0 }, \"offset\": { \"y\": -10, \"x\": -10 }, \"reference\": { \"left\": 1.0, \"top\": 1.0 } } } Operation Example <operation id=\"composite\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration> <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration> <configuration key=\"source-tags-upper\">comp,rss</configuration> <configuration key=\"source-tags-lower\">comp,rss</configuration> <configuration key=\"source-tags-watermark\">branding</configuration> <configuration key=\"source-flavor-watermark\">image/work</configuration> <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration> <configuration key=\"encoding-profile\">composite</configuration> <configuration key=\"target-tags\">composite,rss,atom,archive</configuration> <configuration key=\"target-flavor\">composite/delivery</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-background\">red</configuration> <configuration key=\"layout\">topleft</configuration> <configuration key=\"layout-topleft\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}} </configuration> <configuration key=\"layout-topright\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}} </configuration> </configurations> </operation>","title":"Composite"},{"location":"workflowoperationhandlers/composite-woh/#composite-workflow-operation-handler","text":"","title":"Composite Workflow Operation Handler"},{"location":"workflowoperationhandlers/composite-woh/#description","text":"The CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optional watermark into one video, including encoding to different formats. The audio track is taken from both videos by default. Everything is done using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The layout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information about layouts see Opencast Composer Layout Module. The internal FFmpeg command is using the following filters: scale for scaling the videos, pad for defining the output dimension including the background color, movie for adding additional videos and images and overlay for aligning the videos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide If both upper and lower tracks have audio, \"source-audio-name\" can be set to \"upper\", \"lower\" or \"both\" to choose only the audio from one track or both tracks for the composite video.","title":"Description"},{"location":"workflowoperationhandlers/composite-woh/#sample-complex-composite-filter-command","text":"-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4","title":"Sample complex composite filter command"},{"location":"workflowoperationhandlers/composite-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys value type (EBNF) example description default value source-audio-name \"lower\", \"upper\" or \"both\" upper The \"name\" of track to use as a source audio. both source-tags-upper String , { \",\" , String } comp,rss The \"tag\" of the upper track to use as a source input. EMPTY source-flavor-upper MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the upper track to use as a source input. EMPTY source-tags-lower String , { \",\" , String } comp,rss The \"tag\" of the lower track to use as a source input. EMPTY source-flavor-lower MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the lower track to use as a source input. EMPTY source-tags-watermark String , { \",\" , String } branding The \"tag\" of the attachment image to use as a source input. EMPTY source-flavor-watermark MediaPackageElementFlavor image/work The \"flavor\" of the attachment image to use as a source input. EMPTY source-url-watermark URL file:///Users/me/logo.jpg The \"URL\" of the fallback image to use as a source input. EMPTY target-tags String , { \",\" , String } composite,rss,atom,archive The tags to apply to the compound video track. EMPTY * target-flavor MediaPackageElementFlavor composite/delivery The flavor to apply to the compound video track. EMPTY * encoding-profile String composite The encoding profile to use. EMPTY * output-resolution width , \"x\" , height | lower | higher 1920x1080 The resulting resolution of the compound video e.g. 1920x1080. EMPTY output-background String red The resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color. black layout name Json , \";\" , Json , [ \";\" , Json ] The layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined. EMPTY layout-single name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of one input video track (see layout ) EMPTY layout-dual name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of two input video tracks (see layout ). Defaults to value of layout if not set. EMPTY layout-{name} Json , \";\" , Json , [ \";\" , Json ] Define semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name. EMPTY * mandatory Notes: At least one of the configuration keys layout , layout-single , or layout-multiple must be set","title":"Parameter Table"},{"location":"workflowoperationhandlers/composite-woh/#output-resolution","text":"The output resolution must be specified using the configuration key output-resolution . The output resolution can be either explicitly specified (e.g. 1920x1080) or selected from the lower or upper input video (lower or higher). In case that only a single input track is available, both part-lower and part-higher will refer to that single input track.","title":"Output Resolution"},{"location":"workflowoperationhandlers/composite-woh/#layout-definition","text":"The layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and upper video and an optional specification for the watermark. The specifications have to be separated by comma. It is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately. A single layout is specified as follows: { // How much of the canvas shall be covered. [0.0 - 1.0] // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio. \"horizontalCoverage\": Double, // The offset between the anchor points of the media and the canvas \"anchorOffset\": { // The anchor point of the media. [0.0 - 1.0] // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner. // (0.5, 0.5) is the center. \"referring\": { \"left\": Double, \"top\": Double }, // The anchor point of the canvas. \"reference\": { \"left\": Double, \"top\": Double }, // The offset between the two anchor points. \"offset\": { \"y\": Integer, \"x\": Integer } } } // Example. // The media is scaled to cover the whole width of the canvas and is placed in the upper left corner. { \"horizontalCoverage\": 1.0, \"anchorOffset\": { \"referring\": { \"left\": 0.0, \"top\": 0.0 }, \"offset\": { \"y\": 0, \"x\": 0 }, \"reference\": { \"left\": 0.0, \"top\": 0.0 } } } // Example. // The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner // with an offset of -10px on both x and y axis so that it does not touch the canvas' border. { \"horizontalCoverage\": 0.2, \"anchorOffset\": { \"referring\": { \"left\": 1.0, \"top\": 1.0 }, \"offset\": { \"y\": -10, \"x\": -10 }, \"reference\": { \"left\": 1.0, \"top\": 1.0 } } }","title":"Layout Definition"},{"location":"workflowoperationhandlers/composite-woh/#operation-example","text":"<operation id=\"composite\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration> <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration> <configuration key=\"source-tags-upper\">comp,rss</configuration> <configuration key=\"source-tags-lower\">comp,rss</configuration> <configuration key=\"source-tags-watermark\">branding</configuration> <configuration key=\"source-flavor-watermark\">image/work</configuration> <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration> <configuration key=\"encoding-profile\">composite</configuration> <configuration key=\"target-tags\">composite,rss,atom,archive</configuration> <configuration key=\"target-flavor\">composite/delivery</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-background\">red</configuration> <configuration key=\"layout\">topleft</configuration> <configuration key=\"layout-topleft\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}} </configuration> <configuration key=\"layout-topright\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}} </configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/concat-woh/","text":"Concat Workflow Operation Handler The concat operation handler has been created to concatenate multiple video tracks into one video track. For a concatenation of two video files to work, both files need to have the same format (timebase, resolution, codecs, frame rate, etc.). This workflow operation has two modes to deal with this restriction: A general mode which re-encodes all input files, hence ensuring that this restriction is always met. A same codec mode which assumes the restriction is already met and can hence concatenate the files much faster while also being a lossless process. But it will fail or produce a weird output if if the restrictions are not met. General Mode No restriction on source tracks codecs This will re-encode the videos first to the same format (framerate/timebase/codec, etc) before concatenation. The internal FFmpeg command for re-encoding is using the following filters: fps, scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. This requires an output-resolution and an optional output-framerate for the pre-concatenation encode. The automatically generated FFmpeg filter for this process does look like this: -filter_complex ' [0:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b]; [1:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c]; [2:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d]; aevalsrc=0::d=1[silent]; [b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]' -map '[v]' -map '[a]' Same Codec Mode Requires the source tracks having the same format (same timebase/resolution/encoding, etc.) If the same-codec option is specified to use this mode, the sources files can be arranged into one container losslessly without re-encoding first. This is often the case if the tracks came from the same camera/recorder for example. This mode uses FFmpeg's concat demuxer , which puts all the video content into a single container without any re-encoding. The encoding profile then operates on the source in this container. If -c copy is used in the encoding profile, the complete concatenation is lossless. The FFmpeg command for this is is: -f concat -i videolist.txt \u2026where videolist.txt contains a line in the form file <path to video> for each source track. Usage This operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one source-flavor and source-tag . The operation supports multiple flavor and tags as input. To add multiple sources, add different keys with the prefix source-flavor- / source-tag- and an incremental number starting with 0. For example: source-flavor-part-0 source-flavor-part-1 source-flavor-part-.. Alternatively, using the source-flavor-numbered-files option, the operation supports an undetermined number of ordered input files. This is useful when the number of input files cannot be known in advance, such as chunked output files from some camera/recorders, and the names are ordered by number or timestamps and to be sorted lexicographically. For example, the configuration could be source-flavor-numbered-files: multipart/part+source and the ordered input files: video-201711201020.mp4 video-201711201030.mp4 video-201711201040.mp4 Note that both methods of defining input files are mutually exclusive. Configuration Keys Key Required Description Default Example source-flavor-part-X false An iterative list of part/flavor to use as input track. NULL presenter/trimmed source-tag-part-X false An iterative list of part/tag to use as input track. NULL source-to-concate source-flavor-part-X-mandatory false Define the flavor part-X as optional for concatenation. false true source-tag-part-X-mandatory false Define the tag part-X as optional for concatenation. false true encoding-profile true Encoding profile to use for the concatenation. NULL concat target-flavor true Flavor(s) to add to the output track. NULL presenter/concat target-tags false Tag(s) to add to the output track NULL engage-download output-resolution true Output resolution in width, height or a source part NULL 1900x1080 , part-1 output-framerate false Output frame rate in frames per second or a source part -1.0 25 , 23.976 , part-1 source-flavor-numbered-files false Files of this flavor are ordered lexicographically to use as input track. NULL multipart/sections same-codec false All source files have identical formats. false true Example Example of a concat operation in a workflow definition. <!-- Add intro and outro part to the presenter track --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the presenter track and the intro/outro videos.\"> <configurations> <configuration key=\"source-flavor-part-0\">intro/source</configuration> <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration> <configuration key=\"source-flavor-part-1-mandatory\">true</configuration> <configuration key=\"source-flavor-part-2\">outro/source</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">concat</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-framerate\">part-1</configuration> </configurations> </operation> Example of a lossless concat operation for videos with identical formats in a workflow definition. <!-- Concatenate chunked video from camera --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the generated videos.\"> <configurations> <configuration key=\"source-flavor-numbered-files\">multipart/chunkedsource</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <!-- do not encode before concatenation --> <configuration key=\"same-codec\">true</configuration> <configuration key=\"encoding-profile\">concat-samecodec</configuration> </configurations> </operation> Encoding Profile The encoding profile command must contain the #{concatCommand} parameter which will set all input and possibly filter commands required for this operation: profile.concat.ffmpeg.command = #{concatCommand} \\ \u2026 #{out.dir}/#{out.name}#{out.suffix}","title":"Concat"},{"location":"workflowoperationhandlers/concat-woh/#concat-workflow-operation-handler","text":"The concat operation handler has been created to concatenate multiple video tracks into one video track. For a concatenation of two video files to work, both files need to have the same format (timebase, resolution, codecs, frame rate, etc.). This workflow operation has two modes to deal with this restriction: A general mode which re-encodes all input files, hence ensuring that this restriction is always met. A same codec mode which assumes the restriction is already met and can hence concatenate the files much faster while also being a lossless process. But it will fail or produce a weird output if if the restrictions are not met.","title":"Concat Workflow Operation Handler"},{"location":"workflowoperationhandlers/concat-woh/#general-mode","text":"No restriction on source tracks codecs This will re-encode the videos first to the same format (framerate/timebase/codec, etc) before concatenation. The internal FFmpeg command for re-encoding is using the following filters: fps, scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. This requires an output-resolution and an optional output-framerate for the pre-concatenation encode. The automatically generated FFmpeg filter for this process does look like this: -filter_complex ' [0:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b]; [1:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c]; [2:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d]; aevalsrc=0::d=1[silent]; [b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]' -map '[v]' -map '[a]'","title":"General Mode"},{"location":"workflowoperationhandlers/concat-woh/#same-codec-mode","text":"Requires the source tracks having the same format (same timebase/resolution/encoding, etc.) If the same-codec option is specified to use this mode, the sources files can be arranged into one container losslessly without re-encoding first. This is often the case if the tracks came from the same camera/recorder for example. This mode uses FFmpeg's concat demuxer , which puts all the video content into a single container without any re-encoding. The encoding profile then operates on the source in this container. If -c copy is used in the encoding profile, the complete concatenation is lossless. The FFmpeg command for this is is: -f concat -i videolist.txt \u2026where videolist.txt contains a line in the form file <path to video> for each source track.","title":"Same Codec Mode"},{"location":"workflowoperationhandlers/concat-woh/#usage","text":"This operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one source-flavor and source-tag . The operation supports multiple flavor and tags as input. To add multiple sources, add different keys with the prefix source-flavor- / source-tag- and an incremental number starting with 0. For example: source-flavor-part-0 source-flavor-part-1 source-flavor-part-.. Alternatively, using the source-flavor-numbered-files option, the operation supports an undetermined number of ordered input files. This is useful when the number of input files cannot be known in advance, such as chunked output files from some camera/recorders, and the names are ordered by number or timestamps and to be sorted lexicographically. For example, the configuration could be source-flavor-numbered-files: multipart/part+source and the ordered input files: video-201711201020.mp4 video-201711201030.mp4 video-201711201040.mp4 Note that both methods of defining input files are mutually exclusive.","title":"Usage"},{"location":"workflowoperationhandlers/concat-woh/#configuration-keys","text":"Key Required Description Default Example source-flavor-part-X false An iterative list of part/flavor to use as input track. NULL presenter/trimmed source-tag-part-X false An iterative list of part/tag to use as input track. NULL source-to-concate source-flavor-part-X-mandatory false Define the flavor part-X as optional for concatenation. false true source-tag-part-X-mandatory false Define the tag part-X as optional for concatenation. false true encoding-profile true Encoding profile to use for the concatenation. NULL concat target-flavor true Flavor(s) to add to the output track. NULL presenter/concat target-tags false Tag(s) to add to the output track NULL engage-download output-resolution true Output resolution in width, height or a source part NULL 1900x1080 , part-1 output-framerate false Output frame rate in frames per second or a source part -1.0 25 , 23.976 , part-1 source-flavor-numbered-files false Files of this flavor are ordered lexicographically to use as input track. NULL multipart/sections same-codec false All source files have identical formats. false true","title":"Configuration Keys"},{"location":"workflowoperationhandlers/concat-woh/#example","text":"Example of a concat operation in a workflow definition. <!-- Add intro and outro part to the presenter track --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the presenter track and the intro/outro videos.\"> <configurations> <configuration key=\"source-flavor-part-0\">intro/source</configuration> <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration> <configuration key=\"source-flavor-part-1-mandatory\">true</configuration> <configuration key=\"source-flavor-part-2\">outro/source</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">concat</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-framerate\">part-1</configuration> </configurations> </operation> Example of a lossless concat operation for videos with identical formats in a workflow definition. <!-- Concatenate chunked video from camera --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the generated videos.\"> <configurations> <configuration key=\"source-flavor-numbered-files\">multipart/chunkedsource</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <!-- do not encode before concatenation --> <configuration key=\"same-codec\">true</configuration> <configuration key=\"encoding-profile\">concat-samecodec</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/concat-woh/#encoding-profile","text":"The encoding profile command must contain the #{concatCommand} parameter which will set all input and possibly filter commands required for this operation: profile.concat.ffmpeg.command = #{concatCommand} \\ \u2026 #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding Profile"},{"location":"workflowoperationhandlers/conditional-config-woh/","text":"Conditional Config Workflow Operation ID: conditional-config Description The conditional-config operation sets a workflow configuration variable based on conditions that are tested in sequence. If condition-1 is true, value-1 is assigned to the variable, if condition-2 is true, value-2 is assigned, and so on. If no conditions are true, the value specified in no-match is assigned. Conditions are tested in alphabetical order and the first condition that is true sets the variable so, if two conditions are true, the value is set by the first one that gets evaluated. This operation is useful to reduce workflow complexity when the same operation is repeated many times and executed based on distinct if-conditions. Parameter Table configuration key description example configuration-name Name of workflow configuration variable to be set encoding-profile condition- X Condition to be tested, same syntax as workflow conditions (${presenter_work_resolution_x} > 1600) value- X Value to be assigned to configuration variable if condition- is true encoding-profile-x no-match Value to be assigned to configuration variable if none of the conditions are true encoding-profile-none All condition- X are sorted as strings and then evaluated in sequence e.g. condition-1, condition-2, etc. Example Set presenter encoding profile based on presenter/work media attributes: <operation id=\"conditional-config\" description=\"Evaluate media properties and set presenter-encoding-profiles configuration\"> <configurations> <configuration key=\"configuration-name\">presenter-encoding-profiles</configuration> <configuration key=\"condition-1\"> (${presenter_work_framerate} == 25) AND (${presenter_work_resolution_x} &gt; 1600) AND (${presenter_work_bitrate} &gt; 1999999) </configuration> <configuration key=\"value-1\"> z-full-3m-presenter,z-threequarters-1500k-presenter,z-half-700k-presenter, z-quarter-300k-presenter,z-lowbr-160k-presenter,multiencode-hls </configuration> <configuration key=\"condition-2\"> (${presenter_work_framerate} == 25) AND (${presenter_work_resolution_x} &gt; 1600) AND (${presenter_work_bitrate} &lt; 2000000) AND (${presenter_work_bitrate} &gt; 499999) </configuration> <configuration key=\"value-2\"> z-full-2m-presenter,z-threequarters-1m-presenter,z-half-500k-presenter, z-quarter-250k-presenter,z-lowbr-160k-presenter,multiencode-hls </configuration> <!-- More conditions omitted\u2026 --> <configuration key=\"no-match\"> hls-half-res-presenter,hls-full-res-presenter,hls-threequarters-res-presenter, hls-quarter-res-presenter,hls-quarter-15fps-presenter,multiencode-hls </configuration> </configurations> </operation> Then, use variable set above to encode the presenter file: <operation id=\"multiencode\" description=\"Encode to multiple delivery formats\"> <configurations> <configuration key=\"source-flavors\">presenter/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">archive,engage</configuration> <configuration key=\"encoding-profiles\"> ${presenter-encoding-profiles} </configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation>","title":"Conditional Config"},{"location":"workflowoperationhandlers/conditional-config-woh/#conditional-config-workflow-operation","text":"ID: conditional-config","title":"Conditional Config Workflow Operation"},{"location":"workflowoperationhandlers/conditional-config-woh/#description","text":"The conditional-config operation sets a workflow configuration variable based on conditions that are tested in sequence. If condition-1 is true, value-1 is assigned to the variable, if condition-2 is true, value-2 is assigned, and so on. If no conditions are true, the value specified in no-match is assigned. Conditions are tested in alphabetical order and the first condition that is true sets the variable so, if two conditions are true, the value is set by the first one that gets evaluated. This operation is useful to reduce workflow complexity when the same operation is repeated many times and executed based on distinct if-conditions.","title":"Description"},{"location":"workflowoperationhandlers/conditional-config-woh/#parameter-table","text":"configuration key description example configuration-name Name of workflow configuration variable to be set encoding-profile condition- X Condition to be tested, same syntax as workflow conditions (${presenter_work_resolution_x} > 1600) value- X Value to be assigned to configuration variable if condition- is true encoding-profile-x no-match Value to be assigned to configuration variable if none of the conditions are true encoding-profile-none All condition- X are sorted as strings and then evaluated in sequence e.g. condition-1, condition-2, etc.","title":"Parameter Table"},{"location":"workflowoperationhandlers/conditional-config-woh/#example","text":"Set presenter encoding profile based on presenter/work media attributes: <operation id=\"conditional-config\" description=\"Evaluate media properties and set presenter-encoding-profiles configuration\"> <configurations> <configuration key=\"configuration-name\">presenter-encoding-profiles</configuration> <configuration key=\"condition-1\"> (${presenter_work_framerate} == 25) AND (${presenter_work_resolution_x} &gt; 1600) AND (${presenter_work_bitrate} &gt; 1999999) </configuration> <configuration key=\"value-1\"> z-full-3m-presenter,z-threequarters-1500k-presenter,z-half-700k-presenter, z-quarter-300k-presenter,z-lowbr-160k-presenter,multiencode-hls </configuration> <configuration key=\"condition-2\"> (${presenter_work_framerate} == 25) AND (${presenter_work_resolution_x} &gt; 1600) AND (${presenter_work_bitrate} &lt; 2000000) AND (${presenter_work_bitrate} &gt; 499999) </configuration> <configuration key=\"value-2\"> z-full-2m-presenter,z-threequarters-1m-presenter,z-half-500k-presenter, z-quarter-250k-presenter,z-lowbr-160k-presenter,multiencode-hls </configuration> <!-- More conditions omitted\u2026 --> <configuration key=\"no-match\"> hls-half-res-presenter,hls-full-res-presenter,hls-threequarters-res-presenter, hls-quarter-res-presenter,hls-quarter-15fps-presenter,multiencode-hls </configuration> </configurations> </operation> Then, use variable set above to encode the presenter file: <operation id=\"multiencode\" description=\"Encode to multiple delivery formats\"> <configurations> <configuration key=\"source-flavors\">presenter/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">archive,engage</configuration> <configuration key=\"encoding-profiles\"> ${presenter-encoding-profiles} </configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/","text":"ConfigureByDCTermWorkflowOperationHandler Description With the ConfigureByDCTermWorkflowOperationHandler it's possible to create a workflow configuration property according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to control a workflow so that it will publish before editing if a certain Dublin Core term has the specified value. In combination with TagByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin Core catalogs. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value \"Anon\" the implied value if the dubincore term is not present in the catalog EMPTY configProperty true / false a configuration property and the value it will be given if a match is found EMPTY dccatalog The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series . dcterm The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog. match-value The value of the dcterm which to match against. The comparison is case sensitive. default-value If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not configure anything. If default-value is specified the operation will compare the match-value to the default-value and set the workflow property if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled . \"configProperty\" Specifies as the key the name of a new workflow configuration property and the boolean value to which it will be set if the Dublin Core term matches the specified value. Due to the way a workflow evaluates operation if conditions as configuration properties are created, only new configuration properties can be used to modify the execution of subsequent operations. Also since an undefined property will be evaluated as false in practice the only useful value which can set is true . However operation if conditions can be negated though so it is possible to skip subsequent operations on matched dcterm value. Operation Example <operation id=\"configure-by-dcterm\" fail-on-error=\"true\" description=\"Configure publication channel by dcterm\"> <configurations> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">private</configuration> <configuration key=\"publishPrivate\">true</configuration> </configurations> </operation> ... <operation id=\"publish-engage\" if=\"${publishPrivate}\" description=\"Publish to internal audience only\"> ... </operation> <operation id=\"publish-youtube\" if=\"NOT ${publishPrivate}\" description=\"Publish to global audience\"> ... </operation>","title":"Configure-By-DCTerm"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#configurebydctermworkflowoperationhandler","text":"","title":"ConfigureByDCTermWorkflowOperationHandler"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#description","text":"With the ConfigureByDCTermWorkflowOperationHandler it's possible to create a workflow configuration property according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to control a workflow so that it will publish before editing if a certain Dublin Core term has the specified value. In combination with TagByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin Core catalogs.","title":"Description"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value \"Anon\" the implied value if the dubincore term is not present in the catalog EMPTY configProperty true / false a configuration property and the value it will be given if a match is found EMPTY","title":"Parameter Table"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#dccatalog","text":"The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series .","title":"dccatalog"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#dcterm","text":"The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog.","title":"dcterm"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#match-value","text":"The value of the dcterm which to match against. The comparison is case sensitive.","title":"match-value"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#default-value","text":"If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not configure anything. If default-value is specified the operation will compare the match-value to the default-value and set the workflow property if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled .","title":"default-value"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#configproperty","text":"Specifies as the key the name of a new workflow configuration property and the boolean value to which it will be set if the Dublin Core term matches the specified value. Due to the way a workflow evaluates operation if conditions as configuration properties are created, only new configuration properties can be used to modify the execution of subsequent operations. Also since an undefined property will be evaluated as false in practice the only useful value which can set is true . However operation if conditions can be negated though so it is possible to skip subsequent operations on matched dcterm value.","title":"\"configProperty\""},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#operation-example","text":"<operation id=\"configure-by-dcterm\" fail-on-error=\"true\" description=\"Configure publication channel by dcterm\"> <configurations> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">private</configuration> <configuration key=\"publishPrivate\">true</configuration> </configurations> </operation> ... <operation id=\"publish-engage\" if=\"${publishPrivate}\" description=\"Publish to internal audience only\"> ... </operation> <operation id=\"publish-youtube\" if=\"NOT ${publishPrivate}\" description=\"Publish to global audience\"> ... </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/copy-woh/","text":"CopyWorkflowOperationHandler Description The CopyWorkflowOperationHandler can be used to copy media package elements to a given target directory. Parameter Table Configuration Key Example Description source-flavors presenter/source Comma-separated list of source-flavors source-tags archive Comma-separated list of source-tags target-directory* /mnt/mydisk The directory where the file is copied to target-filename test The optional target filename. The file extension extract from the media package element URI will be appended * mandatory configuration key Notes: source-flavors and source-tags may be used both together to select media package elements based on both flavors and tags In case that neither source-flavors nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavors and source-tags , the operation will be skipped Target Filenames If target-filename is not specified, the filename for each media package element is extracted from the media package element URI. If target-filename is specified, the filename is the result of appending the file extension (extracted from the media package element URI) to target-filename . In case the source-flavors and source-tags match multiple media package elements, a sequentially increasing integer number (starting at 1) can be used within target-filename in Java string formatting manner to ensure unique filenames. Operation Example <operation id=\"copy\" description=\"Copy sources to my disk\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavors\">presenter/source, presentation/source</configuration> <configuration key=\"target-directory\">/mnt/mydisk</configuration> </configurations>","title":"Copy"},{"location":"workflowoperationhandlers/copy-woh/#copyworkflowoperationhandler","text":"","title":"CopyWorkflowOperationHandler"},{"location":"workflowoperationhandlers/copy-woh/#description","text":"The CopyWorkflowOperationHandler can be used to copy media package elements to a given target directory.","title":"Description"},{"location":"workflowoperationhandlers/copy-woh/#parameter-table","text":"Configuration Key Example Description source-flavors presenter/source Comma-separated list of source-flavors source-tags archive Comma-separated list of source-tags target-directory* /mnt/mydisk The directory where the file is copied to target-filename test The optional target filename. The file extension extract from the media package element URI will be appended * mandatory configuration key Notes: source-flavors and source-tags may be used both together to select media package elements based on both flavors and tags In case that neither source-flavors nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavors and source-tags , the operation will be skipped","title":"Parameter Table"},{"location":"workflowoperationhandlers/copy-woh/#target-filenames","text":"If target-filename is not specified, the filename for each media package element is extracted from the media package element URI. If target-filename is specified, the filename is the result of appending the file extension (extracted from the media package element URI) to target-filename . In case the source-flavors and source-tags match multiple media package elements, a sequentially increasing integer number (starting at 1) can be used within target-filename in Java string formatting manner to ensure unique filenames.","title":"Target Filenames"},{"location":"workflowoperationhandlers/copy-woh/#operation-example","text":"<operation id=\"copy\" description=\"Copy sources to my disk\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavors\">presenter/source, presentation/source</configuration> <configuration key=\"target-directory\">/mnt/mydisk</configuration> </configurations>","title":"Operation Example"},{"location":"workflowoperationhandlers/coverimage-woh/","text":"CoverImageWorkflowOperationHandler Description The CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG image that is rasterized as PNG as a last step. Parameter Table Name Type Example Default Value Description stylesheet * URL file:///etc/opencast/branding/coverimage.xsl - File URI to the XSL stylesheet used to generate the SVG image metadata XML <meta><title>Hello!</title></meta> - XML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation episodeFlavor Flavor dublincore/episode dublincore/episode Flavor of the passed episode seriesFlavor Flavor dublincore/series dublincore/series Flavor of the series that the passed episode is part of width * int 1920 - Width of the resulting image height * int 1080 - Height of the resulting image posterimage-flavor Flavor image/poster - Flavor of a poster image which may be used as a part of the cover image (e.g. as a background) posterimage URL http://flickr.com/posterimage.jpg - URL to a custom poster image instead of using one out of the media package target-flavor * Flavor image/cover - Flavor of the resulting cover image target-tags String archive,download - Comma separated list of tags to be applied to the resulting attachment. Metadata If no metadata is passed by using the configuration key metadata , the default metadata is passed to the cover image service which could look like the following example: <?xml version=\"1.0\"?> <metadata> <title>Puppy Love</title> <date>2014-04-24T11:21:00</date> <license>All rights reserved</license> <description>Here is a description of the video</description> <series> <title>Superbowl Commercials</title> <description>Here is a description of the series</description> </series> <contributors>Budweiser</contributors> <creators>Budweiser</creators> <subjects>Commercial</subjects> </metadata> Note that the date is localized based on your servers Java Runtime language settings. Also note that if the default metadata is beeing used and one of the metadata fields exists multiple times, the cover image service currently only adds the first field of each type to the xml. Stylesheet The cover image service uses the Xalan XSLT 1.0 processor to transform an XML stylesheet to an SVG image. The general structure of the stylesheet is expected to look like this: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"> <xsl:param name=\"width\" /> <xsl:param name=\"height\" /> <xsl:param name=\"posterimage\" /> <xsl:template match=\"/\"> <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\"> <xsl:attribute name=\"width\"> <xsl:value-of select=\"$width\" /> </xsl:attribute> <xsl:attribute name=\"height\"> <xsl:value-of select=\"$height\" /> </xsl:attribute> <!-- Your SVG content --> </xsl:template> </xsl:stylesheet> The variables width , height and posterimage will be set to the values of the respective configuration keys. As a starting point for your own template you best take a look at file etc/branding/coverimage.xsl . Using XLST Extensions Xalan is a powerful XSLT 1.0 processor that comes with a rich feature set. For example, it is possible to execute JavaScript or Java code directly within the stylesheet. For commonly used tasks it is simpler, however, to make use of available XSLT Extensions. Opencast Extensions The package org.opencastproject.coverimage.impl.xsl provides classes supposed to be used within XSL stylesheets. To make use of those classes, you need to reference the package from your XSL stylesheet: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"opencast\" extension-element-prefixes=\"opencast\"> </xsl:stylesheet> Later on, you can use methods of those classes as shown in the following example: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> Note: In XSLT, use true() and false() for boolean literals ( true and false won't work since those are not keywords in XSLT) The following classes are provided by the org.opencastproject.coverimage.impl.xsl package: class XsltHelper String split(String text, int maxChars, int line, boolean isLastLine) This method can be used to break strings over multiple lines and to abbreviate strings that are too using ellipsis. Parameter Description text Input string maxChars Maximum number of characters per line line Number of line isLastLine Whether line is the last line used to represent the text Example To use at most two lines (max. 30 characters per line) to represent a string metadata/title and abbreviate the string if two lines aren't enough: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> <tspan class=\"title\" dy=\"10%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 2, true())\" /> </tspan> EXSLT Extensions Xalan supports most of the XSLT extensions of the EXSLT community (see [1] ). In doubt consult [2] for more information about Xalan's implementation of the EXSLT extensions. Please find an example of how to use EXSLT extensions below: <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:date=\"http://exslt.org/dates-and-times\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"date\" extension-element-prefixes=\"date\"> <!-- [...] --> <tspan class=\"presentationdate\" dy=\"12%\" x=\"50%\"> <xsl:value-of select=\"date:format-date(metadata/date, 'MMMMMMMMMM dd, YYYY, HH:mm:ss')\" /> </tspan> <!-- [...] --> </xsl:stylesheet> In this example, the function format-date of the EXSLT dates-and-times functions library is used to format a date. Operation Example Operation example with metadata derived from events metadata: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/coverbackground</configuration> <configuration key=\"target-flavor\">presenter/player+preview</configuration> <configuration key=\"target-tags\">archive, engage-download</configuration> </configurations> </operation> Operation example with metadata provided in the operations configuration: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"metadata\"> <![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]> </configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration> <configuration key=\"target-flavor\">image/cover</configuration> </configurations> </operation>","title":"Cover Image"},{"location":"workflowoperationhandlers/coverimage-woh/#coverimageworkflowoperationhandler","text":"","title":"CoverImageWorkflowOperationHandler"},{"location":"workflowoperationhandlers/coverimage-woh/#description","text":"The CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG image that is rasterized as PNG as a last step.","title":"Description"},{"location":"workflowoperationhandlers/coverimage-woh/#parameter-table","text":"Name Type Example Default Value Description stylesheet * URL file:///etc/opencast/branding/coverimage.xsl - File URI to the XSL stylesheet used to generate the SVG image metadata XML <meta><title>Hello!</title></meta> - XML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation episodeFlavor Flavor dublincore/episode dublincore/episode Flavor of the passed episode seriesFlavor Flavor dublincore/series dublincore/series Flavor of the series that the passed episode is part of width * int 1920 - Width of the resulting image height * int 1080 - Height of the resulting image posterimage-flavor Flavor image/poster - Flavor of a poster image which may be used as a part of the cover image (e.g. as a background) posterimage URL http://flickr.com/posterimage.jpg - URL to a custom poster image instead of using one out of the media package target-flavor * Flavor image/cover - Flavor of the resulting cover image target-tags String archive,download - Comma separated list of tags to be applied to the resulting attachment.","title":"Parameter Table"},{"location":"workflowoperationhandlers/coverimage-woh/#metadata","text":"If no metadata is passed by using the configuration key metadata , the default metadata is passed to the cover image service which could look like the following example: <?xml version=\"1.0\"?> <metadata> <title>Puppy Love</title> <date>2014-04-24T11:21:00</date> <license>All rights reserved</license> <description>Here is a description of the video</description> <series> <title>Superbowl Commercials</title> <description>Here is a description of the series</description> </series> <contributors>Budweiser</contributors> <creators>Budweiser</creators> <subjects>Commercial</subjects> </metadata> Note that the date is localized based on your servers Java Runtime language settings. Also note that if the default metadata is beeing used and one of the metadata fields exists multiple times, the cover image service currently only adds the first field of each type to the xml.","title":"Metadata"},{"location":"workflowoperationhandlers/coverimage-woh/#stylesheet","text":"The cover image service uses the Xalan XSLT 1.0 processor to transform an XML stylesheet to an SVG image. The general structure of the stylesheet is expected to look like this: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"> <xsl:param name=\"width\" /> <xsl:param name=\"height\" /> <xsl:param name=\"posterimage\" /> <xsl:template match=\"/\"> <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\"> <xsl:attribute name=\"width\"> <xsl:value-of select=\"$width\" /> </xsl:attribute> <xsl:attribute name=\"height\"> <xsl:value-of select=\"$height\" /> </xsl:attribute> <!-- Your SVG content --> </xsl:template> </xsl:stylesheet> The variables width , height and posterimage will be set to the values of the respective configuration keys. As a starting point for your own template you best take a look at file etc/branding/coverimage.xsl .","title":"Stylesheet"},{"location":"workflowoperationhandlers/coverimage-woh/#using-xlst-extensions","text":"Xalan is a powerful XSLT 1.0 processor that comes with a rich feature set. For example, it is possible to execute JavaScript or Java code directly within the stylesheet. For commonly used tasks it is simpler, however, to make use of available XSLT Extensions.","title":"Using XLST Extensions"},{"location":"workflowoperationhandlers/coverimage-woh/#opencast-extensions","text":"The package org.opencastproject.coverimage.impl.xsl provides classes supposed to be used within XSL stylesheets. To make use of those classes, you need to reference the package from your XSL stylesheet: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"opencast\" extension-element-prefixes=\"opencast\"> </xsl:stylesheet> Later on, you can use methods of those classes as shown in the following example: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> Note: In XSLT, use true() and false() for boolean literals ( true and false won't work since those are not keywords in XSLT) The following classes are provided by the org.opencastproject.coverimage.impl.xsl package: class XsltHelper String split(String text, int maxChars, int line, boolean isLastLine) This method can be used to break strings over multiple lines and to abbreviate strings that are too using ellipsis. Parameter Description text Input string maxChars Maximum number of characters per line line Number of line isLastLine Whether line is the last line used to represent the text Example To use at most two lines (max. 30 characters per line) to represent a string metadata/title and abbreviate the string if two lines aren't enough: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> <tspan class=\"title\" dy=\"10%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 2, true())\" /> </tspan>","title":"Opencast Extensions"},{"location":"workflowoperationhandlers/coverimage-woh/#exslt-extensions","text":"Xalan supports most of the XSLT extensions of the EXSLT community (see [1] ). In doubt consult [2] for more information about Xalan's implementation of the EXSLT extensions. Please find an example of how to use EXSLT extensions below: <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:date=\"http://exslt.org/dates-and-times\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"date\" extension-element-prefixes=\"date\"> <!-- [...] --> <tspan class=\"presentationdate\" dy=\"12%\" x=\"50%\"> <xsl:value-of select=\"date:format-date(metadata/date, 'MMMMMMMMMM dd, YYYY, HH:mm:ss')\" /> </tspan> <!-- [...] --> </xsl:stylesheet> In this example, the function format-date of the EXSLT dates-and-times functions library is used to format a date.","title":"EXSLT Extensions"},{"location":"workflowoperationhandlers/coverimage-woh/#operation-example","text":"Operation example with metadata derived from events metadata: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/coverbackground</configuration> <configuration key=\"target-flavor\">presenter/player+preview</configuration> <configuration key=\"target-tags\">archive, engage-download</configuration> </configurations> </operation> Operation example with metadata provided in the operations configuration: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"metadata\"> <![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]> </configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration> <configuration key=\"target-flavor\">image/cover</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/cropvideo-woh/","text":"Crop Workflow operation The plugin provides the workflow operation crop-video . This workflow operation executes FFmpeg command cropdetect . cropdetect checks for black bars on the sides of the track of the workflow instance. If cropdetect is successful, then FFmpeg command crop is executed. crop removes these black bars. Parameter Table configuration keys example description source-flavor */source which media should be encoded target-tags sometag Specifies the tags of the new media target-flavor presenter/cropped Flavor of the cropped media track Example for crop-video in a workflow <operation id=\"crop-video\" fail-on-error=\"false\" description=\"Detecting black bars in presentation track\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-tags\">engage-download</configuration> </configurations> </operation>","title":"Crop Video"},{"location":"workflowoperationhandlers/cropvideo-woh/#crop-workflow-operation","text":"The plugin provides the workflow operation crop-video . This workflow operation executes FFmpeg command cropdetect . cropdetect checks for black bars on the sides of the track of the workflow instance. If cropdetect is successful, then FFmpeg command crop is executed. crop removes these black bars.","title":"Crop Workflow operation"},{"location":"workflowoperationhandlers/cropvideo-woh/#parameter-table","text":"configuration keys example description source-flavor */source which media should be encoded target-tags sometag Specifies the tags of the new media target-flavor presenter/cropped Flavor of the cropped media track","title":"Parameter Table"},{"location":"workflowoperationhandlers/cropvideo-woh/#example-for-crop-video-in-a-workflow","text":"<operation id=\"crop-video\" fail-on-error=\"false\" description=\"Detecting black bars in presentation track\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-tags\">engage-download</configuration> </configurations> </operation>","title":"Example for crop-video in a workflow"},{"location":"workflowoperationhandlers/cut-marks-to-smil-woh/","text":"Cut Marks to Smil Operation ID: cut-marks-to-smil Description This operation parses a JSON containing cut marks into a SMIL that can be used by the Video Editor . It does this by attributing the given times to the specified tracks. Tracks are assumed to start at 0. Likewise, cut marks are assumed to be specified relative to the beginning of the tracks. The cut marks must be a media package attachment. For compatibility to early versions, the code falls back to looking for catalogs if no attachment was found. Parameter Table Configuration Keys Example Description source-media-flavors presenter/prepared The flavors identifying the video tracks. source-json-flavor cut-marks/json The flavor of the JSON. Must identify exactly one element. target-smil-flavor smil/cutmarks The flavor of the resulting SMIL. target-tags archive Tags to add to the resulting SMIL. (Default: null ) JSON Format The JSON structure specifies all segments which should be kept after cutting. The property begin marks the start of a segment while duration its duration. The values are specified in milliseconds. [ { \"begin\": 1672, \"duration\": 7199 } ] Operation Example <operation id=\"cut-marks-to-smil\" description=\"Process ingested cut marks by applying them to current tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-media-flavors\">presenter/prepared,presentation/prepared</configuration> <configuration key=\"source-json-flavor\">cut-marks/json</configuration> <configuration key=\"target-smil-flavor\">smil/cutting</configuration> </configurations> </operation>","title":"Cut Marks To Smil"},{"location":"workflowoperationhandlers/cut-marks-to-smil-woh/#cut-marks-to-smil-operation","text":"ID: cut-marks-to-smil","title":"Cut Marks to Smil Operation"},{"location":"workflowoperationhandlers/cut-marks-to-smil-woh/#description","text":"This operation parses a JSON containing cut marks into a SMIL that can be used by the Video Editor . It does this by attributing the given times to the specified tracks. Tracks are assumed to start at 0. Likewise, cut marks are assumed to be specified relative to the beginning of the tracks. The cut marks must be a media package attachment. For compatibility to early versions, the code falls back to looking for catalogs if no attachment was found.","title":"Description"},{"location":"workflowoperationhandlers/cut-marks-to-smil-woh/#parameter-table","text":"Configuration Keys Example Description source-media-flavors presenter/prepared The flavors identifying the video tracks. source-json-flavor cut-marks/json The flavor of the JSON. Must identify exactly one element. target-smil-flavor smil/cutmarks The flavor of the resulting SMIL. target-tags archive Tags to add to the resulting SMIL. (Default: null )","title":"Parameter Table"},{"location":"workflowoperationhandlers/cut-marks-to-smil-woh/#json-format","text":"The JSON structure specifies all segments which should be kept after cutting. The property begin marks the start of a segment while duration its duration. The values are specified in milliseconds. [ { \"begin\": 1672, \"duration\": 7199 } ]","title":"JSON Format"},{"location":"workflowoperationhandlers/cut-marks-to-smil-woh/#operation-example","text":"<operation id=\"cut-marks-to-smil\" description=\"Process ingested cut marks by applying them to current tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-media-flavors\">presenter/prepared,presentation/prepared</configuration> <configuration key=\"source-json-flavor\">cut-marks/json</configuration> <configuration key=\"target-smil-flavor\">smil/cutting</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/defaults-woh/","text":"DefaultsWorkflowOperation Description The DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value key hello world This would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined. - Operation Example <operation id=\"defaults\" description=\"Applying default values\"> <configurations> <configuration key=\"key\">hello world</configuration> </configurations> </operation>","title":"Defaults"},{"location":"workflowoperationhandlers/defaults-woh/#defaultsworkflowoperation","text":"","title":"DefaultsWorkflowOperation"},{"location":"workflowoperationhandlers/defaults-woh/#description","text":"The DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values.","title":"Description"},{"location":"workflowoperationhandlers/defaults-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value key hello world This would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined. -","title":"Parameter Table"},{"location":"workflowoperationhandlers/defaults-woh/#operation-example","text":"<operation id=\"defaults\" description=\"Applying default values\"> <configurations> <configuration key=\"key\">hello world</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/demux-woh/","text":"Demux Workflow Operation Description The demux operation can be used to demux multiple streams (e.g. presenter and presentation) from one container and put them into separate tracks. It uses a special encoding profile that has two outputs. It flavors the target media in the order listed in the encoding profile output. Parameter Table Configuration Key Example Description source-flavors multitrack/source Which media should be encoded target-tags archive,rss;rss Specifies the tags of the new media target-flavors presenter/*,presentation/* Specifies the flavors of the new media encoding-profile demux Specifies the encoding profile Note that target-tags can hold multiple sets of tags separated by ; . Each set is applied to the matching set of output files (same order). Target flavors are separated by , as usual. They are applied in order as well. Operation Example <operation id=\"demux\" exception-handler-workflow=\"partial-error\" description=\"Extract presenter and presentation video from multitrack source\"> <configurations> <configuration key=\"source-flavors\">multitrack/source</configuration> <configuration key=\"target-flavors\">presenter/source,presentation/source</configuration> <configuration key=\"target-tags\">archive</configuration> <configuration key=\"encoding-profile\">demux</configuration> </configurations> </operation> Example Profile profile.demux.name = demux profile.demux.input = visual profile.demux.output = visual profile.demux.suffix = .mp4 profile.demux.ffmpeg.command = -i #{in.video.path} -c copy \\ -map 0:a:0 -map 0:v:0 #{out.dir}/#{out.name}_presenter#{out.suffix} \\ -map 0:a:1 -map 0:v:1 #{out.dir}/#{out.name}_presentation#{out.suffix}","title":"Demux"},{"location":"workflowoperationhandlers/demux-woh/#demux-workflow-operation","text":"","title":"Demux Workflow Operation"},{"location":"workflowoperationhandlers/demux-woh/#description","text":"The demux operation can be used to demux multiple streams (e.g. presenter and presentation) from one container and put them into separate tracks. It uses a special encoding profile that has two outputs. It flavors the target media in the order listed in the encoding profile output.","title":"Description"},{"location":"workflowoperationhandlers/demux-woh/#parameter-table","text":"Configuration Key Example Description source-flavors multitrack/source Which media should be encoded target-tags archive,rss;rss Specifies the tags of the new media target-flavors presenter/*,presentation/* Specifies the flavors of the new media encoding-profile demux Specifies the encoding profile Note that target-tags can hold multiple sets of tags separated by ; . Each set is applied to the matching set of output files (same order). Target flavors are separated by , as usual. They are applied in order as well.","title":"Parameter Table"},{"location":"workflowoperationhandlers/demux-woh/#operation-example","text":"<operation id=\"demux\" exception-handler-workflow=\"partial-error\" description=\"Extract presenter and presentation video from multitrack source\"> <configurations> <configuration key=\"source-flavors\">multitrack/source</configuration> <configuration key=\"target-flavors\">presenter/source,presentation/source</configuration> <configuration key=\"target-tags\">archive</configuration> <configuration key=\"encoding-profile\">demux</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/demux-woh/#example-profile","text":"profile.demux.name = demux profile.demux.input = visual profile.demux.output = visual profile.demux.suffix = .mp4 profile.demux.ffmpeg.command = -i #{in.video.path} -c copy \\ -map 0:a:0 -map 0:v:0 #{out.dir}/#{out.name}_presenter#{out.suffix} \\ -map 0:a:1 -map 0:v:1 #{out.dir}/#{out.name}_presentation#{out.suffix}","title":"Example Profile"},{"location":"workflowoperationhandlers/duplicate-event-woh/","text":"Duplicate Event Workflow Operation Id: duplicate-event Description The duplicate event operation can be used to duplicate an event by copying an existing one. The main use case are events, which contain a series of different presentations which were all recorded with just one recording. In order to create separate events for each presentation, the original recording can be copied and each copy can be cut to only contain one presentation. If the original event was already published, the duplicate won't be published right away. The user will have to publish it manually when he is done editing it. For each duplicated event the new media package ID is stored as a workflow property: Name Example Description duplicate_media_package_ number _id duplicate_media_package_1_id=e72f2265-472a-49ae-bc04-8301d94b4b1a Media package ID of the duplicated event Parameter Table Configuration Key Example Description source-flavors archive Copy any mediapackage elements with one of these (comma separated) flavors. source-tags */* Copy any mediapackage elements with one of these (comma separated) tags. target-tags +copied Apply these (comma separated) tags to any copied media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. property-namespaces org.opencastproject.assetmanager.security Copy all asset manager properties of these (comma separated) namespaces. copy-number-prefix copy The prefix used for the number of the copy which is appended to the title of the new event. number-of-events 2 How many events to create. max-number-of-events 1000 How many events are allowed to be created at maximum. Operation Example <operation id=\"duplicate-event\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Duplicate event\"> <configurations> <configuration key=\"source-flavors\">*/*</configuration> <configuration key=\"number-of-events\">${numberOfEvents}</configuration> <configuration key=\"max-number-of-events\">1000</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"property-namespaces\"> org.opencastproject.assetmanager.security </configuration> <configuration key=\"copy-number-prefix\">copy</configuration> </configurations> </operation>","title":"Duplicate Event"},{"location":"workflowoperationhandlers/duplicate-event-woh/#duplicate-event-workflow-operation","text":"Id: duplicate-event","title":"Duplicate Event Workflow Operation"},{"location":"workflowoperationhandlers/duplicate-event-woh/#description","text":"The duplicate event operation can be used to duplicate an event by copying an existing one. The main use case are events, which contain a series of different presentations which were all recorded with just one recording. In order to create separate events for each presentation, the original recording can be copied and each copy can be cut to only contain one presentation. If the original event was already published, the duplicate won't be published right away. The user will have to publish it manually when he is done editing it. For each duplicated event the new media package ID is stored as a workflow property: Name Example Description duplicate_media_package_ number _id duplicate_media_package_1_id=e72f2265-472a-49ae-bc04-8301d94b4b1a Media package ID of the duplicated event","title":"Description"},{"location":"workflowoperationhandlers/duplicate-event-woh/#parameter-table","text":"Configuration Key Example Description source-flavors archive Copy any mediapackage elements with one of these (comma separated) flavors. source-tags */* Copy any mediapackage elements with one of these (comma separated) tags. target-tags +copied Apply these (comma separated) tags to any copied media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. property-namespaces org.opencastproject.assetmanager.security Copy all asset manager properties of these (comma separated) namespaces. copy-number-prefix copy The prefix used for the number of the copy which is appended to the title of the new event. number-of-events 2 How many events to create. max-number-of-events 1000 How many events are allowed to be created at maximum.","title":"Parameter Table"},{"location":"workflowoperationhandlers/duplicate-event-woh/#operation-example","text":"<operation id=\"duplicate-event\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Duplicate event\"> <configurations> <configuration key=\"source-flavors\">*/*</configuration> <configuration key=\"number-of-events\">${numberOfEvents}</configuration> <configuration key=\"max-number-of-events\">1000</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"property-namespaces\"> org.opencastproject.assetmanager.security </configuration> <configuration key=\"copy-number-prefix\">copy</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/editor-woh/","text":"VideoEditorWorkflowOperationHandler Description The editor operation processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed. Parameter Table configuration keys example description source-flavors */work The flavor(s) of all media files to process smil-flavors */smil The flavor(s) of the SMIL file(s) to be used skipped-flavors */work The flavor(s) of all media files to be \"processed\" (cloned) if the editor operation is skipped target-flavor-subtype trimmed The flavor subtype to be applied to all resulting videos, e.g. for a value of baz , a track with flavor foo/bar will generate another track with flavor foo/baz target-smil-flavor smil/cutting the flavor of the SMIL file containing the final video segments. Should be the same as the smil.catalog.flavor property in etc/org.opencastproject.adminui.cfg skip-if-not-trimmed false (Optional) if set to true , the track encoding will be skipped if no trimming points were defined (i.e. there is only one segment from the very beginning to the very end of the video). Defaults to false skip-processing true Do not do the actual encoding, just create the smil file and exit. This option is used with process-smil workflow operation, which will use the smil to run the encodings then. Default is false. preview_flavors */preview (Legacy) Flavors used to preview the video in the editor. Currently has no effect. Preview flavors are now configured in the file etc/org.opencastproject.adminui.cfg interactive false (Legacy) If true make the operation interactive, i.e. pause and wait for user input. Do not use. Interactive operations are deprecated in the current API. Operation Example <operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"skipped-flavors\">*/work</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">smil/cutting</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation>","title":"Editor"},{"location":"workflowoperationhandlers/editor-woh/#videoeditorworkflowoperationhandler","text":"","title":"VideoEditorWorkflowOperationHandler"},{"location":"workflowoperationhandlers/editor-woh/#description","text":"The editor operation processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.","title":"Description"},{"location":"workflowoperationhandlers/editor-woh/#parameter-table","text":"configuration keys example description source-flavors */work The flavor(s) of all media files to process smil-flavors */smil The flavor(s) of the SMIL file(s) to be used skipped-flavors */work The flavor(s) of all media files to be \"processed\" (cloned) if the editor operation is skipped target-flavor-subtype trimmed The flavor subtype to be applied to all resulting videos, e.g. for a value of baz , a track with flavor foo/bar will generate another track with flavor foo/baz target-smil-flavor smil/cutting the flavor of the SMIL file containing the final video segments. Should be the same as the smil.catalog.flavor property in etc/org.opencastproject.adminui.cfg skip-if-not-trimmed false (Optional) if set to true , the track encoding will be skipped if no trimming points were defined (i.e. there is only one segment from the very beginning to the very end of the video). Defaults to false skip-processing true Do not do the actual encoding, just create the smil file and exit. This option is used with process-smil workflow operation, which will use the smil to run the encodings then. Default is false. preview_flavors */preview (Legacy) Flavors used to preview the video in the editor. Currently has no effect. Preview flavors are now configured in the file etc/org.opencastproject.adminui.cfg interactive false (Legacy) If true make the operation interactive, i.e. pause and wait for user input. Do not use. Interactive operations are deprecated in the current API.","title":"Parameter Table"},{"location":"workflowoperationhandlers/editor-woh/#operation-example","text":"<operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"skipped-flavors\">*/work</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">smil/cutting</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/encode-woh/","text":"Encode Workflow Operation Handler Parallel FFmpeg encoding Description The encode workflow operation can be used to encode media files to different formats using FFmpeg . It can utilize the parallel encoding capabilities of FFmpeg. This has the advantage that the source file needs to be read only once for several encodings, reducing the encoding time quite a lot. Additionally, this will let FFmpeg make better use of multiple CPU cores. Parameter Table configuration keys example description source-flavor\u00b9 presenter/work Single flavor specifying media to be encoded source-flavors\u00b9 presenter/work,presentation/work Comma-separated list of flavors specifying media to be encoded target-flavor presenter/delivery Flavor of the new media source-tags sometag Comma-separated list of tags of media to encode target-tags sometag Comma-separated list of tags to be assigned to the new media encoding-profile parallel.http Encoding profile to use \u00b9If source-flavour s are specified, media of these flavors are considered, if not, media matching the source-flavour configuration option is considered. As explained in the \"Encoding Profile Example\" section , every media file created by an encode operation has its own named suffix. The suffix name is defined in the encode profile definition. It will be added as a tag to the corresponding track in the media package. This is different from the target-tags workflow operation parameter, which will cause the specified tag list to be added to every media file created by the operation. For instance, let us take the example operation and encoding profile defined in this documentation. After a successful run of the operation, the media package will contain four new tracks: the first one containing the new tags engage-download , engage-streaming and low-quality ; the second one containing the new tags engage-download , engage-streaming and medium-quality ; etc. Operation Example <operation id=\"encode\" exception-handler-workflow=\"partial-error\" description=\"encoding media files\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/delivery</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">parallel.http</configuration> </configurations> </operation> Encoding Profile Example Unlike a regular compose operation, this operation can generate more than one output file and, therefore, more than one media package track elements. In order to distinguish these tracks, the encoding profile syntax for this operation allows different named suffix parameters in the form of <profile_name>.suffix.<suffix_name> = <suffix_value> . Because file names are irrelevant for the workflow operations, each suffix name is added as a tag to the corresponding media package element. For instance, if a media file with a filename of myfile.ext is processed with the encoding profile in the example below, the first output file will be myfile-low.mp4 and the resulting media package element will contain a tag with the value low-quality ; the second output file will be myfile-medium.mp4 and the resulting media package element will contain a tag with the value medium-quality ; and so on. # Distribution format definition for low quality presenter download profile.parallel.http.name = parallel video encoding profile.parallel.http.input = visual profile.parallel.http.output = visual profile.parallel.http.suffix.low-quality = -low.mp4 profile.parallel.http.suffix.medium-quality = -medium.mp4 profile.parallel.http.suffix.high-quality = -high.mp4 profile.parallel.http.suffix.hd-quality = -hd.mp4 profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ -c:v libx264 -filter:v yadif,scale=-2:288 -preset slower -crf 28 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 32k #{out.dir}/#{out.name}#{out.suffix.low-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:360 -preset slower -crf 25 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 48k #{out.dir}/#{out.name}#{out.suffix.medium-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:720 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality} Resolution Based Encoding The encode operation supports encoding based on the input video's resolution. For example, you can encode a certain output resolution only for high resolution inputs. For this you can define conditionally set variables like if-height-geq-720 as part of the ffmpeg.command property which retain their value only if the video resolution meets the defined criteria. This variable can then be used in the ffmpeg.command property. This modification to the encoding profile from above will encode the 720p output only if the input height is at least 720 pixels, note the Reference #{if-height-geq-720} to the variable at the end of the ffmpeg.command property: \u2026 profile.parallel.http.ffmpeg.command.if-height-geq-720 = -c:v libx264 -filter:v yadif,scale=-2:720 \\ -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality} profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ \u2026 -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ #{if-height-geq-720} There are currently two resolution based conditionally set variables supported: Variable Example Description if-height-geq-<height> if-height-geq-720 The value is set if the height of the video is greater or equal to <height> pixels. if-width-or-height-geq-<width>-<height> if-width-or-height-geq-1280-720 The value is set if the width of the video is greater or equal to <width> or if the height is greater or equal to <height> . if-height-lt-<height> if-height-lt-480 The value is set if the height of the video is less than <height> pixels.","title":"Encode"},{"location":"workflowoperationhandlers/encode-woh/#encode-workflow-operation-handler","text":"Parallel FFmpeg encoding","title":"Encode Workflow Operation Handler"},{"location":"workflowoperationhandlers/encode-woh/#description","text":"The encode workflow operation can be used to encode media files to different formats using FFmpeg . It can utilize the parallel encoding capabilities of FFmpeg. This has the advantage that the source file needs to be read only once for several encodings, reducing the encoding time quite a lot. Additionally, this will let FFmpeg make better use of multiple CPU cores.","title":"Description"},{"location":"workflowoperationhandlers/encode-woh/#parameter-table","text":"configuration keys example description source-flavor\u00b9 presenter/work Single flavor specifying media to be encoded source-flavors\u00b9 presenter/work,presentation/work Comma-separated list of flavors specifying media to be encoded target-flavor presenter/delivery Flavor of the new media source-tags sometag Comma-separated list of tags of media to encode target-tags sometag Comma-separated list of tags to be assigned to the new media encoding-profile parallel.http Encoding profile to use \u00b9If source-flavour s are specified, media of these flavors are considered, if not, media matching the source-flavour configuration option is considered. As explained in the \"Encoding Profile Example\" section , every media file created by an encode operation has its own named suffix. The suffix name is defined in the encode profile definition. It will be added as a tag to the corresponding track in the media package. This is different from the target-tags workflow operation parameter, which will cause the specified tag list to be added to every media file created by the operation. For instance, let us take the example operation and encoding profile defined in this documentation. After a successful run of the operation, the media package will contain four new tracks: the first one containing the new tags engage-download , engage-streaming and low-quality ; the second one containing the new tags engage-download , engage-streaming and medium-quality ; etc.","title":"Parameter Table"},{"location":"workflowoperationhandlers/encode-woh/#operation-example","text":"<operation id=\"encode\" exception-handler-workflow=\"partial-error\" description=\"encoding media files\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/delivery</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">parallel.http</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/encode-woh/#encoding-profile-example","text":"Unlike a regular compose operation, this operation can generate more than one output file and, therefore, more than one media package track elements. In order to distinguish these tracks, the encoding profile syntax for this operation allows different named suffix parameters in the form of <profile_name>.suffix.<suffix_name> = <suffix_value> . Because file names are irrelevant for the workflow operations, each suffix name is added as a tag to the corresponding media package element. For instance, if a media file with a filename of myfile.ext is processed with the encoding profile in the example below, the first output file will be myfile-low.mp4 and the resulting media package element will contain a tag with the value low-quality ; the second output file will be myfile-medium.mp4 and the resulting media package element will contain a tag with the value medium-quality ; and so on. # Distribution format definition for low quality presenter download profile.parallel.http.name = parallel video encoding profile.parallel.http.input = visual profile.parallel.http.output = visual profile.parallel.http.suffix.low-quality = -low.mp4 profile.parallel.http.suffix.medium-quality = -medium.mp4 profile.parallel.http.suffix.high-quality = -high.mp4 profile.parallel.http.suffix.hd-quality = -hd.mp4 profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ -c:v libx264 -filter:v yadif,scale=-2:288 -preset slower -crf 28 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 32k #{out.dir}/#{out.name}#{out.suffix.low-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:360 -preset slower -crf 25 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 48k #{out.dir}/#{out.name}#{out.suffix.medium-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:720 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality}","title":"Encoding Profile Example"},{"location":"workflowoperationhandlers/encode-woh/#resolution-based-encoding","text":"The encode operation supports encoding based on the input video's resolution. For example, you can encode a certain output resolution only for high resolution inputs. For this you can define conditionally set variables like if-height-geq-720 as part of the ffmpeg.command property which retain their value only if the video resolution meets the defined criteria. This variable can then be used in the ffmpeg.command property. This modification to the encoding profile from above will encode the 720p output only if the input height is at least 720 pixels, note the Reference #{if-height-geq-720} to the variable at the end of the ffmpeg.command property: \u2026 profile.parallel.http.ffmpeg.command.if-height-geq-720 = -c:v libx264 -filter:v yadif,scale=-2:720 \\ -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality} profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ \u2026 -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ #{if-height-geq-720} There are currently two resolution based conditionally set variables supported: Variable Example Description if-height-geq-<height> if-height-geq-720 The value is set if the height of the video is greater or equal to <height> pixels. if-width-or-height-geq-<width>-<height> if-width-or-height-geq-1280-720 The value is set if the width of the video is greater or equal to <width> or if the height is greater or equal to <height> . if-height-lt-<height> if-height-lt-480 The value is set if the height of the video is less than <height> pixels.","title":"Resolution Based Encoding"},{"location":"workflowoperationhandlers/error-resolution-woh/","text":"Error Resolution Workflow Operation Id: error-resolution Description The Error Resolution operation is an internal operation inserted in the workflow by the Workflow Service when an operation that has retry-strategy=\"hold\" fails. This operations pauses the workflow so that the user can retry or abort processing using the Admin UI. See Retry Strategies for more details.","title":"Error Resolution"},{"location":"workflowoperationhandlers/error-resolution-woh/#error-resolution-workflow-operation","text":"Id: error-resolution","title":"Error Resolution Workflow Operation"},{"location":"workflowoperationhandlers/error-resolution-woh/#description","text":"The Error Resolution operation is an internal operation inserted in the workflow by the Workflow Service when an operation that has retry-strategy=\"hold\" fails. This operations pauses the workflow so that the user can retry or abort processing using the Admin UI. See Retry Strategies for more details.","title":"Description"},{"location":"workflowoperationhandlers/execute-many-woh/","text":"Execute Many Workflow Operation This operation handler filters a set of MediaPackageElements that match certain input conditions and runs a command on each of them. The command may be used to create a new mediapackage element, or to add configuration properties to the running workflow. To run a command only once for the whole mediapackage, use the Execute Once operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration. Parameter table All parameters are empty by default if not specified. The special parameters #in and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{in} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No set-workflow-properties true / false Import workflow properties from the output file No source-flavor presentation/source Run the command for any MediaPackage elements with this flavor. Elements must also match the source-tags condition, if present No source-tag rss, trim, -engage Run the command for any MediaPackage elements with one of these (comma- separated) tags. If any of them starts with '-', MediaPackage elements containing this tag will be excluded. Elements must also match the source-flavor condition, if present No source-audio true If present, require the element either to have an audio stream (true) or no audio stream (false), in addition to any source-flavor or source-tag conditions. No source-video true If present, require the element either to have a video stream (true) or no video stream (false), in addition to any source-flavor or source-tag conditions. No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element No If set-workflow-properties is true, the command should write a plain-text properties file to the location specified by #{out} in the key-value format supported by the Java Properties class, for example: key1=value1 key2=value2 Operation Examples Run a command which creates a new version of a track: <operation id=\"execute-many\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">qt-faststart</configuration> <configuration key=\"params\">-f #{in} #{out}</configuration> <configuration key=\"source-flavor\">*/toprocess</configuration> <configuration key=\"source-tags\">copy, -rss</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/processed</configuration> <configuration key=\"target-tags\">copied, -copy</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation> Run a command which inspects any track with a presenter/source flavor and an audio stream, and adds new configuration properties to the running workflow, leaving the mediapackage unchanged: <operation id=\"execute-many\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect track and update workflow properties\"> <configurations> <configuration key=\"exec\">/usr/local/bin/oc-track-inspect-audio.sh</configuration> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-audio\">true</configuration> <configuration key=\"params\">#{in} #{out}</configuration> <configuration key=\"set-workflow-properties\">true</configuration> <configuration key=\"output-filename\">wf.properties</configuration> <configuration key=\"expected-type\">Attachment</configuration> </configurations> </operation>","title":"Execute Many"},{"location":"workflowoperationhandlers/execute-many-woh/#execute-many-workflow-operation","text":"This operation handler filters a set of MediaPackageElements that match certain input conditions and runs a command on each of them. The command may be used to create a new mediapackage element, or to add configuration properties to the running workflow. To run a command only once for the whole mediapackage, use the Execute Once operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration.","title":"Execute Many Workflow Operation"},{"location":"workflowoperationhandlers/execute-many-woh/#parameter-table","text":"All parameters are empty by default if not specified. The special parameters #in and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{in} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No set-workflow-properties true / false Import workflow properties from the output file No source-flavor presentation/source Run the command for any MediaPackage elements with this flavor. Elements must also match the source-tags condition, if present No source-tag rss, trim, -engage Run the command for any MediaPackage elements with one of these (comma- separated) tags. If any of them starts with '-', MediaPackage elements containing this tag will be excluded. Elements must also match the source-flavor condition, if present No source-audio true If present, require the element either to have an audio stream (true) or no audio stream (false), in addition to any source-flavor or source-tag conditions. No source-video true If present, require the element either to have a video stream (true) or no video stream (false), in addition to any source-flavor or source-tag conditions. No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element No If set-workflow-properties is true, the command should write a plain-text properties file to the location specified by #{out} in the key-value format supported by the Java Properties class, for example: key1=value1 key2=value2","title":"Parameter table"},{"location":"workflowoperationhandlers/execute-many-woh/#operation-examples","text":"Run a command which creates a new version of a track: <operation id=\"execute-many\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">qt-faststart</configuration> <configuration key=\"params\">-f #{in} #{out}</configuration> <configuration key=\"source-flavor\">*/toprocess</configuration> <configuration key=\"source-tags\">copy, -rss</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/processed</configuration> <configuration key=\"target-tags\">copied, -copy</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation> Run a command which inspects any track with a presenter/source flavor and an audio stream, and adds new configuration properties to the running workflow, leaving the mediapackage unchanged: <operation id=\"execute-many\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect track and update workflow properties\"> <configurations> <configuration key=\"exec\">/usr/local/bin/oc-track-inspect-audio.sh</configuration> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-audio\">true</configuration> <configuration key=\"params\">#{in} #{out}</configuration> <configuration key=\"set-workflow-properties\">true</configuration> <configuration key=\"output-filename\">wf.properties</configuration> <configuration key=\"expected-type\">Attachment</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/execute-once-woh/","text":"Execute Once Workflow Operation This operation handler runs a single command with multiple MediaPackage elements as arguments. The command may be used to create a new mediapackage element, or to add configuration properties to the running workflow. To run a command for each element in a MediaPackage, use the Execute Many operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration. Parameter table All parameters are empty by default if not specified. The special parameters #id , #flavor and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{flavor(presentation/distribute)} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No set-workflow-properties true / false Import workflow properties from the output file No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command. If no new element is created, this parameter is ignored. Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element. No If set-workflow-properties is true, the command should write a plain-text properties file to the location specified by #{out} in the key-value format supported by the Java Properties class, for example: key1=value1 key2=value2 Operation Examples Run a command which combines two tracks into a new track: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">ges-launch</configuration> <configuration key=\"params\">-e #{flavor(presenter/source)} 0 5m14s #{flavor(presentation/source)} 0 14s</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/joined</configuration> <configuration key=\"target-tags\">joined, -tojoin</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation> Run a command which inspects a mediapackage and adds new configuration properties to the running workflow, leaving the mediapackage unchanged: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media and update workflow properties\"> <configurations> <configuration key=\"exec\">/usr/local/bin/oc-inspect.sh</configuration> <configuration key=\"params\">#{out} #{id}</configuration> <configuration key=\"set-workflow-properties\">true</configuration> <configuration key=\"output-filename\">wf.properties</configuration> <configuration key=\"expected-type\">Attachment</configuration> </configurations> </operation>","title":"Execute Once"},{"location":"workflowoperationhandlers/execute-once-woh/#execute-once-workflow-operation","text":"This operation handler runs a single command with multiple MediaPackage elements as arguments. The command may be used to create a new mediapackage element, or to add configuration properties to the running workflow. To run a command for each element in a MediaPackage, use the Execute Many operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration.","title":"Execute Once Workflow Operation"},{"location":"workflowoperationhandlers/execute-once-woh/#parameter-table","text":"All parameters are empty by default if not specified. The special parameters #id , #flavor and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{flavor(presentation/distribute)} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No set-workflow-properties true / false Import workflow properties from the output file No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command. If no new element is created, this parameter is ignored. Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element. No If set-workflow-properties is true, the command should write a plain-text properties file to the location specified by #{out} in the key-value format supported by the Java Properties class, for example: key1=value1 key2=value2","title":"Parameter table"},{"location":"workflowoperationhandlers/execute-once-woh/#operation-examples","text":"Run a command which combines two tracks into a new track: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">ges-launch</configuration> <configuration key=\"params\">-e #{flavor(presenter/source)} 0 5m14s #{flavor(presentation/source)} 0 14s</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/joined</configuration> <configuration key=\"target-tags\">joined, -tojoin</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation> Run a command which inspects a mediapackage and adds new configuration properties to the running workflow, leaving the mediapackage unchanged: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media and update workflow properties\"> <configurations> <configuration key=\"exec\">/usr/local/bin/oc-inspect.sh</configuration> <configuration key=\"params\">#{out} #{id}</configuration> <configuration key=\"set-workflow-properties\">true</configuration> <configuration key=\"output-filename\">wf.properties</configuration> <configuration key=\"expected-type\">Attachment</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/export-wf-properties-woh/","text":"ExportWfPropertiesWorkflowOperationHandler Description The ExportWfPropertiesWorkflowOperation can be used to export workflow properties to a Java properties file. Those properties can later be imported using the ImportWfPropertiesWorkflowOperation . Parameter Table Configuration Key Example Description target-flavor* processing/defaults The flavor to apply to the exported workflow properties target-tags archive The tags to apply to the exported workflow properties keys variableName1, variableName2 The workflow property keys that need to be persisted. If the option is not specified, all defined properties should be persisted. * mandatory configuration key Operation Example <operation id=\"export-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Export workflow settings to Java properties file\"> <configurations> <configuration key=\"target-flavor\">processing/defaults</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Export Workflow Properties"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#exportwfpropertiesworkflowoperationhandler","text":"","title":"ExportWfPropertiesWorkflowOperationHandler"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#description","text":"The ExportWfPropertiesWorkflowOperation can be used to export workflow properties to a Java properties file. Those properties can later be imported using the ImportWfPropertiesWorkflowOperation .","title":"Description"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#parameter-table","text":"Configuration Key Example Description target-flavor* processing/defaults The flavor to apply to the exported workflow properties target-tags archive The tags to apply to the exported workflow properties keys variableName1, variableName2 The workflow property keys that need to be persisted. If the option is not specified, all defined properties should be persisted. * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#operation-example","text":"<operation id=\"export-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Export workflow settings to Java properties file\"> <configurations> <configuration key=\"target-flavor\">processing/defaults</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/extracttext-woh/","text":"ExtractTextWorkflowOperation Description The ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR. Parameter Table configuration keys example description source-flavor presentation/work Specifies which media should be processed source-tags text Specifies which media should be processed target-tags engage Specifies the tags for the produces media Operation Example <operation id=\"extract-text\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting text from presentation segments\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-tags\">engage,archive</configuration> </configurations> </operation>","title":"Extract Text"},{"location":"workflowoperationhandlers/extracttext-woh/#extracttextworkflowoperation","text":"","title":"ExtractTextWorkflowOperation"},{"location":"workflowoperationhandlers/extracttext-woh/#description","text":"The ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.","title":"Description"},{"location":"workflowoperationhandlers/extracttext-woh/#parameter-table","text":"configuration keys example description source-flavor presentation/work Specifies which media should be processed source-tags text Specifies which media should be processed target-tags engage Specifies the tags for the produces media","title":"Parameter Table"},{"location":"workflowoperationhandlers/extracttext-woh/#operation-example","text":"<operation id=\"extract-text\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting text from presentation segments\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-tags\">engage,archive</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/failing-woh/","text":"Failing Workflow Operation Id: failing Description The Failing operation will always fail and is supposed to be used for testing purposes only.","title":"Failing"},{"location":"workflowoperationhandlers/failing-woh/#failing-workflow-operation","text":"Id: failing","title":"Failing Workflow Operation"},{"location":"workflowoperationhandlers/failing-woh/#description","text":"The Failing operation will always fail and is supposed to be used for testing purposes only.","title":"Description"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/","text":"Google Speech Attach Transcription Description Google Speech Attach Transcription converts the json format file received from the Google Speech-to-Text service into the desired caption format and adds it to the media package. Parameter Table configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" line-size The line size (number of characters) of the transcripts to display at a time. Optional. EMPTY 100 target-flavor The flavor of the caption/transcription file generated. Mandatory. EMPTY captions/timedtext target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package. EMPTY vtt Example <!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">100</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Google Speech Attach Transcription"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#google-speech-attach-transcription","text":"","title":"Google Speech Attach Transcription"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#description","text":"Google Speech Attach Transcription converts the json format file received from the Google Speech-to-Text service into the desired caption format and adds it to the media package.","title":"Description"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#parameter-table","text":"configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" line-size The line size (number of characters) of the transcripts to display at a time. Optional. EMPTY 100 target-flavor The flavor of the caption/transcription file generated. Mandatory. EMPTY captions/timedtext target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package. EMPTY vtt","title":"Parameter Table"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#example","text":"<!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">100</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/","text":"Google Speech Start Transcription Description Google speech Start Transcription invokes the Google Speech-to-Text service by passing an audio file to be translated to text. Parameter Table configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. Optional false captions/timedtext language-code The language code to use for the transcription. Optional. If set, it will override the configuration language code EMPTY en-US, supported language: https://cloud.google.com/speech-to-text/docs/languages One of source-flavor or source-tag must be specified. Example <!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Encoding profile used in example above profile.audio-flac.name = audio-flac profile.audio-flac.input = stream profile.audio-flac.output = audio profile.audio-flac.suffix = -audio.flac profile.audio-flac.mimetype = audio/flac profile.audio-flac.ffmpeg.command = -i /#{in.video.path} -ac 1 #{out.dir}/#{out.name}#{out.suffix}","title":"Google Speech Start Transcription"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#google-speech-start-transcription","text":"","title":"Google Speech Start Transcription"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#description","text":"Google speech Start Transcription invokes the Google Speech-to-Text service by passing an audio file to be translated to text.","title":"Description"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#parameter-table","text":"configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. Optional false captions/timedtext language-code The language code to use for the transcription. Optional. If set, it will override the configuration language code EMPTY en-US, supported language: https://cloud.google.com/speech-to-text/docs/languages One of source-flavor or source-tag must be specified.","title":"Parameter Table"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#example","text":"<!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#encoding-profile-used-in-example-above","text":"profile.audio-flac.name = audio-flac profile.audio-flac.input = stream profile.audio-flac.output = audio profile.audio-flac.suffix = -audio.flac profile.audio-flac.mimetype = audio/flac profile.audio-flac.ffmpeg.command = -i /#{in.video.path} -ac 1 #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding profile used in example above"},{"location":"workflowoperationhandlers/httpnotify-woh/","text":"HttpNotificationWorkflowOperation Description Opencast can through this operation notify any HTTP endpoint about the process of the workflow. Parameter Table A parameter that is always posted is the workflow instance identifier in the parameter named workflowInstanceId containing the current workflow\u2019s identifier. Key Required Description Example url true The target URL to notify http://test.ch subject false The name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published importing_started message false Data supporting the notification. Think of this as the body of an e-mail internal::25 method false Supported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default post max-retry false The maximal number of notification attempts. The default value is 5 5 timeout false The timeout in seconds for the notification request: The default value is 10 10 Operation Example <operation id=\"http-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify test\"> <configurations> <configuration key=\"url\">http://www.test.ch</configuration> <configuration key=\"subject\">importing-started</configuration> <configuration key=\"message\">internal::25</configuration> <configuration key=\"method\">put</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation>","title":"HTTP Notify"},{"location":"workflowoperationhandlers/httpnotify-woh/#httpnotificationworkflowoperation","text":"","title":"HttpNotificationWorkflowOperation"},{"location":"workflowoperationhandlers/httpnotify-woh/#description","text":"Opencast can through this operation notify any HTTP endpoint about the process of the workflow.","title":"Description"},{"location":"workflowoperationhandlers/httpnotify-woh/#parameter-table","text":"A parameter that is always posted is the workflow instance identifier in the parameter named workflowInstanceId containing the current workflow\u2019s identifier. Key Required Description Example url true The target URL to notify http://test.ch subject false The name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published importing_started message false Data supporting the notification. Think of this as the body of an e-mail internal::25 method false Supported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default post max-retry false The maximal number of notification attempts. The default value is 5 5 timeout false The timeout in seconds for the notification request: The default value is 10 10","title":"Parameter Table"},{"location":"workflowoperationhandlers/httpnotify-woh/#operation-example","text":"<operation id=\"http-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify test\"> <configurations> <configuration key=\"url\">http://www.test.ch</configuration> <configuration key=\"subject\">importing-started</configuration> <configuration key=\"message\">internal::25</configuration> <configuration key=\"method\">put</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/image-convert-woh/","text":"Image-Convert Workflow Operation Description The Image-Convert workflow operation allows source images to be converted into target images with different encoding settings. One example is the conversion of preview images into different formats. This operation expects an attachment as input and creates one attachment as output. Parameter Table configuration keys example description default value source-tags* preview+player,preview+search A comma separated list of source image(s) tags. EMPTY source-flavors* */image A comma separated list of source image(s) flavors. EMPTY tags-and-flavors false An boolean value whether to select elements with tags and flavors (then set this option to true) or either tags or flavors (then set this option to false). false target-tags +preview-converted,-preview+player Apply these (comma separated) tags to the output attachments. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor* */image+converted Apply these flavor to the output attachments. EMPTY encoding-profiles* jpeg-player,jpeg-search A comma separated list of encoding profiles to be applied to each input image. EMPTY * mandatory configuration key Note: At least source-tags or source-flavors parameter must be set. Operation Example This operation would convert all image attachments with flavor matches */preview and tag player into two different formats described by the encoding profiles preview-regular.image and preview-small.image . The produced image attachments will have an flavor with the subtype preview+player . <operation id=\"image-convert\" exception-handler-workflow=\"error\" description=\"Resize images to fixed size\"> <configurations> <configuration key=\"source-tags\">player</configuration> <configuration key=\"source-flavors\">*/preview</configuration> <configuration key=\"tags-and-flavors\">true</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"target-flavor\">*/preview+player</configuration> <configuration key=\"encoding-profiles\">preview-regular.image,preview-small.image</configuration> </configurations> </operation> Encoding Profile Example # Player preview image regular size profile.preview-regular.image.name = player preview image regular size profile.preview-regular.image.input = image profile.preview-regular.image.output = image profile.preview-regular.image.suffix = -preview-regular.jpg profile.preview-regular.image.mimetype = image/jpeg profile.preview-regular.image.ffmpeg.command = -i #{in.video.path} -vf scale=480:-2 #{out.dir}/#{out.name}#{out.suffix}","title":"Image convert"},{"location":"workflowoperationhandlers/image-convert-woh/#image-convert-workflow-operation","text":"","title":"Image-Convert Workflow Operation"},{"location":"workflowoperationhandlers/image-convert-woh/#description","text":"The Image-Convert workflow operation allows source images to be converted into target images with different encoding settings. One example is the conversion of preview images into different formats. This operation expects an attachment as input and creates one attachment as output.","title":"Description"},{"location":"workflowoperationhandlers/image-convert-woh/#parameter-table","text":"configuration keys example description default value source-tags* preview+player,preview+search A comma separated list of source image(s) tags. EMPTY source-flavors* */image A comma separated list of source image(s) flavors. EMPTY tags-and-flavors false An boolean value whether to select elements with tags and flavors (then set this option to true) or either tags or flavors (then set this option to false). false target-tags +preview-converted,-preview+player Apply these (comma separated) tags to the output attachments. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor* */image+converted Apply these flavor to the output attachments. EMPTY encoding-profiles* jpeg-player,jpeg-search A comma separated list of encoding profiles to be applied to each input image. EMPTY * mandatory configuration key Note: At least source-tags or source-flavors parameter must be set.","title":"Parameter Table"},{"location":"workflowoperationhandlers/image-convert-woh/#operation-example","text":"This operation would convert all image attachments with flavor matches */preview and tag player into two different formats described by the encoding profiles preview-regular.image and preview-small.image . The produced image attachments will have an flavor with the subtype preview+player . <operation id=\"image-convert\" exception-handler-workflow=\"error\" description=\"Resize images to fixed size\"> <configurations> <configuration key=\"source-tags\">player</configuration> <configuration key=\"source-flavors\">*/preview</configuration> <configuration key=\"tags-and-flavors\">true</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"target-flavor\">*/preview+player</configuration> <configuration key=\"encoding-profiles\">preview-regular.image,preview-small.image</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/image-convert-woh/#encoding-profile-example","text":"# Player preview image regular size profile.preview-regular.image.name = player preview image regular size profile.preview-regular.image.input = image profile.preview-regular.image.output = image profile.preview-regular.image.suffix = -preview-regular.jpg profile.preview-regular.image.mimetype = image/jpeg profile.preview-regular.image.ffmpeg.command = -i #{in.video.path} -vf scale=480:-2 #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding Profile Example"},{"location":"workflowoperationhandlers/image-woh/","text":"Image Workflow Operation ID: image Description The image operation will extract still images from a video using FFmpeg and a list of given encoding profiles. Both absolute and relative positions can be used. Parameter Table configuration keys example description source-flavor presenter/source Specifies which media should be processed. source-flavors presenter/source, presentation/source Specifies a list of media which should be processed. In case a flavor has been specified in source-flavor , it will be added to this list. source-tags engage Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http Comma-separated list of encoding profiles to use. time 1 or 5% Comma-separated list of times in seconds or as percentage of the source track duration where the images should be extracted target-base-name-format-second thumbnail_%.0f%s Used to control the target filenames for images extracted at absolute times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images target-base-name-format-percent thumbnail_%.3f%s Used to control the target filenames for images extracted at relative times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images end-margin 500 Safety margin at the end of the track. Sometimes, image extraction is critical at the end of the file. Using end-margin ensures, that no images are being extracted near the end of the video file to avoid problems with defective inputs. (Default: 100) Notes: Absolute and relative position may be mixed up in the configuration key time Operation Example Extract one image at position 1 second using the encoding profile search-cover.http . <operation id=\"image\" description=\"Encoding presenter preview image\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presenter/search+preview</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">search-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> Extract images at three relative positions ( 1%, 50%, 100% ) from the presenter/trimmed track. For each position, we use three different encoding profiles ( example.encoding.profile.* ). This operation therefore generates nine images in total. The target filenames will be formed based on the target-base-name-format-* configuration keys (prefix) and the configuration of the encoding profiles (file extension and possibly suffix). <operation id=\"image\" description=\"Extract set of thumbnails\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"target-flavor\">presenter/thumbnails</configuration> <configuration key=\"target-base-name-format-second\">thumbnail_%.3f%s</configuration> <configuration key=\"target-base-name-format-percent\">thumbnail_%.0f%s</configuration> <configuration key=\"encoding-profile\"> example.encoding.profile.small, example.encoding.profile.medium, example.encoding.profile.large</configuration> <configuration key=\"time\">1%, 50%, 100%</configuration> <configuration key=\"end-margin\">1000</configuration> </configurations> </operation>","title":"Image"},{"location":"workflowoperationhandlers/image-woh/#image-workflow-operation","text":"ID: image","title":"Image Workflow Operation"},{"location":"workflowoperationhandlers/image-woh/#description","text":"The image operation will extract still images from a video using FFmpeg and a list of given encoding profiles. Both absolute and relative positions can be used.","title":"Description"},{"location":"workflowoperationhandlers/image-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/source Specifies which media should be processed. source-flavors presenter/source, presentation/source Specifies a list of media which should be processed. In case a flavor has been specified in source-flavor , it will be added to this list. source-tags engage Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http Comma-separated list of encoding profiles to use. time 1 or 5% Comma-separated list of times in seconds or as percentage of the source track duration where the images should be extracted target-base-name-format-second thumbnail_%.0f%s Used to control the target filenames for images extracted at absolute times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images target-base-name-format-percent thumbnail_%.3f%s Used to control the target filenames for images extracted at relative times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images end-margin 500 Safety margin at the end of the track. Sometimes, image extraction is critical at the end of the file. Using end-margin ensures, that no images are being extracted near the end of the video file to avoid problems with defective inputs. (Default: 100) Notes: Absolute and relative position may be mixed up in the configuration key time","title":"Parameter Table"},{"location":"workflowoperationhandlers/image-woh/#operation-example","text":"Extract one image at position 1 second using the encoding profile search-cover.http . <operation id=\"image\" description=\"Encoding presenter preview image\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presenter/search+preview</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">search-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> Extract images at three relative positions ( 1%, 50%, 100% ) from the presenter/trimmed track. For each position, we use three different encoding profiles ( example.encoding.profile.* ). This operation therefore generates nine images in total. The target filenames will be formed based on the target-base-name-format-* configuration keys (prefix) and the configuration of the encoding profiles (file extension and possibly suffix). <operation id=\"image\" description=\"Extract set of thumbnails\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"target-flavor\">presenter/thumbnails</configuration> <configuration key=\"target-base-name-format-second\">thumbnail_%.3f%s</configuration> <configuration key=\"target-base-name-format-percent\">thumbnail_%.0f%s</configuration> <configuration key=\"encoding-profile\"> example.encoding.profile.small, example.encoding.profile.medium, example.encoding.profile.large</configuration> <configuration key=\"time\">1%, 50%, 100%</configuration> <configuration key=\"end-margin\">1000</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/imagetovideo-woh/","text":"ImageToVideo Workflow Operation Handler Description The ImageToVideo Workflow Operation Handler allows to create a video track from a source image. Parameters table Tags and flavors can be used in combination. But combined they should match one image. configuration keys example description default value source-tags * intro A comma separated list of tags of the input image EMPTY source-flavor * intro/source The \"flavor\" of the image to use as a source input EMPTY target-tags composite,rss,atom,archive The tags to apply to the output video track EMPTY target-flavor intro/work The flavor to apply to the output video track EMPTY duration * 5 The length of the output video in seconds. EMPTY profile * image-movie Define the encoding-profile to use to create the output video. See example of profile below. EMPTY * mandatory Operation example <operation id=\"image-to-video\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-tags\">intro</configuration> <configuration key=\"source-flavor\">intro/source</configuration> <configuration key=\"target-tags\">intro-video</configuration> <configuration key=\"target-flavor\">intro/video</configuration> <configuration key=\"duration\">10</configuration> <configuration key=\"profile\">image-movie</configuration> </configurations> </operation> Encoding profile example # Image to video profile.image-movie.name = image to video profile.image-movie.input = image profile.image-movie.output = visual profile.image-movie.suffix = -image-video.mp4 profile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}","title":"Image to Video"},{"location":"workflowoperationhandlers/imagetovideo-woh/#imagetovideo-workflow-operation-handler","text":"","title":"ImageToVideo Workflow Operation Handler"},{"location":"workflowoperationhandlers/imagetovideo-woh/#description","text":"The ImageToVideo Workflow Operation Handler allows to create a video track from a source image.","title":"Description"},{"location":"workflowoperationhandlers/imagetovideo-woh/#parameters-table","text":"Tags and flavors can be used in combination. But combined they should match one image. configuration keys example description default value source-tags * intro A comma separated list of tags of the input image EMPTY source-flavor * intro/source The \"flavor\" of the image to use as a source input EMPTY target-tags composite,rss,atom,archive The tags to apply to the output video track EMPTY target-flavor intro/work The flavor to apply to the output video track EMPTY duration * 5 The length of the output video in seconds. EMPTY profile * image-movie Define the encoding-profile to use to create the output video. See example of profile below. EMPTY * mandatory","title":"Parameters table"},{"location":"workflowoperationhandlers/imagetovideo-woh/#operation-example","text":"<operation id=\"image-to-video\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-tags\">intro</configuration> <configuration key=\"source-flavor\">intro/source</configuration> <configuration key=\"target-tags\">intro-video</configuration> <configuration key=\"target-flavor\">intro/video</configuration> <configuration key=\"duration\">10</configuration> <configuration key=\"profile\">image-movie</configuration> </configurations> </operation>","title":"Operation example"},{"location":"workflowoperationhandlers/imagetovideo-woh/#encoding-profile-example","text":"# Image to video profile.image-movie.name = image to video profile.image-movie.input = image profile.image-movie.output = visual profile.image-movie.suffix = -image-video.mp4 profile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding profile example"},{"location":"workflowoperationhandlers/import-wf-properties-woh/","text":"ImportWfPropertiesWorkflowOperationHandler Description The ImportWfPropertiesWorkflowOperationHandler loads workflow properties from a Java properties file and sets the corresponding workflow instance variables so that the properties can be use to control workflow execution. In case that no properties are found in source-flavor , the workflow operation will just skip. Note that the ExportWfPropertiesWorkflowOperationHandler can be used to export workflow properties to a Java properties file. Parameter Table Configuration Key Example Description source-flavor* processing/defaults Flavor of the attachment that contains the serialized workflow instance properties keys variableName1, variableName2 The workflow property keys to retrieve (comma separated list). If the option has not been specified, all keys will be retrieved * mandatory configuration key Operation Example <operation id=\"import-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Load processing settings\"> <configurations> <configuration key=\"source-flavor\">processing/defaults</configuration> </configurations> </operation>","title":"Import Workflow Properties"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#importwfpropertiesworkflowoperationhandler","text":"","title":"ImportWfPropertiesWorkflowOperationHandler"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#description","text":"The ImportWfPropertiesWorkflowOperationHandler loads workflow properties from a Java properties file and sets the corresponding workflow instance variables so that the properties can be use to control workflow execution. In case that no properties are found in source-flavor , the workflow operation will just skip. Note that the ExportWfPropertiesWorkflowOperationHandler can be used to export workflow properties to a Java properties file.","title":"Description"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* processing/defaults Flavor of the attachment that contains the serialized workflow instance properties keys variableName1, variableName2 The workflow property keys to retrieve (comma separated list). If the option has not been specified, all keys will be retrieved * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#operation-example","text":"<operation id=\"import-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Load processing settings\"> <configurations> <configuration key=\"source-flavor\">processing/defaults</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/incident-woh/","text":"IncidentCreatorWorkflowOperationHandler Description The IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing. Parameter Table configuration keys example description default value code 2 The code number of the incident to produce. 1 severity WARNING The severity. See Incident.Severity enum. INFO details \"tagged,+rss\" / \"-rss,+tagged\" Some details: title=content;title=content;... EMPTY params \"presentation/tagged\" Some params: key=value;key=value;... EMPTY Operation Example <operation id=\"incident\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Provoke a job incident\"> <configurations> <configuration key=\"code\">3</configuration> <configuration key=\"severity\">INFO</configuration> <configuration key=\"details\">exception=content;id=325</configuration> <configuration key=\"params\">track=track-1;profile=full</configuration> </configurations> </operation>","title":"Incident"},{"location":"workflowoperationhandlers/incident-woh/#incidentcreatorworkflowoperationhandler","text":"","title":"IncidentCreatorWorkflowOperationHandler"},{"location":"workflowoperationhandlers/incident-woh/#description","text":"The IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.","title":"Description"},{"location":"workflowoperationhandlers/incident-woh/#parameter-table","text":"configuration keys example description default value code 2 The code number of the incident to produce. 1 severity WARNING The severity. See Incident.Severity enum. INFO details \"tagged,+rss\" / \"-rss,+tagged\" Some details: title=content;title=content;... EMPTY params \"presentation/tagged\" Some params: key=value;key=value;... EMPTY","title":"Parameter Table"},{"location":"workflowoperationhandlers/incident-woh/#operation-example","text":"<operation id=\"incident\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Provoke a job incident\"> <configurations> <configuration key=\"code\">3</configuration> <configuration key=\"severity\">INFO</configuration> <configuration key=\"details\">exception=content;id=325</configuration> <configuration key=\"params\">track=track-1;profile=full</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/include-woh/","text":"Include Workflow Operation Id: include Description The Include operation can be used to add a workflow definition to the current workflow. This enables re-usable sequences of operations to be factored out and allows better structuring of complex workflows. Parameter Table Configuration Key Example Description workflow-id partial-cleanup The workflow definition id of the workflow to be included Operation Example <operation id=\"include\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"workflow-id\">partial-cleanup</configuration> </configurations> </operation>","title":"Include"},{"location":"workflowoperationhandlers/include-woh/#include-workflow-operation","text":"Id: include","title":"Include Workflow Operation"},{"location":"workflowoperationhandlers/include-woh/#description","text":"The Include operation can be used to add a workflow definition to the current workflow. This enables re-usable sequences of operations to be factored out and allows better structuring of complex workflows.","title":"Description"},{"location":"workflowoperationhandlers/include-woh/#parameter-table","text":"Configuration Key Example Description workflow-id partial-cleanup The workflow definition id of the workflow to be included","title":"Parameter Table"},{"location":"workflowoperationhandlers/include-woh/#operation-example","text":"<operation id=\"include\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"workflow-id\">partial-cleanup</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/ingestdownload-woh/","text":"IngestDownloadWorkflowOperationHandler Description With the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage elements and store them to the working file repository. The external element URI's are then rewritten to the stored working file repository URI. In case of having external element URI's showing to a different Opencast working file repository, it's also possible to delete them after downloading it by activating the \"delete-external\" option. Additionally the \"source-flavors\" and \"source-tags\" option can be used to specify exactly, which external URI's should be downloaded. This operation is originally implemented to get rid of remaining files on ingest working file repositories. Parameter Table configuration keys example description default value delete-external \"true\" Whether to try to delete external working file repository URIs. FALSE source-flavors \"dublincore/episode\" List of flavors (separated by comma), elements matching a flavor will be downloaded \"*/*\" source-tags \"archive\" List of tags (separated by comma), elements matching a tag will be downloaded \"\" (empty list) tags-and-flavors \"true\" Whether both, a tag and a flavor, must match or if one is sufficient FALSE Operation Example <operation id=\"ingest-download\" fail-on-error=\"false\" description=\"Downloads external artifacts to the working file repository\"> <configurations> <configuration key=\"delete-external\">true</configuration> <configuration key=\"source-flavors\">dublincore/episode</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"tags-and-flavors\">true</configuration> </configurations> </operation>","title":"Ingest-Download"},{"location":"workflowoperationhandlers/ingestdownload-woh/#ingestdownloadworkflowoperationhandler","text":"","title":"IngestDownloadWorkflowOperationHandler"},{"location":"workflowoperationhandlers/ingestdownload-woh/#description","text":"With the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage elements and store them to the working file repository. The external element URI's are then rewritten to the stored working file repository URI. In case of having external element URI's showing to a different Opencast working file repository, it's also possible to delete them after downloading it by activating the \"delete-external\" option. Additionally the \"source-flavors\" and \"source-tags\" option can be used to specify exactly, which external URI's should be downloaded. This operation is originally implemented to get rid of remaining files on ingest working file repositories.","title":"Description"},{"location":"workflowoperationhandlers/ingestdownload-woh/#parameter-table","text":"configuration keys example description default value delete-external \"true\" Whether to try to delete external working file repository URIs. FALSE source-flavors \"dublincore/episode\" List of flavors (separated by comma), elements matching a flavor will be downloaded \"*/*\" source-tags \"archive\" List of tags (separated by comma), elements matching a tag will be downloaded \"\" (empty list) tags-and-flavors \"true\" Whether both, a tag and a flavor, must match or if one is sufficient FALSE","title":"Parameter Table"},{"location":"workflowoperationhandlers/ingestdownload-woh/#operation-example","text":"<operation id=\"ingest-download\" fail-on-error=\"false\" description=\"Downloads external artifacts to the working file repository\"> <configurations> <configuration key=\"delete-external\">true</configuration> <configuration key=\"source-flavors\">dublincore/episode</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"tags-and-flavors\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/inspect-woh/","text":"InspectWorkflowOperation Description The InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks. The InspectWorkflowOperation will also set the duration and creation date of the dublincore/episode catalog (if available) to the media package duration and media package creation date. Parameter Table Configuration Key Type Description Default accept-no-media Boolean Whether mediapackages with no media tracks should be accepted false accurate-frame-count Booelan Whether the media inspection service should determine the exact frame count false overwrite Boolean Whether to rewrite existing metadata false Accept No Media If the configuration key accept-no-media is set to false , the operation will fail if the media package does not contain any media tracks. If this behavior is not appropriate, set accept-no-media to true . Accurate Frame Count The media inspection service will provide the number of frames in case of video streams. Normally, this information is extracted from the media file header. In case of incorrect media file headers, this information might not be accurate. Using the configuration key accurate-frame-count , the media inspection service can be forced to perform a full decoding of the video stream. While this does result in an exact count of frames, this is expensive in terms of computation power. Overwrite The inspection service will try to fill empty metadata fields. It will not overwrite any existing values except when you specify the option overwrite as true . Operation Example <operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspecting mediapackage track elements\"> <configurations> <configuration key=\"overwrite\">false</configuration> <configuration key=\"accept-no-media\">false</configuration> <configuration key=\"accurate-frame-count\">false</configuration> </configurations> </operation>","title":"Inspect"},{"location":"workflowoperationhandlers/inspect-woh/#inspectworkflowoperation","text":"","title":"InspectWorkflowOperation"},{"location":"workflowoperationhandlers/inspect-woh/#description","text":"The InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks. The InspectWorkflowOperation will also set the duration and creation date of the dublincore/episode catalog (if available) to the media package duration and media package creation date.","title":"Description"},{"location":"workflowoperationhandlers/inspect-woh/#parameter-table","text":"Configuration Key Type Description Default accept-no-media Boolean Whether mediapackages with no media tracks should be accepted false accurate-frame-count Booelan Whether the media inspection service should determine the exact frame count false overwrite Boolean Whether to rewrite existing metadata false","title":"Parameter Table"},{"location":"workflowoperationhandlers/inspect-woh/#accept-no-media","text":"If the configuration key accept-no-media is set to false , the operation will fail if the media package does not contain any media tracks. If this behavior is not appropriate, set accept-no-media to true .","title":"Accept No Media"},{"location":"workflowoperationhandlers/inspect-woh/#accurate-frame-count","text":"The media inspection service will provide the number of frames in case of video streams. Normally, this information is extracted from the media file header. In case of incorrect media file headers, this information might not be accurate. Using the configuration key accurate-frame-count , the media inspection service can be forced to perform a full decoding of the video stream. While this does result in an exact count of frames, this is expensive in terms of computation power.","title":"Accurate Frame Count"},{"location":"workflowoperationhandlers/inspect-woh/#overwrite","text":"The inspection service will try to fill empty metadata fields. It will not overwrite any existing values except when you specify the option overwrite as true .","title":"Overwrite"},{"location":"workflowoperationhandlers/inspect-woh/#operation-example","text":"<operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspecting mediapackage track elements\"> <configurations> <configuration key=\"overwrite\">false</configuration> <configuration key=\"accept-no-media\">false</configuration> <configuration key=\"accurate-frame-count\">false</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/log-woh/","text":"LoggingWorkflowOperationHandler Description The LoggingWorkflowOperationHandler is primarily meant for testing and debugging purposes. It allows to log the current state of of a workflow and/or its media package. Name Default Description directory If set, write the logs to this directory workflowinstance-xml false Log the current state of the workflow as XML mediapackage-xml false Log the state of the current workflow's media package as XML mediapackage-json true Log the state of the current workflow's media package as JSON Setting any output configuration ( *-xml and *-json options) will overwrite all defaults and only the formats explicitly enabled will be logged. Operation Example <operation id=\"log\" description=\"Log to system logger\"> </operation> <operation id=\"log\" description=\"Log to file\"> <configurations> <configuration key=\"directory\">/tmp/logtest</configuration> </configurations> </operation>","title":"Log"},{"location":"workflowoperationhandlers/log-woh/#loggingworkflowoperationhandler","text":"","title":"LoggingWorkflowOperationHandler"},{"location":"workflowoperationhandlers/log-woh/#description","text":"The LoggingWorkflowOperationHandler is primarily meant for testing and debugging purposes. It allows to log the current state of of a workflow and/or its media package. Name Default Description directory If set, write the logs to this directory workflowinstance-xml false Log the current state of the workflow as XML mediapackage-xml false Log the state of the current workflow's media package as XML mediapackage-json true Log the state of the current workflow's media package as JSON Setting any output configuration ( *-xml and *-json options) will overwrite all defaults and only the formats explicitly enabled will be logged.","title":"Description"},{"location":"workflowoperationhandlers/log-woh/#operation-example","text":"<operation id=\"log\" description=\"Log to system logger\"> </operation> <operation id=\"log\" description=\"Log to file\"> <configurations> <configuration key=\"directory\">/tmp/logtest</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/move-storage-woh/","text":"MoveStorageOperationHandler Description The MoveStorageOperationHandler can be used to move files in the Asset Manager from one storage system to another. Parameter Table Configuration Key Example Description target-storage* local-storage The ID of the storage to move the files to target-version 0 The (optional) snapshot version to move. Use the keyword latest to move the last snapshot version. * mandatory configuration key Notes: Omitting target-version will move all current versions of the mediapackage to target-storage . An example usecase would be moving the raw input media to a cold(er) storage system after initial processing. Operation Example <operation id=\"move-storage\" description=\"Offloading to AWS S3\"> <configurations> <configuration key=\"target-storage\">aws-s3</configuration> </configurations> </operation>","title":"Move Storage"},{"location":"workflowoperationhandlers/move-storage-woh/#movestorageoperationhandler","text":"","title":"MoveStorageOperationHandler"},{"location":"workflowoperationhandlers/move-storage-woh/#description","text":"The MoveStorageOperationHandler can be used to move files in the Asset Manager from one storage system to another.","title":"Description"},{"location":"workflowoperationhandlers/move-storage-woh/#parameter-table","text":"Configuration Key Example Description target-storage* local-storage The ID of the storage to move the files to target-version 0 The (optional) snapshot version to move. Use the keyword latest to move the last snapshot version. * mandatory configuration key Notes: Omitting target-version will move all current versions of the mediapackage to target-storage . An example usecase would be moving the raw input media to a cold(er) storage system after initial processing.","title":"Parameter Table"},{"location":"workflowoperationhandlers/move-storage-woh/#operation-example","text":"<operation id=\"move-storage\" description=\"Offloading to AWS S3\"> <configurations> <configuration key=\"target-storage\">aws-s3</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/multiencode-woh/","text":"MultiencodeWorkflowHandler Description The MultiencodeWorkflowHandler is used to encode source media into multiple formats concurrently. The source recording are selected by source-flavors AND source-tags. Each source media selector (eg presenter or presentation) can have an independent set of encoding profile ids (one for each target recording) and target tags. Encoding of each source medium runs as one FFmpeg command. This operation will generate one multiencode operation per source medium, all of them running concurrently on the same or on different workers. In addition, the target media can be optionally tagged with the encoding profile ids. Configuration details This workflow handles each source selector independently as a section. The parameters for each configuration, such as flavors are separated positionally into sections by \" ; \". The use of the semi-colon is optional. If it is absent, there is only one section. <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section. Each source selector can have only one corresponding section. If there is only one section in one parameter, eg: target-flavors, but multiple sections in another, eg: source-flavors, then the sections are collapsed into one. For example: <configuration key=\"target-flavors\">*/preview</configuration> All targets are flavored the same way, using the example above, becomes \"presenter/preview\" and \"presentation/preview\" Each source selector can have its own set of target tags and flavors, defined as a comma delimited list. For example: <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> Using the example above. \"presenter/preview\" is tagged with \"engage-streaming,rss,atom\". \"presentation/preview\" is tagged with \"engage-download,rss,atom\". When a configuration has the same number of sections as the source, then the configurations for the operation are taken from the corresponding sections. Each section runs independently as a parallel encoding job. For example, if presenter/source is to encoded with \"mp4-low.http,mp4-medium.http\" and presentation/source is to be encoded with \"mp4-hd.http,mp4-hd.http\" The target flavors are presenter/delivery and presentation/delivery and all are tagged \"rss, archive\". The target flavors are additionally tagged with encoding profiles, so that they can selected individually. This workflow supports HLS adaptive streaming. By: 1) Using only H.264/HENV encodings in the list of encoding profiles. 2) In the encoding profile, use the \"- : \" form in FFmpeg options when appropriate (eg: \"-b:a\" instead of \"-ab\"), and add the suffix \":v\" for options that apply to video and \":a\" to options that apply to audio, (eg: -maxrate:v, -g:v ) 3) Use the same keyframe intervals (-keyint and -keyint_min ) in each profile and segment size (see below) should be a multiple of this integer. 4) Adding a special encoding profile \"multiencode-hls\" to the list of encoding profiles. By default, the segments size is 6s (-hls-time) . HLS Playlists are generated as part of the encoding process. Each mp4 is a fragmented MP4. A variant playlist is created for each mp4 and a master playlist is used to access all the different qualities. To make sure that stream switching works as expected, state the bitrates explicitly for each of mp4 encoding profiles used. For advices on how to pick bitrates see: https://developer.apple.com/documentation/http_live_streaming/hls_authoring_specification_for_apple_devices For more details on HLS, see: https://tools.ietf.org/html/rfc8216 https://tools.ietf.org/html/draft-pantos-http-live-streaming-23 Without HLS, it will look like the following. Parameter Table configuration keys example description source-flavors presenter/source ; presentation/source Which media should be encoded target-flavors */preview Specifies the flavor of the new media target-tags rss,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-medium.http ; mp4-hd.http,mp4-hd.http Encoding profiles for each source flavor tag-with-profile true (default to false) target medium are tagged with corresponding encoding profile Id Operation Example <operation id=\"multiencode\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video to Flash download\"> <configurations> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">rss,archive</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-hd.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation> Note: (Important) Each source flavor generates all the target formats in one FFmpeg call by incorporating relevant parts of the encoding profile commands. Care must be taken that no FFmpeg complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict. Encoded target recording are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes to use \"tag-with-profile\" configuration, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4","title":"Multiencode"},{"location":"workflowoperationhandlers/multiencode-woh/#multiencodeworkflowhandler","text":"","title":"MultiencodeWorkflowHandler"},{"location":"workflowoperationhandlers/multiencode-woh/#description","text":"The MultiencodeWorkflowHandler is used to encode source media into multiple formats concurrently. The source recording are selected by source-flavors AND source-tags. Each source media selector (eg presenter or presentation) can have an independent set of encoding profile ids (one for each target recording) and target tags. Encoding of each source medium runs as one FFmpeg command. This operation will generate one multiencode operation per source medium, all of them running concurrently on the same or on different workers. In addition, the target media can be optionally tagged with the encoding profile ids.","title":"Description"},{"location":"workflowoperationhandlers/multiencode-woh/#configuration-details","text":"This workflow handles each source selector independently as a section. The parameters for each configuration, such as flavors are separated positionally into sections by \" ; \". The use of the semi-colon is optional. If it is absent, there is only one section. <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section. Each source selector can have only one corresponding section. If there is only one section in one parameter, eg: target-flavors, but multiple sections in another, eg: source-flavors, then the sections are collapsed into one. For example: <configuration key=\"target-flavors\">*/preview</configuration> All targets are flavored the same way, using the example above, becomes \"presenter/preview\" and \"presentation/preview\" Each source selector can have its own set of target tags and flavors, defined as a comma delimited list. For example: <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> Using the example above. \"presenter/preview\" is tagged with \"engage-streaming,rss,atom\". \"presentation/preview\" is tagged with \"engage-download,rss,atom\". When a configuration has the same number of sections as the source, then the configurations for the operation are taken from the corresponding sections. Each section runs independently as a parallel encoding job. For example, if presenter/source is to encoded with \"mp4-low.http,mp4-medium.http\" and presentation/source is to be encoded with \"mp4-hd.http,mp4-hd.http\" The target flavors are presenter/delivery and presentation/delivery and all are tagged \"rss, archive\". The target flavors are additionally tagged with encoding profiles, so that they can selected individually. This workflow supports HLS adaptive streaming. By: 1) Using only H.264/HENV encodings in the list of encoding profiles. 2) In the encoding profile, use the \"- : \" form in FFmpeg options when appropriate (eg: \"-b:a\" instead of \"-ab\"), and add the suffix \":v\" for options that apply to video and \":a\" to options that apply to audio, (eg: -maxrate:v, -g:v ) 3) Use the same keyframe intervals (-keyint and -keyint_min ) in each profile and segment size (see below) should be a multiple of this integer. 4) Adding a special encoding profile \"multiencode-hls\" to the list of encoding profiles. By default, the segments size is 6s (-hls-time) . HLS Playlists are generated as part of the encoding process. Each mp4 is a fragmented MP4. A variant playlist is created for each mp4 and a master playlist is used to access all the different qualities. To make sure that stream switching works as expected, state the bitrates explicitly for each of mp4 encoding profiles used. For advices on how to pick bitrates see: https://developer.apple.com/documentation/http_live_streaming/hls_authoring_specification_for_apple_devices For more details on HLS, see: https://tools.ietf.org/html/rfc8216 https://tools.ietf.org/html/draft-pantos-http-live-streaming-23 Without HLS, it will look like the following.","title":"Configuration details"},{"location":"workflowoperationhandlers/multiencode-woh/#parameter-table","text":"configuration keys example description source-flavors presenter/source ; presentation/source Which media should be encoded target-flavors */preview Specifies the flavor of the new media target-tags rss,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-medium.http ; mp4-hd.http,mp4-hd.http Encoding profiles for each source flavor tag-with-profile true (default to false) target medium are tagged with corresponding encoding profile Id","title":"Parameter Table"},{"location":"workflowoperationhandlers/multiencode-woh/#operation-example","text":"<operation id=\"multiencode\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video to Flash download\"> <configurations> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">rss,archive</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-hd.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/multiencode-woh/#note-important","text":"Each source flavor generates all the target formats in one FFmpeg call by incorporating relevant parts of the encoding profile commands. Care must be taken that no FFmpeg complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict. Encoded target recording are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes to use \"tag-with-profile\" configuration, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4","title":"Note: (Important)"},{"location":"workflowoperationhandlers/normalizeaudio-woh/","text":"Audio Normalization Operation Description This operation normalizes the first audio stream of a video or audio track through SoX , it creates a new track with a reference to the original track which can be flavored and tagged. It can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs: Used with Audio only file (forceTranscode is deactivated): Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with original audio file. Replace the normalized audio file with the original. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files. Used with Audio only file and forceTranscode activated: Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. (forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX) Run audio normalization with original audio file or encoded FLAC audio file. (forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files Used with Video file: Extract audio file encoded as FLAC audio and save it temporary in a collection Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with extracted audio file. Mux normalized audio file back to the original video container by replacing it with original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\"> <mimetype>audio/x-flv</mimetype> <tags> <tag>norm</tag> </tags> <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url> <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum> <duration>414407</duration> <audio id=\"audio-1\"> <device/> <encoder type=\"MPEG Audio\"/> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>64000.0</bitrate> <peakleveldb>-4.03</peakleveldb> <!-- NEW --> <rmsleveldb>-30.54</rmsleveldb> <!-- NEW --> <rmspeakdb>-10.85</rmspeakdb> <!-- NEW --> </audio> </track> Parameter Table configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY target-flavor \"presentation/normalized\" The flavor to apply to the normalized file EMPTY target-tags \"norm\" The tags to apply to the normalized file EMPTY target-decibel * -30.4 The target RMS Level Decibel EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE * required keys Operation Example <operation id=\"normalize-audio\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Normalize audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/normalized</configuration> <configuration key=\"target-tags\">norm</configuration> <configuration key=\"target-decibel\">-30</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Normalize Audio"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#audio-normalization-operation","text":"","title":"Audio Normalization Operation"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#description","text":"This operation normalizes the first audio stream of a video or audio track through SoX , it creates a new track with a reference to the original track which can be flavored and tagged. It can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:","title":"Description"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated","text":"Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with original audio file. Replace the normalized audio file with the original. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files.","title":"Used with Audio only file (forceTranscode is deactivated):"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-and-forcetranscode-activated","text":"Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. (forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX) Run audio normalization with original audio file or encoded FLAC audio file. (forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files","title":"Used with Audio only file and forceTranscode activated:"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#used-with-video-file","text":"Extract audio file encoded as FLAC audio and save it temporary in a collection Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with extracted audio file. Mux normalized audio file back to the original video container by replacing it with original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\"> <mimetype>audio/x-flv</mimetype> <tags> <tag>norm</tag> </tags> <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url> <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum> <duration>414407</duration> <audio id=\"audio-1\"> <device/> <encoder type=\"MPEG Audio\"/> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>64000.0</bitrate> <peakleveldb>-4.03</peakleveldb> <!-- NEW --> <rmsleveldb>-30.54</rmsleveldb> <!-- NEW --> <rmspeakdb>-10.85</rmspeakdb> <!-- NEW --> </audio> </track>","title":"Used with Video file:"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#parameter-table","text":"configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY target-flavor \"presentation/normalized\" The flavor to apply to the normalized file EMPTY target-tags \"norm\" The tags to apply to the normalized file EMPTY target-decibel * -30.4 The target RMS Level Decibel EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE * required keys","title":"Parameter Table"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#operation-example","text":"<operation id=\"normalize-audio\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Normalize audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/normalized</configuration> <configuration key=\"target-tags\">norm</configuration> <configuration key=\"target-decibel\">-30</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/notification/","text":"Mattermost Notification Description The MattermostNotificationOperationHander sends a notification to a channel of Mattermost or similar applications, like Slack, with the chosen parameters provided. It is useful to send such notifications when some operation(s) have been completed or some error has occurred in a workflow. The notification message can be freely chosen. You can use different parameters which will be replaced with the corresponding metadata of the current workflow instance (see List of parameters). List of configuration options configuration keys description default url URL of the mattermost webhook EMPTY message Message that will be send EMPTY method HTTP method that will be used post max-retry Value for the number of attempts for a request 5 timeout Maximum time to wait for client to execute a request 10 * 1000 Example for mattermost-notify operation <operation id=\"mattermost-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify Mattermost about error\"> <configurations> <configuration key=\"url\">insert-url-of-mattermost-webhook</configuration> <configuration key=\"message\">Error at Workflow %i (%t) State: %s</configuration> <configuration key=\"method\">post</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation> List of parameters All parameters (% ) will be substituted with corresponding metadata of the current workflow instance. Parameter Metadata %t Title of workflow %i ID of workflow %s State of workflow %o ID of current workflow operation %I ID of Mediapackage %T Title of Mediapackage %C Creators of Mediapackage %c Contributors of Mediapackage %D Date of Mediapackage %d Duration of Mediapackage %L License of Mediapackage %l Language of Mediapackage %S Series-Title of Mediapackage","title":"Mattermost Notification Module"},{"location":"workflowoperationhandlers/notification/#mattermost-notification","text":"","title":"Mattermost Notification"},{"location":"workflowoperationhandlers/notification/#description","text":"The MattermostNotificationOperationHander sends a notification to a channel of Mattermost or similar applications, like Slack, with the chosen parameters provided. It is useful to send such notifications when some operation(s) have been completed or some error has occurred in a workflow. The notification message can be freely chosen. You can use different parameters which will be replaced with the corresponding metadata of the current workflow instance (see List of parameters).","title":"Description"},{"location":"workflowoperationhandlers/notification/#list-of-configuration-options","text":"configuration keys description default url URL of the mattermost webhook EMPTY message Message that will be send EMPTY method HTTP method that will be used post max-retry Value for the number of attempts for a request 5 timeout Maximum time to wait for client to execute a request 10 * 1000","title":"List of configuration options"},{"location":"workflowoperationhandlers/notification/#example-for-mattermost-notify-operation","text":"<operation id=\"mattermost-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify Mattermost about error\"> <configurations> <configuration key=\"url\">insert-url-of-mattermost-webhook</configuration> <configuration key=\"message\">Error at Workflow %i (%t) State: %s</configuration> <configuration key=\"method\">post</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation>","title":"Example for mattermost-notify operation"},{"location":"workflowoperationhandlers/notification/#list-of-parameters","text":"All parameters (% ) will be substituted with corresponding metadata of the current workflow instance. Parameter Metadata %t Title of workflow %i ID of workflow %s State of workflow %o ID of current workflow operation %I ID of Mediapackage %T Title of Mediapackage %C Creators of Mediapackage %c Contributors of Mediapackage %D Date of Mediapackage %d Duration of Mediapackage %L License of Mediapackage %l Language of Mediapackage %S Series-Title of Mediapackage","title":"List of parameters"},{"location":"workflowoperationhandlers/partial-import-woh/","text":"Partial Import Operation ID: partial-import Description The PartialImportWorkflowOperation processes a set of audio and video files according to a SMIL document describing their relations. Its primary use is to post-process audio and video files ingested by capture agents using /ingest/addPartialTrack of the ingest endpoint. Prerequisite When using the PartialImportWorkflowOperation, it is recommended to perform a media inspection beforehand using the InspectWorkflowOperation with the option accurate-frame-count set to true . This ensures that the PartialImportWorkflowOperation works correctly in case of media files with incorrect frame count in their header. Note that the use of accurate-frame-count will force the InspectWorkflowOperation to decode the complete video stream which makes the operation more expensive in terms of load. Parameter Table configuration keys type description default value source-presenter-flavor MediaPackageElementFlavor The flavor of tracks for the presenter video source-presentation-flavor MediaPackageElementFlavor The flavor of tracks for the presentation video source-smil-flavor * MediaPackageElementFlavor The flavor of the SMIL file describing how to build the targets. When using /ingest/addPartialTrack, the ingest service will create the SMIL file and add it to the media package as flavor smil/source+partial target-presenter-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type and subtype must not be * target-presentation-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type nor subtype must not be * concat-encoding-profile * String Encoding profile used for concatenating audio or video files concat-output-framerate Float The optional output framerate for concatenated video files trim-encoding-profile * String Encoding profile using for trimming tracks force-encoding Boolean If set to true , all generated target files will be encoded using the encoding profile force-encoding-profile false force-encoding-profile * String Encoding profile to be used when force-encoding is set to true or a given target track has a file extension not included in required-extensions preencode-encoding Boolean If set to true , all source target files will be encoded using the encoding profile preencode-encoding-profile before they're processed further false preencode-encoding-profile String Encoding profile to be used when preencode-encoding is set to true required-extensions String , { \",\" , String } Comma-separated list of file extension names (case insensitive). All generated target files whose file extensions are not in this list will be encoded using the encoding profile force-encoding-profile \"mp4\" enforce-divisible-by-two Boolean If set, all video targets will have widths and heights divisible by two. This might be necessary depending since some encoder fail when encountering uneven widths or heights. false * required keys Note that it is allowed to set the configuration keys 'target-presenter-flavor' and 'target-presentation-flavor' to the same value. Operation Example What exactly the PartialImportWorkflowOperation does is best described by example. In our example, a capture agent records three sources: Presenter camera (video only) Presenter microphone (audio only) Presentation (video only) While the capture agent internally triggers the recording for all sources at the same time, the actual recording of the individual sources might not necessarily start at the exact same time, e.g. due to latency of the recording devices. Also, while recording, a watch dog in our example capture agent recognizes that for whatever reason, the recording of the sources had stopped and restarted again several times - resulting in multiple audio and/or video files per source. Here is a graphics showing how this example could look like: So we have three tracks, but seven files: Presenter camera: 2 video-only files Presenter microphone: 2 audio-only files Presentation: 3 video-only files We call that individual fragments of a track partial tracks . Our example capture agent can now use the addPartialTrack ingest facility to specify for each of the ingested files, at which time the content fits into the overall recording. The ingest service will automatically create the SMIL file describing how the files relate to each other and add it to the media package as flavor smil/source+partial . In our example, this SMIL file would like something like: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"93861ms\"> <seq> <video begin=\"412ms\" dur=\"13440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15324ms\" dur=\"73440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"40861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"43400ms\" dur=\"13861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"948ms\" dur=\"33440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"35643ms\" dur=\"15430ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"45448ms\" dur=\"25440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> What we finally want, however, is a single presenter and a single presentation track that can be processed by Opencast workflow operations. To achieve this, the PartialImportWorkflowOperation is used to post-process the files as described in the SMIL file: <operation id=\"partial-import\" description=\"Post-processing raw audio and video files from capture agent\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-presenter-flavor\">presenter/source</configuration> <configuration key=\"source-presentation-flavor\">presentation/source</configuration> <configuration key=\"source-smil-flavor\">smil/source+partial</configuration> <configuration key=\"target-presenter-flavor\">presenter/standard</configuration> <configuration key=\"target-presentation-flavor\">presentation/standard</configuration> <configuration key=\"concat-encoding-profile\">concat.work</configuration> <configuration key=\"trim-encoding-profile\">trim.work</configuration> <configuration key=\"force-encoding-profile\">editor.work</configuration> </configurations> </operation> In our example, the PartialImportWorkflowOperation will create the target flavors presenter/standard and presentation/standard as depicted below: The green parts have been filled in by the PartialImportWorkflowOperation by either silence (audio) or pictures (video). To achieve this, the PartialImportWorkflowOperation performs the following steps: Extend content at the beginning: If the first partial track of a given source and type (audio/video) does not begin at position zero, content is added in front of it so that the corresponding target track will start at position zero. For audio, silence is added. In case of video, the first frame of the first partial track is added. Filling the gaps: As you can see in our example, it is possible that content is missing within the actual tracks. Those gaps are filled by adding silence (in case of audio) or adding the last frame of the previous partial track (in case of video). In this step, content is also added at the end of the track in case its duration is less than the overall duration of the recording. Trim the tracks: It is possible that processing the ingested files according to the SMIL file would result in tracks that have a longer duration than the overall recording should. Therefore, all tracks are trimmed individually to the target duration. Mux audio tracks: To avoid the necessity to call further workflow operations just for audio muxing, the PartialImportWorkflowOperation can perform audio muxing itself. In our example, it would mux the audio and video track of the presenter into a single audio/video track. Ensure specific output formats: There may be situations where you want to ensure that the output of this operations comes with a specific file format, e.g. MP4 . The configuration keys force-encoding and required_extensions can be used to control the behavior of the PartialImportWorkflowOperation: In case the force-encoding is set to true , the target tracks will be re-encoded using the force-encoding-profile . The target tracks will also be re-encoded using that encoding profile in case its file extensions don't match the required_extensions . SMIL File Structure The PartialImportWorkflowOperation expects a specific subset of SMIL that is described in this section. The overall structure of the SMIL file is shown by example below: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"15000ms\"> <seq> <video begin=\"400ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15000ms\" dur=\"70000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"400ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"900ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"900ms\" dur=\"30000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> The PartialImportWorkflowOperation can handle at most one par element that is used to describe to overall media duration using the attribute dur . The resulting tracks will be trimmed to this duration if necessary. In the example above, the overall media duration is set to 15 seconds. The par element has one or two sequence sub elements seq , each describing a track that is to be built from its sub elements - the partial tracks. Each sequence ( seq ) has at least one sub element. Sub elements can be either video elements, audio elements or both video and audio elements. Each of those sub elements requires the attributes begin (position of partial track in milliseconds relative to start of overall media) and dur (duration of partial track in milliseconds) The audio elements are used to indicate that the media file referred to is an audio-only media file, whereas video elements can refer to either video-only or audio-video media files. The following combinations result in a defined behavior: Supported Combinations of Video and Audio Elements video audio resulting track audio/video track n/a audio/video track video-only track n/a video-only track video-only track audio-only track audio/video track n/a audio-only track audio-only track All other combinations of video and audio elements result in unspecified behavior of the PartialImportWorkflowOperation. Order of Video and Audio Elements Within a sequence ( seq ), the video elements most occur in ascending order considering the values of their attributes begin . The same holds for audio elements. Note the video and audio elements are processed individually, so the order of occurrences of video and audio elements are independent from each other. Important: The PartialImportWorkflowOperation will not process video or audio elements correctly if the order of appearance in the SMIL file is not correct. Overlapping Partial Tracks The behavior of overlapping partial tracks is unspecified, i.e. for a given element e ( video or audio ), the value of begin for the subsequent element (e+1) of the same type ( video or audio ) within the same sequence must be equal or greater than e.begin + e.dur , i.e. make sure that the following invariant holds: (e+1).begin >= e.begin + e.dur Encoding Profiles The PartialImportWorkflowOperation uses a number of encoding profiles to perform its processing. Some of the encoding profiles can be explicitly configured by the user, others are used implicitly in means of being hard-coded and are not supposed to be changed by the user. Hard-coded Encoding Profiles encoding profile description import.preview Extract the first frame of a given partial track import.image-frame Extract the last frame of a given partial track. Note that this profile is used to extract the exactly last frame of a partial track - not just a frame close to the last one. To make this work for video files with headers that don't contain the exact frame count, set accurate_frame_count to true in etc/org.opencastproject.inspection.ffmpeg.MediaInspectionServiceImpl.cfg image-movie.work Generate video partial tracks based on extracted images used to fill video gaps import.silent Generate silent audio tracks used to fill audio gaps Configurable Encoding Profiles configuration key description concat-encoding-profile Used to concatenate partial tracks into tracks trim-encoding-profile Used to trim the resulting concatenated single tracks if necessary force-encoding-profile Used to re-encode target tracks in case the file extension of a given target track is not included in required-extensions or the configuration key force-encoding is set to true preencode-encoding-profile Only used if preencode-encoding is set to true. Can be used to encode all source tracks before any processing happens, to avoid errors with non-uniform input. Should be used instead of Encode , as the latter will break source-smil.","title":"Partial Import"},{"location":"workflowoperationhandlers/partial-import-woh/#partial-import-operation","text":"ID: partial-import","title":"Partial Import Operation"},{"location":"workflowoperationhandlers/partial-import-woh/#description","text":"The PartialImportWorkflowOperation processes a set of audio and video files according to a SMIL document describing their relations. Its primary use is to post-process audio and video files ingested by capture agents using /ingest/addPartialTrack of the ingest endpoint.","title":"Description"},{"location":"workflowoperationhandlers/partial-import-woh/#prerequisite","text":"When using the PartialImportWorkflowOperation, it is recommended to perform a media inspection beforehand using the InspectWorkflowOperation with the option accurate-frame-count set to true . This ensures that the PartialImportWorkflowOperation works correctly in case of media files with incorrect frame count in their header. Note that the use of accurate-frame-count will force the InspectWorkflowOperation to decode the complete video stream which makes the operation more expensive in terms of load.","title":"Prerequisite"},{"location":"workflowoperationhandlers/partial-import-woh/#parameter-table","text":"configuration keys type description default value source-presenter-flavor MediaPackageElementFlavor The flavor of tracks for the presenter video source-presentation-flavor MediaPackageElementFlavor The flavor of tracks for the presentation video source-smil-flavor * MediaPackageElementFlavor The flavor of the SMIL file describing how to build the targets. When using /ingest/addPartialTrack, the ingest service will create the SMIL file and add it to the media package as flavor smil/source+partial target-presenter-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type and subtype must not be * target-presentation-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type nor subtype must not be * concat-encoding-profile * String Encoding profile used for concatenating audio or video files concat-output-framerate Float The optional output framerate for concatenated video files trim-encoding-profile * String Encoding profile using for trimming tracks force-encoding Boolean If set to true , all generated target files will be encoded using the encoding profile force-encoding-profile false force-encoding-profile * String Encoding profile to be used when force-encoding is set to true or a given target track has a file extension not included in required-extensions preencode-encoding Boolean If set to true , all source target files will be encoded using the encoding profile preencode-encoding-profile before they're processed further false preencode-encoding-profile String Encoding profile to be used when preencode-encoding is set to true required-extensions String , { \",\" , String } Comma-separated list of file extension names (case insensitive). All generated target files whose file extensions are not in this list will be encoded using the encoding profile force-encoding-profile \"mp4\" enforce-divisible-by-two Boolean If set, all video targets will have widths and heights divisible by two. This might be necessary depending since some encoder fail when encountering uneven widths or heights. false * required keys Note that it is allowed to set the configuration keys 'target-presenter-flavor' and 'target-presentation-flavor' to the same value.","title":"Parameter Table"},{"location":"workflowoperationhandlers/partial-import-woh/#operation-example","text":"What exactly the PartialImportWorkflowOperation does is best described by example. In our example, a capture agent records three sources: Presenter camera (video only) Presenter microphone (audio only) Presentation (video only) While the capture agent internally triggers the recording for all sources at the same time, the actual recording of the individual sources might not necessarily start at the exact same time, e.g. due to latency of the recording devices. Also, while recording, a watch dog in our example capture agent recognizes that for whatever reason, the recording of the sources had stopped and restarted again several times - resulting in multiple audio and/or video files per source. Here is a graphics showing how this example could look like: So we have three tracks, but seven files: Presenter camera: 2 video-only files Presenter microphone: 2 audio-only files Presentation: 3 video-only files We call that individual fragments of a track partial tracks . Our example capture agent can now use the addPartialTrack ingest facility to specify for each of the ingested files, at which time the content fits into the overall recording. The ingest service will automatically create the SMIL file describing how the files relate to each other and add it to the media package as flavor smil/source+partial . In our example, this SMIL file would like something like: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"93861ms\"> <seq> <video begin=\"412ms\" dur=\"13440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15324ms\" dur=\"73440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"40861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"43400ms\" dur=\"13861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"948ms\" dur=\"33440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"35643ms\" dur=\"15430ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"45448ms\" dur=\"25440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> What we finally want, however, is a single presenter and a single presentation track that can be processed by Opencast workflow operations. To achieve this, the PartialImportWorkflowOperation is used to post-process the files as described in the SMIL file: <operation id=\"partial-import\" description=\"Post-processing raw audio and video files from capture agent\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-presenter-flavor\">presenter/source</configuration> <configuration key=\"source-presentation-flavor\">presentation/source</configuration> <configuration key=\"source-smil-flavor\">smil/source+partial</configuration> <configuration key=\"target-presenter-flavor\">presenter/standard</configuration> <configuration key=\"target-presentation-flavor\">presentation/standard</configuration> <configuration key=\"concat-encoding-profile\">concat.work</configuration> <configuration key=\"trim-encoding-profile\">trim.work</configuration> <configuration key=\"force-encoding-profile\">editor.work</configuration> </configurations> </operation> In our example, the PartialImportWorkflowOperation will create the target flavors presenter/standard and presentation/standard as depicted below: The green parts have been filled in by the PartialImportWorkflowOperation by either silence (audio) or pictures (video). To achieve this, the PartialImportWorkflowOperation performs the following steps: Extend content at the beginning: If the first partial track of a given source and type (audio/video) does not begin at position zero, content is added in front of it so that the corresponding target track will start at position zero. For audio, silence is added. In case of video, the first frame of the first partial track is added. Filling the gaps: As you can see in our example, it is possible that content is missing within the actual tracks. Those gaps are filled by adding silence (in case of audio) or adding the last frame of the previous partial track (in case of video). In this step, content is also added at the end of the track in case its duration is less than the overall duration of the recording. Trim the tracks: It is possible that processing the ingested files according to the SMIL file would result in tracks that have a longer duration than the overall recording should. Therefore, all tracks are trimmed individually to the target duration. Mux audio tracks: To avoid the necessity to call further workflow operations just for audio muxing, the PartialImportWorkflowOperation can perform audio muxing itself. In our example, it would mux the audio and video track of the presenter into a single audio/video track. Ensure specific output formats: There may be situations where you want to ensure that the output of this operations comes with a specific file format, e.g. MP4 . The configuration keys force-encoding and required_extensions can be used to control the behavior of the PartialImportWorkflowOperation: In case the force-encoding is set to true , the target tracks will be re-encoded using the force-encoding-profile . The target tracks will also be re-encoded using that encoding profile in case its file extensions don't match the required_extensions .","title":"Operation Example"},{"location":"workflowoperationhandlers/partial-import-woh/#smil-file-structure","text":"The PartialImportWorkflowOperation expects a specific subset of SMIL that is described in this section. The overall structure of the SMIL file is shown by example below: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"15000ms\"> <seq> <video begin=\"400ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15000ms\" dur=\"70000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"400ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"900ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"900ms\" dur=\"30000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> The PartialImportWorkflowOperation can handle at most one par element that is used to describe to overall media duration using the attribute dur . The resulting tracks will be trimmed to this duration if necessary. In the example above, the overall media duration is set to 15 seconds. The par element has one or two sequence sub elements seq , each describing a track that is to be built from its sub elements - the partial tracks. Each sequence ( seq ) has at least one sub element. Sub elements can be either video elements, audio elements or both video and audio elements. Each of those sub elements requires the attributes begin (position of partial track in milliseconds relative to start of overall media) and dur (duration of partial track in milliseconds) The audio elements are used to indicate that the media file referred to is an audio-only media file, whereas video elements can refer to either video-only or audio-video media files. The following combinations result in a defined behavior:","title":"SMIL File Structure"},{"location":"workflowoperationhandlers/partial-import-woh/#supported-combinations-of-video-and-audio-elements","text":"video audio resulting track audio/video track n/a audio/video track video-only track n/a video-only track video-only track audio-only track audio/video track n/a audio-only track audio-only track All other combinations of video and audio elements result in unspecified behavior of the PartialImportWorkflowOperation.","title":"Supported Combinations of Video and Audio Elements"},{"location":"workflowoperationhandlers/partial-import-woh/#order-of-video-and-audio-elements","text":"Within a sequence ( seq ), the video elements most occur in ascending order considering the values of their attributes begin . The same holds for audio elements. Note the video and audio elements are processed individually, so the order of occurrences of video and audio elements are independent from each other. Important: The PartialImportWorkflowOperation will not process video or audio elements correctly if the order of appearance in the SMIL file is not correct.","title":"Order of Video and Audio Elements"},{"location":"workflowoperationhandlers/partial-import-woh/#overlapping-partial-tracks","text":"The behavior of overlapping partial tracks is unspecified, i.e. for a given element e ( video or audio ), the value of begin for the subsequent element (e+1) of the same type ( video or audio ) within the same sequence must be equal or greater than e.begin + e.dur , i.e. make sure that the following invariant holds: (e+1).begin >= e.begin + e.dur","title":"Overlapping Partial Tracks"},{"location":"workflowoperationhandlers/partial-import-woh/#encoding-profiles","text":"The PartialImportWorkflowOperation uses a number of encoding profiles to perform its processing. Some of the encoding profiles can be explicitly configured by the user, others are used implicitly in means of being hard-coded and are not supposed to be changed by the user.","title":"Encoding Profiles"},{"location":"workflowoperationhandlers/partial-import-woh/#hard-coded-encoding-profiles","text":"encoding profile description import.preview Extract the first frame of a given partial track import.image-frame Extract the last frame of a given partial track. Note that this profile is used to extract the exactly last frame of a partial track - not just a frame close to the last one. To make this work for video files with headers that don't contain the exact frame count, set accurate_frame_count to true in etc/org.opencastproject.inspection.ffmpeg.MediaInspectionServiceImpl.cfg image-movie.work Generate video partial tracks based on extracted images used to fill video gaps import.silent Generate silent audio tracks used to fill audio gaps","title":"Hard-coded Encoding Profiles"},{"location":"workflowoperationhandlers/partial-import-woh/#configurable-encoding-profiles","text":"configuration key description concat-encoding-profile Used to concatenate partial tracks into tracks trim-encoding-profile Used to trim the resulting concatenated single tracks if necessary force-encoding-profile Used to re-encode target tracks in case the file extension of a given target track is not included in required-extensions or the configuration key force-encoding is set to true preencode-encoding-profile Only used if preencode-encoding is set to true. Can be used to encode all source tracks before any processing happens, to avoid errors with non-uniform input. Should be used instead of Encode , as the latter will break source-smil.","title":"Configurable Encoding Profiles"},{"location":"workflowoperationhandlers/postmediapackage-woh/","text":"PostMediapackageWorkflowHandler Description This Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication. Parameter Table Configuration Keys Description url The target URL format The desired export format: xml or json debug Disable this on a productive system. If enabled, request bodies etc. will be written to log. If disabled, only errors will be logged. mediapackage.type Type of Mediapackage to send (possible values: workflow , search ; default: search ) auth.enabled enable authentication (simple/digest will be detected automatically) auth.username username for authentication auth.password password for authentication +source_system fields with keys beginning with + will be added to the message body Operation Example <operation id=\"post-mediapackage\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Sending MediaPackage to Lernfunk3\"> <configurations> <configuration key=\"url\">http://example.com:5000/</configuration> <configuration key=\"format\">xml</configuration> <configuration key=\"debug\">no</configuration> <configuration key=\"mediapackage.type\">search</configuration> <configuration key=\"auth.enabled\">yes</configuration> <configuration key=\"auth.username\">exportuser</configuration> <configuration key=\"auth.password\">secret</configuration> <configuration key=\"+source_system\">video.example.com</configuration> </configurations> </operation>","title":"Post Media Package"},{"location":"workflowoperationhandlers/postmediapackage-woh/#postmediapackageworkflowhandler","text":"","title":"PostMediapackageWorkflowHandler"},{"location":"workflowoperationhandlers/postmediapackage-woh/#description","text":"This Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication.","title":"Description"},{"location":"workflowoperationhandlers/postmediapackage-woh/#parameter-table","text":"Configuration Keys Description url The target URL format The desired export format: xml or json debug Disable this on a productive system. If enabled, request bodies etc. will be written to log. If disabled, only errors will be logged. mediapackage.type Type of Mediapackage to send (possible values: workflow , search ; default: search ) auth.enabled enable authentication (simple/digest will be detected automatically) auth.username username for authentication auth.password password for authentication +source_system fields with keys beginning with + will be added to the message body","title":"Parameter Table"},{"location":"workflowoperationhandlers/postmediapackage-woh/#operation-example","text":"<operation id=\"post-mediapackage\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Sending MediaPackage to Lernfunk3\"> <configurations> <configuration key=\"url\">http://example.com:5000/</configuration> <configuration key=\"format\">xml</configuration> <configuration key=\"debug\">no</configuration> <configuration key=\"mediapackage.type\">search</configuration> <configuration key=\"auth.enabled\">yes</configuration> <configuration key=\"auth.username\">exportuser</configuration> <configuration key=\"auth.password\">secret</configuration> <configuration key=\"+source_system\">video.example.com</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/prepareav-woh/","text":"PrepareAVWorkflowOperation Description The PrepareAVWorkflowOperation works is like this: If there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container. If it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by FFmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking FFmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwise occur later in the pipeline (encoding to flash, mjpeg etc.). Parameter Table configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. mux-encoding-profile mux-av.prepared The encoding profile to use for media that needs to be muxed (default is 'mux-av.work') audio-video-encoding-profile av.prepared The encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work) video-encoding-profile video-only.prepared The encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work) audio-encoding-profile audio-only.prepared The encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work) rewrite true Should files be rewritten audio-muxing-source-flavors presentation/source,presentation/*,*/* If there is no matching flavor to mux, search for a track with audio that can be muxed by going from left to right through this comma-separated list of source flavors Operation Example <operation id=\"prepare-av\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Preparing presenter audio and video work versions\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/work</configuration> <configuration key=\"rewrite\">false</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> </configurations> </operation> Audio Muxing The PrepareAVWorkflowOperation can be used for audio muxing in case a matching source video track has no audio. Audio muxing is performed as described below: In case the source-flavor matches to exactly two tracks whereas one track is a video-only track and the other is an audio-only track, those tracks will be merged into a single audio-video track. If there is no such matching flavor to mux, additional audio muxing facilities can be controlled by the use of the configuration key audio-muxing-source-flavors . That configuration key contains a comma-separated list of flavors that defines the search order of how to find an audio track. The following two wildcard characters can be used in flavors in that list: '*' will match to any type or subtype '?' will match to the type or subtype of the matching source-flavor Note: In case that a flavor used with audio-muxing-source-flavors matches to multiple tracks within the media package resulting in a list of matching tracks, the search order within that list is undefined, i.e. PrepareAVWorkflowOperation will just pick any of those tracks that has audio. Example [...] <configuration key=\"source-flavor\">presenter/*</configuration> <configuration key=\"audio-muxing-source-flavors\">presenter-audio/?, presentation/?,presentation/*,?/audio,*/*</configuration> [...] Let's assume that exactly one video-only track of flavor presenter/source in the media package and another track of flavor audio/track that has audio. In this example, the PrepareAVWorkflowOperation would perform the following steps: Search tracks of flavor presenter-audio/source (presenter-audio/?) Search tracks of flavor presentation/source (presentation/?) Search tracks of flavor presentation/* Search tracks of flavor presenter/audio (?/audio) Search tracks of flavor */*","title":"Prepare A/V"},{"location":"workflowoperationhandlers/prepareav-woh/#prepareavworkflowoperation","text":"","title":"PrepareAVWorkflowOperation"},{"location":"workflowoperationhandlers/prepareav-woh/#description","text":"The PrepareAVWorkflowOperation works is like this: If there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container. If it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by FFmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking FFmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwise occur later in the pipeline (encoding to flash, mjpeg etc.).","title":"Description"},{"location":"workflowoperationhandlers/prepareav-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. mux-encoding-profile mux-av.prepared The encoding profile to use for media that needs to be muxed (default is 'mux-av.work') audio-video-encoding-profile av.prepared The encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work) video-encoding-profile video-only.prepared The encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work) audio-encoding-profile audio-only.prepared The encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work) rewrite true Should files be rewritten audio-muxing-source-flavors presentation/source,presentation/*,*/* If there is no matching flavor to mux, search for a track with audio that can be muxed by going from left to right through this comma-separated list of source flavors","title":"Parameter Table"},{"location":"workflowoperationhandlers/prepareav-woh/#operation-example","text":"<operation id=\"prepare-av\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Preparing presenter audio and video work versions\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/work</configuration> <configuration key=\"rewrite\">false</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/prepareav-woh/#audio-muxing","text":"The PrepareAVWorkflowOperation can be used for audio muxing in case a matching source video track has no audio. Audio muxing is performed as described below: In case the source-flavor matches to exactly two tracks whereas one track is a video-only track and the other is an audio-only track, those tracks will be merged into a single audio-video track. If there is no such matching flavor to mux, additional audio muxing facilities can be controlled by the use of the configuration key audio-muxing-source-flavors . That configuration key contains a comma-separated list of flavors that defines the search order of how to find an audio track. The following two wildcard characters can be used in flavors in that list: '*' will match to any type or subtype '?' will match to the type or subtype of the matching source-flavor Note: In case that a flavor used with audio-muxing-source-flavors matches to multiple tracks within the media package resulting in a list of matching tracks, the search order within that list is undefined, i.e. PrepareAVWorkflowOperation will just pick any of those tracks that has audio.","title":"Audio Muxing"},{"location":"workflowoperationhandlers/prepareav-woh/#example","text":"[...] <configuration key=\"source-flavor\">presenter/*</configuration> <configuration key=\"audio-muxing-source-flavors\">presenter-audio/?, presentation/?,presentation/*,?/audio,*/*</configuration> [...] Let's assume that exactly one video-only track of flavor presenter/source in the media package and another track of flavor audio/track that has audio. In this example, the PrepareAVWorkflowOperation would perform the following steps: Search tracks of flavor presenter-audio/source (presenter-audio/?) Search tracks of flavor presentation/source (presentation/?) Search tracks of flavor presentation/* Search tracks of flavor presenter/audio (?/audio) Search tracks of flavor */*","title":"Example"},{"location":"workflowoperationhandlers/probe-resolution-woh/","text":"ProbeResolutionWorkflowOperationHandler Description The ProbeResolutionWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the video resolution and the mapping set-up. Parameter Table Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input var:VARNAME 1280x720,1920x1080 Resolutions to variable mapping val:VARNAME 16/9 Value to set if resolution matches * mandatory configuration key There can be an arbitrary number of variable parameters. They must be prefixed by var: , followed by the variable name to set to true if the video has a resolution listed. The var: prefix will not be part of the resulting variable name but will be replaced with a representation of the tracks flavor. By default, the variable will be set to true if the resolution matches. If a val:VARNAME configuration is present which matches a var:VARNAME , the value from that configuration key will be used instead. Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken. Operation Example <operation id=\"probe-resolution\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Set control variables based on video resolution\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"var:aspect\">1280x720,1920x1080,2592x1080</configuration> <configuration key=\"val:aspect\">16/9</configuration> <configuration key=\"var:is_720\">1280x720</configuration> <configuration key=\"var:is_1080\">1920x1080,2592x1080</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 is passed to this operation as presentation/source , the resulting variables would be: presentation_source_is_720=true presentation_source_aspect=16/9","title":"Probe Resolution"},{"location":"workflowoperationhandlers/probe-resolution-woh/#proberesolutionworkflowoperationhandler","text":"","title":"ProbeResolutionWorkflowOperationHandler"},{"location":"workflowoperationhandlers/probe-resolution-woh/#description","text":"The ProbeResolutionWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the video resolution and the mapping set-up.","title":"Description"},{"location":"workflowoperationhandlers/probe-resolution-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input var:VARNAME 1280x720,1920x1080 Resolutions to variable mapping val:VARNAME 16/9 Value to set if resolution matches * mandatory configuration key There can be an arbitrary number of variable parameters. They must be prefixed by var: , followed by the variable name to set to true if the video has a resolution listed. The var: prefix will not be part of the resulting variable name but will be replaced with a representation of the tracks flavor. By default, the variable will be set to true if the resolution matches. If a val:VARNAME configuration is present which matches a var:VARNAME , the value from that configuration key will be used instead. Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken.","title":"Parameter Table"},{"location":"workflowoperationhandlers/probe-resolution-woh/#operation-example","text":"<operation id=\"probe-resolution\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Set control variables based on video resolution\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"var:aspect\">1280x720,1920x1080,2592x1080</configuration> <configuration key=\"val:aspect\">16/9</configuration> <configuration key=\"var:is_720\">1280x720</configuration> <configuration key=\"var:is_1080\">1920x1080,2592x1080</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 is passed to this operation as presentation/source , the resulting variables would be: presentation_source_is_720=true presentation_source_aspect=16/9","title":"Operation Example"},{"location":"workflowoperationhandlers/process-smil-woh/","text":"ProcessSmilWorkflowHandler Description The ProcessSmilWorkflowHandler is used to edit media files using descriptions from a SMIL file. The SMIL file is typically generated by the editor or it can be constructed and uploaded. It contains names of one or more source tracks and a list of selected clips defined by in/out points in ms in the source tracks. It will concatenate all the clips from the source tracks according to the in/out points and encode the result into multiple target videos using a list of encoding profiles. In addition, the target videos are optionally tagged with the name of the encoding profiles. The Video editor produces a SMIL file and by default will also encode one set of edited videos targets as an intermediate format to be used to do segmentation and then used as source to generate multiple delivery formats. This workflow operation is used to bypass the generation of the temporary targets and generate the delivery formats directly. Subsequent workflow operations can select the highest quality source medium by tags and flavors. This operation saves the encoding time of one set of full length video and allows concurrent processing of multiple independent FFmpeg operations. To use this operation with the editor, the following must be added to the editor workflow operation to bypass the video editor encoding, <configuration key=\"skip-processing\">true</configuration> Configuration details Currently, there is only one transition type, which is \"fade to black\". The edited video will fade in from black with a fade-out/fade-in for each clip transition and a fade out at the end. The transition duration is a 2 second fade, configured in org.opencastproject.composer.impl.ComposerServiceImpl.cfg. In the future, each transition can be configurable as a SMIL element. The SMIL file can use more than one source video, but the caller has to take care that the dimension of all the source videos are the same. This workflow will generate one independent FFmpeg operation per SMIL paramgroup (based on source) regardless of the number of target outputs. This workflow can handle each source flavor selector independently. eg: Each source selector can have its own set of encoding profiles, target tags and flavors. The parameters for each configuration, such as flavor are separated into sections by \" ; \". E ach source media selector can have its own sets of encoding profile ids (one for each target recording) and target tags, as well as its own set of target tags and flavors, defined as a comma delimited list. As an example, using presenter/source and presentation/source as uploaded media. eg: <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors separated by semicolons means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section of the other configuration values such as encoding profiles. Each source selector can have only one corresponding section in each set of values. The use of the semi-colon is optional. If it is absent, there is only one section. If there is only one source selector, but multiple sections in the parameters, then the sections are collapsed into one and they will apply to all the source flavors in the source selector. \"N to N\" means that each section has its own processing configuration. \"1 to N\" or \"N to 1\" means that all the sections are processed the same way, but \"M to N\" where \"M <> N\" will result in an error. eg: <configuration key=\"target-flavors\">*/preview</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-vga-medium</configuration> All targets are flavored the same way. Using the example above, all media are encoded with \"mp4-low.http\" and \"mp4-vga-medium\" and targets are flavored as \"presenter/preview\" and \"presentation/preview\" <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> <configuration key=\"encoding-profiles\">mp4-medium.http;mp4-vga-medium</configuration> Each section is tagged individually. Using the example above, presenter/preview is encoded with \"mp4-medium.http\" and tagged with \"engage-streaming\" ,\"rss\" and \"atom\", presentation/preview is encoded with \"mp4-vga-medium\" and tagged with \"engage-download\",\"rss\" and \"atom\". If presenter/work is to be encoded with \"mp4-low.http,mp4-medium.http\" and presentation/work is to be encoded with \"mp4-vga-medium,mp4-medium.http\", and the target media are flavored as \"presenter/delivery\" and \"presentation/delivery\" respectively, and all targets are tagged with \"engage\" and \"archive\" in addition to the names of the encoding profiles used. This workflow supports HLS adaptive streaming. By: 1) Using only H.264/HENV encodings in the encoding profiles. 2) Adding a special encoding profile \"multiencode-hls\" to the list of encoding profiles. HLS Playlists are generated as part of the encoding process. Each mp4 is a fragmented MP4. A variant playlist is created for each mp4 and a master playlist is used to access all the different qualities. To make sure that stream switching works as expected, state the bitrates explicitly for each of mp4 encoding profiles used. For advices on how to pick bitrates see: https://developer.apple.com/documentation/http_live_streaming/hls_authoring_specification_for_apple_devices For more details on HLS, see: https://tools.ietf.org/html/rfc8216 https://tools.ietf.org/html/draft-pantos-http-live-streaming-23 Without HLS, it will look like the following. Parameter Table configuration keys example description smil-flavor smil/smil Specifies the flavor of the new media source-flavors presenter/work ; presentation/work Which media should be encoded target-flavors */delivery Specifies the flavor of the new media target-tags engage,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-med.http ; mp4-vga-med,mp4-med.http Profiles for each source flavor tag-with-profile true (default to false) target medium are tagged with corresponding encoding profile Id With HLS, encoding profiles will look like the following. |encoding-profiles | mp4-low.http,mp4-med.http,multiencode-hls ; mp4-vga-med,mp4-med.http,multiencode-hls | Profiles| Operation Example The parameters in the table above will look like this as a workflow operation. <operation id=\"process-smil\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video to Flash download\"> <configurations> <configuration key=\"smil-flavor\">smil/cutting</configuration> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">engage,archive</configuration> <configuration key=\"encoding-profiles\"> mp4-low.http,mp4-medium.http*;*mp4-vga-medium,mp4-medium.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation> With HLS, encoding profiles line will look like: <configuration key=\"encoding-profiles\"> mp4-low.http,mp4-medium.http,multiencode-hls*;*mp4-vga-medium,mp4-medium.http,multiencode-hls</configuration> Note:(Very Important) Each encoding section generates all the target media in one FFmpeg call by incorporating relevant parts of each encoding profile command using complex filters. Care must be taken that no complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict and FFmpeg will fail. Simple filters (i.e.: -vf, -af , -filter:v, -filter:a) can be used. Encoded target recording are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes or the target video tagging can be wrong, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4 If using this to process SMIL files generated by the editor in the same workflow, be sure to set the \"skip-processing\" key in the editor to true.","title":"Process Smil"},{"location":"workflowoperationhandlers/process-smil-woh/#processsmilworkflowhandler","text":"","title":"ProcessSmilWorkflowHandler"},{"location":"workflowoperationhandlers/process-smil-woh/#description","text":"The ProcessSmilWorkflowHandler is used to edit media files using descriptions from a SMIL file. The SMIL file is typically generated by the editor or it can be constructed and uploaded. It contains names of one or more source tracks and a list of selected clips defined by in/out points in ms in the source tracks. It will concatenate all the clips from the source tracks according to the in/out points and encode the result into multiple target videos using a list of encoding profiles. In addition, the target videos are optionally tagged with the name of the encoding profiles. The Video editor produces a SMIL file and by default will also encode one set of edited videos targets as an intermediate format to be used to do segmentation and then used as source to generate multiple delivery formats. This workflow operation is used to bypass the generation of the temporary targets and generate the delivery formats directly. Subsequent workflow operations can select the highest quality source medium by tags and flavors. This operation saves the encoding time of one set of full length video and allows concurrent processing of multiple independent FFmpeg operations. To use this operation with the editor, the following must be added to the editor workflow operation to bypass the video editor encoding, <configuration key=\"skip-processing\">true</configuration>","title":"Description"},{"location":"workflowoperationhandlers/process-smil-woh/#configuration-details","text":"Currently, there is only one transition type, which is \"fade to black\". The edited video will fade in from black with a fade-out/fade-in for each clip transition and a fade out at the end. The transition duration is a 2 second fade, configured in org.opencastproject.composer.impl.ComposerServiceImpl.cfg. In the future, each transition can be configurable as a SMIL element. The SMIL file can use more than one source video, but the caller has to take care that the dimension of all the source videos are the same. This workflow will generate one independent FFmpeg operation per SMIL paramgroup (based on source) regardless of the number of target outputs. This workflow can handle each source flavor selector independently. eg: Each source selector can have its own set of encoding profiles, target tags and flavors. The parameters for each configuration, such as flavor are separated into sections by \" ; \". E ach source media selector can have its own sets of encoding profile ids (one for each target recording) and target tags, as well as its own set of target tags and flavors, defined as a comma delimited list. As an example, using presenter/source and presentation/source as uploaded media. eg: <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors separated by semicolons means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section of the other configuration values such as encoding profiles. Each source selector can have only one corresponding section in each set of values. The use of the semi-colon is optional. If it is absent, there is only one section. If there is only one source selector, but multiple sections in the parameters, then the sections are collapsed into one and they will apply to all the source flavors in the source selector. \"N to N\" means that each section has its own processing configuration. \"1 to N\" or \"N to 1\" means that all the sections are processed the same way, but \"M to N\" where \"M <> N\" will result in an error. eg: <configuration key=\"target-flavors\">*/preview</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-vga-medium</configuration> All targets are flavored the same way. Using the example above, all media are encoded with \"mp4-low.http\" and \"mp4-vga-medium\" and targets are flavored as \"presenter/preview\" and \"presentation/preview\" <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> <configuration key=\"encoding-profiles\">mp4-medium.http;mp4-vga-medium</configuration> Each section is tagged individually. Using the example above, presenter/preview is encoded with \"mp4-medium.http\" and tagged with \"engage-streaming\" ,\"rss\" and \"atom\", presentation/preview is encoded with \"mp4-vga-medium\" and tagged with \"engage-download\",\"rss\" and \"atom\". If presenter/work is to be encoded with \"mp4-low.http,mp4-medium.http\" and presentation/work is to be encoded with \"mp4-vga-medium,mp4-medium.http\", and the target media are flavored as \"presenter/delivery\" and \"presentation/delivery\" respectively, and all targets are tagged with \"engage\" and \"archive\" in addition to the names of the encoding profiles used. This workflow supports HLS adaptive streaming. By: 1) Using only H.264/HENV encodings in the encoding profiles. 2) Adding a special encoding profile \"multiencode-hls\" to the list of encoding profiles. HLS Playlists are generated as part of the encoding process. Each mp4 is a fragmented MP4. A variant playlist is created for each mp4 and a master playlist is used to access all the different qualities. To make sure that stream switching works as expected, state the bitrates explicitly for each of mp4 encoding profiles used. For advices on how to pick bitrates see: https://developer.apple.com/documentation/http_live_streaming/hls_authoring_specification_for_apple_devices For more details on HLS, see: https://tools.ietf.org/html/rfc8216 https://tools.ietf.org/html/draft-pantos-http-live-streaming-23 Without HLS, it will look like the following.","title":"Configuration details"},{"location":"workflowoperationhandlers/process-smil-woh/#parameter-table","text":"configuration keys example description smil-flavor smil/smil Specifies the flavor of the new media source-flavors presenter/work ; presentation/work Which media should be encoded target-flavors */delivery Specifies the flavor of the new media target-tags engage,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-med.http ; mp4-vga-med,mp4-med.http Profiles for each source flavor tag-with-profile true (default to false) target medium are tagged with corresponding encoding profile Id With HLS, encoding profiles will look like the following. |encoding-profiles | mp4-low.http,mp4-med.http,multiencode-hls ; mp4-vga-med,mp4-med.http,multiencode-hls | Profiles|","title":"Parameter Table"},{"location":"workflowoperationhandlers/process-smil-woh/#operation-example","text":"The parameters in the table above will look like this as a workflow operation. <operation id=\"process-smil\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video to Flash download\"> <configurations> <configuration key=\"smil-flavor\">smil/cutting</configuration> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">engage,archive</configuration> <configuration key=\"encoding-profiles\"> mp4-low.http,mp4-medium.http*;*mp4-vga-medium,mp4-medium.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation> With HLS, encoding profiles line will look like: <configuration key=\"encoding-profiles\"> mp4-low.http,mp4-medium.http,multiencode-hls*;*mp4-vga-medium,mp4-medium.http,multiencode-hls</configuration>","title":"Operation Example"},{"location":"workflowoperationhandlers/process-smil-woh/#notevery-important","text":"Each encoding section generates all the target media in one FFmpeg call by incorporating relevant parts of each encoding profile command using complex filters. Care must be taken that no complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict and FFmpeg will fail. Simple filters (i.e.: -vf, -af , -filter:v, -filter:a) can be used. Encoded target recording are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes or the target video tagging can be wrong, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4 If using this to process SMIL files generated by the editor in the same workflow, be sure to set the \"skip-processing\" key in the editor to true.","title":"Note:(Very Important)"},{"location":"workflowoperationhandlers/publish-aws-woh/","text":"PublishAWSS3WorkflowOperation Description The PublishAWSS3WorkflowOperation will publish your recording to the normal publication channel (e.g. engage), but the media files will be hosted via AWS S3/Cloudfront. Parameter Table configuration keys description check-availability Check if the media if reachable download-source-flavors Specifies which media should be published for download download-source-tags Specifies which media should be published for download download-target-subflavors Subflavor to use for distributed material download-target-tags Modify tags of published media strategy If there is no key, published media would be retracted before publishing merge merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-target-tags Modify tags of published media streaming-target-subflavors Subflavor to use for distributed material Operation Example <operation id=\"publish-aws\" max-attempts=\"2\" exception-handler-workflow=\"partial-error\" description=\"Publishing to Amazon Web Services\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"download-source-tags\">engage-download,atom,rss,mobile</configuration> <configuration key=\"streaming-source-tags\">engage-streaming</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Publish AWS"},{"location":"workflowoperationhandlers/publish-aws-woh/#publishawss3workflowoperation","text":"","title":"PublishAWSS3WorkflowOperation"},{"location":"workflowoperationhandlers/publish-aws-woh/#description","text":"The PublishAWSS3WorkflowOperation will publish your recording to the normal publication channel (e.g. engage), but the media files will be hosted via AWS S3/Cloudfront.","title":"Description"},{"location":"workflowoperationhandlers/publish-aws-woh/#parameter-table","text":"configuration keys description check-availability Check if the media if reachable download-source-flavors Specifies which media should be published for download download-source-tags Specifies which media should be published for download download-target-subflavors Subflavor to use for distributed material download-target-tags Modify tags of published media strategy If there is no key, published media would be retracted before publishing merge merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-target-tags Modify tags of published media streaming-target-subflavors Subflavor to use for distributed material","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-aws-woh/#operation-example","text":"<operation id=\"publish-aws\" max-attempts=\"2\" exception-handler-workflow=\"partial-error\" description=\"Publishing to Amazon Web Services\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"download-source-tags\">engage-download,atom,rss,mobile</configuration> <configuration key=\"streaming-source-tags\">engage-streaming</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/publish-configure-woh/","text":"ConfigurablePublishWorkflowOperationHandler Description The ConfigurablePublishWorkflowOperationHandler will distribute the given elements and create a publication element for them. By default it will retract all published download elements before publishing anew. Parameter Table These are the keys that can be configured for this operation in the workflow definition. At least one media package element must match the supplied source-flavors or source-tags (either for download or streaming or both) or else the operation will not know what to publish. The channel-id and url-pattern are also mandatory. Key Description Example Default channel-id Id of the channel to publish to internal mimetype Mime type of the published element text/html Type of last distributed element download-source-flavors Flavors of the download media package elements to publish */trimmed download-source-tags Tags of the download media package elements to publish engage-download streaming-source-flavors Flavors of the streaming media package elements to publish */trimmed streaming-source-tags Tags of the streaming media package elements to publish engage-streaming url-pattern Pattern to create the URI for the published from ftp://\u2026/${event_id} with-published-elements Use the current contents of the media package instead of publishing elements to a channel true check-availability Check if the media is reachable after publication false false strategy Strategy for when there is already published material fail retract mode How elements are distributed mixed bulk retract-streaming Whether to also retract streaming elements * true false * Enable if you have published streaming elements to this channel. Mode The configuration key mode can be used to control how media package elements are being distributed: Mode Description single For each media package element, a job is created mixed One job for all media package elements that are not tracks and one job per track bulk One job for all media package elements This allows you to choose a lot of jobs and parallelism ( single ), just one job and no parallelism ( bulk ) or something in between ( mixed ). The best choice depends on your setup. URL Pattern Variables These are the variables available in the url-pattern configuration. They will be replaced with the value during the execution of the workflow operation. Variable Description Example ${event_id} The event (media package) identifier 18633e04-1a3f-4bbb-a72a-99c15deba1b9 ${player_path} The player path for the event /engage/theodul/ui/core.html?id= ${publication_id} The id of this publication. 54f6c12d-8e68-4ec8-badf-cd045b33d01e ${series_id} The id of the series if available 36f3c5d8-ad4d-4dab-beb1-1400ffab4a69 The organization properties are also available and can be accessed with the org_ prefix followed by the property name, eg. ${org_player} will be replaced by the value of the organization property named player . Note some organization properties contain an . (period) in their name (e.g. org.opencastproject.external.api.url ). As this character have an special meaning in the FreeMarker library (used for substitution), all occurrences are replaced with _ (underscore). Additional to the organization properties you can use org_id , org_name , org_admin_role and org_anonymous_role as well. Publication Channel Labels and Icons Using this workflow operation, you can create arbitrary custom publication channels. Without further action, the administrative user interface will label these channels \"Custom\". You can specify both a label and an icon for each custom publication channels in the configuration files etc/listproviders/publication.channel.labels.properties and etc/listproviders/publication.channel.icons.properties . Operation Examples Internal Channel <operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to internal channel\"> <configurations> <configuration key=\"download-source-tags\">engage,atom,rss</configuration> <configuration key=\"channel-id\">internal</configuration> <configuration key=\"url-pattern\">http://localhost:8080/admin-ng/index.html#/events/events/${event_id}/tools/playback</configuration> </configurations> </operation> External API <operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> <configuration key=\"mimetype\">application/json</configuration> <configuration key=\"download-source-tags\">engage-download,engage-streaming</configuration> <configuration key=\"url-pattern\">http://api.oc.org/api/events/${event_id}</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation> Meta publication Meta publications are URL only publications as reference to external systems like media portal. <operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to meta publication channel\"> <configurations> <configuration key=\"channel-id\">edu-reference</configuration> <configuration key=\"mimetype\">text/html</configuration> <configuration key=\"url-pattern\">https://org.mediaportal.edu/events/${event_id}</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation>","title":"Publish Configure"},{"location":"workflowoperationhandlers/publish-configure-woh/#configurablepublishworkflowoperationhandler","text":"","title":"ConfigurablePublishWorkflowOperationHandler"},{"location":"workflowoperationhandlers/publish-configure-woh/#description","text":"The ConfigurablePublishWorkflowOperationHandler will distribute the given elements and create a publication element for them. By default it will retract all published download elements before publishing anew.","title":"Description"},{"location":"workflowoperationhandlers/publish-configure-woh/#parameter-table","text":"These are the keys that can be configured for this operation in the workflow definition. At least one media package element must match the supplied source-flavors or source-tags (either for download or streaming or both) or else the operation will not know what to publish. The channel-id and url-pattern are also mandatory. Key Description Example Default channel-id Id of the channel to publish to internal mimetype Mime type of the published element text/html Type of last distributed element download-source-flavors Flavors of the download media package elements to publish */trimmed download-source-tags Tags of the download media package elements to publish engage-download streaming-source-flavors Flavors of the streaming media package elements to publish */trimmed streaming-source-tags Tags of the streaming media package elements to publish engage-streaming url-pattern Pattern to create the URI for the published from ftp://\u2026/${event_id} with-published-elements Use the current contents of the media package instead of publishing elements to a channel true check-availability Check if the media is reachable after publication false false strategy Strategy for when there is already published material fail retract mode How elements are distributed mixed bulk retract-streaming Whether to also retract streaming elements * true false * Enable if you have published streaming elements to this channel.","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-configure-woh/#mode","text":"The configuration key mode can be used to control how media package elements are being distributed: Mode Description single For each media package element, a job is created mixed One job for all media package elements that are not tracks and one job per track bulk One job for all media package elements This allows you to choose a lot of jobs and parallelism ( single ), just one job and no parallelism ( bulk ) or something in between ( mixed ). The best choice depends on your setup.","title":"Mode"},{"location":"workflowoperationhandlers/publish-configure-woh/#url-pattern-variables","text":"These are the variables available in the url-pattern configuration. They will be replaced with the value during the execution of the workflow operation. Variable Description Example ${event_id} The event (media package) identifier 18633e04-1a3f-4bbb-a72a-99c15deba1b9 ${player_path} The player path for the event /engage/theodul/ui/core.html?id= ${publication_id} The id of this publication. 54f6c12d-8e68-4ec8-badf-cd045b33d01e ${series_id} The id of the series if available 36f3c5d8-ad4d-4dab-beb1-1400ffab4a69 The organization properties are also available and can be accessed with the org_ prefix followed by the property name, eg. ${org_player} will be replaced by the value of the organization property named player . Note some organization properties contain an . (period) in their name (e.g. org.opencastproject.external.api.url ). As this character have an special meaning in the FreeMarker library (used for substitution), all occurrences are replaced with _ (underscore). Additional to the organization properties you can use org_id , org_name , org_admin_role and org_anonymous_role as well.","title":"URL Pattern Variables"},{"location":"workflowoperationhandlers/publish-configure-woh/#publication-channel-labels-and-icons","text":"Using this workflow operation, you can create arbitrary custom publication channels. Without further action, the administrative user interface will label these channels \"Custom\". You can specify both a label and an icon for each custom publication channels in the configuration files etc/listproviders/publication.channel.labels.properties and etc/listproviders/publication.channel.icons.properties .","title":"Publication Channel Labels and Icons"},{"location":"workflowoperationhandlers/publish-configure-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/publish-configure-woh/#internal-channel","text":"<operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to internal channel\"> <configurations> <configuration key=\"download-source-tags\">engage,atom,rss</configuration> <configuration key=\"channel-id\">internal</configuration> <configuration key=\"url-pattern\">http://localhost:8080/admin-ng/index.html#/events/events/${event_id}/tools/playback</configuration> </configurations> </operation>","title":"Internal Channel"},{"location":"workflowoperationhandlers/publish-configure-woh/#external-api","text":"<operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> <configuration key=\"mimetype\">application/json</configuration> <configuration key=\"download-source-tags\">engage-download,engage-streaming</configuration> <configuration key=\"url-pattern\">http://api.oc.org/api/events/${event_id}</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"External API"},{"location":"workflowoperationhandlers/publish-configure-woh/#meta-publication","text":"Meta publications are URL only publications as reference to external systems like media portal. <operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to meta publication channel\"> <configurations> <configuration key=\"channel-id\">edu-reference</configuration> <configuration key=\"mimetype\">text/html</configuration> <configuration key=\"url-pattern\">https://org.mediaportal.edu/events/${event_id}</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation>","title":"Meta publication"},{"location":"workflowoperationhandlers/publish-engage-woh/","text":"Publish Engage Workflow Operation ID: publish-engage Description The publish-engage operation will bring your media to the engage distribution channels (streaming, progressive download, \u2026) Parameter Table configuration keys description check-availability Check if the media is reachable download-source-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-source-tags Distribute any mediapackage elements with one of these (comma separated) tags to download download-target-subflavors Subflavor to use for distributed material download-target-tags Add tags (comma separated) to published media strategy If there is no key, published media would be retracted before publishing <configuration key=\"strategy\">merge</configuration> merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-target-tags Add tags (comma separated) to published media streaming-target-subflavors Subflavor to use for distributed material merge-force-flavors Flavors of elements for which an update is enforced when merging catalogs. Defaults to dublincore/*,security/* . Operation Example <operation id=\"publish-engage\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute and publish to engage player\"> <configurations> <configuration key=\"download-source-tags\">engage,atom,rss</configuration> <configuration key=\"streaming-source-tags\">engage</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"strategy\">merge</configuration> </configurations> </operation>","title":"Publish Engage"},{"location":"workflowoperationhandlers/publish-engage-woh/#publish-engage-workflow-operation","text":"ID: publish-engage","title":"Publish Engage Workflow Operation"},{"location":"workflowoperationhandlers/publish-engage-woh/#description","text":"The publish-engage operation will bring your media to the engage distribution channels (streaming, progressive download, \u2026)","title":"Description"},{"location":"workflowoperationhandlers/publish-engage-woh/#parameter-table","text":"configuration keys description check-availability Check if the media is reachable download-source-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-source-tags Distribute any mediapackage elements with one of these (comma separated) tags to download download-target-subflavors Subflavor to use for distributed material download-target-tags Add tags (comma separated) to published media strategy If there is no key, published media would be retracted before publishing <configuration key=\"strategy\">merge</configuration> merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-target-tags Add tags (comma separated) to published media streaming-target-subflavors Subflavor to use for distributed material merge-force-flavors Flavors of elements for which an update is enforced when merging catalogs. Defaults to dublincore/*,security/* .","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-engage-woh/#operation-example","text":"<operation id=\"publish-engage\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute and publish to engage player\"> <configurations> <configuration key=\"download-source-tags\">engage,atom,rss</configuration> <configuration key=\"streaming-source-tags\">engage</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"strategy\">merge</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/","text":"PublishOaiPmhWorkflowOperation Description The Publish OAI-PMH workflow operation exposes your media's metadata in a OAI-PMH repository for harvesting by OAI-PMH aware applications. Parameter Table Configuration Keys Description download-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-tags Distribute any mediapackage elements with one of these (comma separated) tags to download streaming-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to streaming streaming-tags Distribute any mediapackage elements with one of these (comma separated) tags to streaming check-availability Check if the distributed download artifact is available at its URL (default: true) repository The name of the OAI-PMH repository where the media should be published to external-template The optional URL template for URL the OAI-PMH publication element external-channel The optional channel name for the OAI-PMH publication element external-mime-type The optional mime type for the OAI-PMH publication element Note: The all or none of the configuration keys external-template , external-channel and external-mime-type must to be set. Customizing the OAI-PMH Publication Element If the configuration keys external-template , external-channel and external-mime-type are not set, the publication element will use the following default values: Field Default Value url prop.org.opencastproject.oaipmh.server.hosturl + org.opencastproject.oaipmh.mountpoint + repository mime type \"text/xml\" channel name \"oaipmh-\" + repository Note that org.opencastproject.oaipmh.server.hosturl is defined in etc/org.opencastproject.organization-mh_default_org.cfg and org.opencastproject.oaipmh.mountpoint is defined in custom.properties and defaults to /oaipmh . Example: http://localhost:8080/oaipmh/default The OAI-PMH publication element can be customized by setting the configuration keys external-template , external-channel and external-mime-type . The URL of the publication element can be set by using external-template . The following variables can be used in the template: Variable Name Description event ID of the event being published series ID of the series being published Example: https://www.externalURL.com/watch.html?series={series}&id={event} The configuration key external-mime-type is used to set the mime type of the content return when accessing the URL of the publication element. The configuration key 'external-channel' is used to set the name of the publication channel. Operation Example <operation id=\"publish-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Publish event to the OAI-PMH repository\"> <configurations> <configuration key=\"download-tags\">oaipmh-download</configuration> <configuration key=\"streaming-tags\">oaipmh-streaming</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Publish OAI-PMH"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#publishoaipmhworkflowoperation","text":"","title":"PublishOaiPmhWorkflowOperation"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#description","text":"The Publish OAI-PMH workflow operation exposes your media's metadata in a OAI-PMH repository for harvesting by OAI-PMH aware applications.","title":"Description"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#parameter-table","text":"Configuration Keys Description download-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-tags Distribute any mediapackage elements with one of these (comma separated) tags to download streaming-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to streaming streaming-tags Distribute any mediapackage elements with one of these (comma separated) tags to streaming check-availability Check if the distributed download artifact is available at its URL (default: true) repository The name of the OAI-PMH repository where the media should be published to external-template The optional URL template for URL the OAI-PMH publication element external-channel The optional channel name for the OAI-PMH publication element external-mime-type The optional mime type for the OAI-PMH publication element Note: The all or none of the configuration keys external-template , external-channel and external-mime-type must to be set.","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#customizing-the-oai-pmh-publication-element","text":"If the configuration keys external-template , external-channel and external-mime-type are not set, the publication element will use the following default values: Field Default Value url prop.org.opencastproject.oaipmh.server.hosturl + org.opencastproject.oaipmh.mountpoint + repository mime type \"text/xml\" channel name \"oaipmh-\" + repository Note that org.opencastproject.oaipmh.server.hosturl is defined in etc/org.opencastproject.organization-mh_default_org.cfg and org.opencastproject.oaipmh.mountpoint is defined in custom.properties and defaults to /oaipmh . Example: http://localhost:8080/oaipmh/default The OAI-PMH publication element can be customized by setting the configuration keys external-template , external-channel and external-mime-type . The URL of the publication element can be set by using external-template . The following variables can be used in the template: Variable Name Description event ID of the event being published series ID of the series being published Example: https://www.externalURL.com/watch.html?series={series}&id={event} The configuration key external-mime-type is used to set the mime type of the content return when accessing the URL of the publication element. The configuration key 'external-channel' is used to set the name of the publication channel.","title":"Customizing the OAI-PMH Publication Element"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#operation-example","text":"<operation id=\"publish-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Publish event to the OAI-PMH repository\"> <configurations> <configuration key=\"download-tags\">oaipmh-download</configuration> <configuration key=\"streaming-tags\">oaipmh-streaming</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/publish-youtube-woh/","text":"PublishYoutubeWorkflowOperation Description The PublishYoutubeWorkflowOperation publishes a single stream to YouTube. This stream must meet YouTube's format requirements, and may consist of audio and/or video. If you want to publish both your presenter and presentation streams we suggest using the Composite workflow operation handler to prepare a composite file with both streams inside of it. The default Opencast workflow prepares a video using this method. Parameter Table configuration keys description source-flavors The flavors to publish to YouTube source-tags The tags to publish to YouTube Operation Example <operation id=\"publish-youtube\" max-attempts=\"2\" exception-handler-workflow=\"ng-partial-error\" description=\"Publishing to YouTube\"> <configurations> <configuration key=\"source-tags\">youtube</configuration> </configurations> </operation>","title":"Publish YouTube"},{"location":"workflowoperationhandlers/publish-youtube-woh/#publishyoutubeworkflowoperation","text":"","title":"PublishYoutubeWorkflowOperation"},{"location":"workflowoperationhandlers/publish-youtube-woh/#description","text":"The PublishYoutubeWorkflowOperation publishes a single stream to YouTube. This stream must meet YouTube's format requirements, and may consist of audio and/or video. If you want to publish both your presenter and presentation streams we suggest using the Composite workflow operation handler to prepare a composite file with both streams inside of it. The default Opencast workflow prepares a video using this method.","title":"Description"},{"location":"workflowoperationhandlers/publish-youtube-woh/#parameter-table","text":"configuration keys description source-flavors The flavors to publish to YouTube source-tags The tags to publish to YouTube","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-youtube-woh/#operation-example","text":"<operation id=\"publish-youtube\" max-attempts=\"2\" exception-handler-workflow=\"ng-partial-error\" description=\"Publishing to YouTube\"> <configurations> <configuration key=\"source-tags\">youtube</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/","text":"RepublishOaiPmhWorkflowOperation Description The Republish OAI-PMH workflow operation will update metadata in your OAI-PMH repositories. In case that the media has not been published before, this operation will skip. Otherwise all elements matching the flavors and tags will be replaced. In case of missing elements in the media package, the published elements will be also removed. Parameter Table Configuration Keys Description source-flavors Republish any media package elements with one of these (comma-separated) flavors source-tags Republish only media package elements that are tagged with one of these (comma-separated) tags repository The name of the OAI-PMH repository where the media should be updated Operation Example <operation id=\"republish-oaipmh\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Republish OAI-PMH"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#republishoaipmhworkflowoperation","text":"","title":"RepublishOaiPmhWorkflowOperation"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#description","text":"The Republish OAI-PMH workflow operation will update metadata in your OAI-PMH repositories. In case that the media has not been published before, this operation will skip. Otherwise all elements matching the flavors and tags will be replaced. In case of missing elements in the media package, the published elements will be also removed.","title":"Description"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#parameter-table","text":"Configuration Keys Description source-flavors Republish any media package elements with one of these (comma-separated) flavors source-tags Republish only media package elements that are tagged with one of these (comma-separated) tags repository The name of the OAI-PMH repository where the media should be updated","title":"Parameter Table"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#operation-example","text":"<operation id=\"republish-oaipmh\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/retract-aws-woh/","text":"RetractAWSWorkflowOperationHandler Description The RetractAWSWorkflowOperationHandler retracts the published elements from Amazon S3. There are no configuration keys at this time. Operation Examples Retract <!-- Retract from AWS --> <operation id=\"retract-aws\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from AWS\"> </operation>","title":"Retract AWS S3 and Cloudfront"},{"location":"workflowoperationhandlers/retract-aws-woh/#retractawsworkflowoperationhandler","text":"","title":"RetractAWSWorkflowOperationHandler"},{"location":"workflowoperationhandlers/retract-aws-woh/#description","text":"The RetractAWSWorkflowOperationHandler retracts the published elements from Amazon S3. There are no configuration keys at this time.","title":"Description"},{"location":"workflowoperationhandlers/retract-aws-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-aws-woh/#retract","text":"<!-- Retract from AWS --> <operation id=\"retract-aws\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from AWS\"> </operation>","title":"Retract"},{"location":"workflowoperationhandlers/retract-configure-woh/","text":"ConfigurableRetractWorkflowOperationHandler Description The ConfigurableRetractWorkflowOperationHandler retracts the published elements from a configured publication. If the elements have been added to the Publication using \"with-published-elements\", as in the case with the external api, they haven't actually been published so it is unnecessary to have a retract-configuration. Adding a retraction won't cause any errors, it will just skip those elements. Parameters These are the keys that can be configured for the workflow operation in the workflow definition. The channel-id is mandatory. Key Description Example Default channel-id The id of the channel to retract from internal retract-streaming Whether to retract streaming elements as well true false Setting retract-streaming to true only makes sense if you've published streaming elements for this channel before. Operation Examples Retract from Internal Channel <!-- Remove the internal publication if the mediapackage is being deleted. --> <operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from internal publication channel\"> <configurations> <configuration key=\"channel-id\">internal</configuration> </configurations> </operation> Retract from External API <operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> <configuration key=\"retract-streaming\">false</configuration> </configurations> </operation>","title":"Retract Configure"},{"location":"workflowoperationhandlers/retract-configure-woh/#configurableretractworkflowoperationhandler","text":"","title":"ConfigurableRetractWorkflowOperationHandler"},{"location":"workflowoperationhandlers/retract-configure-woh/#description","text":"The ConfigurableRetractWorkflowOperationHandler retracts the published elements from a configured publication. If the elements have been added to the Publication using \"with-published-elements\", as in the case with the external api, they haven't actually been published so it is unnecessary to have a retract-configuration. Adding a retraction won't cause any errors, it will just skip those elements.","title":"Description"},{"location":"workflowoperationhandlers/retract-configure-woh/#parameters","text":"These are the keys that can be configured for the workflow operation in the workflow definition. The channel-id is mandatory. Key Description Example Default channel-id The id of the channel to retract from internal retract-streaming Whether to retract streaming elements as well true false Setting retract-streaming to true only makes sense if you've published streaming elements for this channel before.","title":"Parameters"},{"location":"workflowoperationhandlers/retract-configure-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-configure-woh/#retract-from-internal-channel","text":"<!-- Remove the internal publication if the mediapackage is being deleted. --> <operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from internal publication channel\"> <configurations> <configuration key=\"channel-id\">internal</configuration> </configurations> </operation>","title":"Retract from Internal Channel"},{"location":"workflowoperationhandlers/retract-configure-woh/#retract-from-external-api","text":"<operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> <configuration key=\"retract-streaming\">false</configuration> </configurations> </operation>","title":"Retract from External API"},{"location":"workflowoperationhandlers/retract-engage-woh/","text":"RetractEngageWorkflowOperationHandler Description The RetractEngageWorkflowOperationHandler retracts the published elements from the local Opencast Media Module. There are no configuration keys at this time. Operation Examples Retract <!-- Retract from engage player --> <operation id=\"retract-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from Engage\"> </operation>","title":"Retract Engage"},{"location":"workflowoperationhandlers/retract-engage-woh/#retractengageworkflowoperationhandler","text":"","title":"RetractEngageWorkflowOperationHandler"},{"location":"workflowoperationhandlers/retract-engage-woh/#description","text":"The RetractEngageWorkflowOperationHandler retracts the published elements from the local Opencast Media Module. There are no configuration keys at this time.","title":"Description"},{"location":"workflowoperationhandlers/retract-engage-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-engage-woh/#retract","text":"<!-- Retract from engage player --> <operation id=\"retract-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from Engage\"> </operation>","title":"Retract"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/","text":"RetractOaiPmhWorkflowOperation Description The Retract OAI-PMH workflow operation retracts the published elements from a OAI-PMH repository. Parameter Table Configuration Keys Description repository The name of the OAI-PMH repository where the media should be retracted from Operation Examples <operation id=\"retract-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Retract event from the OAI-PMH repository\"> <configurations> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Retract OAI-PMH"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#retractoaipmhworkflowoperation","text":"","title":"RetractOaiPmhWorkflowOperation"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#description","text":"The Retract OAI-PMH workflow operation retracts the published elements from a OAI-PMH repository.","title":"Description"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#parameter-table","text":"Configuration Keys Description repository The name of the OAI-PMH repository where the media should be retracted from","title":"Parameter Table"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#operation-examples","text":"<operation id=\"retract-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Retract event from the OAI-PMH repository\"> <configurations> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-partial-woh/","text":"Partial Retract Engage Workflow Operation ID: retract-partial Description The partial retract engage operation retracts a subset of the published elements from the search service. This is useful to e.g. remove incorrect captions without reprocessing the entire workflow. The elements selected for retraction match any combination of flavor or tag, and the resulting publication may become unusable if you accidentally retract one or more delivery files. Use this operation with caution. Parameter Table configuration keys description retract-flavors Which flavor(s) to retract. Use a comma to separate multiple flavors. retract-tags Which tags(s) to retract. Use a comma to separate multiple tags. Operation Example <operation id=\"retract-partial\" description=\"Retracting elements flavored with presentation and tagged with preview from Engage\"> <configurations> <configuration key=\"retract-flavors\">presentation/*</configuration> <configuration key=\"retract-tags\">preview</configuration> </configurations> </operation>","title":"Retract Partial"},{"location":"workflowoperationhandlers/retract-partial-woh/#partial-retract-engage-workflow-operation","text":"ID: retract-partial","title":"Partial Retract Engage Workflow Operation"},{"location":"workflowoperationhandlers/retract-partial-woh/#description","text":"The partial retract engage operation retracts a subset of the published elements from the search service. This is useful to e.g. remove incorrect captions without reprocessing the entire workflow. The elements selected for retraction match any combination of flavor or tag, and the resulting publication may become unusable if you accidentally retract one or more delivery files. Use this operation with caution.","title":"Description"},{"location":"workflowoperationhandlers/retract-partial-woh/#parameter-table","text":"configuration keys description retract-flavors Which flavor(s) to retract. Use a comma to separate multiple flavors. retract-tags Which tags(s) to retract. Use a comma to separate multiple tags.","title":"Parameter Table"},{"location":"workflowoperationhandlers/retract-partial-woh/#operation-example","text":"<operation id=\"retract-partial\" description=\"Retracting elements flavored with presentation and tagged with preview from Engage\"> <configurations> <configuration key=\"retract-flavors\">presentation/*</configuration> <configuration key=\"retract-tags\">preview</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/retract-youtube-woh/","text":"RetractYoutubeWorkflowOperation Description The RetractYoutubeWorkflowOperationHandler retracts the published elements from YouTube. There are no configuration keys at this time. Operation Example <operation id=\"retract-youtube\" fail-on-error=\"true\" exception-handler-workflow=\"ng-partial-error\" description=\"Retract recording from YouTube\"> </operation>","title":"Retract YouTube"},{"location":"workflowoperationhandlers/retract-youtube-woh/#retractyoutubeworkflowoperation","text":"","title":"RetractYoutubeWorkflowOperation"},{"location":"workflowoperationhandlers/retract-youtube-woh/#description","text":"The RetractYoutubeWorkflowOperationHandler retracts the published elements from YouTube. There are no configuration keys at this time.","title":"Description"},{"location":"workflowoperationhandlers/retract-youtube-woh/#operation-example","text":"<operation id=\"retract-youtube\" fail-on-error=\"true\" exception-handler-workflow=\"ng-partial-error\" description=\"Retract recording from YouTube\"> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/retry-strategies/","text":"Retry Strategies An operation can have a retry-strategy specified to define what will happen if the operation fails : Strategy Description none This is the default. No action taken. If the operation fails, the behavior will depend on the fail-on-error parameter. If fail-on-error=\"true\", the workflow will fail. If fail-on-error=\"false\", the next operation will be executed. retry If the operation fails, it will be re-tried until the number of attempts reaches max-attempts, which defaults to 2. hold If the operation fails, the workflow will be paused, until the user takes an action. The user can choose to Retry the operation or Abort it. The user can retry the operation many times, until the number of attempts reaches max-attempts. If the user aborts the operation, the behavior will depend on the fail-on-error parameter as described above. Example 1 : No retry If the operation1 fails, the workflow will fail because fail-on-error=\"true\". <operation id=\"operation1\" retry-strategy=\"none\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation One\"> </operation> Example 2 : Automatic retry If operation2 fails, it will be retried until it succeeds or until it has failed 5 times. <operation id=\"operation2\" retry-strategy=\"retry\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Two\"> </operation> Example 3 : Manual retry If operation3 fails, the user can choose between Retry or Abort. The user can manually retry the operation 4 times. <operation id=\"operation3\" retry-strategy=\"hold\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Three\"> </operation>","title":"Retry Strategies"},{"location":"workflowoperationhandlers/retry-strategies/#retry-strategies","text":"An operation can have a retry-strategy specified to define what will happen if the operation fails : Strategy Description none This is the default. No action taken. If the operation fails, the behavior will depend on the fail-on-error parameter. If fail-on-error=\"true\", the workflow will fail. If fail-on-error=\"false\", the next operation will be executed. retry If the operation fails, it will be re-tried until the number of attempts reaches max-attempts, which defaults to 2. hold If the operation fails, the workflow will be paused, until the user takes an action. The user can choose to Retry the operation or Abort it. The user can retry the operation many times, until the number of attempts reaches max-attempts. If the user aborts the operation, the behavior will depend on the fail-on-error parameter as described above. Example 1 : No retry If the operation1 fails, the workflow will fail because fail-on-error=\"true\". <operation id=\"operation1\" retry-strategy=\"none\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation One\"> </operation> Example 2 : Automatic retry If operation2 fails, it will be retried until it succeeds or until it has failed 5 times. <operation id=\"operation2\" retry-strategy=\"retry\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Two\"> </operation> Example 3 : Manual retry If operation3 fails, the user can choose between Retry or Abort. The user can manually retry the operation 4 times. <operation id=\"operation3\" retry-strategy=\"hold\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Three\"> </operation>","title":"Retry Strategies"},{"location":"workflowoperationhandlers/sanitize-adaptive-woh/","text":"SanitizeAdaptiveWorkflowHandler Description The SanitizeAdaptiveWorkflowHandler is used to fix references to media files in a playlist. When files are ingested, they are put into system created and uniquely named directories. This code will attempt to match the referenced files by changing the references in the playlists. All the file names must be unique. This will allow the inspection to parse and inspect all the renditions in an adaptive playlist. Currently only HLS is supported Parameter Table configuration keys example description source-flavor presenter/work Which media should be checked target-flavor presenter/delivery Specifies the flavor of the new media target-tags sometag Specifies the tags of the new media Operation Example <operation id=\"sanitize-adaptive\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Fix uploaded HLS files \"> <configurations> <configuration key=\"source-flavor\">presenter/ingested</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">engage</configuration> </configurations> </operation>","title":"Sanitize Adaptive"},{"location":"workflowoperationhandlers/sanitize-adaptive-woh/#sanitizeadaptiveworkflowhandler","text":"","title":"SanitizeAdaptiveWorkflowHandler"},{"location":"workflowoperationhandlers/sanitize-adaptive-woh/#description","text":"The SanitizeAdaptiveWorkflowHandler is used to fix references to media files in a playlist. When files are ingested, they are put into system created and uniquely named directories. This code will attempt to match the referenced files by changing the references in the playlists. All the file names must be unique. This will allow the inspection to parse and inspect all the renditions in an adaptive playlist. Currently only HLS is supported","title":"Description"},{"location":"workflowoperationhandlers/sanitize-adaptive-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/work Which media should be checked target-flavor presenter/delivery Specifies the flavor of the new media target-tags sometag Specifies the tags of the new media","title":"Parameter Table"},{"location":"workflowoperationhandlers/sanitize-adaptive-woh/#operation-example","text":"<operation id=\"sanitize-adaptive\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Fix uploaded HLS files \"> <configurations> <configuration key=\"source-flavor\">presenter/ingested</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">engage</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/segmentpreviews-woh/","text":"SegmentpreviewsWorkflowOperation Description The SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments. Parameter Table configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. source-tags engage Specifies which media should be processed. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http The encoding profile to use. reference-flavor presentation/work Flavor of the segments to use. reference-tags engage Tags of the segments to use. Operation Example <operation id=\"segmentpreviews\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Encoding presentation (screen) to segment preview image\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presentation/segment+preview</configuration> <configuration key=\"reference-flavor\">presentation/delivery</configuration> <configuration key=\"reference-tags\">engage</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">player-slides.http</configuration> </configurations> </operation>","title":"Segment Previews"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#segmentpreviewsworkflowoperation","text":"","title":"SegmentpreviewsWorkflowOperation"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#description","text":"The SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments.","title":"Description"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. source-tags engage Specifies which media should be processed. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http The encoding profile to use. reference-flavor presentation/work Flavor of the segments to use. reference-tags engage Tags of the segments to use.","title":"Parameter Table"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#operation-example","text":"<operation id=\"segmentpreviews\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Encoding presentation (screen) to segment preview image\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presentation/segment+preview</configuration> <configuration key=\"reference-flavor\">presentation/delivery</configuration> <configuration key=\"reference-tags\">engage</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">player-slides.http</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/segmentvideo-woh/","text":"SegmentVideoWorkflowOperation Description The SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screen recording and the slides which were shown change. If both tag and flavor are used, the the element will be chosen by tag AND flavor. Parameter Table configuration keys example description source-flavor presentation/trimmed Specifies which media should be processed. source-tags tag Specifies which media should be processed by tag. Operation Example <operation id=\"segment-video\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting segments from presentation\"> <configurations> <configuration key=\"source-tags\">presentation-lowres</configuration> <configuration key=\"source-flavor\">presentation/trimmed</configuration> </configurations> </operation>","title":"Segment Video"},{"location":"workflowoperationhandlers/segmentvideo-woh/#segmentvideoworkflowoperation","text":"","title":"SegmentVideoWorkflowOperation"},{"location":"workflowoperationhandlers/segmentvideo-woh/#description","text":"The SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screen recording and the slides which were shown change. If both tag and flavor are used, the the element will be chosen by tag AND flavor.","title":"Description"},{"location":"workflowoperationhandlers/segmentvideo-woh/#parameter-table","text":"configuration keys example description source-flavor presentation/trimmed Specifies which media should be processed. source-tags tag Specifies which media should be processed by tag.","title":"Parameter Table"},{"location":"workflowoperationhandlers/segmentvideo-woh/#operation-example","text":"<operation id=\"segment-video\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting segments from presentation\"> <configurations> <configuration key=\"source-tags\">presentation-lowres</configuration> <configuration key=\"source-flavor\">presentation/trimmed</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/select-streams-woh/","text":"SelectTracksWorkflowOperationHandler Description The SelectTracksWorkflowOperationHandler can be used in case not all source tracks should be processed. For example, given a recording with a presenter and a presentation track, the final recording to be published should only include the video stream of the presenter track and the audio stream of the presentation track. The workflow operation will use workflow properties set by the Opencast video editor to determine which tracks should be selected for further processing and add them to the media package based on target-flavor and target-tags . IMPORTANT: The input tracks need to be inspected using the workflow operation inspect before running this operation. Parameter Table Configuration Key Example Description source-flavor* */source The flavor of the track(s) to use as a source input target-flavor* */work The flavor of the target track(s) target-tags download The tags applied to all target tracks audio-muxing force Move single-audio media packages to a specific track (see below) force-target presenter Target track for the force setting for audio-muxing * mandatory configuration key Workflow Properties The names of the workflow properties that control which streams are included in the output tracks are \"hide_\" + source-flavor.type + \"_audio\" \"hide_\" + source-flavor.type + \"_video\" Example: For the source flavor presenter/work , use the boolean workflow properties hide_presenter_audio and hide_presenter_video to control which streams should be included in the output tracks. Those properties are set by the Opencast video editor and can also be set using a custom workflow configuration panel. Audio Muxing The optional audio-muxing parameter has three possible values: none (same as omitting the option), force and duplicate . none If none is specified or the option is omitted, the audio stream is taken from the specified source-flavor track and is edited according to the selections in video editor\u2019s \u201cTracks\u201d panel. The resulting tracks are stored in the corresponding target-flavor and target-tags are applied. Note: If your editing results in a single video and single audio (track/stream) they will be muxed together even if this option is set to none . force The parameter value force only applies to media packages that have exactly one non-hidden audio stream. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted. The same applies to media packages for which there is only one audio stream, and it already belongs to the track with flavor type given by force-target (or presenter if that parameter is omitted). If, however, there is only one non-hidden audio stream and it does not belong to the track given by force-target , then the WOH will \u201cmove\u201d the audio stream to this target track. Specifically, it will mux the video stream of force-target with the audio stream it found. Then, it removes the audio stream from the original track. For example, consider a media package with two tracks, presenter and presentation . Both of these tracks have audio components, however the presenter audio stream is hidden. This WOH will mux presentations 's audio stream with presenter 's video, and remove the audio track from presentation 's video. duplicate The parameter value duplicate only applies to media packages that have exactly one non-hidden audio stream and no hidden video streams. For these media packages, the WOH will mux the audio stream it found to all video streams in the media package. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted. Encoding Profiles This workflow operation handler depends on the presence of the following encoding profiles: Name Description video-only.work Removes all audio streams from a media track audio-only.work Removes all video streams from a media track mux-av.work Mux a video stream and an audio stream into a media track Note that those encoding profiles are included in the default configuration of Opencast. Operation Example <operation id=\"select-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Select tracks for further processing\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">*/work</configuration> <configuration key=\"audio-muxing\">force</configuration> </configurations> </operation>","title":"Select Streams"},{"location":"workflowoperationhandlers/select-streams-woh/#selecttracksworkflowoperationhandler","text":"","title":"SelectTracksWorkflowOperationHandler"},{"location":"workflowoperationhandlers/select-streams-woh/#description","text":"The SelectTracksWorkflowOperationHandler can be used in case not all source tracks should be processed. For example, given a recording with a presenter and a presentation track, the final recording to be published should only include the video stream of the presenter track and the audio stream of the presentation track. The workflow operation will use workflow properties set by the Opencast video editor to determine which tracks should be selected for further processing and add them to the media package based on target-flavor and target-tags . IMPORTANT: The input tracks need to be inspected using the workflow operation inspect before running this operation.","title":"Description"},{"location":"workflowoperationhandlers/select-streams-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* */source The flavor of the track(s) to use as a source input target-flavor* */work The flavor of the target track(s) target-tags download The tags applied to all target tracks audio-muxing force Move single-audio media packages to a specific track (see below) force-target presenter Target track for the force setting for audio-muxing * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/select-streams-woh/#workflow-properties","text":"The names of the workflow properties that control which streams are included in the output tracks are \"hide_\" + source-flavor.type + \"_audio\" \"hide_\" + source-flavor.type + \"_video\" Example: For the source flavor presenter/work , use the boolean workflow properties hide_presenter_audio and hide_presenter_video to control which streams should be included in the output tracks. Those properties are set by the Opencast video editor and can also be set using a custom workflow configuration panel.","title":"Workflow Properties"},{"location":"workflowoperationhandlers/select-streams-woh/#audio-muxing","text":"The optional audio-muxing parameter has three possible values: none (same as omitting the option), force and duplicate .","title":"Audio Muxing"},{"location":"workflowoperationhandlers/select-streams-woh/#none","text":"If none is specified or the option is omitted, the audio stream is taken from the specified source-flavor track and is edited according to the selections in video editor\u2019s \u201cTracks\u201d panel. The resulting tracks are stored in the corresponding target-flavor and target-tags are applied. Note: If your editing results in a single video and single audio (track/stream) they will be muxed together even if this option is set to none .","title":"none"},{"location":"workflowoperationhandlers/select-streams-woh/#force","text":"The parameter value force only applies to media packages that have exactly one non-hidden audio stream. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted. The same applies to media packages for which there is only one audio stream, and it already belongs to the track with flavor type given by force-target (or presenter if that parameter is omitted). If, however, there is only one non-hidden audio stream and it does not belong to the track given by force-target , then the WOH will \u201cmove\u201d the audio stream to this target track. Specifically, it will mux the video stream of force-target with the audio stream it found. Then, it removes the audio stream from the original track. For example, consider a media package with two tracks, presenter and presentation . Both of these tracks have audio components, however the presenter audio stream is hidden. This WOH will mux presentations 's audio stream with presenter 's video, and remove the audio track from presentation 's video.","title":"force"},{"location":"workflowoperationhandlers/select-streams-woh/#duplicate","text":"The parameter value duplicate only applies to media packages that have exactly one non-hidden audio stream and no hidden video streams. For these media packages, the WOH will mux the audio stream it found to all video streams in the media package. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted.","title":"duplicate"},{"location":"workflowoperationhandlers/select-streams-woh/#encoding-profiles","text":"This workflow operation handler depends on the presence of the following encoding profiles: Name Description video-only.work Removes all audio streams from a media track audio-only.work Removes all video streams from a media track mux-av.work Mux a video stream and an audio stream into a media track Note that those encoding profiles are included in the default configuration of Opencast.","title":"Encoding Profiles"},{"location":"workflowoperationhandlers/select-streams-woh/#operation-example","text":"<operation id=\"select-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Select tracks for further processing\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">*/work</configuration> <configuration key=\"audio-muxing\">force</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/send-email-woh/","text":"Send Email Workflow Operation ID: send-email Description The send-email operation invokes the SMTP Service to send an email with the parameters provided. It is useful to send email notifications when some operation(s) have been completed or some error(s) have occurred in a workflow. The email body, if not specified by body or body-template-file, will consist of a single line of the form: <Recording Title> (<Mediapackage ID>) . Freemarker templates can be used in the following fields to allow replacement with values obtained from the workflow or media package: to, cc, bcc, subject, and body. If body-template-file is specified, the operation will use a Freemarker template file located in <config_dir>/etc/email to generate the email body. User names can be provided in to , cc , or bcc in lieu of email addresses so that the user directory is searched and that user's email address is used (see Example 5). Parameter Table configuration keys description default value example body Email body content. Takes precedence over body-template-file. <Recording Title> (<Mediapackage ID>) Lecture 1 (4bf316fc-ea78-4903-b00e-9976b0912e4d) body-template-file Name of file that will be used as a template for the content of the email body. EMPTY templateName subject Email subject. EMPTY Operation has been completed to The field to of the email i.e. the comma separated list of email accounts the email will be sent to. EMPTY email-account@email-domain.org,second-account@second-domain.org cc The field cc of the email i.e. the comma separated list of email accounts that will receive a carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org bcc The field bcc of the email i.e. the comma separated list of email accounts that will receive a blind carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org use-html Flag to indicate that the email content should be displayed as 'text/html' false true/false address-separator Separator to use for splitting a string into separate email addresses , <tab> , skip-invalid-address If the operation should skip invalid addresses instead of failing false true/false Some other email parameters can be customized in the SMTP Service configuration Variable Substitution The template will have access to the media package, workflow instance (including its configuration properties and last failed operation), catalogs, and any incidents. Fields should be tested for null/empty values before being used. Media Package Information Use ${mediaPackage.FIELD} Examples Field How To Get It media package id ${mediaPackage.identifier} recording title ${mediaPackage.title} recording date and time ${mediaPackage.date?datetime?iso_utc} - See Freemarker manual for date manipulation (extract date only, time only, format, etc) series title ${mediaPackage.seriesTitle} series id ${mediaPackage.series} Workflow Information Use ${workflow.FIELD} Field How To Get It workflow id ${workflow.id} workflow template id ${workflow.template} workflow state ${workflow.state} workflow title ${workflow.title} workflow description ${workflow.description} id of parent workflow ${workflow.parentId} name of workflow creator ${workflow.creatorName} workflow organization ${workflow.organizationId} Note that some of these values may not exist depending on the workflow. Workflow Configuration Properties Use ${workflowConfig['PROPERTY']} Last Failed Operation Operation that caused the workflow to fail. Should be tested before accessing any of its fields: <#if failedOperation?has_content>Workflow failed in operation: ${failedOperation.template}<!--#if--> Incidents In your email template: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b}</#list> </#list> </#if> Catalog fields Use ${catalogs['SUBTYPE']['FIELD']} Examples Field How To Get It episode creator ${catalogs['episode']['creator']} episode title ${catalogs['episode']['title']} series creator ${catalogs['series']['creator']} series title ${catalogs['series']['title']} Examples Example 1 Media package title in subject field, default email body. <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user after media package is published\"> <configurations> <configuration key=\"to\">email-account@email-domain.org</configuration> <!-- This is going to be replaced with the media package title --> <configuration key=\"subject\">${mediaPackage.title} has been published</configuration> <!-- Neither body or body-template-file specified so default body <Recording Title> (<Mediapackage ID>)<br>is sent --> </configurations> </operation> Example 2 To and subject are inline templates; the email body uses a template file named sample stored in \u2026/etc/email : <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user before holding for edit\"> <configurations> <!-- This is going to be replaced with the episode catalog publisher field, which in this example it is assumed it contains a notification email address --> <configuration key=\"to\">${catalogs['episode']['publisher']}</configuration> <!-- This is going to be replaced with the episode catalog title field --> <configuration key=\"subject\">${catalogs['episode']['title']} is ready for EDIT</configuration> <!-- Email body is going to be built using the sample template found in <config_dir>/etc/email --> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation> Template: sample The contents of the \u2026/etc/email/sample email template: Event Details <#if catalogs['series']?has_content> Series Title: ${catalogs['series']['title']} Instructor: ${catalogs['series']['contributor']} </#if> Media Package Id: ${mediaPackage.identifier} Title: ${mediaPackage.title} Workflow Id: ${workflow.id} Event Date: ${mediaPackage.date?datetime?iso_local} Example 3 Email address entered via admin UI as a workflow configuration parameter: <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sends email\"> <configurations> <configuration key=\"to\">${workflowConfig['emailAddress']}</configuration> <configuration key=\"subject\">Media package has been published</configuration> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation> Workflow Configuration Panel: <configuration_panel> <![CDATA[ <!-- Add after the other configuration fields (Holds, Archive, etc) --> <fieldset> <legend>Notification</legend> <ul class=\"oc-ui-form-list\"> <li class=\"ui-helper-clearfix\"> <label class=\"scheduler-label\"> <span class=\"color-red\">* </span><span id=\"i18n_email_label\">Email Address</span>: </label> <span id=\"emailconfig\"> <input id=\"emailAddress\" name=\"emailAddress\" type=\"text\" class=\"configField\" value=\"my-email-account@my-email-domain.org\"/> </span> </li> </ul> </fieldset> <script type=\"text/javascript\"> // Add email variable var emailAddress = $('input#emailAddress'); // Register email configuration property ocWorkflowPanel.registerComponents = function(components){ /* components with keys that begin with 'org.opencastproject.workflow.config' will be passed * into the workflow. The component's nodeKey must match the components array key. * * Example:'org.opencastproject.workflow.config.myProperty' will be availible at ${my.property} */ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'] = new ocAdmin.Component( ['emailAddress'], {key: 'org.opencastproject.workflow.config.emailAddress'}, {getValue: function(){ return this.fields.emailAddress.value;} }); //etc... } ocWorkflowPanel.setComponentValues = function(values, components){ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'].setValue( values['org.opencastproject.workflow.config.emailAddress']); } </script> ]]> </configuration_panel> Example 4 In error handling workflow (email-error): <operation id=\"send-email\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Sends email\"> <configurations> <!-- Note that you can use variable substitution in to, subject, body e.g. ${(catalogs['episode']['FIELD']!'root@localhost'} --> <configuration key=\"to\">root@localhost</configuration> <configuration key=\"subject\">Failure processing a mediapackage</configuration> <configuration key=\"body-template-file\">errorDetails</configuration> </configurations> </operation> Template: errorDetails The contents of the /etc/email/errorDetails email template: Error Details <#if catalogs['series']?has_content> Course: ${catalogs['series']['subject']!'series subject missing'}-${catalogs['series']['title']!'series title missing'} Instructor: ${catalogs['series']['contributor']!'instructor missing'} </#if> Title: ${catalogs['episode']['title']!'title missing'} Event Date: ${mediaPackage.date?datetime?iso_local} <#if failedOperation?has_content> Workflow failed in operation: ${failedOperation.position}-${failedOperation.template} Started: ${failedOperation.dateStarted?datetime?iso_local} Ended: ${failedOperation.dateCompleted?datetime?iso_local} Execution Host: ${failedOperation.executionHost} </#if> Logged incident of the error looks like this: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b} </#list> </#list> </#if> Example 5 The user name is stored in the episode dublin core contributor field. There's a user jharvard with email jharvard@harvard.edu defined in the system. The message will be sent to jharvard@harvard.edu : <operation id=\"send-email\" fail-on-error=\"false\" description=\"Notify user associated to this recording that it is ready to be trimmed\"> <configurations> <configuration key=\"to\">${(catalogs['episode']['contributor'])}</configuration> <configuration key=\"subject\">Recording is ready for EDIT</configuration> <configuration key=\"body-template-file\">eventDetails</configuration> </configurations> </operation> Episode Dublin Core <?xml version=\"1.0\" encoding=\"UTF-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <dcterms:contributor>jharvard</dcterms:contributor> <dcterms:created>2018-05-01T16:14:00Z</dcterms:created> <dcterms:extent xsi:type=\"dcterms:ISO8601\">PT17M1.933S</dcterms:extent> <dcterms:isPartOf>20180229999</dcterms:isPartOf> <dcterms:spatial>classroom-20</dcterms:spatial> <dcterms:temporal>start=2018-05-01T16:14:00Z; end=2018-05-01T16:31:00Z; scheme=W3C-DTF;</dcterms:temporal> <dcterms:title>Test Lecture</dcterms:title> </dublincore> Example 6 Send an email to the user which started the workflow. Requires the user account to have a valid email address. <operation id=\"send-email\" description=\"Sending email to user after media package is published\"> <configurations> <!-- Lookup email address of the creator --> <configuration key=\"to\">${workflow.creatorName}</configuration> <configuration key=\"subject\">${mediaPackage.title} has been published</configuration> </configurations> </operation>","title":"Send Email"},{"location":"workflowoperationhandlers/send-email-woh/#send-email-workflow-operation","text":"ID: send-email","title":"Send Email Workflow Operation"},{"location":"workflowoperationhandlers/send-email-woh/#description","text":"The send-email operation invokes the SMTP Service to send an email with the parameters provided. It is useful to send email notifications when some operation(s) have been completed or some error(s) have occurred in a workflow. The email body, if not specified by body or body-template-file, will consist of a single line of the form: <Recording Title> (<Mediapackage ID>) . Freemarker templates can be used in the following fields to allow replacement with values obtained from the workflow or media package: to, cc, bcc, subject, and body. If body-template-file is specified, the operation will use a Freemarker template file located in <config_dir>/etc/email to generate the email body. User names can be provided in to , cc , or bcc in lieu of email addresses so that the user directory is searched and that user's email address is used (see Example 5).","title":"Description"},{"location":"workflowoperationhandlers/send-email-woh/#parameter-table","text":"configuration keys description default value example body Email body content. Takes precedence over body-template-file. <Recording Title> (<Mediapackage ID>) Lecture 1 (4bf316fc-ea78-4903-b00e-9976b0912e4d) body-template-file Name of file that will be used as a template for the content of the email body. EMPTY templateName subject Email subject. EMPTY Operation has been completed to The field to of the email i.e. the comma separated list of email accounts the email will be sent to. EMPTY email-account@email-domain.org,second-account@second-domain.org cc The field cc of the email i.e. the comma separated list of email accounts that will receive a carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org bcc The field bcc of the email i.e. the comma separated list of email accounts that will receive a blind carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org use-html Flag to indicate that the email content should be displayed as 'text/html' false true/false address-separator Separator to use for splitting a string into separate email addresses , <tab> , skip-invalid-address If the operation should skip invalid addresses instead of failing false true/false Some other email parameters can be customized in the SMTP Service configuration","title":"Parameter Table"},{"location":"workflowoperationhandlers/send-email-woh/#variable-substitution","text":"The template will have access to the media package, workflow instance (including its configuration properties and last failed operation), catalogs, and any incidents. Fields should be tested for null/empty values before being used.","title":"Variable Substitution"},{"location":"workflowoperationhandlers/send-email-woh/#media-package-information","text":"Use ${mediaPackage.FIELD}","title":"Media Package Information"},{"location":"workflowoperationhandlers/send-email-woh/#examples","text":"Field How To Get It media package id ${mediaPackage.identifier} recording title ${mediaPackage.title} recording date and time ${mediaPackage.date?datetime?iso_utc} - See Freemarker manual for date manipulation (extract date only, time only, format, etc) series title ${mediaPackage.seriesTitle} series id ${mediaPackage.series}","title":"Examples"},{"location":"workflowoperationhandlers/send-email-woh/#workflow-information","text":"Use ${workflow.FIELD} Field How To Get It workflow id ${workflow.id} workflow template id ${workflow.template} workflow state ${workflow.state} workflow title ${workflow.title} workflow description ${workflow.description} id of parent workflow ${workflow.parentId} name of workflow creator ${workflow.creatorName} workflow organization ${workflow.organizationId} Note that some of these values may not exist depending on the workflow.","title":"Workflow Information"},{"location":"workflowoperationhandlers/send-email-woh/#workflow-configuration-properties","text":"Use ${workflowConfig['PROPERTY']}","title":"Workflow Configuration Properties"},{"location":"workflowoperationhandlers/send-email-woh/#last-failed-operation","text":"Operation that caused the workflow to fail. Should be tested before accessing any of its fields: <#if failedOperation?has_content>Workflow failed in operation: ${failedOperation.template}<!--#if-->","title":"Last Failed Operation"},{"location":"workflowoperationhandlers/send-email-woh/#incidents","text":"In your email template: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b}</#list> </#list> </#if>","title":"Incidents"},{"location":"workflowoperationhandlers/send-email-woh/#catalog-fields","text":"Use ${catalogs['SUBTYPE']['FIELD']}","title":"Catalog fields"},{"location":"workflowoperationhandlers/send-email-woh/#examples_1","text":"Field How To Get It episode creator ${catalogs['episode']['creator']} episode title ${catalogs['episode']['title']} series creator ${catalogs['series']['creator']} series title ${catalogs['series']['title']}","title":"Examples"},{"location":"workflowoperationhandlers/send-email-woh/#examples_2","text":"","title":"Examples"},{"location":"workflowoperationhandlers/send-email-woh/#example-1","text":"Media package title in subject field, default email body. <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user after media package is published\"> <configurations> <configuration key=\"to\">email-account@email-domain.org</configuration> <!-- This is going to be replaced with the media package title --> <configuration key=\"subject\">${mediaPackage.title} has been published</configuration> <!-- Neither body or body-template-file specified so default body <Recording Title> (<Mediapackage ID>)<br>is sent --> </configurations> </operation>","title":"Example 1"},{"location":"workflowoperationhandlers/send-email-woh/#example-2","text":"To and subject are inline templates; the email body uses a template file named sample stored in \u2026/etc/email : <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user before holding for edit\"> <configurations> <!-- This is going to be replaced with the episode catalog publisher field, which in this example it is assumed it contains a notification email address --> <configuration key=\"to\">${catalogs['episode']['publisher']}</configuration> <!-- This is going to be replaced with the episode catalog title field --> <configuration key=\"subject\">${catalogs['episode']['title']} is ready for EDIT</configuration> <!-- Email body is going to be built using the sample template found in <config_dir>/etc/email --> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation>","title":"Example 2"},{"location":"workflowoperationhandlers/send-email-woh/#template-sample","text":"The contents of the \u2026/etc/email/sample email template: Event Details <#if catalogs['series']?has_content> Series Title: ${catalogs['series']['title']} Instructor: ${catalogs['series']['contributor']} </#if> Media Package Id: ${mediaPackage.identifier} Title: ${mediaPackage.title} Workflow Id: ${workflow.id} Event Date: ${mediaPackage.date?datetime?iso_local}","title":"Template: sample"},{"location":"workflowoperationhandlers/send-email-woh/#example-3","text":"Email address entered via admin UI as a workflow configuration parameter: <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sends email\"> <configurations> <configuration key=\"to\">${workflowConfig['emailAddress']}</configuration> <configuration key=\"subject\">Media package has been published</configuration> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation> Workflow Configuration Panel: <configuration_panel> <![CDATA[ <!-- Add after the other configuration fields (Holds, Archive, etc) --> <fieldset> <legend>Notification</legend> <ul class=\"oc-ui-form-list\"> <li class=\"ui-helper-clearfix\"> <label class=\"scheduler-label\"> <span class=\"color-red\">* </span><span id=\"i18n_email_label\">Email Address</span>: </label> <span id=\"emailconfig\"> <input id=\"emailAddress\" name=\"emailAddress\" type=\"text\" class=\"configField\" value=\"my-email-account@my-email-domain.org\"/> </span> </li> </ul> </fieldset> <script type=\"text/javascript\"> // Add email variable var emailAddress = $('input#emailAddress'); // Register email configuration property ocWorkflowPanel.registerComponents = function(components){ /* components with keys that begin with 'org.opencastproject.workflow.config' will be passed * into the workflow. The component's nodeKey must match the components array key. * * Example:'org.opencastproject.workflow.config.myProperty' will be availible at ${my.property} */ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'] = new ocAdmin.Component( ['emailAddress'], {key: 'org.opencastproject.workflow.config.emailAddress'}, {getValue: function(){ return this.fields.emailAddress.value;} }); //etc... } ocWorkflowPanel.setComponentValues = function(values, components){ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'].setValue( values['org.opencastproject.workflow.config.emailAddress']); } </script> ]]> </configuration_panel>","title":"Example 3"},{"location":"workflowoperationhandlers/send-email-woh/#example-4","text":"In error handling workflow (email-error): <operation id=\"send-email\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Sends email\"> <configurations> <!-- Note that you can use variable substitution in to, subject, body e.g. ${(catalogs['episode']['FIELD']!'root@localhost'} --> <configuration key=\"to\">root@localhost</configuration> <configuration key=\"subject\">Failure processing a mediapackage</configuration> <configuration key=\"body-template-file\">errorDetails</configuration> </configurations> </operation>","title":"Example 4"},{"location":"workflowoperationhandlers/send-email-woh/#template-errordetails","text":"The contents of the /etc/email/errorDetails email template: Error Details <#if catalogs['series']?has_content> Course: ${catalogs['series']['subject']!'series subject missing'}-${catalogs['series']['title']!'series title missing'} Instructor: ${catalogs['series']['contributor']!'instructor missing'} </#if> Title: ${catalogs['episode']['title']!'title missing'} Event Date: ${mediaPackage.date?datetime?iso_local} <#if failedOperation?has_content> Workflow failed in operation: ${failedOperation.position}-${failedOperation.template} Started: ${failedOperation.dateStarted?datetime?iso_local} Ended: ${failedOperation.dateCompleted?datetime?iso_local} Execution Host: ${failedOperation.executionHost} </#if> Logged incident of the error looks like this: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b} </#list> </#list> </#if>","title":"Template: errorDetails"},{"location":"workflowoperationhandlers/send-email-woh/#example-5","text":"The user name is stored in the episode dublin core contributor field. There's a user jharvard with email jharvard@harvard.edu defined in the system. The message will be sent to jharvard@harvard.edu : <operation id=\"send-email\" fail-on-error=\"false\" description=\"Notify user associated to this recording that it is ready to be trimmed\"> <configurations> <configuration key=\"to\">${(catalogs['episode']['contributor'])}</configuration> <configuration key=\"subject\">Recording is ready for EDIT</configuration> <configuration key=\"body-template-file\">eventDetails</configuration> </configurations> </operation>","title":"Example 5"},{"location":"workflowoperationhandlers/send-email-woh/#episode-dublin-core","text":"<?xml version=\"1.0\" encoding=\"UTF-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <dcterms:contributor>jharvard</dcterms:contributor> <dcterms:created>2018-05-01T16:14:00Z</dcterms:created> <dcterms:extent xsi:type=\"dcterms:ISO8601\">PT17M1.933S</dcterms:extent> <dcterms:isPartOf>20180229999</dcterms:isPartOf> <dcterms:spatial>classroom-20</dcterms:spatial> <dcterms:temporal>start=2018-05-01T16:14:00Z; end=2018-05-01T16:31:00Z; scheme=W3C-DTF;</dcterms:temporal> <dcterms:title>Test Lecture</dcterms:title> </dublincore>","title":"Episode Dublin Core"},{"location":"workflowoperationhandlers/send-email-woh/#example-6","text":"Send an email to the user which started the workflow. Requires the user account to have a valid email address. <operation id=\"send-email\" description=\"Sending email to user after media package is published\"> <configurations> <!-- Lookup email address of the creator --> <configuration key=\"to\">${workflow.creatorName}</configuration> <configuration key=\"subject\">${mediaPackage.title} has been published</configuration> </configurations> </operation>","title":"Example 6"},{"location":"workflowoperationhandlers/series-woh/","text":"SeriesWorkflowOperationHandler Description The SeriesWorkflowOperation will apply a series to the mediapackage. Parameter Table configuration keys example description default value series 0d06537e-09d3-420c-8314-a21e45c5d032 The optional series identifier. If empty the current series of the medipackage will be taken. attach creativecommons/*,dublincore/* The flavors of the series catalogs to attach to the mediapackage. apply-acl true Whether the ACL should be applied or not. false copy-metadata {http://purl.org/dc/terms/}title, isPartOf A comma-separated list of metadata fields (possibly \"expanded\") to be transferred from the series catalog to the episode catalog if they do not exist in the latter. default-namespace http://purl.org/dc/elements/1.1/ The default namespace to use when the metadata fields in the copy-metadata property are not fully \"expanded\". http://purl.org/dc/terms/ (DublinCore Term namespace) About Expanded Names Expanded names are qualified XML terms where the prefix has been expanded to the full namespace it represents. For convention, they are written as: {namespace}localname \u2026 where namespace is the full namespace (not a prefix like in XML documents) and localname is the term itself. Some examples of expanded names are: {http://purl.org/dc/terms/}title {http://mediapackage.opencastproject.org}mediapackage {}term-with-an-empty-namespace The value of the copy-metadata may contain expanded and non-expanded names. In the latter case, the names will be expanded using the provided namespace, if any, or the DublinCore namespace by default. Please note that: An empty namespace (such as in {}example ) is still a namespace. That means that the default namespace will not be substituted in this case and the term will be handled \"as-is\", i.e. with an empty namespace. Most of the terms used by Opencast belong to the DublinCore namespace, so using non-expanded names and the default namespace should be sufficient. However, custom metadata fields may be in a different namespace which must be explicitly specified. Allowed Namespaces For technical reasons, namespaces need to be pre-registered in Opencast to be used. That is why only a defined set of namespaces can be used in this operation. The allowed namespaces are: DublinCore Terms: http://purl.org/dc/terms/ DublinCore Elements 1.1: http://purl.org/dc/elements/1.1/ Opencast Properties: http://www.opencastproject.org/ Operation Examples <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">true</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">contributor, license</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">dublincore/*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">{http://purl.org/dc/terms/}contributor custom1 custom2</configuration> <configuration key=\"default-namespace\">http://www.opencastproject.org/</configuration> </configurations> </operation>","title":"Series"},{"location":"workflowoperationhandlers/series-woh/#seriesworkflowoperationhandler","text":"","title":"SeriesWorkflowOperationHandler"},{"location":"workflowoperationhandlers/series-woh/#description","text":"The SeriesWorkflowOperation will apply a series to the mediapackage.","title":"Description"},{"location":"workflowoperationhandlers/series-woh/#parameter-table","text":"configuration keys example description default value series 0d06537e-09d3-420c-8314-a21e45c5d032 The optional series identifier. If empty the current series of the medipackage will be taken. attach creativecommons/*,dublincore/* The flavors of the series catalogs to attach to the mediapackage. apply-acl true Whether the ACL should be applied or not. false copy-metadata {http://purl.org/dc/terms/}title, isPartOf A comma-separated list of metadata fields (possibly \"expanded\") to be transferred from the series catalog to the episode catalog if they do not exist in the latter. default-namespace http://purl.org/dc/elements/1.1/ The default namespace to use when the metadata fields in the copy-metadata property are not fully \"expanded\". http://purl.org/dc/terms/ (DublinCore Term namespace)","title":"Parameter Table"},{"location":"workflowoperationhandlers/series-woh/#about-expanded-names","text":"Expanded names are qualified XML terms where the prefix has been expanded to the full namespace it represents. For convention, they are written as: {namespace}localname \u2026 where namespace is the full namespace (not a prefix like in XML documents) and localname is the term itself. Some examples of expanded names are: {http://purl.org/dc/terms/}title {http://mediapackage.opencastproject.org}mediapackage {}term-with-an-empty-namespace The value of the copy-metadata may contain expanded and non-expanded names. In the latter case, the names will be expanded using the provided namespace, if any, or the DublinCore namespace by default. Please note that: An empty namespace (such as in {}example ) is still a namespace. That means that the default namespace will not be substituted in this case and the term will be handled \"as-is\", i.e. with an empty namespace. Most of the terms used by Opencast belong to the DublinCore namespace, so using non-expanded names and the default namespace should be sufficient. However, custom metadata fields may be in a different namespace which must be explicitly specified.","title":"About Expanded Names"},{"location":"workflowoperationhandlers/series-woh/#allowed-namespaces","text":"For technical reasons, namespaces need to be pre-registered in Opencast to be used. That is why only a defined set of namespaces can be used in this operation. The allowed namespaces are: DublinCore Terms: http://purl.org/dc/terms/ DublinCore Elements 1.1: http://purl.org/dc/elements/1.1/ Opencast Properties: http://www.opencastproject.org/","title":"Allowed Namespaces"},{"location":"workflowoperationhandlers/series-woh/#operation-examples","text":"<operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">true</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">contributor, license</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">dublincore/*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">{http://purl.org/dc/terms/}contributor custom1 custom2</configuration> <configuration key=\"default-namespace\">http://www.opencastproject.org/</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/silence-woh/","text":"SilenceDetectionWorkflowOperationHandler Description The silence operation performs a silence detection on an audio-only input file. Parameter Table configuration keys example description default value source-flavors */audio The input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type EMPTY reference-tracks-flavor */preview The input parameter reference-tracks-flavor is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. EMPTY smil-flavor-subtype smil The output parameter is smil-flavor-subtype which provides the modification for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. EMPTY export-segments-duration true Set this value to true and this operation will set two workflow properties for each analyzed track, the sum of duration of each non silent segment and same value in relation to the whole track length (in percent). false Workflow properties generated if export-segments-duration is set to true For each source track the silence detection will run as expected. As a result we get a list of non-silent segments. Each segment has a start and end timestamp, where we can calculate the segment duration. The sum of duration of all non-silent segments will be set as workflow property with the name <source_flavor_type>_<source_flavor_subtype>_active_audio_duration and value in seconds. The relation to the whole track length will be set with the workflow property named <source_flavor_type>_<source_flavor_subtype>_active_audio_duration_percent as percent value (0-100). Example output for an 120 minutes long presenter/source track: presenter_source_active_audio_duration = 5400 presenter_source_active_audio_duration_percent = 75 Operation Example <operation id=\"silence\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> <configuration key=\"export-segments-duration\">true</configuration> </configurations> </operation>","title":"Silence"},{"location":"workflowoperationhandlers/silence-woh/#silencedetectionworkflowoperationhandler","text":"","title":"SilenceDetectionWorkflowOperationHandler"},{"location":"workflowoperationhandlers/silence-woh/#description","text":"The silence operation performs a silence detection on an audio-only input file.","title":"Description"},{"location":"workflowoperationhandlers/silence-woh/#parameter-table","text":"configuration keys example description default value source-flavors */audio The input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type EMPTY reference-tracks-flavor */preview The input parameter reference-tracks-flavor is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. EMPTY smil-flavor-subtype smil The output parameter is smil-flavor-subtype which provides the modification for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. EMPTY export-segments-duration true Set this value to true and this operation will set two workflow properties for each analyzed track, the sum of duration of each non silent segment and same value in relation to the whole track length (in percent). false","title":"Parameter Table"},{"location":"workflowoperationhandlers/silence-woh/#workflow-properties-generated-if-export-segments-duration-is-set-to-true","text":"For each source track the silence detection will run as expected. As a result we get a list of non-silent segments. Each segment has a start and end timestamp, where we can calculate the segment duration. The sum of duration of all non-silent segments will be set as workflow property with the name <source_flavor_type>_<source_flavor_subtype>_active_audio_duration and value in seconds. The relation to the whole track length will be set with the workflow property named <source_flavor_type>_<source_flavor_subtype>_active_audio_duration_percent as percent value (0-100). Example output for an 120 minutes long presenter/source track: presenter_source_active_audio_duration = 5400 presenter_source_active_audio_duration_percent = 75","title":"Workflow properties generated if export-segments-duration is set to true"},{"location":"workflowoperationhandlers/silence-woh/#operation-example","text":"<operation id=\"silence\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> <configuration key=\"export-segments-duration\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/snapshot-woh/","text":"AssetManagerSnapshotWorkflowOperationHandler Description The snapshot operation allows you to take a new, versioned snapshot of a media package which is put into the asset manager. Parameter Table configuration keys example description source-tags text Comma separated list of tags. Specifies which media should be the source of a snapshot. source-flavors presenter/source Comma separated list of flavors. Specifies which media should be the source of a snapshot. Operation Example <operation id=\"snapshot\" description=\"Archiving\"> <configurations> <configuration key=\"source-tags\">archive</configuration> </configurations> </operation>","title":"Asset Snapshot"},{"location":"workflowoperationhandlers/snapshot-woh/#assetmanagersnapshotworkflowoperationhandler","text":"","title":"AssetManagerSnapshotWorkflowOperationHandler"},{"location":"workflowoperationhandlers/snapshot-woh/#description","text":"The snapshot operation allows you to take a new, versioned snapshot of a media package which is put into the asset manager.","title":"Description"},{"location":"workflowoperationhandlers/snapshot-woh/#parameter-table","text":"configuration keys example description source-tags text Comma separated list of tags. Specifies which media should be the source of a snapshot. source-flavors presenter/source Comma separated list of flavors. Specifies which media should be the source of a snapshot.","title":"Parameter Table"},{"location":"workflowoperationhandlers/snapshot-woh/#operation-example","text":"<operation id=\"snapshot\" description=\"Archiving\"> <configurations> <configuration key=\"source-tags\">archive</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/","text":"Start Watson Transcription Description The Start Watson Transcription invokes the IBM Watson Speech-to-Text service, passing an audio file to be translated to text. Parameter Table configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript-audio skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. false captions/vtt+en One of source-flavor or source-tag must be specified. Example <!-- Extract audio from video in ogg/opus format --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Encoding profile used in example above profile.audio-opus.name = audio-opus profile.audio-opus.input = stream profile.audio-opus.output = audio profile.audio-opus.suffix = -audio.opus profile.audio-opus.ffmpeg.command = -i /#{in.video.path} -c:a libvorbis -ac 1 -ar 16k -b:a 64k #{out.dir}/#{out.name}#{out.suffix}","title":"Start Watson Transcription"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#start-watson-transcription","text":"","title":"Start Watson Transcription"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#description","text":"The Start Watson Transcription invokes the IBM Watson Speech-to-Text service, passing an audio file to be translated to text.","title":"Description"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#parameter-table","text":"configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript-audio skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. false captions/vtt+en One of source-flavor or source-tag must be specified.","title":"Parameter Table"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#example","text":"<!-- Extract audio from video in ogg/opus format --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#encoding-profile-used-in-example-above","text":"profile.audio-opus.name = audio-opus profile.audio-opus.input = stream profile.audio-opus.output = audio profile.audio-opus.suffix = -audio.opus profile.audio-opus.ffmpeg.command = -i /#{in.video.path} -c:a libvorbis -ac 1 -ar 16k -b:a 64k #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding profile used in example above"},{"location":"workflowoperationhandlers/start-workflow-woh/","text":"StartWorkflowWorkflowOperationHandler Description The StartWorkflowWorkflowOperationHandler can be used to start a new workflow for given media package and workflow definition. Parameter Table Configuration Key Example Description media-package* e72f2265-472a-49ae-bc04-8301d94b4b1a The ID of the media package that should be used workflow-definition* fast The workflow definition that should be used configProperty abc / false Workflow configuration property * mandatory configuration key Operation Example <operation id=\"start-workflow\"> <configurations> <configuration key=\"workflow-definition\">fast</configuration> <configuration key=\"media-package\">e72f2265-472a-49ae-bc04-8301d94b4b1a</configuration> <configuration key=\"key\">value</configuration> <configuration key=\"publish\">true</configuration> </configurations> </operation>","title":"Start Workflow"},{"location":"workflowoperationhandlers/start-workflow-woh/#startworkflowworkflowoperationhandler","text":"","title":"StartWorkflowWorkflowOperationHandler"},{"location":"workflowoperationhandlers/start-workflow-woh/#description","text":"The StartWorkflowWorkflowOperationHandler can be used to start a new workflow for given media package and workflow definition.","title":"Description"},{"location":"workflowoperationhandlers/start-workflow-woh/#parameter-table","text":"Configuration Key Example Description media-package* e72f2265-472a-49ae-bc04-8301d94b4b1a The ID of the media package that should be used workflow-definition* fast The workflow definition that should be used configProperty abc / false Workflow configuration property * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/start-workflow-woh/#operation-example","text":"<operation id=\"start-workflow\"> <configurations> <configuration key=\"workflow-definition\">fast</configuration> <configuration key=\"media-package\">e72f2265-472a-49ae-bc04-8301d94b4b1a</configuration> <configuration key=\"key\">value</configuration> <configuration key=\"publish\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/statistics-writer/","text":"Statistics Writer Workflow Operation ID: statistics-writer Description The statistics writer operation can be used to publish statistics about a video to a statistics backend such as InfluxDB. Currently, it only writes the length of the video in seconds to the data base. It can be configured to write the negative length and can thus be used for retract workflows, too. Parameter Table configuration keys required description flavor yes The flavor of the track you want to publish statistics about measurement-name yes Measurement name in the statistics DB organization-resource-id-name yes Resource ID name for the organization length-field-name yes Field name for the length of the video temporal-resolution yes Temporal resolution to store the length in * retention-policy no Retention policy to use for the statistics DB retract no Whether to publish positive or negative numbers (default: false ) * Possible values are milliseconds , seconds , minutes , hours , days Operation Examples <operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"retention-policy\">infinite</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation>","title":"Statistics Writer"},{"location":"workflowoperationhandlers/statistics-writer/#statistics-writer-workflow-operation","text":"ID: statistics-writer","title":"Statistics Writer Workflow Operation"},{"location":"workflowoperationhandlers/statistics-writer/#description","text":"The statistics writer operation can be used to publish statistics about a video to a statistics backend such as InfluxDB. Currently, it only writes the length of the video in seconds to the data base. It can be configured to write the negative length and can thus be used for retract workflows, too.","title":"Description"},{"location":"workflowoperationhandlers/statistics-writer/#parameter-table","text":"configuration keys required description flavor yes The flavor of the track you want to publish statistics about measurement-name yes Measurement name in the statistics DB organization-resource-id-name yes Resource ID name for the organization length-field-name yes Field name for the length of the video temporal-resolution yes Temporal resolution to store the length in * retention-policy no Retention policy to use for the statistics DB retract no Whether to publish positive or negative numbers (default: false ) * Possible values are milliseconds , seconds , minutes , hours , days","title":"Parameter Table"},{"location":"workflowoperationhandlers/statistics-writer/#operation-examples","text":"<operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"retention-policy\">infinite</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/","text":"TagByDCTermWorkflowOperationHandler Description With the TagByDCTermWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to pick elements like the Dublin Core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on or even an application that harvests the mediapackage from a publication channel. In combination with ConfigureByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin core catalogs. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value\" \"Anon\" the implied value if the dublincore term is not present in the catalog EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE Note: see TagWorkflowOperationHandler for further explanation of the source/target-flavor/tags dccatalog The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series . dcterm The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog. match-value The value of the dcterm which to match against. The comparison is case sensitive. default-value If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not tag anything. If default-value is specified the operation will compare the match-value to the default-value and apply the tags if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled . Operation Example <operation id=\"tag-by-dcterm\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements according to dcterm\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">learning-difficulties</configuration> <configuration key=\"default-value\">all-enrolled</confiuration> <configuration key=\"target-tags\">+publishBeforeEditing</configuration> </configurations> </operation>","title":"Tag-By-DCTerm"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#tagbydctermworkflowoperationhandler","text":"","title":"TagByDCTermWorkflowOperationHandler"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#description","text":"With the TagByDCTermWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to pick elements like the Dublin Core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on or even an application that harvests the mediapackage from a publication channel. In combination with ConfigureByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin core catalogs.","title":"Description"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value\" \"Anon\" the implied value if the dublincore term is not present in the catalog EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE Note: see TagWorkflowOperationHandler for further explanation of the source/target-flavor/tags","title":"Parameter Table"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#dccatalog","text":"The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series .","title":"dccatalog"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#dcterm","text":"The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog.","title":"dcterm"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#match-value","text":"The value of the dcterm which to match against. The comparison is case sensitive.","title":"match-value"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#default-value","text":"If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not tag anything. If default-value is specified the operation will compare the match-value to the default-value and apply the tags if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled .","title":"default-value"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#operation-example","text":"<operation id=\"tag-by-dcterm\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements according to dcterm\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">learning-difficulties</configuration> <configuration key=\"default-value\">all-enrolled</confiuration> <configuration key=\"target-tags\">+publishBeforeEditing</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/tag-woh/","text":"TagWorkflowOperation Description With the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor. So for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE Target Tags Example Target-Tags Preexisting Tags Resulting Tags rss engage rss +rss engage engage,rss -rss engage,rss engage tagged,+rss engage tagged -rss,+tagged engage,rss engage,tagged Operation Example <operation id=\"tag\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements\"> <configurations> <configuration key=\"source-tags\">engage,atom,publish</configuration> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-tags\">-atom,+rss</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> <configuration key=\"copy\">true</configuration> </configurations> </operation>","title":"Tag"},{"location":"workflowoperationhandlers/tag-woh/#tagworkflowoperation","text":"","title":"TagWorkflowOperation"},{"location":"workflowoperationhandlers/tag-woh/#description","text":"With the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor. So for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on.","title":"Description"},{"location":"workflowoperationhandlers/tag-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE","title":"Parameter Table"},{"location":"workflowoperationhandlers/tag-woh/#target-tags-example","text":"Target-Tags Preexisting Tags Resulting Tags rss engage rss +rss engage engage,rss -rss engage,rss engage tagged,+rss engage tagged -rss,+tagged engage,rss engage,tagged","title":"Target Tags Example"},{"location":"workflowoperationhandlers/tag-woh/#operation-example","text":"<operation id=\"tag\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements\"> <configurations> <configuration key=\"source-tags\">engage,atom,publish</configuration> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-tags\">-atom,+rss</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> <configuration key=\"copy\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/theme-woh/","text":"ThemeWorkflowOperationHandler Description The ThemeWorkflowOperation loads workflow properties and adds elements to the media package if available. This information can be used within workflow definitions to actually implement themes. Bumpers The property theme_bumper_active indicates whether the theme defines a bumper video. If true, the bumper video is added to the media package with the flavor bumper-flavor and/or tags bumper-tags . Trailers The property theme_trailer_active indicates whether the theme defines a trailer video. If true, the trailer video is added to the media package with the flavor trailer-flavor and/or tags trailer-tags . Title Slide The property theme_title_slide_active indicates whether the theme defines a title slide. Additionally, the property theme_title_slide_uploaded indicates whether the image needed as background for the generation of the title slide should be extracted from a video track or has been uploaded. In the later case, the background image is added to the media package with the flavor title-slide-flavor and/or tags title-slide-tags . Watermark The property theme_watermark_active indicates whether the theme defines a watermark. If true, the watermark image is added to the media package with the flavor watermark-flavor and/or tags watermark-tags . Additionally, a watermark layout compatible to the CompositeWorkflowOperation is added as property watermark_layout_variable*. Workflow Properties The ThemeWorkflowOperation will set the following workflow properties: Property Name Description theme_active true if the theme has active settings, false or undefined otherwise theme_bumper_active true if the theme has an active bumper video, false otherwise theme_trailer_active true if the theme has an active trailer video, false otherwise theme_title_slide_active true if the theme has an active title slide, false otherwise theme_title_slide_uploaded true if the theme come with an uploaded title slide, false otherwise theme_watermark_active true if the theme has an active watermark, false otherwise Note: The property theme_active can be used to test whether a theme has any active settings, i.e. at least one of the properties theme_*_active is true. Parameter Table Configuration Keys Example Description *bumper-flavor branding/bumper Flavor of the bumper video *bumper-tags bumper Tags of of the bumper video *trailer-flavor branding/trailer Flavor of the trailer video *trailer-tags trailer Tags of the trailer video *title-slide-flavor branding/titleslide Flavor of the title slide image *title-slide-tags titleslide Tags of the title slide image *watermark-flavor branding/watermark Flavor of the watermark image *watermark-tags watermark Tags of the watermark image *watermark-layout-variable theme_watermark_layout Variable that will hold the watermark layout * Mandatory configuration key (in case the feature is active) Operation Example <operation id=\"theme\" exception-handler-workflow=\"partial-error\" description=\"Apply the theme\"> <configurations> <configuration key=\"bumper-flavor\">branding/bumper</configuration> <configuration key=\"bumper-tags\">archive</configuration> <configuration key=\"trailer-flavor\">branding/trailer</configuration> <configuration key=\"trailer-tags\">archive</configuration> <configuration key=\"title-slide-flavor\">branding/titleslide</configuration> <configuration key=\"title-slide-tags\">archive</configuration> <configuration key=\"watermark-flavor\">branding/titleslide</configuration> <configuration key=\"watermark-tags\">archive</configuration> <configuration key=\"watermark-layout-variable\">theme_watermark_layout</configuration> </configurations> </operation>","title":"Theme"},{"location":"workflowoperationhandlers/theme-woh/#themeworkflowoperationhandler","text":"","title":"ThemeWorkflowOperationHandler"},{"location":"workflowoperationhandlers/theme-woh/#description","text":"The ThemeWorkflowOperation loads workflow properties and adds elements to the media package if available. This information can be used within workflow definitions to actually implement themes. Bumpers The property theme_bumper_active indicates whether the theme defines a bumper video. If true, the bumper video is added to the media package with the flavor bumper-flavor and/or tags bumper-tags . Trailers The property theme_trailer_active indicates whether the theme defines a trailer video. If true, the trailer video is added to the media package with the flavor trailer-flavor and/or tags trailer-tags . Title Slide The property theme_title_slide_active indicates whether the theme defines a title slide. Additionally, the property theme_title_slide_uploaded indicates whether the image needed as background for the generation of the title slide should be extracted from a video track or has been uploaded. In the later case, the background image is added to the media package with the flavor title-slide-flavor and/or tags title-slide-tags . Watermark The property theme_watermark_active indicates whether the theme defines a watermark. If true, the watermark image is added to the media package with the flavor watermark-flavor and/or tags watermark-tags . Additionally, a watermark layout compatible to the CompositeWorkflowOperation is added as property watermark_layout_variable*.","title":"Description"},{"location":"workflowoperationhandlers/theme-woh/#workflow-properties","text":"The ThemeWorkflowOperation will set the following workflow properties: Property Name Description theme_active true if the theme has active settings, false or undefined otherwise theme_bumper_active true if the theme has an active bumper video, false otherwise theme_trailer_active true if the theme has an active trailer video, false otherwise theme_title_slide_active true if the theme has an active title slide, false otherwise theme_title_slide_uploaded true if the theme come with an uploaded title slide, false otherwise theme_watermark_active true if the theme has an active watermark, false otherwise Note: The property theme_active can be used to test whether a theme has any active settings, i.e. at least one of the properties theme_*_active is true.","title":"Workflow Properties"},{"location":"workflowoperationhandlers/theme-woh/#parameter-table","text":"Configuration Keys Example Description *bumper-flavor branding/bumper Flavor of the bumper video *bumper-tags bumper Tags of of the bumper video *trailer-flavor branding/trailer Flavor of the trailer video *trailer-tags trailer Tags of the trailer video *title-slide-flavor branding/titleslide Flavor of the title slide image *title-slide-tags titleslide Tags of the title slide image *watermark-flavor branding/watermark Flavor of the watermark image *watermark-tags watermark Tags of the watermark image *watermark-layout-variable theme_watermark_layout Variable that will hold the watermark layout * Mandatory configuration key (in case the feature is active)","title":"Parameter Table"},{"location":"workflowoperationhandlers/theme-woh/#operation-example","text":"<operation id=\"theme\" exception-handler-workflow=\"partial-error\" description=\"Apply the theme\"> <configurations> <configuration key=\"bumper-flavor\">branding/bumper</configuration> <configuration key=\"bumper-tags\">archive</configuration> <configuration key=\"trailer-flavor\">branding/trailer</configuration> <configuration key=\"trailer-tags\">archive</configuration> <configuration key=\"title-slide-flavor\">branding/titleslide</configuration> <configuration key=\"title-slide-tags\">archive</configuration> <configuration key=\"watermark-flavor\">branding/titleslide</configuration> <configuration key=\"watermark-tags\">archive</configuration> <configuration key=\"watermark-layout-variable\">theme_watermark_layout</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/timelinepreviews-woh/","text":"TimelinePreviewsWorkflowOperationHandler Description The timeline previews operation creates preview images for the given track that can be shown when hovering above the timeline. It will generate the in image-count specified number of preview images, that will all be saved in one large image file. You can use the source-flavor to specify for which video the preview images will be generated. In the engage player only the preview images of one video are shown (the first that is found), so to make sure the correct preview images are shown, better generate them only for one video. If source-flavor and source-tags are both used, and the resultant source is source-flavor AND source-tags Parameter Table configuration keys example description default value source-tags high-res Specifies which tagged media should be processed. This can be combined with flavor, so that the source is high-res AND */trimmed . EMPTY source-flavors */trimmed Specifies which media should be processed. The *-operator can be used if the preview images should be created for all flavors with a certain subtype (like \"trimmed\" in the example) Hereby you can for example choose whether you want to create the timeline preview images from a presenter or a presentation video. EMPTY target-flavor */timeline+preview Specifies the flavor the new files will get. This should use the *-operator if it was used in the source-flavor too. This flavor has to contain the words \"timeline\" and \"preview\" for the file to be found by the player. EMPTY target-tags engage-download Specifies the tags the new files will get. EMPTY image-count 100 Specifies the number of generated timeline preview images. In the example 100 timeline preview images will be generated and stored in a 10x10 grid in the output image 100 process-first-match-only true Only use the first resource that matches the source-flavor and/or target-tag false Operation Example <operation id=\"timelinepreviews\" description=\"Creating presentation timeline preview images\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/timeline+preview</configuration> <configuration key=\"target-tags\">engage-download</configuration> <configuration key=\"image-count\">100</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation>","title":"Timelinepreviews"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#timelinepreviewsworkflowoperationhandler","text":"","title":"TimelinePreviewsWorkflowOperationHandler"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#description","text":"The timeline previews operation creates preview images for the given track that can be shown when hovering above the timeline. It will generate the in image-count specified number of preview images, that will all be saved in one large image file. You can use the source-flavor to specify for which video the preview images will be generated. In the engage player only the preview images of one video are shown (the first that is found), so to make sure the correct preview images are shown, better generate them only for one video. If source-flavor and source-tags are both used, and the resultant source is source-flavor AND source-tags","title":"Description"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#parameter-table","text":"configuration keys example description default value source-tags high-res Specifies which tagged media should be processed. This can be combined with flavor, so that the source is high-res AND */trimmed . EMPTY source-flavors */trimmed Specifies which media should be processed. The *-operator can be used if the preview images should be created for all flavors with a certain subtype (like \"trimmed\" in the example) Hereby you can for example choose whether you want to create the timeline preview images from a presenter or a presentation video. EMPTY target-flavor */timeline+preview Specifies the flavor the new files will get. This should use the *-operator if it was used in the source-flavor too. This flavor has to contain the words \"timeline\" and \"preview\" for the file to be found by the player. EMPTY target-tags engage-download Specifies the tags the new files will get. EMPTY image-count 100 Specifies the number of generated timeline preview images. In the example 100 timeline preview images will be generated and stored in a 10x10 grid in the output image 100 process-first-match-only true Only use the first resource that matches the source-flavor and/or target-tag false","title":"Parameter Table"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#operation-example","text":"<operation id=\"timelinepreviews\" description=\"Creating presentation timeline preview images\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/timeline+preview</configuration> <configuration key=\"target-tags\">engage-download</configuration> <configuration key=\"image-count\">100</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/transfer-metadata-woh/","text":"Transfer Metadata Workflow Operation Description The transfer metadata operation allows to transfer arbitrary metadata fields from one metadata catalog to another one. Parameter Table configuration key example description source-flavor dublincore/episode The catalog from which the metadata is copied target-flavor myterms/episode The catalog to which the data is copied source-element {http://purl.org/dc/terms/}creator The XML element to copy target-element {http://purl.org/dc/terms/}creator The XML element to which the values are copied force false Overwrite existing targets concat , Join multiple values by set delimiter target-prefix dcterms Prefix to use for the given namespace force By default, the operation will fail if a target element already exists at the specified location. If force is set, all existing target elements will be removed before copying the new elements. concat If multiple source elements are selected (e.g. the title in multiple languages), by default, all elements are copied to the destination. The language information are preserved in this operation. If concat is defined, the value of this option will be used as a delimiter for joining all selected source elements and only ever one element will be written. All language information for this combined element will be discarded in the process. target-prefix This option lets you specify the XML namespace identifier for the target elements namespace. For example, Opencast usually uses dcterms for elements from the set of DublinCore terms, resulting in elements like <dcterms:creator> . Operation Example <operation id=\"transfer-metadata\" description=\"Transfer dcterms:creator to myterms:owner\"> <configurations> <configuration key=\"source-flavor\">dublincore/episode</configuration> <configuration key=\"target-flavor\">myterms/episode</configuration> <configuration key=\"source-element\">{http://purl.org/dc/terms/}creator</configuration> <configuration key=\"target-element\">{http://my-institution.edu/metadata}owner</configuration> <configuration key=\"force\">true</configuration> </configurations> </operation>","title":"Transfer Metadata"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#transfer-metadata-workflow-operation","text":"","title":"Transfer Metadata Workflow Operation"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#description","text":"The transfer metadata operation allows to transfer arbitrary metadata fields from one metadata catalog to another one.","title":"Description"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#parameter-table","text":"configuration key example description source-flavor dublincore/episode The catalog from which the metadata is copied target-flavor myterms/episode The catalog to which the data is copied source-element {http://purl.org/dc/terms/}creator The XML element to copy target-element {http://purl.org/dc/terms/}creator The XML element to which the values are copied force false Overwrite existing targets concat , Join multiple values by set delimiter target-prefix dcterms Prefix to use for the given namespace","title":"Parameter Table"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#force","text":"By default, the operation will fail if a target element already exists at the specified location. If force is set, all existing target elements will be removed before copying the new elements.","title":"force"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#concat","text":"If multiple source elements are selected (e.g. the title in multiple languages), by default, all elements are copied to the destination. The language information are preserved in this operation. If concat is defined, the value of this option will be used as a delimiter for joining all selected source elements and only ever one element will be written. All language information for this combined element will be discarded in the process.","title":"concat"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#target-prefix","text":"This option lets you specify the XML namespace identifier for the target elements namespace. For example, Opencast usually uses dcterms for elements from the set of DublinCore terms, resulting in elements like <dcterms:creator> .","title":"target-prefix"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#operation-example","text":"<operation id=\"transfer-metadata\" description=\"Transfer dcterms:creator to myterms:owner\"> <configurations> <configuration key=\"source-flavor\">dublincore/episode</configuration> <configuration key=\"target-flavor\">myterms/episode</configuration> <configuration key=\"source-element\">{http://purl.org/dc/terms/}creator</configuration> <configuration key=\"target-element\">{http://my-institution.edu/metadata}owner</configuration> <configuration key=\"force\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/video-grid-woh/","text":"VideoGridWorkflowOperationHandler Description The VideoGridWorkflowOperationHandler offers a way to combine several, partially simultaneously playing videos into a single video file. For example, the webcam feeds during a video conference can be combined by this WOH. The resulting video puts each input video on a grid that dynamically resizes based on the number of inputs videos currently active. Which input video is active when is defined through a SMIL catalogue from e.g. a partial ingest. If the SMIL defines a section where there are no videos active, the background color will be shown instead for the duration of the section. This also holds true for potentially empty beginning and end sections, ensuring that a final single video is as long as the overall duration defined in the SMIL (e.g. if the first input video becomes active at 30 seconds, the first generated output is a 30 second long video of the background color). The background color is also shown whenever the input videos cannot fully fill up the available space. This WOH relies on the inspect service for enriching generated, temporary video files with metadata. Furthermore, it relies on the composers concat service to combine temporary video files into a single output file. Parameter Table configuration keys example description source-flavors * presenter/source Flavors containing all the video tracks to be combined. source-smil-flavor * smil/source+partial Flavor containing the SMIL specifying when each video track is active. The example shows the flavor used by partial ingest. concat-encoding-profile * concat-samecodec.work Encoding profile used for the final concatenation. resolution 1280x720 Resolution of the output. Example value is the default. background-color 0xFFFFFF The color used to fill space not occupied by input videos in the output. Example value is the default. target-flavor * presenter/partial Flavor containing the output video tracks. target-tags archive Tag(s) to add to the output track. Default is null . * required keys Example For this example, let us assume that our source-flavor contains three videos. The SMIL file from our source-smil-flavor defines the duration for the final video as 3 (units of time). It also defines the start time and end time for each individual video, as seen below: Every time a video starts or ends, it marks the beginning of a new section. For each section, a video is generated. In our case, this happens three times, so three videos are generated. The image below shows how the videos from our source-flavor are arranged in each section. Finally, the videos for each section are combined into one final, single video file. Operation Example <operation id=\"video-grid\" description=\"Generate sections of the final video\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-smil-flavor\">smil/source+partial</configuration> <configuration key=\"target-flavor\">presenter/partial</configuration> <configuration key=\"concat-encoding-profile\">concat-samecodec.work</configuration> </configurations> </operation>","title":"Video Grid"},{"location":"workflowoperationhandlers/video-grid-woh/#videogridworkflowoperationhandler","text":"","title":"VideoGridWorkflowOperationHandler"},{"location":"workflowoperationhandlers/video-grid-woh/#description","text":"The VideoGridWorkflowOperationHandler offers a way to combine several, partially simultaneously playing videos into a single video file. For example, the webcam feeds during a video conference can be combined by this WOH. The resulting video puts each input video on a grid that dynamically resizes based on the number of inputs videos currently active. Which input video is active when is defined through a SMIL catalogue from e.g. a partial ingest. If the SMIL defines a section where there are no videos active, the background color will be shown instead for the duration of the section. This also holds true for potentially empty beginning and end sections, ensuring that a final single video is as long as the overall duration defined in the SMIL (e.g. if the first input video becomes active at 30 seconds, the first generated output is a 30 second long video of the background color). The background color is also shown whenever the input videos cannot fully fill up the available space. This WOH relies on the inspect service for enriching generated, temporary video files with metadata. Furthermore, it relies on the composers concat service to combine temporary video files into a single output file.","title":"Description"},{"location":"workflowoperationhandlers/video-grid-woh/#parameter-table","text":"configuration keys example description source-flavors * presenter/source Flavors containing all the video tracks to be combined. source-smil-flavor * smil/source+partial Flavor containing the SMIL specifying when each video track is active. The example shows the flavor used by partial ingest. concat-encoding-profile * concat-samecodec.work Encoding profile used for the final concatenation. resolution 1280x720 Resolution of the output. Example value is the default. background-color 0xFFFFFF The color used to fill space not occupied by input videos in the output. Example value is the default. target-flavor * presenter/partial Flavor containing the output video tracks. target-tags archive Tag(s) to add to the output track. Default is null . * required keys","title":"Parameter Table"},{"location":"workflowoperationhandlers/video-grid-woh/#example","text":"For this example, let us assume that our source-flavor contains three videos. The SMIL file from our source-smil-flavor defines the duration for the final video as 3 (units of time). It also defines the start time and end time for each individual video, as seen below: Every time a video starts or ends, it marks the beginning of a new section. For each section, a video is generated. In our case, this happens three times, so three videos are generated. The image below shows how the videos from our source-flavor are arranged in each section. Finally, the videos for each section are combined into one final, single video file.","title":"Example"},{"location":"workflowoperationhandlers/video-grid-woh/#operation-example","text":"<operation id=\"video-grid\" description=\"Generate sections of the final video\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-smil-flavor\">smil/source+partial</configuration> <configuration key=\"target-flavor\">presenter/partial</configuration> <configuration key=\"concat-encoding-profile\">concat-samecodec.work</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/waveform-woh/","text":"WaveformWorkflowOperationHandler Description The waveform operation creates an image showing the temporal audio activity within the recording like this: The implementation uses an FFmpeg filter that produces a waveform PNG image file from an audio/video file with at least one audio channel. Parameter Table configuration example description default source-flavors */audio Flavor specifying tracks for which a waveform should be created n/a source-tags edit Tags specifying tracks for which a waveform should be created n/a target-flavor */waveform Flavor used for the generated waveform n/a target-tags preview Comma-separated list of tags to be added to the waveform n/a pixels-per-minute 400 Width of waveform image in pixels per minute 200 min-width 10000 Minimum width of waveform image in pixels 5000 max-width 30000 Maximum width of waveform image in pixels 20000 height 60 Height of waveform image in pixels 500 color black Color of waveform image, see ffmpeg.org/ffmpeg-all.html#Color black Additional notes: All media, that match either source-flavors or source tags will be processed. Using a wildcard in the target-flavor will cause the main flavor of the input being used. Operation Example <operation id=\"waveform\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> <configuration key=\"target-tags\">preview</configuration> <configuration key=\"pixels-per-minute\">200</configuration> <configuration key=\"min-width\">5000</configuration> <configuration key=\"max-width\">20000</configuration> <configuration key=\"height\">60</configuration> <configuration key=\"color\">black</configuration> </configurations> </operation>","title":"Waveform"},{"location":"workflowoperationhandlers/waveform-woh/#waveformworkflowoperationhandler","text":"","title":"WaveformWorkflowOperationHandler"},{"location":"workflowoperationhandlers/waveform-woh/#description","text":"The waveform operation creates an image showing the temporal audio activity within the recording like this: The implementation uses an FFmpeg filter that produces a waveform PNG image file from an audio/video file with at least one audio channel.","title":"Description"},{"location":"workflowoperationhandlers/waveform-woh/#parameter-table","text":"configuration example description default source-flavors */audio Flavor specifying tracks for which a waveform should be created n/a source-tags edit Tags specifying tracks for which a waveform should be created n/a target-flavor */waveform Flavor used for the generated waveform n/a target-tags preview Comma-separated list of tags to be added to the waveform n/a pixels-per-minute 400 Width of waveform image in pixels per minute 200 min-width 10000 Minimum width of waveform image in pixels 5000 max-width 30000 Maximum width of waveform image in pixels 20000 height 60 Height of waveform image in pixels 500 color black Color of waveform image, see ffmpeg.org/ffmpeg-all.html#Color black Additional notes: All media, that match either source-flavors or source tags will be processed. Using a wildcard in the target-flavor will cause the main flavor of the input being used.","title":"Parameter Table"},{"location":"workflowoperationhandlers/waveform-woh/#operation-example","text":"<operation id=\"waveform\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> <configuration key=\"target-tags\">preview</configuration> <configuration key=\"pixels-per-minute\">200</configuration> <configuration key=\"min-width\">5000</configuration> <configuration key=\"max-width\">20000</configuration> <configuration key=\"height\">60</configuration> <configuration key=\"color\">black</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/zip-woh/","text":"ZipWorkflowOperation Description The ZipWorkflowOperationHandler creates a zip archive including all elements of the current media package that are specified in the operation configuration. It then adds the archive to the media package as an attachment with the given flavor and tags and by default stores the zip file in the working file repository's \"zip\" collection. Parameter Table configuration example description default value zip-collection zips A comma separated list of flavors to preserve from deleting zip include-flavors */source,dublincore/* Which elements to include in the archive (all) target-flavor archive/zip The flavor of the created attachment archive/zip target-tags archive The tags to apply to the attachment compression true Whether to compress the archive content flase Additional notes: The include-flavors configuration parameter accepts exact flavors like presenter/source as well as wildcard flavor definitions like */source . Usually, for media content, zip compression does not reduce the size of the archive very much but adds significant processing time. That is why activating this is usually not recommended. Operation Example <operation id=\"zip\" description=\"Creating zipped recording archive\"> <configurations> <configuration key=\"zip-collection\">failed.zips</configuration> <configuration key=\"include-flavors\">*/source,dublincore/*</configuration> <configuration key=\"target-flavor\">all/zip</configuration> <configuration key=\"compression\">false</configuration> </configurations> </operation>","title":"Zip"},{"location":"workflowoperationhandlers/zip-woh/#zipworkflowoperation","text":"","title":"ZipWorkflowOperation"},{"location":"workflowoperationhandlers/zip-woh/#description","text":"The ZipWorkflowOperationHandler creates a zip archive including all elements of the current media package that are specified in the operation configuration. It then adds the archive to the media package as an attachment with the given flavor and tags and by default stores the zip file in the working file repository's \"zip\" collection.","title":"Description"},{"location":"workflowoperationhandlers/zip-woh/#parameter-table","text":"configuration example description default value zip-collection zips A comma separated list of flavors to preserve from deleting zip include-flavors */source,dublincore/* Which elements to include in the archive (all) target-flavor archive/zip The flavor of the created attachment archive/zip target-tags archive The tags to apply to the attachment compression true Whether to compress the archive content flase Additional notes: The include-flavors configuration parameter accepts exact flavors like presenter/source as well as wildcard flavor definitions like */source . Usually, for media content, zip compression does not reduce the size of the archive very much but adds significant processing time. That is why activating this is usually not recommended.","title":"Parameter Table"},{"location":"workflowoperationhandlers/zip-woh/#operation-example","text":"<operation id=\"zip\" description=\"Creating zipped recording archive\"> <configurations> <configuration key=\"zip-collection\">failed.zips</configuration> <configuration key=\"include-flavors\">*/source,dublincore/*</configuration> <configuration key=\"target-flavor\">all/zip</configuration> <configuration key=\"compression\">false</configuration> </configurations> </operation>","title":"Operation Example"}]}